[{"content":" From: Grafana Labs 官网\n我们很高兴地宣布，Grafana Labs has been recognized as a Leader in the 2025 Gartner® Magic Quadrant™ for Observability Platforms，这是我们连续第二年获此殊荣。\n今年的报告将 Grafana Labs 定位在“愿景完整性 (Completeness of Vision)”方面最靠前的位置，我们认为这反映了我们对构建一个真正开放、可组合的可观测性（Observability）堆栈的坚定承诺，该堆栈为用户提供了灵活性、控制力以及自主制定可观测性策略的工具。\n我们为过去一年所产生的影响感到自豪，我们支持了超过 2500 万用户和 5000 多家客户，助力他们实现可观测性之旅。\n除了在魔力象限（Magic Quadrant）中的位置，Grafana Labs 还被纳入 2025 Gartner® 可观测性平台关键能力（Critical Capabilities）报告。该报告对关键用例进行了更深入的评估。我们很自豪能成为所有用例中得分最高的四家供应商之一，其中包括：\n成本优化 (4.18/5) IT 运维 (4.15/5) 平台运维 (4.15/5) 软件工程 (4.15/5) SRE (4.14/5) 业务洞察 (4.10/5) AI 工程 (3.96/5) 我们的表现和影响力 我们相信，今年在魔力象限中的排名反映了我们在开放可观测性堆栈中实现的创新所带来的实际影响。Gartner 强调了 Grafana Labs 表现突出的几个领域——特别是在成本优化和开源生态系统领导力方面。同时，我们也为过去一年中持续推出的 持续创新 和 产品更新 感到自豪。\n正如关键能力报告中所述，一个主要差异化因素是我们的 自适应遥测 (Adaptive Telemetry) 套件，它帮助客户显著降低可观测性成本——平均可节省 20% 到 50% 的指标费用和 20% 到 40% 的日志费用。这些成本效益的实现无需牺牲可见性或性能，使团队能够更可持续地扩展可观测性。\nGartner 还指出我们深度参与了开源社区，尤其是 Prometheus 和 OpenTelemetry，根据我们最近的 可观测性调研，这两个项目目前被 71% 的组织使用。我们对开放标准的承诺不仅体现在贡献上，也体现在领导力方面：我们最近 欢迎 OpenTelemetry 联合创始人 Ted Young 加入 Grafana Labs，并向 OpenTelemetry 项目 捐赠了我们的 eBPF 自动检测工具 Beyla，这进一步强化了我们致力于构建一个以互操作性 (interoperability) 和透明度 (transparency) 为常态的未来的决心。\n尽管 Gartner 的评估中没有明确提及，但我们在过去一年中推出的两项重大增强功能获得了客户的强烈积极反馈，这两项功能都旨在帮助团队更快地行动，并以更小的阻力获取洞察。\n首先，Grafana Drilldown 应用 让探索数据变得前所未有的简单，无需编写复杂的查询语句。其次，客户越来越多地采用 Grafana Cloud Asserts——我们的持续关联 (continuous correlation) 和根本原因分析 (root cause analysis) 工具。Grafana Cloud Asserts 能够自动映射你的整个技术栈中的依赖关系，持续分析信号，并呈现相关洞察，从而帮助你在问题升级前发现、理解并解决它们。\n各组织已经在使用这些工具来更智能地工作和更快地响应，我们很高兴能将这一切与 Grafana Assistant（目前处于私有预览 (private preview) 阶段）整合起来，它是一个上下文感知 (context-aware)、集成的聊天代理，可帮助用户了解 Grafana，探索和查询他们的可观测性 (observability) 数据，管理仪表盘，并进行调查——所有这些都通过自然语言 (natural language) 完成。\n用户评价 我们很荣幸被 Gartner 评为领导者，但我们最重要的反馈来自每天使用 Grafana 的用户。\n截至 2025 年 7 月 1 日，在 Gartner Peer Insights™ 上：\nGrafana Labs 的整体评分为 4.5/5 基于 268 条经过验证的客户评论 91% 的评论者表示会推荐我们的产品 以下是用户们的评价：\n“LGTM 堆栈 (LGTM stack) 在易用性和功能性方面都是最佳选择——而 Grafana Cloud 则是扩展它的最佳方式。” - 一家软件公司的工程师 “在使用我们之前的可观测性 (observability) 工具之后再用 Grafana Cloud，感觉耳目一新。它满足了我对可观测性提供商的所有期望。” - 一家软件公司的软件开发人员 “它帮助我们整合了所有不同的监控解决方案。其中的‘自适应’功能极大地节省了成本。” - Manager of IT services at a bank 我们非常感谢我们的用户和社区给予的信任、反馈和伙伴关系。可观测性的未来是开放、灵活和用户驱动的——而这仅仅是个开始。\n常见问题解答：Grafana Labs 与 2025 年 Gartner® 魔力象限™ 什么是 Gartner 魔力象限？\n魔力象限报告是在特定市场进行严谨、基于事实的研究的成果，它为高增长且供应商差异显著的市场中的供应商相对位置提供了广阔的视角。供应商被分为四个象限：领导者 (Leaders)、挑战者 (Challengers)、远见者 (Visionaries) 和特定领域者 (Niche Players)。该研究使组织能够根据其独特的业务和技术需求，最大程度地利用市场分析。\n被评为领导者意味着什么？\n领导者能够很好地执行其当前愿景，并为未来做好了充分准备。对于 Grafana Labs 而言，这验证了我们对开放性、创新以及帮助用户掌控其可观测性堆栈 (observability stack) 的承诺。\n这是 Grafana Labs 第一次获得认可吗？\n不是，这已是 Grafana Labs 连续第二年被评为领导者。\n什么是关键能力报告，Grafana Labs 的表现如何？\nGartner 可观测性平台关键能力 (Gartner Critical Capabilities for Observability Platforms) 报告提供了对供应商更深入、基于用例 (use cases) 的评估。Grafana Labs 是所有用例中得分最高的四家供应商之一，其中包括在成本优化 (Cost Optimization)（4.18/5）和平台运营 (Platform Operations)（4.15/5）中排名第三。\n客户是怎么说的？\n截至 2025 年 7 月 1 日，Grafana Labs 在 Gartner Peer Insights™ (Gartner Peer Insights™) 上的总体评分为 4.5/5，基于 268 份经过验证的客户评论，91% 的评论者推荐我们的产品。\n在哪里可以了解更多或开始使用？\n阅读完整的 Gartner 魔力象限报告 了解更多关于 Grafana Cloud 的信息 立即创建永久免费 Grafana Cloud 账户 Gartner，《可观测性平台关键能力》（Critical Capabilities for Observability Platforms），作者：Matt Crossley, Gregg Siegfried, Padraig Byrne, Andre Bridges, Martin Caren，发布日期：2025年7月8日\nGARTNER 是 Gartner, Inc. 和/或其在美国和国际上的关联公司的注册商标和服务标志，MAGIC QUADRANT 和 PEER INSIGHTS 是 Gartner, Inc. 和/或其在美国和国际上的关联公司的商标和服务标志，本文经许可使用。保留所有权利。\nGartner 不对其研究出版物中描述的任何厂商、产品或服务进行认可，也不建议技术用户仅选择那些获得最高评级或其他称号的厂商。Gartner 研究出版物包含 Gartner 研究组织的观点，不应被解释为事实陈述。Gartner 对本研究不作任何明示或暗示的保证，包括任何适销性或特定用途适用性的保证。\nGartner Peer Insights 的内容包含基于个体最终用户自身经验的观点，不应被解释为事实陈述，也不代表 Gartner 或其关联公司的观点。Gartner 不对此内容中描述的任何厂商、产品或服务进行认可，也不对该内容的准确性或完整性作任何明示或暗示的保证，包括任何适销性或特定用途适用性的保证。\n","date":"2025-08-27T10:00:00+08:00","image":"https://martinliu.cn/blog/grafana-labs-named-a-leader-again-in-the-2025-gartner-magic-quadrant-for-observability-platforms/Gartner-MQ-observability-platforms-meta_hu_dac22fd523dd071b.png","permalink":"https://martinliu.cn/blog/grafana-labs-named-a-leader-again-in-the-2025-gartner-magic-quadrant-for-observability-platforms/","title":"Grafana Labs 连续第二年荣膺 2025 年 Gartner® 可观测性平台魔力象限™ 的领导者称号"},{"content":" 作者：Zudonu Osomudeya\n我确实具备一些实打实的技能。\nTerraform：我能写模块，并且大多数时候看起来还算清晰有条理。 Kubernetes：我与集群的缠斗已经久到，连梦里都在敲 kubectl apply -f。 CI/CD：GitHub Actions 对我来说就像心情晴雨表，有时流畅，有时又不明所以地失败。 然而，问题来了：为什么我依然一无所有、默默无闻，甚至感觉自己只是在对着虚空呐喊？\n学习 ≠ 出路 我一度认为，答案可能是再多拿一张证书，或者去掌握一些没人真正用、但在简历上好看的小众工具。\n于是我陷入了无休止的循环：学习，再学习。\n可现实是：没有发生过任何改变。\n没有新工作机会 没有兼职 没有私信 猎头也视我为空气 只剩下我和终端，以及那句越来越刺耳的问题：“我到底做错了什么？”\n问题的真正根源 后来我才意识到，问题根本不在于技能，而在于：没人知道我存在。\n如果没人看到你，你就无法被雇佣。 如果没人记住你的名字，你就不会获得推荐。 DevOps 的职业发展，不可能在真空里发生。 然而，我却一直在“隐身”。\n我常常安慰自己：等我什么都懂了，再出来分享。 可事实是，在 DevOps 领域，你永远不可能什么都懂。\n今天你是 YAML 大师，明天可能就被一个缩进打回原形。\n打破沉默：从一次小小的分享开始 很长一段时间里，我都选择沉默：不发帖、不展示、不寻求帮助。\n原因只有一个——我觉得自己还没有资格。\n直到有一天，我鼓起勇气，发了一条看似微不足道的朋友圈：\n“还在学习，还在犯错，但这个集群在调试了四天之后终于能用了。DevOps 真是令人谦卑😅。”\n差点我就没点下“发布”。我担心它太傻，太微小，不够“专业”。 但结果让我意外：很多人留言分享了他们的经历。\n那一刻，我明白了：你永远不知道谁在关注你。\n真实比完美更有价值 从那之后，我不再试图“证明”自己有多聪明。 我开始选择真实地展现自己：\n分享学到的知识 偶尔发一张 YAML 崩溃的梗图 写下一篇像这样的经验分享 渐渐地，人们开始注意到我。 我并没有变成专家，我只是变得可见了。\nDevOps 不只是技术，更是个人品牌 我们谈论 DevOps 时，总是聚焦在容器和集群，但其实它还有更重要的商业层面：你需要像品牌一样去思考自己的职业发展。\nGitHub：是我的作品集 LinkedIn：是我的个人着陆页 博客/Medium：是我的产品展示 本质上，我不仅仅是一个 DevOps 工程师。 我同时也是一个“产品”，一种“服务”，一个可以被认同、被记住的“故事”。\n参与比完美更重要 是的，我依然在学习，也依然在犯错。 但我不再等待“完美”的时机。\n我理解了：\n自信不是无所不知 自信是坦然接受“不知道”，并依然选择分享和参与 给仍在犹豫的你 如果你还在等待那个“合适的时机”，去发帖、去展示、去申请机会—— 请把这段文字当作信号：\n发布那篇文章 展示那个项目 讲述你的故事 因为，你永远不知道：在某个角落，或许就有人在默默关注你，而那个人，可能就是改变你职业生涯的关键。\n写在最后 如果这篇文章让你有所共鸣，或者让你心里一笑，请点赞、评论、转发，或者关注我。 我写作的目的，是和那些同样在一次次集群崩溃与重建中成长的 DevOps 同行们建立连接。\n记住：你不仅仅是在做 DevOps，你正在创造价值。 别忘了，也要成就自己。\n","date":"2025-08-26T20:00:00+08:00","image":"https://martinliu.cn/blog/devops-wasnt-my-problem-nobody-just-knew-i-existed/1_3vFTMBRkvLlFBa3v3VukRA_hu_cb4f65a98ff8a226.png","permalink":"https://martinliu.cn/blog/devops-wasnt-my-problem-nobody-just-knew-i-existed/","title":"技能不是问题，可见性才是关键 —— 我的 DevOps 职场经验分享"},{"content":" 作者：Faruk Ahmed\n对于许多 Linux 管理员来说，使用单个 SSH 密钥对登录他们所有的服务器、测试环境或云实例是默认做法。 这种方式简单、方便——但它也是一个单点故障。\n随着时间的推移，我了解到按用途和环境分离 SSH 密钥不仅是良好的安全习惯，更是重大的安全提升。\n🛑 “一钥通吃”的风险 如果你对所有事务都使用同一个 SSH 私钥，那么一旦泄露，后果可能是灾难性的：\n笔记本电脑丢失？所有使用该密钥的服务器都将面临风险。 密钥从安全性较低的环境中被窃取？攻击者可以利用它渗透到关键系统。 需要轮换密钥？你将不得不手忙脚乱地在所有地方替换它。 这就是爆炸半径问题 (blast radius problem) 的定义。\n🧩 我如何划分密钥 我为以下用途维护单独的 SSH 密钥：\n生产环境 (Production)\n存储在硬件令牌 (hardware token) 或安全密钥保管库 (secure key vault) 中 仅用于关键服务器 绝不离开安全设备 预演/测试环境 (Staging/Test)\n与生产环境分离 存在于工作笔记本电脑上 易于替换 个人项目 (Personal Projects)\n用于家庭实验室 (home labs)、个人 VPS、树莓派 (Raspberry Pis) 绝不与工作系统混用 一次性/临时用途 (Disposable/Temporary)\n为短期项目或供应商访问创建 使用后删除 🛠 我的工作流程 密钥生成 (Key Generation)：\n1 2 3 ssh-keygen -t ed25519 -f ~/.ssh/prod_id_ed25519 -C \u0026#34;Production Key\u0026#34; ssh-keygen -t ed25519 -f ~/.ssh/staging_id_ed25519 -C \u0026#34;Staging Key\u0026#34; ssh-keygen -t ed25519 -f ~/.ssh/personal_id_ed25519 -C \u0026#34;Personal Key\u0026#34; SSH 配置示例 (~/.ssh/config)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Host prod-server-1 HostName 192.168.1.100 User admin IdentityFile ~/.ssh/prod_id_ed25519 Host staging-box-alpha HostName staging.example.com User deploy IdentityFile ~/.ssh/staging_id_ed25519 Host personal-pi HostName raspberrypi.local User pi IdentityFile ~/.ssh/personal_id_ed25519 这样，我就不必记住要使用哪个密钥——SSH 会自动选择正确的密钥。\n🧠 这种方法为何有效 限制损害 (Limits Damage) — 如果一个密钥泄露，只有该环境面临风险。 更易轮换 (Easier Rotation) — 我可以轮换单个密钥而无需触及其他密钥。 利于审计 (Audit-Friendly) — 密钥直接映射到其用途，使合规性 (compliance) 更容易。 鼓励最小权限原则 (Encourages Principle of Least Privilege) — 没有单个密钥可以访问所有内容。 📌 总结 一开始，管理多个 SSH 密钥可能感觉有些多余，但这却是最简单、最不影响效率的风险降低方法之一。\n一个密钥通吃所有事务可能很方便……直到它不再方便为止。\n扩展附录：SSH Config 常用技巧 1. 通配符与模式匹配 Host *\n匹配所有主机，可以用来定义全局默认配置。 Host *.example.com\n匹配所有 example.com 域下的主机。 Host staging-*\n匹配前缀为 staging- 的所有主机别名。 优先级：具体匹配 \u0026gt; 通配符匹配 \u0026gt; Host *。\n2. Include 指令 可以拆分配置文件，保持清晰：\n1 Include ~/.ssh/config.d/*.conf 3. JumpHost / ProxyJump 通过中间跳板机连接：\n1 2 3 4 Host prod-app HostName app.internal User deploy ProxyJump bastion.example.com 4. 端口转发 本地转发：\n1 LocalForward 8080 localhost:80 远程转发：\n1 RemoteForward 9000 localhost:9000 5. 指定端口与超时 非标准端口：\n1 Port 2222 连接保持活跃：\n1 2 ServerAliveInterval 60 ServerAliveCountMax 5 6. 多身份密钥管理 全局默认密钥：\n1 IdentityFile ~/.ssh/id_ed25519 针对特定主机指定：\n1 2 3 Host gitlab.com User git IdentityFile ~/.ssh/gitlab_id_ed25519 7. 控制连接复用 (提升速度) 避免重复握手，复用连接：\n1 2 3 4 Host * ControlMaster auto ControlPath ~/.ssh/control-%r@%h:%p ControlPersist 10m 8. 别名与简化命令 配置好 Host 别名后，可以直接：\n1 2 3 ssh prod-server-1 ssh staging-box-alpha ssh personal-pi ⚡ 这些技巧组合使用，可以大幅简化 SSH 日常管理，尤其是 多环境运维 或 开发调试 场景。\n","date":"2025-08-25T10:00:00+08:00","image":"https://martinliu.cn/blog/why-i-run-multiple-ssh-keys-instead-of-just-one/ssh-key-management-best-practices-feature_hu_5b7a96ff9e39e239.jpg","permalink":"https://martinliu.cn/blog/why-i-run-multiple-ssh-keys-instead-of-just-one/","title":"我为什么使用多个 SSH 密钥，而不是只用一个？"},{"content":" 作者：Andrey Byhalenko\nDevOps 不仅仅是工具，更是一种思维模式。了解团队如何卓越协作、重视持续改进、分担责任并乐于接受变化。深入探讨 DevOps (Development and Operations) 的核心理念，以简单易懂的方式呈现给每个人，无论其语言背景如何。\n当我开始学习 DevOps 时，我做了大多数初学者都会做的事。\n我追逐工具。\nDocker \u0026raquo; Kubernetes \u0026raquo; AWS \u0026raquo; Terraform。\n我跟着教程学习，搭建了一些宠物项目，甚至通过了几项认证。我从技术上讲会使用这些工具，但我并没有真正理解为什么要使用它们。我不知道它们究竟解决了哪些实际问题。\n在某个时刻，我碰壁了。\n然后一切都变了。\n转变 1：从以工具为导向到以解决方案为导向 有一天，我不再问： “我接下来应该学什么？” 我开始问： “我正在解决什么问题？”\n我不再试图掌握所有热门的新工具，而是设想我正在为一家真正的公司构建基础设施。是我自己的初创公司。\n从那时起，事情就豁然开朗了。\n我不再一切从工具开始。而是从需求开始，然后寻找正确的解决方案。\n例如：\n我有供给虚拟服务器的需要 → 使用 EC2 或 VMware。 我有版本控制的需要 → 使用 Git。 我有将微服务 (Microservices) 容器化的需要 → 使用 Docker 和 Docker Compose。 我有编排 (Orchestrate) 它们的需要 → 使用 Kubernetes。 我有集中式日志的需要 → 使用 ELK stack。 我有监控我的服务器的需要 → 使用 Grafana。 我使用的每个工具都成为了思考后的结果，而不是起点。\n这种思维模式让我的学习速度提升了 10 倍，也更有意义。 我不再只是练习命令。我正在解决实际的基础设施挑战。\n转变 2：从技术思维到业务思维 这个转变让我花了更长的时间才意识到。\n即使在我对工具和架构充满信心之后，我仍然缺少一些关键的东西：业务背景。\n我过去常常想，\n“这些都是最佳实践。他们为什么接受呢？”\n但现在我明白，最佳技术解决方案，并不总是对业务来说正确的解决方案。\n也许它太昂贵了。 也许它对团队来说太复杂了。 也许它解决了一个根本不存在的问题。 也许它正在制造另一个问题。 作为 DevOps 工程师，我们不仅仅是构建系统。\n我们的最终目标是用技术解决业务问题。\n第二次思维模式的转变改变了我工作的方式、思考的方式以及与团队沟通的方式。\n如果你是 DevOps 新手，请记住这一点 ✅ 工具很重要。 ✅ 教程有帮助。 ✅ 项目涨经验。\n但是，拥有正确的心态会让你比获得任何证书或 Udemy 课程走得更远。\n要着眼于解决方案，而不是工具。 要着眼于业务价值，而不仅仅是技术上的优雅。\n这才是让你成为一名真正的 DevOps 工程师 (DevOps engineer) 的关键。\n","date":"2025-08-25T10:00:00+08:00","image":"https://martinliu.cn/blog/two-mindset-shifts-that-changed-everything-for-me/1_7OnOS2Hlt5vIKFVozBhN-g_hu_3376141e7637512a.jpeg","permalink":"https://martinliu.cn/blog/two-mindset-shifts-that-changed-everything-for-me/","title":"在 DevOps 实践中的两次思维转变，彻底改变了我"},{"content":"可观测性平台正在彻底改变企业管理系统健康状况的方式，这一变革由分析技术的创新、成本优化及 AI 可观测性（AI observability）的兴起所推动。基础架构与运营（I\u0026amp;O）负责人可以借助本研究，评估供应商格局，把握不断演进的解决方案市场。\n市场定义／描述 本文于 2025 年 7 月 17 日修订。您当前查看的是更正版本。更多信息请访问 gartner.com 上的更正页面。\nGartner 将可观测性平台定义为：帮助用户了解应用、服务和基础设施的健康状况、性能及行为的产品。平台通过采集来自日志、指标、事件、追踪等多个来源的遥测数据（telemetry，运营数据），再由人工或机器智能进行分析，以识别可能影响终端用户体验的系统行为变化，如故障或性能下降。借助这些能力，团队能够及早发现甚至主动预防问题。使用这些平台的包括 IT 运维人员、站点可靠性工程师（Site Reliability Engineer） 、云与平台团队、应用开发者及产品负责人等。\n现代企业高度依赖关键的数字化应用与服务，这些系统不仅创收且面向客户，同时关系到整体业务效率。因此，系统宕机、性能下降或不稳定将直接影响收入、客户感知与品牌形象。\n组织通过可观测性平台掌握这些系统的运行状况，并持续优化其可用性、性能与弹性。投入并成功部署这类平台有助于避免营收损失，加快产品交付速度，并提升品牌形象。\n以下是可观测性平台在不同场景中的典型用途：\nIT 运维： 生产环境中的 IT 团队需确保系统在任何时刻，尤其是高负载期间，始终保持可用、高效与稳定。可观测性平台能够及时发出告警，并帮助团队深入分析数据，查明问题根源。\n平台工程： 平台工程师的使用方式融合了运维和开发两类实践。平台不仅帮助保障服务满足服务级别目标（SLO），也推动基于数据的持续改进与平台升级。\n软件开发： 开发团队将可观测性能力集成进 CI/CD 流水线，从而在代码部署后迅速获得反馈。这不仅加快了新功能的上线，也增强了系统的弹性。\n业务分析： 分析师可以利用平台追踪关键业务指标，这些指标通常具有行业或客户特定性。例如，零售商可能会关注购物车放弃成本和客户平均消费水平等数据。\n强制性功能 可观测性平台至少应具备以下能力：\n支持采集、存储和分析各类运营遥测数据，包括但不限于指标、事件、日志和追踪信息。 能识别并分析应用、服务和基础设施的行为变化，明确宕机或性能下降的根因，并量化其对终端用户体验的影响。 提供拓扑依赖、服务映射等上下文信息，以丰富遥测数据内容。 支持构建或映射被监控服务与其在业务流程中角色之间的关系。 能从主流公有云服务（如 Amazon Web Services、Microsoft Azure、Oracle Cloud Infrastructure）中采集遥测数据。 支持对追踪、指标、日志等多种遥测数据进行交互式分析，从而洞察用户和应用行为。 常见功能 在本市场中，主流可观测性平台通常具备以下特性：\n支持监控通过浏览器、移动应用及 API 提供的应用和服务的数字化用户体验。 能与其他运维、服务管理与开发工具集成，包括 IT 服务管理（ITSM）、配置管理数据库（CMDB）、事件与故障响应、编排与自动化系统，以及各类 DevOps 工具。 利用高级分析与机器学习技术，提供传统人工分析难以获得的深度洞察。 自动发现并建立基础设施、网络、应用组件与服务之间的关系映射。 提供成本管理功能，既能衡量与优化应用工作负载的成本，也可评估与优化平台自身的资源使用与开销。 支持对用户行为路径进行业务流程和活动监控，如从登录到结账、转化率漏斗分析、客户注册流程或贷款申请等。 提供 AI 可观测性能力，支持分析大语言模型（LLM）及其生成式 AI（Generative AI）负载的性能、成本、容量与合规性。 具备自动化功能，能够对应用和基础设施的代码或配置发起更改，以优化成本、容量、性能，或在出现故障与性能下降时采取修复行动。 提供应用安全功能，能识别受监控应用中的已知漏洞，并阻止相关利用行为的发生。 魔力象限 图 1: 可观测性平台魔力象限\n厂商优势与注意事项 Amazon Web Services Amazon Web Services（AWS）在本次魔力象限中被评为挑战者。其可观测性解决方案以 Amazon CloudWatch 为核心，涵盖指标、日志、事件等多类遥测数据的处理能力。AWS 还提供 AWS X-Ray（分布式追踪）、Amazon OpenSearch Service（日志分析）、Amazon Managed Service for Prometheus 和 Amazon Managed Grafana 等组件。这些服务构成 AWS Cloud Operations 体系的一部分，该体系还包含治理与财务管理功能。AWS 的客户遍布全球，从初创企业到大型机构不等，并持续稳定发布产品更新。\n优势 AI 创新： Amazon 推出 CloudWatch Investigations，帮助 SRE、IT 运维与云工程团队快速诊断和修复问题。此外，AWS 为 CloudWatch、CloudTrail、OpenSearch 和 Config 提供自然语言查询功能，降低了性能分析的门槛。 客户体验： AWS 提供业内领先的客户支持，涵盖全尺寸客户的定制化上手流程，全天候 7×24 全球支持，社区活跃，认证体系完备。 生态系统： AWS 原生工具（如 CloudWatch）与 AWS 服务深度集成，遥测数据可自动采集，配置简便；统一的控制台支持集中管理与计费，通过 IAM 实现一致的安全控制。 注意事项 多云支持： CloudWatch 主要优化于 AWS 环境。虽然 AWS 提供对 Azure 指标的有限支持，其他来源则需使用 OTel 代理、CloudWatch 代理或手动配置。用户还需关注跨环境数据传出与 AWS 数据摄取相关费用。 市场营销策略： 相较其他厂商，AWS 在可观测性方面的推广力度相对不足。可观测性并非其核心产品，市场关注度相对落后于本象限中的领导者。 成本问题： 根据客户咨询及 Peer Insights 上的反馈，CloudWatch 及相关工具的费用常被提及为痛点。由于 AWS 服务间的紧密集成，数据易被自动推送至 CloudWatch，增加了不经意的成本开销。建议客户使用 AWS Cost Explorer、AWS Budgets 等管理工具，并优化日志与追踪的摄取频率以控制支出。 Apica Apica 被评为本次魔力象限中的远见者。其可观测性平台 Apica Ascent 具备遥测数据管道功能，是其整体数据管理解决方案的重要组成部分。Apica 的业务主要集中在美国和 EMEA 地区，客户多位于北美。公司成立于 2005 年，早期专注于合成监控，并以支持多因素认证（MFA）等功能而知名。通过在 2023 年和 2024 年先后收购 LogIQ 和 Circonus，Apica 正式进军可观测性领域，并正在将其原有的合成监控能力整合至 Ascent 平台中。\n优势 易于采集接入： Apica Ascent 无需部署专属代理即可接入数据，客户可灵活使用 OpenTelemetry Collector、Fluent Bit、Logstash，甚至 Datadog Agent 等采集技术。其遥测管道产品 Flow 提供了更多数据接入与处理选项。 代理自动化管理： Apica 的代理管理系统 Fleet 基于 OpAMP 协议，可实现遥测采集器的自动部署与配置，功能强大，即使用户未采用 Ascent 的核心可观测性能力也值得单独评估。 灵活的存储选项： 对于 SaaS 用户，Apica Ascent 支持客户自定义使用对象存储，从而完全掌控数据存放位置，有助于简化合规工作并满足数据主权需求。 注意事项 功能尚不完善： 尽管平台具备 AI 可观测性等高级能力，但目前仍在演进中，尚缺少服务级别目标（SLO）管理和真实用户监控（RUM）等关键功能。 市场影响力较弱： 虽然 Apica 成立已有 20 年，但作为可观测性平台的市场认知度较低，在 Gartner 客户群体中的采用率仍有限。 公司规模偏小： 与本研究中的其他厂商相比，Apica 的整体规模较小，这在竞争激烈的市场中可能成为制约因素。 BMC Helix BMC Helix 在本次魔力象限中被评为利基厂商。其 Observability \u0026amp; AIOps 套件覆盖多项 IT 运维与可观测性能力，产品组合包括 BMC Helix Discovery 等模块。BMC Helix 还在相关的 IT 服务管理市场中占有一席之地，其产品 BMC Helix ITSM（前称 Remedy）应用广泛。公司业务遍布全球，覆盖各行业、各规模客户。2024 年 10 月，BMC 宣布将业务拆分为两家独立实体，其中一家保留 BMC 名称，另一家为 BMC Helix。本文分析仅聚焦后者的可观测性相关产品。\n优势 创新投入： BMC Helix 持续增强平台能力，在各产品中广泛嵌入 AI，例如推出用于事件调查的生成式 AI 工具 BMC HelixGPT。 全球服务能力： BMC Helix 的客户遍布全球，配备本地办事处、区域合作伙伴，并提供多样化的全球托管选项。 工具链整合能力： 尽管支持与第三方工具共存，BMC Helix 依然将自身的 ITSM、资产发现与 CMDB 功能集成到可观测性方案中，有助于客户整合运维工具链与供应商体系。 注意事项 战略转型阶段： BMC Helix 正处于从 BMC 拆分后的独立运营阶段，客户应注意此期间客户关系、支持模式等方面可能出现的调整。 市场影响力有限： BMC Helix 的市场推广主要聚焦原有客户，尚未在可观测性领域建立广泛认知，因此在 Gartner 客户提及率偏低。 产品功能不全： 相较市场领导者，BMC Helix 缺少部分关键功能，如成本控制工具有限、未支持 eBPF 等。虽然存在替代方案，但可能增加成本或影响部署效率。 Chronosphere Chronosphere 是本次魔力象限中的领导者。其平台由 Chronosphere Observability Platform 与 Telemetry Pipeline 构成，主要服务于北美客户，业务覆盖美国与 EMEA 地区。近期推出的 “Differential Diagnosis（DDx） for Traces” 功能帮助用户更快定位性能问题原因。支持指标的 DDx 功能已于 2025 年 5 月发布，日志支持与业务影响分析功能也在后续计划中。\n优势 成本控制能力强： 平台提供策略驱动的摄取、存储与保留控制，用户可精细化管理遥测数据，降低不必要的成本浪费。该功能已成为行业参考标准。 无需代理采集： 平台广泛采用 OpenTelemetry 和 Prometheus 等开放协议接入遥测数据，无需安装代理。客户可灵活选择最适合各类工作负载的接入机制。 高可用性保障： Chronosphere 为每位客户分配独立租户及私有存储资源，减少资源争抢，提升安全性，服务可用性持续达成 99.9% SLA 承诺。 注意事项 数字体验监控依赖第三方： Chronosphere 通过与 Checkly（合成监控）和 Sentry（RUM）合作实现 DEM，但遥测数据生成与集成仍需客户主导。 权限控制粒度有限： 当前平台权限模型较为粗略，不支持基于对象的职责分离。如有此需求，用户需采用多个租户或 GitOps 机制加以实现。 AI 能力未成重点： 与多数竞争对手相比，Chronosphere 在平台中未将 AI 作为主要能力强调。虽然目前未对功能完整性造成实质影响，但若企业对 AI 功能有明确需求，建议评估其他方案。 Coralogix Coralogix 被评为本次魔力象限中的远见者。其平台支持可观测性与安全相关场景，基于品牌化的数据管道架构 Streama 构建。公司业务集中于美国与 EMEA 地区，客户群主要分布在北美和 EMEA。近期推出的产品包括基于收购 Aporia 构建的 Coralogix AI 中心（AI Center）和基于 eBPF 的遥测采集代理。平台未来规划将继续强化持续分析和 AI 能力，并计划引入代理式 AI（Agentic AI）。\n优势 优化存储成本： TCO 优化器支持通过策略制定遥测数据（如日志与追踪）的分层存储与保留机制，用户甚至可使用自有 S3 存储，灵活控制性能与成本平衡。 AI 功能丰富： AI Center 提供对基于 LLM 应用的性能、安全与运行状况的监控，支持 OpenAI 与 Amazon Bedrock，涵盖 token 使用、错误率、响应质量与成本等维度。平台还内置生成式 AI 助手 Cora。 客户支持及时： Coralogix 提供 7×24 全天候产品内支持，平均响应时间仅为 17 秒，问题平均解决时间为 1 小时。客户上手流程由专属团队协助完成，确保快速启动与稳定落地。 注意事项 学习成本较高： 平台功能强大但设置繁多，新用户在熟悉过程中可能遇到学习曲线陡峭的问题。 代理管理缺失： 平台不具备统一的代理部署与生命周期管理功能，可能导致运维负担上升，限制大规模扩展。 开发集成受限： 目前尚不支持开发者在 IDE 中直接接入平台进行生产问题排查，流程依赖此能力的团队需考虑替代方案。 Datadog Datadog 是本次魔力象限的领导者之一。其可观测性平台属于一套更广泛的监控与安全产品组合。公司持续扩展全球覆盖，2023 年在日本建立数据中心，并计划于 2025 年进驻澳大利亚。2024 年推出了包括 LLM Observability（生成式 AI 可观测性）与 On-Call（事件响应管理工具）在内的新功能，并收购 Quickwit、Metaplane 和 Eppo，进一步拓展在日志优化、数据质量与产品实验分析方面的能力。\n优势 SLO 全生命周期管理： 平台支持多类型数据的服务级别目标管理，包括历史回放、误差预算告警与配置建议等，帮助用户建立稳定可靠的服务交付机制。 深入系统可视化： 广泛采用 eBPF 技术，在无需代码插桩的前提下，实现对应用与系统行为的深度监控，用于 APM 和云工作负载保护等关键场景。 产品分析能力强： 通过真实用户监控、会话重现、热力图与转化分析等功能，平台可用于产品使用行为分析与功能迭代优先级决策，超越传统健康指标监控范畴。 注意事项 授权与合同流程复杂： 随着产品线扩展，授权模型也变得复杂，合同协商与预算管理难度上升，缺乏灵活组合也限制了配置自由度。 平台成本不低： 日志与指标的摄取与保留成本是客户常提到的问题，Datadog 通过引入 Flex Logs 和“无限制”模式尝试缓解这一压力。 生态绑定强： 平台高度集成，使用门槛低但退出成本高。一旦深入使用，其与其他工具集成或替换成本将显著上升，形成潜在厂商锁定。 Dynatrace Dynatrace 是本次魔力象限中的领导者。其统一的可观测性与安全平台涵盖多个功能模块，包括基础设施与应用可观测性、应用安全与威胁监测、数字体验分析、自动化功能以及业务可观测性等。近期，Dynatrace 进一步扩展产品能力，新增成本优化与生成式 AI／大语言模型（LLM）相关的可观测性功能。公司客户遍及全球主要区域（包括拉美和亚太），以大型企业与技术密集型公司为主。最近，Dynatrace 收购了 AI 驱动的数据库可观测性平台 Metis。\n优势 产品线全面： Dynatrace 提供种类丰富的可观测性与安全解决方案，特别适用于企业级场景。其平台既支持 Kubernetes、容器、云函数、LLM 等现代架构，也兼容主机系统和 SAP 等传统企业软件。 AI 自动化与根因定位： 平台核心 AI 引擎 Davis 能自动执行根因分析和预测建模。它可智能发现并映射复杂的应用环境、检测性能异常，并实时定位问题根源，大幅减少人工介入与平均修复时间（MTTR）。此外，平台还支持基线建立、异常检测与洞察生成的全流程自动化。 强大可扩展性： Dynatrace 专为应对大型、动态的企业 IT 架构而设计，包括微服务、多云与容器环境。平台支持同时监控数万个主机与数百万依赖，适合 IT 系统庞大的组织。其高度自动化与弹性架构有助于控制现代企业环境的复杂性与规模化难题。 注意事项 授权模型较复杂： Dynatrace 的订阅授权（DPS）引入了多个新项目，相比旧模式更难理解和预算。客户应确保相关团队熟悉报告、告警与预测等功能的成本控制机制。 平台上手需引导： 功能深度和数据量庞大可能导致新用户面临学习门槛。建议组织通过厂商或可信合作伙伴提供的专业服务完成初期部署，并强化培训以提高使用效果。 中小企业适配性有限： 作为企业级全功能平台，Dynatrace 虽可通过公有云市场等方式获取，但对中小企业而言，其成本通常只能在关键系统中获得投入回报。 Elastic Elastic 在本次魔力象限中被评为领导者。其产品组合覆盖多种部署方式，包括自托管、云托管以及基于 Elastic Cloud 提供的全托管 Serverless 服务。Elastic Observability 构建于其核心平台 Search AI Platform 之上，该平台也支持 Elastic 的搜索与安全产品。Elastic Cloud 目前在主流云平台上广泛部署。公司总部位于北美，客户主要分布于美洲与 EMEA 地区。未来发展重点包括增强生成式 AI（GenAI）能力，并进一步推进 OpenTelemetry 的标准化支持。\n优势 AI 助力洞察： Elastic 的 AI 助手可通过自然语言与遥测数据交互，帮助用户快速定位问题与解决方案，降低了技术门槛。 平台能力领先： Elastic 在服务级别目标（SLO）、代理管理和数据分析等核心可观测性能力方面表现出色，有效提升 IT 运维与 SRE 团队效率。 开源平台战略清晰： Elastic 坚持开放平台战略，覆盖可观测性、安全与企业搜索领域，其差异化定位在众多厂商中极具特色。 注意事项 产品认知仍在提升： Elastic 的搜索与安全产品广为人知，但可观测性方案 Elastic Observability 的市场覆盖仍处于扩展阶段，公司正在加大市场投入。 平台使用需具备一定技术背景： 虽然托管服务降低了部署门槛，但若要发挥平台全部能力，仍需内部具备较强的技术实施能力。 定价模型复杂： Elastic Cloud 基于多维度（内存、存储、流量、功能层级）计费，随着数据量增长，成本预测难度增加。平台提供的定价工具与数据分层策略可一定程度缓解此问题。 Grafana Labs Grafana Labs 被评为本次魔力象限中的领导者。公司发源于开源项目 Grafana，并陆续推出 Loki、Tempo、Mimir、Beyla 与 Faro 等多个开源项目。其团队聚集了众多 Prometheus 与 OpenTelemetry 核心维护者。Grafana Cloud 是其核心可观测性平台，客户遍及全球，重点集中在北美与 EMEA 地区。近期更新包括统一事件响应管理与云服务可观测性支持，未来还将推出增强型根因分析与成本优化功能。\n优势 灵活的成本控制机制： Grafana Cloud 推出的 Adaptive Telemetry 功能（目前适用于日志和指标）可通过减少不必要的数据摄取来降低开销。用户可根据推荐自动执行、手动配置或设定例外。目前对追踪数据的支持已在开发中。 全球部署灵活： 平台部署于全球 25 个 AWS、Azure 和 GCP 区域，用户可根据延迟与数据主权要求选择合适位置，提升性能与合规性。 完整客户体验： Grafana Labs 提供详尽的上手支持，包括激活、迁移、架构设计与培训，并配有丰富的社区资源和官方支持选项，助力用户顺利上云。 注意事项 学习成本较高： 对缺乏 Prometheus 背景的用户来说，配置文件语法和操作模式可能较难理解，需安排必要培训。为缓解此问题，Grafana 正逐步推出预设模板支持常见场景。 文档体系不完善： 平台文档体现出开源特性，虽覆盖基础组件，但整体结构不够系统，对新手用户指导不足。 依赖社区插件存在风险： Grafana 生态构建在大量社区插件基础上，尽管提升了功能多样性，但也带来兼容性与安全风险，建议运维团队评估并纳入风控流程。 Honeycomb Honeycomb 是本次魔力象限中的远见者。其平台专注于处理高基数遥测数据（即具有大量唯一标签组合的数据），支持开放标准，面向需要实时、探索式可观测性的工程团队。虽然 Honeycomb 的客户群主要集中在北美，但自 2024 年推出欧盟 SaaS 服务以来，公司持续拓展 APAC 和 LATAM 市场。2024 年发布了多项新功能，包括 Honeycomb Telemetry Pipeline（HTP）、日志分析功能，以及前端可观测性方案。2025 年初，公司收购了开源代码分析与自动插桩引擎 Grit，标志其首次并购。\n优势 灵活的遥测数据管理： HTP 可帮助企业在不同数据源与目标间高效路由、抽样和过滤遥测数据，在扩展可观测性覆盖的同时控制成本与生命周期。 集中式代理管理： 平台利用 OpAMP 协议，实现对 OpenTelemetry Collectors 的集中部署与配置，简化大规模遥测部署的运维流程。 技术创新快速推进： 通过收购 Grit，Honeycomb 引入 AI 驱动的代码分析能力，提升代码层级的遥测集成效率，助力开发团队提升老旧代码库的可观测性。 注意事项 定价模型预测难度大： Honeycomb 采用按事件计费的方式，适合处理高基数遥测，但初期可能难以精确评估预算与使用量。 合作伙伴体系薄弱： 公司以直销为主，渠道合作较少，企业如需本地实施或第三方集成支持，可能缺乏充足选择。 AI 能力尚处追赶阶段： 虽然已有如 BubbleUp 异常检测等探索性功能，但在生成式 AI 方面仍相对滞后，目前主要功能为 Query Assistant。公司希望借助 Grit 缩小差距。 IBM IBM 是本次魔力象限的领导者之一。其可观测性平台 Instana 支持 SaaS 与自托管部署，并采用轻量的单代理架构。公司全球业务广泛，客户以大型企业为主。IBM 的产品组合覆盖从主机系统、网络（SevOne）到现代云原生架构（如容器与 Kubernetes）的可观测性需求。近期，IBM 收购了 HashiCorp 和 Kubecost，进一步加强其在自动化与 Kubernetes 成本管理领域的能力。\n优势 强大的市场执行能力： IBM 在全球市场均设有销售与支持团队，服务能力成熟。Instana 与 Apptio 和 HashiCorp 同属软件业务线，形成面向 IT 运维、自动化与 FinOps 的完整企业解决方案组合。 本地化与合规优势： IBM 的全球合作网络支持各区域客户的本地部署与合规要求，数据中心布局广泛，产品也支持多语言环境。 定价简洁透明： Instana 采用按主机计费的方式，易于理解，能随着企业规模增长平滑扩展，在成本敏感环境中具备一定优势。 注意事项 AI 产品功能相对保守： 2024 年 IBM 在 AI 方面的创新节奏慢于其他领导厂商。尽管正探索代理式能力与 AI 可观测性，但仍有较大提升空间。 中小企业关注度不足： 许多客户仍将 Instana 视为大型企业专属方案。若未使用 IBM 其他产品，中小企业接触意愿偏低。 社区活跃度有限： 虽然平台提供线上用户论坛，但整体社区互动度不如其他厂商，用户间经验交流与学习资源较为欠缺。 ITRS ITRS 是本次魔力象限中的利基厂商，其可观测性平台 ITRS Analytics 包含采集管道、分析引擎与客户访问层等核心模块，具备覆盖全面的遥测数据处理能力。公司主要业务区域为北美、欧洲和亚太。为简化遥测数据接入，ITRS 近期推出数据采集管道。未来将进一步支持服务级别目标（SLO）管理、代理集群管理与安全威胁检测功能。\n优势 灵活的定价方案： ITRS 全新定价策略提供基础版与企业版打包选择，产品形态也正从多个独立组件向统一平台转型，主要面向大型、复杂的企业 IT 环境。 极快的实时响应能力： 源于金融行业经验，ITRS 在遥测摄取与告警方面表现突出，响应时间可低至一秒以内，优于多数同类产品。 高安全性的权限管理： 平台提供细粒度、可审计的 RBAC 控制，支持按属性设定访问规则，并能对命令权限进行分区控制，为运维安全与合规提供保障。 注意事项 定价不透明： 尽管已更新为分级打包形式，但官方未公开价格信息，客户需联系销售团队才能了解成本，影响采购前期决策。 尚未支持生成式 AI： 平台目前未集成大语言模型或生成式 AI 能力，相比市场中已引入代理式 AI 的厂商存在滞后，虽已纳入产品规划，但落地时间尚未可知。 代理部署复杂： ITRS 尚不支持集中式代理部署，需依赖如 Puppet、Chef 等第三方工具进行安装，并需分别管理 NetProbe、基础设施代理与 RUM 收集器等多个代理组件，增加了运维复杂度与管理成本。 LogicMonitor LogicMonitor 被评为本次魔力象限的挑战者。其可观测性平台 LM Envision 基于本地采集器构建，支持混合架构环境，可从云、本地、SaaS 及容器中采集指标、日志、追踪与事件数据。平台引入多项生成式 AI（GenAI）功能，包括根因分析、告警聚类、基础设施智能监控（支持如 Nvidia GPU 和 OpenAI）。其客户主要分布于北美与 EMEA，并在亚太市场快速拓展。过去一年，公司陆续推出 Edwin AI（跨域事件摄取与关联）、LM Co-Pilot（AI 聊天助手）与 LM Cost Optimization（云成本优化）等新工具。\n优势 客户扩展性强： 2024 财年 LogicMonitor 实现 108% 净留存率，得益于客户快速实现平台价值、高粘性使用体验与多模块组合使用，尤其在大型企业与 MSP 客户群中增长显著。 强大的合作伙伴生态： 80% 收入来自合作伙伴通路，覆盖 SI、VAR、MSP 与技术联盟等角色。公司持续通过培训赋能、资源投入与联合市场推广计划，拓展合作广度与深度。 优秀的混合架构覆盖能力： 采用无代理采集方式，平台可同时管理传统系统与现代部署环境（如云与边缘计算），为组织提供灵活的混合 IT 管理方案，降低迁移与整合成本。 注意事项 SLI／SLO 功能仍待完善： 当前平台尚未提供统一的服务级别指标与目标管理方案，无法有效支持误差预算等 SRE 关键实践，在对可用性要求严格的场景中存在短板。 DevOps 集成覆盖有限： 当前平台对 DevOps 工具链的支持不够全面，缺少针对 CI/CD 全流程的原生功能，需通过额外工具实现功能补足。尽管有如 Ops Notes 记录变更的功能提供问题上下文，但整体仍以可观测性为主。 缺失真实用户监控（RUM）： 平台尚未提供前端性能或用户路径的可观测性功能，限制了对用户体验的深入洞察。需要此类视角的组织需额外集成 RUM 工具，或转向支持该功能的平台。 Microsoft Microsoft 被评为本次魔力象限的挑战者。其可观测性平台 Azure Monitor 是 Azure 原生监控解决方案，覆盖云、容器与基础设施层，具备良好的全球可用性。客户主要为中大型企业，地理覆盖范围广。近期更新包括：增强版 Azure Kubernetes Service 监控能力，以及 Log Analytics 的跨区域工作区复制功能。未来产品路线图将聚焦于提升 AI 驱动的可观测性能力，并进一步深化与 Microsoft Fabric 和 Microsoft Sentinel 的集成。\n优势 成熟的日志分析方案： Azure Monitor 中的 Log Analytics 功能成熟且持续进化。最新支持的 Auxiliary Logs（低成本存储层）适合低频访问日志数据，同时推出的 Simple Mode 模式让用户无需掌握 KQL 查询语言即可通过低代码方式从日志中获取洞察。 AI 能力加持： Azure Monitor 的 Application Insights 模块集成了 AI 驱动的性能优化分析，能够基于实时遥测数据识别潜在瓶颈，并推荐相应的代码改进措施。该能力可与 Azure 中的 Microsoft Copilot 搭配使用，进一步增强诊断效率。 统一的安全与运维视角： Azure Monitor 与 Microsoft 的安全工具 Sentinel 和 Defender 深度融合，使得用户可以在同一平台上实现跨运维与安全团队的事件分析、告警响应与报表生成，提升整体可视性与协同效率。 注意事项 缺乏 SLO 原生支持： Azure Monitor 尚未提供完整的 SLO 创建与监控功能，虽然可通过自定义方法实现部分能力，但配置过程复杂，难以满足 SRE 的高效实践需求。 OpenTelemetry 支持不一致： 虽然 Azure Monitor 可通过导出器支持 OTel 数据的导入，但不支持直接通过采集器接口接收 OTLP 协议，增加了数据集成复杂度。客户端可使用 Azure 提供的 OpenTelemetry Distro SDK，将数据发送至 Application Insights，但该流程仍不够直观。 长期预览功能影响生产使用： Microsoft 习惯以“公测（Preview）”形式发布新功能，部分功能预览期超过一年，虽对所有用户开放，但不提供正式支持或 SLA。Azure Monitor 中多个关键能力尚处于长期预览状态，不建议在生产环境中使用，影响企业落地信心。 New Relic New Relic 被评为本次魔力象限中的领导者。其可观测性平台功能全面，覆盖 APM、AI 监控、数字体验监控（DEM）、基础设施与安全监控，以及日志管理。客户遍布全球，以中大型企业为主。除了在北美和欧洲部署数据中心外，公司于 2024 年大幅扩展了印度的创新中心，进一步提升全球运营能力。其产品发展重点是加速代理式 AI（Agentic AI）集成，已与 ServiceNow 与 GitHub Copilot 展开深度合作。\n优势 AI 自动化战略清晰： New Relic 致力于构建基于代理的自动化编排框架。平台推出标准化 API 用于代理接入，并持续扩展专用代理库，推动跨平台的智能化自动响应能力。与 GitHub 和 ServiceNow 的合作展示了 AI 驱动工作流在实际场景中的落地前景。 产品功能不断增强： 过去一年中，New Relic 增强了 eBPF 支持、推出生成式 AI 接口的多项优化，新增 LLM 可观测性能力，并扩展成本控制工具，产品能力日益完善。 优质客户支持体验： 客户通过 Peer Insights 和咨询反馈表示，New Relic 在服务响应和技术支持方面表现优异，满意度居高。 注意事项 增长节奏放缓： 虽然 New Relic 的客户续约率持续稳定，但自从被 Francisco Partners 与 TPG 收购并私有化以来，其整体市场拓展速度相较于其他领先厂商略显保守。 遥测数据成本控制挑战： New Relic 采用按用户数与遥测摄取量计费的方式，在数据量快速增长时可能带来较高费用。公司已推出成本优化器功能，帮助用户应对突发数据峰值。 业务指标可见性不足： Pathpoint 功能可用于监控业务流程与“业务可观测性”，但目前知晓与实际使用的客户仍较少，功能价值尚未被充分利用。 Oracle Oracle 被评为本次魔力象限中的挑战者。其 可观测性与管理平台（Observability and Management, O\u0026amp;M） 提供一体化能力，涵盖应用性能监控（APM）、日志分析、数据库管理、运维洞察、漏洞检测与补丁管理等模块。平台支持跨公有云、私有云和传统数据中心环境的混合工作负载监控。Oracle 在全球多个地区设有服务节点，客户涵盖政府机构及中大型企业，行业覆盖广泛。\n优势 内建数据库漏洞检测： 平台内置数据库安全能力，可自动识别 Oracle 数据库中的配置缺陷、安全漏洞与合规风险，降低运营风险。 数据主权与区域合规优势： Oracle 在 25 个国家提供主权云部署选项，满足数据驻留、地理隔离等合规要求。可选部署形式包括欧盟主权云、美国政府云以及 OCI 专属区域，可落地至客户本地数据中心。 成熟的支持与认证体系： Oracle 提供全面的上手与支持服务，包括官方认证合作伙伴与集成商生态、面向 SRE 与 DevOps 团队的专业认证课程，以及一系列客户赋能与参与计划，帮助客户快速应用平台能力。 注意事项 生成式 AI 功能尚处初期阶段： 目前平台仅提供基础型支持助手，与同类厂商相比，在生成式 AI 功能的广度与深度上仍有差距。Oracle 计划于 2025 年推出 “可观测性助手” 功能，以补齐此短板。 缺乏业务视角下的可观测性能力： 对于关注业务连续性与服务弹性的团队而言，平台尚不支持 SLO、误差预算等 SRE 核心指标，限制其在业务层面分析与决策中的适用性。 平台依赖 OCI 战略： Oracle O\u0026amp;M 平台与其云产品（OCI）深度绑定，在 Oracle 云用户中使用体验良好，但对于构建云中立或多云可观测性平台的组织而言，其高度集成策略可能成为限制因素。 ScienceLogic ScienceLogic 被评为本次魔力象限中的远见者。其 AI 平台由四大核心模块组成：SL1（可观测性平台）、PowerFlow（代理式自动化）、RestorePoint（安全与网络合规）以及 Skylar AI（用于无监督事件分析与智能推理）。SL1 支持自托管部署，也可运行于 AWS 和 Azure 环境。客户群体主要集中于北美与 EMEA 地区。公司当前产品路线图着重发展生成式 AI（GenAI）驱动的智能分析与自动化能力。\n优势 AI 驱动的智能运维战略： ScienceLogic 以事件智能分析与 AI 能力为差异化核心，特别是 Skylar AI 模块，通过无监督学习方式实现事件识别与处理，推动智能化运维自动化。 市场执行力强： ScienceLogic 通过直销、全球系统集成商（GSI）以及多层渠道生态，成功构建了稳定的市场份额，在竞争激烈的运维管理市场中脱颖而出。 卓越的客户体验： ScienceLogic 提供全面的客户成功支持体系，包括活跃的用户社区、在线培训资源、专属客户成功经理（CSM），并通过 SL360 项目，帮助客户最大化产品价值，实现长期业务收益。 注意事项 缺少 SLO 支持机制： 平台目前不支持原生的服务级别目标（SLO）定义与可视化，限制了 SRE 团队对可靠性目标与误差预算的持续追踪与管理。 应用与开发集成能力较弱： 平台偏向基础设施监控，缺乏对代码层面的深入洞察，并在 DevOps 工具链方面的集成度不如同类产品，影响其在应用可观测性领域的覆盖深度。 全球扩展策略不均衡： 虽然在北美与 EMEA 市场表现稳定，ScienceLogic 在拉美等新兴市场的投入有限，可能因此错失地域扩张机会。 SolarWinds SolarWinds 被评为本次魔力象限的利基厂商，其可观测性平台 SolarWinds Observability 基于 SaaS 架构，支持多种部署场景。公司全球业务广泛，客户覆盖从中小型企业到大型组织。近期平台新增了 Kubernetes 自动遥测注入能力，并增强了对 AWS 的原生集成支持。未来路线图将包括事件响应系统、告警抑制引擎、自动化工作流、Runbook 触发，以及基于代理式 AI（Agentic AI）的智能操作流程。\n优势 eBPF 加持的容器可视化： 平台通过 eBPF 技术提升了对 Kubernetes 环境的深度性能分析能力，相较传统监控手段更易快速发现集群中的潜在问题。 灵活部署与透明定价： SolarWinds 支持云与本地部署混合使用，帮助企业在混合架构中灵活扩展，同时保持良好的价格透明度与竞争力。 收购 Squadcast 提升响应能力： 通过并购事件响应平台 Squadcast，SolarWinds 增强了在告警去重、MTTR 优化、工具链集成与流水线支持等方面的能力，并引入 AI 驱动的事件智能处理机制，改善整体运维效率。 注意事项 AI/ML 功能尚不完善： 当前平台仅具备基础 AI 能力，例如异常检测与查询辅助功能，在自动化决策、根因分析等方面仍与行业领先厂商存在差距。 代理统一性不足： 虽具备统一代理架构，但 APM 与 DEM 仍需额外代理模块，带来额外部署与维护成本。 DevOps 工具链支持薄弱： 平台主要支持通过 IaC 或打包方式集成遥测代理，但缺乏对 DevOps 工具链的双向通信支持，配置流程复杂，降低了与开发流程的契合度。 Splunk Splunk（现为 Cisco 旗下公司）在本次魔力象限中被评为领导者。自 2024 年 3 月被 Cisco 收购以来，Splunk 成为其专责可观测性业务的事业部。Splunk 的核心产品为 Splunk Observability Cloud，涵盖基础设施监控、应用性能管理（APM）、值班响应、合成监控、日志分析与真实用户监控（RUM），并整合了 Splunk Platform、IT 服务智能（ITSI）与 AppDynamics 等产品。公司在全球范围内建立了广泛的运营与客户基础，服务对象以大型企业为主。\n优势 全球化运营与生态支持： Cisco 与 Splunk 在全球主要市场均设有销售与服务团队，并构建了强大的合作伙伴网络，确保客户在部署、运营、维护各阶段都能获得全面支持。 稳定的产品战略与行业基础： 在监控与可观测性领域拥有深厚积累，结合 Splunk 的日志、安全与 IT 运维能力，使其在金融、科技与公共领域具备强大综合实力。 AI 创新集成推进迅速： 持续在 AI 能力上加大投入，推出 Cisco AI Assistant 与可观测性平台集成，支持生成查询、自动解读遥测数据，并加速洞察生成，显著提升操作效率。 注意事项 平台整合度不足： Splunk 的产品线通过多次收购构建，导致不同模块之间集成度不高，影响平台的一致性与使用效率，增加运维复杂性。 产品认知度偏低： 尽管 Splunk 在日志与安全分析领域具有较高知名度，但 Splunk Observability Cloud 的市场认知度较低，部分客户甚至未意识到其可观测性平台已全面上线。 运营成本难以控制： 虽然 Splunk 引入了指标处理优化工具，但在 Splunk Cloud 与 ITSI 场景下，客户普遍面临成本增长快、用量预估难等问题，管理大型遥测环境的成本控制仍是一大挑战。 Sumo Logic Sumo Logic 是本次魔力象限中的利基厂商。其核心定位为大规模日志分析平台，同时拓展至安全监控与可观测性领域，适配 DevSecOps 场景。尽管北美是其主要市场，公司也服务于全球客户，平台已部署于多个 AWS 区域，并在亚太地区持续加大投入。2024 年，Sumo Logic 推出 AI 助手 Mo Copilot，计划于 2025 年底上线基于生成式 AI 的问题分析功能。\n优势 强大的日志分析能力： 平台提供 Log Search、LogReduce、LogCompare 等专用工具，便于高效处理大规模日志数据。结合基于分析量而非数据摄取量计费的 Flex Licensing 模式，帮助客户更好地控制成本。 开源兼容性强： Sumo Logic 广泛支持开源遥测采集框架，如 OpenTelemetry、Telegraf 和 Fluent Bit，支持通过 OTLP 协议接收数据。同时平台也支持 OpenSLO 用于服务级别目标管理，并通过 OpAMP 实现对遥测采集器的统一编排与管理。 可观测性与安全一体化： 平台同时服务于运维与安全团队，适合实施 DevSecOps 战略的组织，在单一平台中实现威胁监测与系统性能洞察的融合。 注意事项 缺乏针对 LLM 的可观测性能力： 虽然平台支持将 AWS Bedrock 与 Google Vertex AI 的日志与指标接入，但尚不具备对大语言模型运行关键维度（如 Token 使用、成本、偏差、漂移、幻觉）的深入分析功能，落后于其他主流平台。 生成式 AI 助手功能有限： Mo Copilot 于 2024 年底上线，目前主要用于数据探索与可视化，仍处于功能早期，缺乏复杂任务的自动化处理能力。 调试体验不佳： 平台尚未与主流 IDE（集成开发环境）集成，不便于开发者在调试过程中直接回溯日志或异常，限制了 DevOps 流程中的效率提升空间。 新增与移除厂商 我们会根据市场变化，定期审查并调整魔力象限的入选标准。随着评估标准的更新，每年入选厂商的组合也会有所变化。某个厂商在某一年出现而下一年未被列入，并不代表我们对其评价发生变化，可能反映的是市场格局或厂商战略重心的调整。\n新增厂商 以下厂商符合入选标准，首次加入本年度魔力象限：\nApica Coralogix ITRS ScienceLogic SolarWinds 被移除厂商 Logz.io 因未达到本市场所要求的客户兴趣指标（CII）阈值，被移出本次评选。 ServiceNow 未满足本次研究的入选条件，未被纳入本次魔力象限。 入选与排除标准 基本条件 截至 2025 年 3 月 27 日，平台必须提供正式上线（GA）的功能，且可通过常规销售渠道向所有客户开放。 可观测性平台必须可直接售卖给客户，且无需强制依赖专业服务。厂商需为平台（包括所用开源组件）至少提供一线支持，如产品文档、安装指南、参考用例等。 平台需具备明确的产品路线图和销售推广战略。 厂商需提供电话、邮件或在线客服，并支持英文合同、控制台、技术文档与客户支持。 功能能力要求 平台必须原生支持所有强制功能，并至少满足九项常见功能中的四项（详见 Gartner 市场定义部分）。 平台必须以 SaaS 形式交付。虽可提供自托管版本，但本次研究不评估自托管方案。 业绩门槛要求 满足以下任一条件：\n拥有至少 50 家生产环境的付费客户，且客户分布至少覆盖两个大区（亚太、EMEA、拉美、北美），不含 MSP 销售； 在过去 12 个月中，实现符合 GAAP 的年收入不少于 7500 万美元； 或者：年收入达到至少 1000 万美元，且同比增长率不低于 25%。 此外，厂商还需在 Gartner 设定的客户兴趣指标（CII）中排名靠前。CII 是结合内部数据与外部市场反馈（如客户咨询热度、客户满意度等）形成的加权指标。\n特别提及厂商 Gartner 当前正跟踪超过 40 家可观测性平台厂商。本次魔力象限仅聚焦于其中 20 家符合入选标准的供应商。但未被纳入并不代表这些厂商不具备市场竞争力，部分平台在特定场景下依然非常值得客户关注和评估。\nDash0： 由 Instana（后被 IBM 收购）联合创始人之一创建，Dash0 是一个基于 ClickHouse 构建、原生支持 OpenTelemetry 的现代可观测性平台。虽然基础架构并不独特，但 Dash0 在用户体验和产品实现方面表现出色，拥有简洁的定价方案与面向开发者的界面。其同时支持 PromQL（Prometheus 查询语言）与 Perses 仪表盘工具，全面拥抱开放标准。Dash0 因未达业绩门槛，未能入选本次评选。\ngroundcover： 适合对遥测数据主权与位置控制有严格要求的组织。该平台尽管提供 SaaS 控制平面，但所有遥测数据均保留在客户自建环境内，部署于 ClickHouse 与 VictoriaMetrics 私有实例中，支持 BYOC（Bring Your Own Cloud，自带云）架构。groundcover 因未达业绩门槛，未被纳入本次象限。\nHPE OpsRamp： 作为一款 SaaS 化 IT 运维平台，OpsRamp 以事件智能为特色功能，在产品演进中不断引入领先能力。HPE 于 2023 年收购 OpsRamp，并将其整合至 Greenlake 平台核心，协同 Morpheus Data 提供运营支撑能力。今年由于整体市场认知度不高，未满足入选标准。\nKloudfuse： 这是一款由客户自行托管的可观测性平台，可部署于公有云或私有云资源中。虽然未提供 SaaS 版本，但通过托管控制平面降低了运维难度，同时数据完全保留在客户侧。平台基于数据湖架构，致力于打造统一可观测性视角。由于缺乏 SaaS 交付形式，Kloudfuse 不符合功能能力入选标准。\nObserve： 作为首批构建于 Snowflake 云数据平台上的数据湖型可观测性产品之一，Observe 在 2021 年被评为 Gartner Cool Vendor。该平台以数据分析能力为核心，近年来企业采用率持续提升。然而，鉴于象限仅评选最多 20 家厂商，Observe 今年因未达市场认知度门槛而未能入选。\n评估标准 执行能力（Ability to Execute） Gartner 分析师通过厂商在流程、系统、执行方法与运营机制上的质量与效率，评估其在市场中的竞争力与表现。这些因素不仅影响厂商在营收、客户保留率与品牌声誉方面的表现，也体现其将战略愿景转化为实际成果的能力。\n产品能力： 评估平台在可观测性核心技术上的表现，包括当前的产品特性、稳定性、功能丰富度等。还会考虑其在扩展性、可用性、集成能力与安全功能方面的成熟度。\n整体可持续性： 衡量厂商整体财务健康状况及其核心业务单元的运营表现，具体包括盈利能力、收入地域分布与研发投入强度等。\n销售与定价策略： 评估厂商在市场中的销售成功程度，分析其定价模型是否具备透明性、灵活性与客户价值。还包括新客户与续约客户的比例、与竞争对手的价格对比等。\n市场响应速度： 衡量厂商是否具备快速适应市场变化与客户需求演变的能力，包括对竞争格局的敏锐反应与客户反馈的响应机制。\n市场推广执行力： 评估厂商在市场宣传与品牌建设方面的策略效果，包括信息传递的清晰度、宣传内容的创意性与影响力，以及产品的市场认知度。\n客户体验： 考察厂商是否通过产品、服务与支持机制，帮助客户实现预期目标。包含售后支持、高触达服务、VIP 项目与区域交付能力等。\n运营能力： 评估厂商是否具备履行承诺与服务目标的执行力，涉及组织结构、团队技能、合作伙伴关系以及服务等级协议（SLA）的遵守情况。包括是否与主流云服务商协作，以及宕机与服务中断的响应能力。\n愿景完整性（Completeness of Vision） Gartner 分析师通过评估厂商对当前市场机会的理解能力、对未来发展方向的构想能力，以及其愿景表达的清晰度与落地能力，来判断其在可观测性平台领域的长期发展潜力。最终评分基于厂商愿景的前瞻性与其与 Gartner 市场判断之间的一致性。\n市场理解力： 厂商是否能够准确理解客户需求，并将其转化为产品特性。优秀的厂商不仅能回应客户诉求，还能主动推动市场方向，特别是在可观测性快速发展、与 APM 不断区分的趋势中展现清晰判断力。\n市场战略： 评估厂商在品牌定位与市场传播上的清晰性与差异性，以及其通过社交媒体、广告宣传、客户计划等渠道将理念传达给内外部受众的能力。也会关注其在新市场的拓展、营销创新与战略独特性。\n销售策略： 考察厂商是否建立了覆盖直销、渠道、服务与合作伙伴网络的销售体系，能否拓展客户群并满足不同买家与决策者的选型需求。包括渠道布局、影响者策略与市场触达能力。\n产品策略： 厂商在产品开发与迭代中是否注重差异化竞争、功能覆盖、交付方法及未来能力的布局。关注其产品路线图的发布节奏、质量与在 IT 运维领域周边市场的投资方向。\n商业模式： 评估厂商的商业逻辑是否具备可持续性，包括价值主张、对授权／定价模式变化的预判能力，以及与开源社区的合作与生态关系。\n垂直行业策略： 由于可观测性平台通常不依赖具体行业，因此本研究不将其作为主要评估项。如涉及行业差异化策略，相关内容已整合进其他指标中评估。\n创新能力： 分析厂商是否对可观测性核心或相邻领域进行战略投资，包括资源整合、AI/ML 应用、合作伙伴生态建设等。也关注其在整合、防御性布局或前瞻性产品方向上的行动力。\n地域策略： 厂商是否具备将产品、人才与服务本地化的能力，并能覆盖本土以外地区的客户需求。包括各区域团队建设、SaaS 平台部署位置、面向区域差异的产品策略，以及当地合作伙伴的广度与深度。\n象限定义说明（Quadrant Descriptions） Leaders（领导者） 领导者的可观测性平台产品在功能上与市场主流需求高度匹配，且在客户获取与扩张方面表现卓越。他们通常拥有全面的产品组合，具备先进的数据分析能力与可视化能力，并能与其他 IT 运维（ITOM）工具实现广泛集成。这些厂商展现出前瞻性的战略视野和强大的执行力，持续推动产品创新与优化客户体验。\nChallengers（挑战者） 挑战者在市场覆盖范围和平台部署规模方面具备显著优势。此类厂商通常执行力强，并借助企业整体品牌或销售网络在市场中占据一席之地，即使其可观测性业务尚未成为核心。他们可能曾是市场领先者，也可能正经历产品与战略的转型。部分挑战者的产品被作为更大 IT 解决方案的一部分，甚至超出传统 IT 运维的范畴。\nVisionaries（远见者） 远见者具备清晰的市场策略与竞争愿景，正在构建有潜力的可观测性平台产品组合。然而，由于产品尚处于发展阶段，其在市场响应速度、平台整合能力与市场份额拓展方面的执行力仍不及领导者。\nNiche Players（利基者） 利基者主要面向特定客户群体，或专注于某些细分使用场景。由于在核心功能方面不具备全面覆盖，通常难以满足广泛市场的全部需求，或仅在特定行业、区域或场景中具备竞争力。此外，利基者在功能开发、市场拓展与渠道建设上的投入相对有限。不过，入选此象限并不代表其市场价值不足，而是表明其专注于更具针对性的市场定位。\n背景 可观测性平台：VUCA 的微观缩影还是一片绿洲？ 正如我们在去年的会议演讲中所回顾的，这项研究的起点可以追溯到 1997 年。2025 年是我主持该 Magic Quadrant 的第四年，回顾自 2022 年以来的种种变化，尤其是在 Gartner 所描述的这个充满动荡、不确定、复杂和模糊（VUCA）的全球环境中，感触尤深。\n可观测性平台市场（以及早期的应用性能监控市场）这几年几乎一直处于不断演变的状态。这无疑增加了本报告对 Gartner 客户的参考价值。但我们也要保持清醒：这毕竟是众多竞争激烈的软件市场之一。那可观测性平台有何不同？一种观点认为，云原生工作负载的复杂性与规模已经打破了人们对可见性与资源管理的长期认知。下面我们从当前环境出发，深入探讨这个问题。\n波动性： 最直观的波动表现来自行业并购。例如 Cisco 收购 Splunk 的影响如今才开始显现，而 Broadcom 收购 VMware 与 New Relic、Riverbed、Sumo Logic 与 SolarWinds 的私有化或易主也在不断重塑市场格局。Datadog、Dynatrace 与 Grafana Labs 等厂商也陆续收购了诸多初创企业，包括 Quickwit、Metaplane、Rookout、Runecast、Asserts 和 Pyroscope 等。行业对基础能力的要求正在快速提升，而 AI 可观测性创业公司极有可能成为下一波收购浪潮的核心目标。\n不确定性： 对客户而言，可观测性平台的持续拥有成本仍是不确定因素；而对潜在买家来说，成本之外，还有价值实现周期和实施复杂度的顾虑。随着厂商从基于主机数量的定价模式转向基于资源消耗的计费方式，或将两者结合，客户对成本上涨的担忧持续升温。越来越多客户向 Gartner 咨询如何优化支出，并开始接受功能取舍或转向开源方案以控制预算。\n复杂性： 当今企业构建和运行的系统愈发复杂。Kubernetes、多云服务、API 驱动的外部依赖不断增加，需求复杂化最终也让产品更复杂。AI 的兴起也为运维团队带来了全新挑战。虽然客户部署 AI 工作负载的浪潮尚未全面到来，但趋势已然明确。如今，AI 功能已成为可观测性平台的标配，许多厂商也正迈向具代理能力的 AI。不过，“用 AI 工具来运维 AI 系统”这一说法，尚未成为主流卖点。\n模糊性： 我们看到，产品与运维团队中出现了大量新角色与组织，例如 SRE、平台工程师、AI 工程师、数据科学家、云卓越中心以及集中可观测性团队等。将这些新角色纳入原本以技术职能划分的组织架构中，往往令人困惑。同时，对运维团队的期待也变得模糊：什么才算是优秀的可用性与性能？当数据和告警已经压得我喘不过气时，再加遥测数据真能带来帮助吗？\n事实上，运维团队似乎也无法逃离 VUCA，甚至可以说，运维社区已经拥有一个属于自己的 “VUCA 宇宙”。\n不过，在评估了本报告中涵盖的厂商与产品后，我们依然感到振奋。如今市面上已有不少表现出色的可观测性平台产品，它们中的多数已纳入此次研究。在 VUCA 的大环境下，正是投身数字化运维的好时机。\n如果说对抗 VUCA 的方法，是掌握将遥测数据转化为业务行动与洞察的能力，从而让运维团队持续驱动业务飞轮，那么我们愿意承认，现在就是那片“绿洲”。\n市场概览 截至 2025 年中，可观测性平台市场仍延续着自全球疫情以来的高速演进。今年，为遵守 Magic Quadrant 最多纳入 20 家厂商的限制，我们在厂商遴选过程中面临诸多艰难取舍——部分具备竞争力的厂商因此未能入选，它们有的被收录于“值得关注”部分，另一些则可能在未来研究中出现。预计这一市场的活跃状态在短期内仍将持续。当前的市场格局已经带来了功能深度的不断增强与产品选择的显著扩展，未来厂商之间的差异化可能不再局限于技术能力，而是进一步演变成“功能秀”的角力。\n影响市场持续增长与采纳的关键因素包括：\n应对 VUCA 环境： 企业在技术平台、部署位置、地域策略与拥有成本等方面不得不做出权衡。即便在挑战加剧的环境下，可用性与性能要求并未放宽。组织往往需以更少资源应对更高标准，或借助新方式达成目标。例如，随着 VMware 产品对部分企业而言变得难以获得，自管私有云基础设施的未来愈发不明朗，这对相关工作负载的可观测性提出了新挑战。\nAI 热度持续： 每当 AI 热潮似乎达到顶峰，市场总会因新动向再度升温。目前的焦点是“具代理能力的 AI”，这一方向在 IT 运维领域展现出巨大潜力。虽然部分宣称具备此类能力的产品仍存虚名，但整体趋势值得关注。同时，企业对 AI 工作负载的运维支持需求正在快速增长，可观测性平台厂商与专用工具厂商都在加快布局。\n遥测数据的业务价值愈加突出： 越来越多平台声称可支持“业务可观测性”功能，帮助监测业务活动而非仅限技术指标。这类能力虽具价值，但往往需要配套的工作负载改造。此外，许多企业也开始意识到遥测数据中蕴含的业务洞察，并寻求手段将其普惠化。然而，要持续有效地将洞察交付至更多角色，还需在技术与非技术层面投入资源，这在现实中仍被普遍忽视。\n同时，多个监控领域与实践正加速融合。市场重心正从单点技术优化，转向保障应用实现其业务目标。相应地，资金投入也更集中于数字体验监控（DEM）与基础设施监控等与业务成效紧密相关的领域。根据 Gartner 预测，全球可观测性产品市场将在 2028 年达到约 142 亿美元，2021 至 2028 年年复合增长率（CAGR）为 11.1%（恒定汇率计）。\n未来几年，市场将继续围绕以下趋势发展：\n客户对于可观测性平台的成本与价值比问题愈发敏感，相关咨询频率持续上升； 数据量与种类持续增长，推动平台向通用分析工具靠拢，AI 助力下的“自驱型”功能日益普及； AI 可观测性成为部署 AI 与 LLM 工作负载的企业刚需； 平台正延伸至更多角色，如业务负责人、产品经理、平台工程师、开发人员等； 渐进式交付、版本管理与可观测性的融合趋势明显； 集中式可观测性团队被越来越多企业采纳，用于统一管理 SLO、遥测流转与工具选型； OpenTelemetry、eBPF 与遥测管道解决方案将推动行业标准与最佳实践的形成。 ","date":"2025-08-24T16:57:03+08:00","image":"https://martinliu.cn/blog/magic-quadrant-observability-platforms-2025/1180-thumbnail_hu_4c68741a2b8bc1a9.jpg","permalink":"https://martinliu.cn/blog/magic-quadrant-observability-platforms-2025/","title":"2025 年 Magic Quadrant：可观测性平台魔力象限"},{"content":" From: Grafana Labs Blog\n我们持续为 Grafana Cloud 推出实用更新和新特性。Grafana Cloud 是一款由开源的 Grafana LGTM Stack 提供支持的全托管可观测性平台，其中包括 Loki（日志）、Grafana（可视化）、Tempo（链路追踪）和 Mimir（指标监控）。\n还不是 Grafana Cloud 用户？立即注册 账户，使用我们的 Cloud Free 免费计划即可试用所有功能。\n更轻松上手 Grafana Cloud：Grafana Assistant 现已开放公开预览 在 Grafana Labs，我们始终坚信，AI 不只是可观测性领域的一时潮流，它将在未来成为保障系统稳定运行的重要基石。\n这一理念也持续推动我们构建新的工具。例如，本月我们很高兴宣布：Grafana Assistant——一款嵌入于 Grafana Cloud 的 AI 助手，现已进入公开预览阶段。它支持自然语言操作，帮助你更高效地进行查询、构建和故障排查。\nGrafana Assistant 可简化常见的工作流程，比如编写 PromQL、LogQL 或 TraceQL 查询，以及创建仪表盘等，同时始终让你掌控操作过程。它能帮助你减少重复性工作，提升整体效率，包括：\n更快速地编写和调试查询语句 构建并优化可视化仪表盘 排查系统问题与异常 分析观测数据中的趋势与模式 更直观地使用 Grafana 界面 降低团队上手门槛，加速使用流程 想深入了解 Grafana Assistant 的功能和应用场景，欢迎访问官方文档。\n安全凭证管理：Grafana Cloud Synthetic Monitoring 引入密钥管理功能 随着基础设施的不断扩展，安全管理可观测性系统中的 API 密钥、密码、Token 等敏感信息也变得愈发复杂和重要。\n为了解决这一问题，我们本月在 Grafana Cloud 中推出了机密管理功能，目前已开放公开预览。该功能为 API 密钥、密码、Token 和凭证等数据提供了集中化、安全存储与统一管理的能力。首个集成此功能的产品是 Synthetic Monitoring。\n借助 Grafana Cloud Synthetic Monitoring 中的机密管理，你可以：\n创建密钥，并附加描述、标签等元数据信息 在 k6 脚本型 和 k6 浏览器型 检查中通过名称引用密钥 重置或吊销已有的密钥 当前，密钥的创建、修改和删除权限仅限于管理员用户。不过，只要用户具备检查项的编辑权限，且知晓密钥名称，即可在相应脚本中调用密钥。\nSynthetic Monitoring 用户界面截图，左侧显示“创建密钥”对话框，右侧是“密钥管理”部分。\n目前，密钥仅支持在脚本型和浏览器型检查中使用，但未来将扩展支持更多类型的监控检查。\n如需详细了解，请查阅我们的博客文章与密钥管理官方文档。\nLLM 驱动的追踪数据洞察：Grafana Cloud Traces 现已支持 MCP 协议 分布式追踪数据是一种独特而强大的可观测性信号，能够帮助你深入了解系统中服务之间的交互关系。然而，将这些原始数据转化为可操作的洞察往往充满挑战。\n为此，我们在由 Grafana Tempo 驱动的全托管分布式追踪系统 Grafana Cloud Traces 中，现已新增对 Model Context Protocol（MCP） 的原生支持。\nMCP 协议 是由 Anthropic 推出的标准协议，广泛用于定义应用程序如何向大语言模型（Large Language Model，LLM）提供上下文信息。通过将 MCP 集成进 Grafana Cloud Traces，你现在可以使用如 Claude Code 和 Cursor 等基于 LLM 的工具，更高效地分析追踪数据并获取深度洞察。\n具体来说，这项集成可以帮助你：\n探索服务结构与交互：通过 LLM 分析追踪数据，新入职的开发者可以快速了解系统中服务之间的调用关系。 快速定位与诊断问题：LLM 可辅助识别调用链中的异常或错误，加快问题定位流程。 优化性能，降低延迟：通过分析链路数据，LLM 可帮助识别延迟瓶颈，指导优化策略。 要在 Grafana Cloud Traces 中配置 LLM 智能体，需要提供 Grafana Cloud API Token 并完成相应的配置流程。该功能目前处于公开预览阶段。\n如需进一步了解 MCP 支持及其使用方式，请参阅我们的博客文章和技术文档。\n安全访问私有数据源：Tailscale 与 Grafana Cloud 全新集成上线 我们深知，用户在希望通过 Grafana Cloud 实现数据可视化和洞察分析的同时，也极为关注数据源的私密性与安全性。\n为此，我们推出了全新的 Tailscale 与 Grafana Cloud 集成方案。该集成现已开启私密预览，允许你通过 Private Data Source Connect，从 Grafana Cloud 直接安全访问位于 Tailscale 网络（称为 tailnet）中的数据源。\n该集成带来的关键优势包括：\n安全私密的数据访问：借助 Tailscale，无需将数据源暴露在公网环境中，即可安全地进行查询操作。 配置简便，减少运维负担：使用 Tailscale 搭配 Private Data Source Connect，无需部署 PDC agent。你只需通过 MagicDNS 填写数据源的 tailnet 地址或机器名，并提供 Tailscale 授权密钥，即可完成连接。 扩展 Grafana Cloud 的可观测性覆盖：相比自托管方案，Grafana Cloud 提供更强大的可观测能力和使用便捷性。你可以在任何地点访问私有网络中的数据源，特别适合远程办公和分布式团队。 想了解该集成的更多细节及使用方式，欢迎阅读官方博客，以及查阅我们的 Private Data Source Connect 文档。\n前端可观测性新增开箱即用告警功能 Grafana Cloud Frontend Observability 是我们为 Web 应用推出的真实用户监测（Real User Monitoring，RUM）托管服务，能够即时提供清晰且可操作的终端用户体验洞察。\n本月，配置前端可观测性告警的流程变得更加轻松便捷。\n随着开箱即用的告警功能正式发布，Grafana Cloud Frontend Observability 向前迈出了重要一步，即使是首次使用 Grafana 告警功能的用户，也可以通过 Grafana 托管告警 快速上手，无需预先了解复杂的配置流程。\n借助简化的工作流，你可以：\n基于 Web 应用中的错误或 Web Vitals 指标启用并配置告警 快速定位并排查前端问题，因告警规则由系统自动配置与管理 编写可复用模板，拓展前端告警策略的覆盖范围 想了解更多详细内容，请访问我们的 Frontend Observability 文档。\nGrafana Cloud IRM 事件管理功能全面升级 快速通报事件状态更新 在 Grafana Cloud IRM 中，你现在可以为事件添加结构化的状态更新，帮助团队与干系人实时掌握处理进展。\n状态更新贯穿整个事件生命周期，无论是确认影响、交由其他团队处理，还是完成事件解决，都能以统一格式高效传递关键信息，提升沟通透明度。\n你可以直接在 Web 界面中添加状态更新，或在关联的 Slack 事件频道中使用以下指令：\n/grafana incident update add \u0026lt;内容\u0026gt;：发布新的状态更新 /grafana incident update：查看最新状态更新 该功能现已全面上线。只需打开任一事件页面，在 活动时间轴（activity timeline） 中找到 状态更新（Status updates） 区域即可使用。如需了解详情，请查阅使用指南。\n全新 Webhook 集成体验 Grafana Cloud IRM 的外发 Webhook 现已支持事件相关触发器，为自动化告警分组和事件处理提供更强大的统一工作流管理能力。你可在 Outgoing Webhooks 配置页中设置，在事件声明、更新或解决时自动触发请求。\n新版本 Webhook 支持以下能力：\n支持任意 HTTP 方法，灵活配置请求 URL、Header、请求体均可模板化定义 可动态引用事件数据和先前 Webhook 响应结果 可在事件或告警分组时间轴中直接查看执行记录 支持使用 Terraform 进行配置管理 现有旧版 Incident Outgoing Webhooks 及其配置仍可继续使用。但为获得更好的功能体验和长期支持，我们建议迁移至新版统一 Webhook 集成。\n更多信息请参阅官方文档。\nGrafana Cloud k6 正式支持扩展机制，现已全面上线 我们正式推出 Grafana Cloud k6 的扩展功能支持！Grafana Cloud k6 是一款基于 Grafana k6 构建的托管性能测试平台，适用于多种测试场景。\n通过 k6 扩展机制，你可以扩展 k6 的核心功能。开源版本用户需自行编写扩展并重新编译 k6，而在 Grafana Cloud k6 中，你可直接使用平台支持的一部分扩展模块，无需构建自定义二进制文件。\n你可以通过以下方式灵活执行测试脚本：\n本地运行测试：k6 run test.js 在云端运行测试：k6 cloud run test.js 本地运行并将测试结果实时传输到云端：k6 cloud run test.js --local-execution 如需进一步了解扩展功能和使用方式，请访问官方公告。\nGrafana Cloud 全新 Enterprise 数据源与集成支持上线 我们还新增了多项集成与 Enterprise 数据源，帮助你进一步扩展 Grafana Cloud 的可观测能力。\n使用 Anthropic 集成监控 Claude 模型的使用与成本 全新发布的 Anthropic 集成 允许你直接在 Grafana Cloud 中连接 Anthropic Usage and Cost API，实时监控 Claude 系列大语言模型（Large Language Models, LLM）的使用情况与开销。\n通过这一集成，你可以在统一平台中查看 Claude 模型的调用频率、响应时间和累计费用，配套的预设仪表盘与告警机制可帮助你迅速启动监控并及时采取优化措施。\n详细信息请参阅官方文档。\n可视化 Jenkins 数据指标 全新上线的 Jenkins Enterprise 数据源 现已支持在 Grafana Cloud 和 Grafana Enterprise 中，查询并展示 Jenkins 自动化服务器中的性能指标。Jenkins 是开源的持续集成（CI）/持续部署（CD）平台，用于项目的构建与发布管理。\n该数据源内置两个预设仪表盘，助你快速上手 Jenkins 数据可视化：\nJenkins 概览仪表盘：展示整个 Jenkins 实例的运行状况，包括所有项目、节点、执行器状态和构建队列等信息。 Jenkins DORA 指标仪表盘：聚焦衡量研发效能的四项核心指标：部署频率、变更交付时长、变更失败率与服务恢复时间。 ","date":"2025-08-21T16:55:49+08:00","image":"https://martinliu.cn/blog/grafana-cloud-updates-onboard-teams-with-new-ai-powered-tooling-secrets-management-for-enhanced-security/cloud-updates-aug-2025_hu_e105ff1d814461f6.png","permalink":"https://martinliu.cn/blog/grafana-cloud-updates-onboard-teams-with-new-ai-powered-tooling-secrets-management-for-enhanced-security/","title":"Grafana Cloud 推出多项更新：AI 驱动工具、秘钥管理强化安全性，以及更多功能"},{"content":"最近，我一直在利用业余时间学习和试验 AWS 的数据服务，发现它们非常引人入胜。\n在本文中，我们将探讨我是如何利用 AWS 服务（如 Data Catalog、DataBrew 和 DynamoDB）构建一个实时无服务器数据管道的，以及如何借助 Terraform 将其无缝部署到 AWS。\n无论您是数据工程领域的新手还是经验丰富的专家，本指南都将为您提供帮助！\n前提条件 AWS 账户 Python 3 Terraform 为什么选择 Terraform 开源 庞大的开发者社区 不可变基础设施 (Immutable Infrastructure) IaC (Infrastructure as Code) 云无关性 (Cloud agnostic) 旨在提升我对新技术的了解 项目结构 概述 我即不是数据工程师，也没有在构建数据管道项目中；但是，我最近接触了一些数据服务。结合我对 AWS 的普遍了解，我决定亲手探索一些新服务。\n本文源于我将构建数据管道作为一个有趣的项目来实践的经验，我发现整个过程非常有趣且富有成效。\n使用到的关键服务 1. Amazon S3 作为数据存储层。 存储了项目中使用的 JSON 文件 2. Amazon DynamoDB 作为数据库层。 使用 DynamoDB 流 (DynamoDB streams) 和 AWS Lambda 将 JSON 数据从 DynamoDB 导出到 S3 3. AWS Glue 负责数据提取、转换和加载 (ETL - Extraction, Transformation, and Loading)。 使用 Glue Data Catalog 管理数据集的元数据 (metadata)。 它还支持使用爬网程序 (crawler) 进行爬网，该程序自动发现架构 (schema) 并创建表；然而，在这个项目中，我们手动定义了架构，因此不需要此功能。 4. Amazon DataBrew 用于转换 S3 中存储的数据，方法是删除重复条目。 一旦项目放置在 S3 存储桶的路径 /data 中，它就会作为触发作业（来自 Lambda）运行。 指向 Glue Data Catalog 作为输入数据集。 5. Amazon Athena 使用标准 SQL 查询存储在 Glue Catalog 中的转换数据。 完全无服务器，并与 Glue Data Catalog 集成。 最终架构 架构解释 第一流程 一个 .json 文件被添加到 S3 上的路径 /data 第一个 Glue 数据目录表 (Glue Catalog Table) 从 S3 的 /data 路径读取数据 上传到 /data 会触发一个 Lambda 函数，该函数启动 DataBrew 转换作业，通过移除 email 列中的任何重复行来清理第一个 Glue 数据目录表（输入数据集）中的数据 DataBrew 作业将转换后的数据输出到 S3 中的新路径 /cleaned 下，覆盖该路径中的其他项目以避免输出路径中出现重复 第二个 Glue 数据目录表从 S3 的 /cleaned 路径读取数据 Athena 工作组 (workgroup) 从第二个 Glue 数据目录表读取数据并对其运行查询。这反过来又将查询结果存储在 S3 中的新输出位置 /athena-results/ 第二流程 一条数据被添加到 DynamoDB。 随着新数据的增加，DynamoDB 流 (stream) 被触发 连接到 DynamoDB 流的 Lambda 函数（用 Python 编写）被调用，它将新项目转换为 .json 文件 执行第一个流程中的所有步骤 总而言之，实时数据处理的目标是通过 DynamoDB Streams 和 S3 存储桶通知 (S3 Bucket Notification) 与 Lambda 的集成来实现的。\n代码定义 main.tf 提供商 (Provider)：第一步通常是定义提供商。这里我们将云提供商定义为 aws。\n此外，我们还包含了将在项目中使用的各种模块 (module)，并传入所有必需的变量。\n1 2 3 4 5 6 7 8 9 terraform { required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;~\u0026gt; 5.0\u0026#34; } } required_version = \u0026#34;\u0026gt;= 1.3.0\u0026#34; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 provider \u0026#34;aws\u0026#34; { region = \u0026#34;us-east-1\u0026#34; }module \u0026#34;s3_bucket\u0026#34; { source = \u0026#34;./modules/s3\u0026#34; bucket_name = \u0026#34;upload-bucket-data-pipeline-234\u0026#34; }module \u0026#34;dynamodb_table\u0026#34; { source = \u0026#34;./modules/dynamodb\u0026#34; table_name = \u0026#34;dynamodb-table\u0026#34; }module \u0026#34;lambda_function\u0026#34; { source = \u0026#34;./modules/lambda\u0026#34; lambda_name = \u0026#34;dynamodb_to_s3\u0026#34; handler_trigger = \u0026#34;dynamodb_to_s3_trigger.lambda_handler\u0026#34; s3_bucket = module.s3_bucket.bucket_name table_name = module.dynamodb_table.table_name dynamodb_stream_arn = module.dynamodb_table.stream_arn }module \u0026#34;glue_catalog\u0026#34; { source = \u0026#34;./modules/glue/glue_raw\u0026#34; database_name = \u0026#34;catalog_db\u0026#34; table_name = \u0026#34;catalog_json_table\u0026#34; s3_location = \u0026#34;s3://${module.s3_bucket.bucket_name}/data/\u0026#34; }module \u0026#34;databrew\u0026#34; { source = \u0026#34;./modules/databrew\u0026#34; glue_table = module.glue_catalog.table_name glue_db = module.glue_catalog.database_name s3_bucket_name = module.s3_bucket.bucket_name data_zip = module.lambda_function.data_zip }module \u0026#34;glue_catalog_cleaned\u0026#34; { source = \u0026#34;./modules/glue/glue_cleaned\u0026#34; database_name = \u0026#34;catalog_cleaned_db\u0026#34; table_name = \u0026#34;catalog_cleaned_json_table\u0026#34; s3_location = \u0026#34;s3://${module.s3_bucket.bucket_name}/cleaned/\u0026#34; }module \u0026#34;athena\u0026#34; { source = \u0026#34;./modules/athena\u0026#34; result_output_location = \u0026#34;s3://${module.s3_bucket.bucket_name}/athena-results/\u0026#34; } backend.tf 首先，创建 S3 存储桶用于远程存储 Terraform 状态文件 (state file)，这有助于促进协作。\n创建后，将以下内容添加到 backend.tf 文件中：\n1 2 3 4 5 6 7 terraform { backend \u0026#34;s3\u0026#34; { bucket = \u0026#34;serverless-data-pipeline-backend-bucket\u0026#34; key = \u0026#34;serverless-pipeline/dev/terraform.tfstate\u0026#34; region = \u0026#34;us-east-1\u0026#34; } } 一旦我们运行 terraform init 和 terraform apply 来部署项目，我们就应该看到状态存储在存储桶中，如下所示：\nmodule/main.tf : 每个服务的基础设施和配置都放置在各自的 main.tf 文件中 module/output.tf : 每个服务的输出详情 (output detail) 都放置在各自的 output.tf 文件中 module/variable.tf : 每个服务期望的输入变量 (input variables) 都放置在各自的 variable.tf 文件中 部署应用程序 现在我们已准备好部署应用程序。运行以下命令进行部署。\nTerraform init：这会初始化项目，拉取部署所需的所有必要软件包。\n1 terraform init Terraform plan：这会显示提议的更改，在部署前发现任何意外更改时非常有用。\n1 terraform plan Terraform apply：这会将项目部署到 AWS。\n1 terraform apply 测试应用程序 S3 存储桶 (S3 bucket) 最初加载了一个 sample.json 文件，其内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [ { \u0026#34;id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john@example.com\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-04-19T12:00:00Z\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Mary Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;mary@example.com\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-06-20T12:00:00Z\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;3\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Jane Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john@example.com\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-06-22T12:00:00Z\u0026#34; } ] 注： 如您所见，我们有一个重复的电子邮件地址 *john@example.com*，理想的结果是移除这个重复条目。\n这个文件是在使用 Terraform 创建存储桶后立即上传的，因此它不会触发 DataBrew 作业，因为该触发器设置是在项目的后期才进行的。\n为了测试实时功能 (Real-time feature) 和项目的完整流程，我们可以向 S3 上传新对象，或向 DynamoDB 添加新条目。我们将向 DynamoDB 添加一个新条目来测试完整流程：\n通过 AWS 控制台 (console) 进入 DynamoDB，并添加一条新数据：\n添加此条目将触发 DynamoDB 流 (stream)，它会使用关联的 Lambda 函数 (lambda function) 将新对象插入 S3。\n前往 S3，我们看到新条目 7.json 已添加：\n接下来，前往数据目录 (Data Catalog)，我们看到数据库 (Databases) 和表 (Tables)。\n数据目录数据库\n数据目录表\n前往 DataBrew，我们看到该项目。\n一旦 Lambda 函数被添加到 /data 路径的新内容触发，它就会启动 DataBrew 转换作业 (transformation job)：\n完成后，它看起来像这样：\n已完成的 DataBrew 作业\nDataBrew 数据血缘 (Data lineage) 允许我们查看使用 DataBrew 的流程的图形化表示。\n空闲作业：\n运行中作业：\n最后，前往 Athena，并选择 my-athena-workgroup 工作组 (workgroup) 来运行查询。\n在 DataBrew 作业运行之前，如果我们使用 Athena 运行查询，将不会有任何结果，因为 /cleaned 路径中还没有任何项目：\n然而，在 DataBrew 作业成功运行后，我们点击 Run again 按钮以在 Athena 中重新运行查询：\n结果如下：\n如果你仔细观察，会发现它移除了在项目创建时上传到 S3 的 sample.json 文件中发现的邮箱为 john@example.com 的重复条目。\n它还添加了邮箱为 mathew@gmail.com 的新的 DynamoDB 条目。\n这意味着我们的管道按预期工作！！\n通过 DynamoDB 添加重复条目 让我们通过向 DynamoDB 添加一个新条目来进一步测试，但这次它的邮箱将与我们现有的记录匹配。\n我们添加了一个邮箱为 mathew@gmail.com 的新冲突条目\n这将触发一个新的 DataBrew 作业 (Job)：\n一旦成功了，我们会看到下图：\n接下来，前往 Athena 再次运行查询，这次它不再包含重复记录了！\n结论 我创建这个项目和文章是为了提高我在 Terraform 方面的技能，并亲自动手实践数据工程领域，同时磨练我的 Python 技能。\n你可以在 这里 找到完整的源代码。\n我希望这篇文章能帮助你对在 AWS 中构建数据工程项目更有信心。我很高兴看到你将创造出什么！\n全栈开发人员、技术作家和 Jamstack 爱好者。热爱终身学习。\n","date":"2025-08-02T15:42:33+08:00","image":"https://martinliu.cn/blog/building-a-serverless-real-time-data-pipeline-with-terraform-aws-and-python/serverless-data-pipeline_hu_eb29fa6d29109cfa.png","permalink":"https://martinliu.cn/blog/building-a-serverless-real-time-data-pipeline-with-terraform-aws-and-python/","title":"使用 Terraform、AWS 和 Python 构建无服务器实时数据管道"},{"content":"最新版本带来了多项新功能，简化了 Grafana 实例（Grafana instances） 的管理方式，也优化了 告警规则（alert rules） 的管理体验，方便你快速定位所需的告警内容。此外还有更多改进。\n以下是本次 Grafana 版本的一些亮点。如果你想了解本次发布的全部更新内容，请参考 更新日志 或 新版功能文档。\nGrafana Advisor：智能化运维监控 我们一直在探索降低运维负担的方法，帮助你更高效地进行维护与故障排查。因此，在 Grafana 12.1 中，我们很高兴地宣布 Grafana Advisor —— 一个用于帮助管理员保持 Grafana 实例稳定和安全运行的监控工具 —— 现已进入公开预览阶段。\nGrafana Advisor 最初在 Grafana 12 中作为实验性功能推出，如今它能够自动对你的 Grafana 服务器执行定期健康检查，提供可操作的洞见与建议，帮助你维持系统的最佳运行状态。\n目前，Grafana Advisor 会定期检查 数据源连接（data source connections）、插件（plugins） 和 SSO 设置（SSO settings），未来版本中我们计划扩展其功能范围。\n在 Grafana Cloud 中，Advisor 默认启用。若要在 Grafana OSS 与 Enterprise 版 中启用该功能，可通过配置开关 grafanaAdvisor 实现。详情请参见我们的 技术文档。\n告警功能的重大升级 告警是任何可观测性策略中的关键组成部分。在 Grafana 12.1 中，我们带来了几项新的告警功能，包括重新设计的 告警规则列表页面（alert rule list page），帮助你以更可扩展、直观的方式管理告警。\n全新设计的告警规则列表页面 适用于所有版本的 Grafana\n在 Grafana Alerting 中，一个 告警规则（alert rule） 定义了触发告警的评估条件。你可能拥有数百甚至上千条这样的规则，而在本次发布中，我们通过完全 重新设计的规则列表页面 让浏览管理更加轻松。\n新版页面整体提供了更流畅、更快捷、更灵活的使用体验。它支持两种视图模式，满足不同使用场景：\n分组视图（Grouped view）：按命名空间组织，便于深入查看特定规则组。 列表视图（List view）：展示所有告警规则的完整列表，支持快速搜索与过滤。近期的性能优化大幅提升了使用效率。 我们还对界面进行了简化，聚焦于“管理告警规则”这一核心任务。现在你将看到一个更简洁、更清晰的视图，仅显示最关键的信息字段，包括 规则名称（rule name）、所属位置（location）、类型（type） 和 状态（state）。\n此外，我们还为规则列表页面引入了新的分页 API，使管理操作更轻松便捷。无论你是希望查看结构化的告警规则层级，还是需要快速检索和筛选成千上万条规则，现在都能获得更简洁、更流畅的体验。\n对于 Grafana Cloud 用户，我们正逐步向所有实例推出新版规则页面；对于 Grafana OSS 用户，当前可通过功能开关启用。请在 Grafana 配置文件的 feature_toggles 部分中添加开关 alertingListViewV2：\n1 2 [feature_toggles] alertingListViewV2 = true 重启 Grafana 后，即可访问新版规则列表页面。\n支持 Prometheus YAML 文件导入规则 我们近期还 新增支持：可以将由数据源管理的规则导入为由 Grafana 管理的告警规则（Grafana-managed alert rules）。不过，以前用户在没有配置 ruler 的情况下，无法导入现有的 Prometheus 规则（Prometheus rules）。\n而在 Grafana 12.1 中，你现在可以直接 通过 Prometheus YAML 文件导入规则，并使用同一套 Alerting UI 完成配置。\n引入“活动时间区间”（active time intervals） 在本次告警功能更新中，我们将原先的 静默时间区间（mute time intervals） 重命名为 活动时间区间（active time intervals），以更准确地反映其用途 —— 即定义告警“何时应当触发”。\n如需进一步了解 Grafana 告警功能中的这些改动和其他更新，请查看我们的 官方文档。\n用更灵活的方式查询与可视化数据 无论你是想深入分析某项指标，还是构建复杂的仪表盘，这些新功能都将帮助你以更符合需求的方式探索数据。\n趋势线转换（Trendlines transformation） 适用于所有版本的 Grafana\n在 Grafana 中，转换操作（transformations） 是一种强大手段，用于在系统进行可视化之前处理查询返回的数据。Grafana 12.1 中新增了一个全新的转换类型：趋势线（trendlines，也称回归分析）。\n这一新转换会对任意数据集拟合一个数学函数 —— 支持线性或多项式回归 —— 以预测原始数据中未直接体现的某一时间点的数值。\n换句话说，你可以基于统计模型生成一个新序列，用于表示趋势线中的预测值。这在处理波动剧烈、难以洞察趋势的数据时尤为有用。\n你可以在 Grafana Play 示例 中查看这一转换的实际效果，或在我们的 文档 中了解更多细节。\n可视化操作中支持自定义变量 适用于所有版本的 Grafana\n我们很高兴地宣布，你现在可以在 可视化操作（visualization actions）中定义自定义变量 了。\n当你触发一个 操作（action）（例如调用 API 创建支持工单）时，系统会提示你填写这些变量的值。这样一来，操作变得更加动态、交互性更强，你无需修改仪表盘配置就能实时定制请求内容。\n这项功能在触发告警、过滤 API 调用，或将用户定义参数传递给外部系统时尤其有用。\n仪表盘支持服务器配置的快捷时间范围 适用于 Grafana OSS 与 Grafana Enterprise\nGrafana 服务器管理员现在可以为仪表盘的 时间选择器（time picker） 定义自定义的时间范围预设。这一功能非常适合那些需要经常分析特定上下文时间窗口的团队。\n服务器配置时间范围的截图\n只需在你的 服务器配置 文件中配置 [time_picker] quick_ranges，即可根据监控数据的实际情况设置全局默认值。\n1 2 3 4 5 6 7 8 [time_picker] quick_ranges = \u0026#34;\u0026#34;\u0026#34;[ {\u0026#34;from\u0026#34;:\u0026#34;now-6s\u0026#34;,\u0026#34;to\u0026#34;:\u0026#34;now\u0026#34;,\u0026#34;display\u0026#34;:\u0026#34;Last 6 seconds\u0026#34;}, {\u0026#34;from\u0026#34;:\u0026#34;now-10m\u0026#34;,\u0026#34;to\u0026#34;:\u0026#34;now\u0026#34;,\u0026#34;display\u0026#34;:\u0026#34;Last 10 minutes\u0026#34;}, {\u0026#34;from\u0026#34;:\u0026#34;now-25h\u0026#34;,\u0026#34;to\u0026#34;:\u0026#34;now\u0026#34;,\u0026#34;display\u0026#34;:\u0026#34;Last 24 hours\u0026#34;}, {\u0026#34;from\u0026#34;:\u0026#34;now/w\u0026#34;,\u0026#34;to\u0026#34;:\u0026#34;now/w\u0026#34;,\u0026#34;display\u0026#34;:\u0026#34;This week\u0026#34;}, {\u0026#34;from\u0026#34;:\u0026#34;now-1w/w\u0026#34;,\u0026#34;to\u0026#34;:\u0026#34;now-1w/w\u0026#34;,\u0026#34;display\u0026#34;:\u0026#34;Last week\u0026#34;} ]\u0026#34;\u0026#34;\u0026#34; 特别感谢社区成员 Chris Hodges 为该功能贡献代码！\n增强的自定义货币格式 适用于所有版本的 Grafana\n你现在可以 显示精确的财务数值（或按需缩写），以便更灵活地控制仪表盘中的展示方式。\n此前，Grafana 会自动缩写较大的货币数值 —— 例如 $1,235,667 会显示为 $1.24M，$555,558 会变成 $555.6K。虽然这种方式适用于大多数可视化场景，但财务数据往往需要显示精确数值。\n为此，我们增强了自定义货币格式。你现在可以使用 currency:financial:\u0026lt;unit\u0026gt; 格式完整显示数字。例如：使用 currency:financial:$ 会将 1235667 格式化为 $1,235,667，而非 $1.24M。\n财务格式还支持灵活的货币符号位置，包括：\n前缀（默认）：currency:financial:$ 会显示为 $1,235,667\n后缀：currency:financial:€:suffix 会显示为 1,235,667€\nMicrosoft Entra Workload Identity 支持 适用于所有版本的 Grafana\nGrafana 现在 支持 Microsoft Entra Workload Identity，显著增强了基于联合凭据的身份验证能力。该更新简化了 OAuth 流程，并提升了在 Microsoft Azure 上运行 Grafana 实例的安全性。\n关于 Entra ID（前身为 Azure AD）身份验证配置的更多信息，请参见我们的 官方文档。感谢社区成员 mehiglow 对该功能的宝贵贡献！\nGrafana 扩展性：数据源新增功能 在 Grafana Labs，我们始终相信 —— 不论你的数据存储在哪里，你都应该能够查询和可视化它。因此，我们持续扩展并改进 Grafana 的数据源支持能力。\n以下是最新的数据源相关更新。\n可视化 LogicMonitor 数据 LogicMonitor 是一个可观测性平台，提供基础设施监控、AIOps 和 IT 运维洞察。现已进入公开预览阶段，全新的 LogicMonitor Devices Enterprise 数据源 让你可以在 Grafana Cloud 或 Grafana Enterprise 中直接查询与可视化 Device Instance Data，以及列出 Devices、Datasources 和 Instances。\n你可以在我们的 官方文档 中了解如何使用与安装该数据源。如需全面了解 Enterprise 数据源，请参考这篇 指南。\nBigQuery 数据源支持服务账号模拟（Service Account Impersonation） 为提升安全性，Google 建议使用服务账号令牌配合 服务账号模拟（Service Account Impersonation）。一旦服务账号令牌遭到泄露，若未关联可模拟的服务账号，该令牌将无法访问 Google Cloud API，从而显著降低未授权访问的风险。\n这一额外的安全层级现已在我们的 BigQuery 数据源 配置中 正式支持，可有效防止令牌泄露后被滥用。目前该功能已全面开放。\n你可以通过我们的 插件目录 或这篇 最新博客文章 深入了解 Grafana 中 BigQuery 数据源的使用方式。\n如需查看 Grafana 中全部新增功能，请参阅我们的 官方文档、更新日志，或 新版亮点文档。\n","date":"2025-07-29T14:34:27+08:00","image":"https://martinliu.cn/blog/grafana-12-1-release-all-the-latest-features/grafana-12.1-meta_hu_678aa6284acf68d7.png","permalink":"https://martinliu.cn/blog/grafana-12-1-release-all-the-latest-features/","title":"Grafana 12.1 正式发布！"},{"content":"✨ TL;DR — 一套真正可用的本地 DevOps 技术栈 问题：云端 DevOps 费用高、迭代慢，还难调试。\n解决方案：用 Docker Compose 跑起来的一套完整 DevOps 技术栈，全部本地化。\n核心组件包括： Jenkins（CI/CD） Prometheus + Grafana（监控） Loki + Promtail（日志聚合） NGINX / Traefik（反向代理） Mailhog（邮件测试） Postgres + Redis（辅助服务） 我的经验总结： 从小起步，逐步扩展。 固定版本，避免意外变更。 健康检查能救命。 Docker Compose 胜过过早引入 Kubernetes。 养成写“技术栈日志”的习惯。 我的需求其实很简单。\n我只想要一个稳的 CI 流水线、一套能看懂的监控指标，以及在部署前能本地测试全部功能的方式，不必再为云服务花冤枉钱。\n结果呢？Jenkins 启动就挂，Prometheus 抓不到数据，Docker Compose 日志铺天盖地像在写小说。\n我差点放弃。但在无数次试错、两次烧坏电脑，还有通宵翻遍 DevOps 博客之后，我终于搞出了一套真的能用的本地环境。\n不用 Kubernetes。不付 AWS 账单。没有凌晨四点的 Slack 报警。\n这不是教程，而是我自己打磨出来的生存指南，你完全可以照着用。🤝\n什么才是 DevOps 技术栈（本地，而非理论） 提到 DevOps，大多数人想到的是云原生架构、Kubernetes 自动扩容集群，还有那种比房租还贵的精美仪表盘。但如果你是独立开发者、在搞实验，或只是想学习而不影响线上环境，你需要的，是能直接在自己电脑上跑的东西。\n对我来说，一个“本地优先”的 DevOps 技术栈应该包含：\nDocker： 容器的基础设施。所有服务都运行在容器里，包括 Jenkins 和 Prometheus。 Jenkins： 仍然是最灵活的 CI/CD 引擎。虽说有点老派，但用得好依然顶用。 Prometheus + Grafana： 用于采集与可视化监控指标。Prometheus 负责抓，Grafana 负责看。 Loki： 日志聚合利器。因为容器一多，docker logs 根本不够用。 NGINX 或 Traefik： 做反向代理，把多个服务统一映射到本地域名下。 Mailhog / Redis / Postgres： 可选组件，用于测试邮件、缓存或数据库相关功能。 这就是基础配置。没有 AWS，没有 GCP，也不用托管的 EKS。只有 容器、端口，以及偶尔崩溃的终端窗口。\n让我豁然开朗的 docker-compose.yml 配置 谈本地 DevOps，绕不开 docker-compose.yml。它是整个系统的指挥中枢，决定了你是轻松一键部署，还是陷入无尽的手动操作噩梦。\n下面是我用的一个简化版本配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 version: \u0026#34;3.8\u0026#34; services: jenkins: image: jenkins/jenkins:lts-jdk17 ports: - \u0026#34;8080:8080\u0026#34; volumes: - jenkins_home:/var/jenkins_home prometheus: image: prom/prometheus ports: - \u0026#34;9090:9090\u0026#34; volumes: - ./prometheus.yml:/etc/prometheus/prometheus.yml grafana: image: grafana/grafana ports: - \u0026#34;3000:3000\u0026#34; volumes: - grafana_data:/var/lib/grafana loki: image: grafana/loki:2.9.0 ports: - \u0026#34;3100:3100\u0026#34; command: -config.file=/etc/loki/local-config.yaml nginx: image: nginx:stable ports: - \u0026#34;80:80\u0026#34; volumes: - ./nginx.conf:/etc/nginx/nginx.conf mailhog: image: mailhog/mailhog ports: - \u0026#34;8025:8025\u0026#34; - \u0026#34;1025:1025\u0026#34; redis: image: redis ports: - \u0026#34;6379:6379\u0026#34; postgres: image: postgres:14 ports: - \u0026#34;5432:5432\u0026#34; environment: POSTGRES_USER: dev POSTGRES_PASSWORD: dev POSTGRES_DB: app_db volumes: - pgdata:/var/lib/postgresql/data volumes: jenkins_home: grafana_data: pgdata: 让我少走弯路的配置笔记 分离 .env 文件：不要在配置中硬编码密钥或端口。 挂载配置文件：Prometheus 和 NGINX 的配置最好通过挂载方式管理，方便随时调整。 状态服务使用数据卷：Jenkins、Grafana、Postgres 等需要持久化的服务应该使用数据卷。 尽量避免使用 depends_on：它不会真正等待服务就绪。建议用 restart: unless-stopped 配合健康检查来提升稳定性。 这套配置让我可以放心地搭建和试验。每个服务都在容器里运行，出问题直接重建，简单又高效。\n我的本地 DevOps 文件结构（也就是理智的来源） 尝试了多个混乱结构之后，我最终找到了这样一套清晰、模块化的目录布局，让调试更高效。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /devops-stack ├── docker-compose.yml ├── .env ├── README.md ├── prometheus/ │ └── prometheus.yml ├── grafana/ │ └── provisioning/ │ ├── datasources/ │ └── dashboards/ ├── loki/ │ └── local-config.yaml ├── nginx/ │ └── nginx.conf ├── jenkins/ │ └── jobs/ │ └── sample-job.groovy ├── volumes/ │ ├── grafana/ │ ├── jenkins/ │ └── postgres/ └── logs/ └── stack.log 为什么这套结构有效？ 🔹 prometheus/ 自定义抓取配置都放在这里。我用 Git 做版本管理，便于追踪每次修改。 🔹 grafana/provisioning/ 通过这个目录预配置仪表盘和数据源，重建容器时无需手动重复设置。 🔹 loki/ Loki 的 local-config.yaml 存放位置。如果你聚合多个容器日志，这个配置经常需要调整。 🔹 nginx/ 将代理配置从项目根目录独立出来，便于快速热更新和测试路由变更。 🔹 jenkins/jobs/ 用于保存流水线定义、Groovy 脚本或种子任务，比每次在 Jenkins UI 操作方便得多。 🔹 volumes/ 可选目录，用于挂载持久化数据。无需深入 Docker 内部也能查看状态数据。 🔹 logs/ 集中存放容器日志或自定义输出，调试更高效。特别是在 Promtail 表现不稳定时很有用。 如果重来一次，我会这样做： 1. 不要从 Jenkins 起步 Jenkins 虽然强大，但太笨重。如果你只是想学习 CI/CD，建议先从 GitHub Actions（可通过 act 本地运行）或 Drone CI 开始。Jenkins 附带插件多、配置烦人，还有那些让人头大的 XML 配置文件（Extensible Markup Language）。\n2. 不要过度设计监控 就算你是为了跑个博客，也没必要一开始就上 Prometheus + Grafana + Loki + Tempo。先用简单的日志输出（docker logs，或者加个 Mailhog）起步，有需要时再慢慢加监控。\n3. 坚持用 Docker Compose 我曾花了好几天尝试 Minikube、Kind 和 Kubernetes，结果发现其实一个靠谱的 docker-compose.yml 足以应付本地需求。除非你要部署到云上或准备考 Kubernetes 认证，不然 K8s 只会拖慢你的前期学习节奏。\n4. 保持“技术栈日志” 每次出错或修好 bug，我都会记一笔。这份日志成了我的生存手册，也成了这篇文章的基础。强烈推荐你也开始记录，真的有用。\n复制即用：最简本地 DevOps 技术栈 如果你读到这里心想“我就想马上试一把”，下面就是你需要的——一套最小可行的 DevOps 技术栈：\n1 2 mkdir devops-mini \u0026amp;\u0026amp; cd devops-mini touch docker-compose.yml 编辑 docker-compose.yml 文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 version: \u0026#39;3.8\u0026#39; services: jenkins: image: jenkins/jenkins:lts-jdk17 ports: - \u0026#34;8080:8080\u0026#34; volumes: - jenkins_home:/var/jenkins_home grafana: image: grafana/grafana ports: - \u0026#34;3000:3000\u0026#34; volumes: jenkins_home: 启动本地技术栈。\n1 docker compose up -d 搞定了。CI + 监控，完全本地，不靠云。\n等你准备好折腾时，再加上 Postgres、Redis、Loki、Prometheus 或 NGINX。\n放心，总会出点问题。\n收尾：搭建它，搞崩它，掌握它 搭一套本地 DevOps 技术栈并不轻松、不优雅，更不会很快。\n但这个过程教会我的，比任何云服务仪表盘或 YouTube 教程都更接近真实世界。\n当你亲手跑 Jenkins、从头配置 Grafana 仪表盘、或者搞清楚容器间为什么无法通信时，\n你就不再只是执行脚本的人，而是真的开始具备系统工程师的思维了。\n所以，如果你还在等 CI 部署完成，或厌倦了在黑盒云服务里调 bug……\n🔥 自己动手搭一套。搞崩它。修复它。大胆去学。\n如果这篇文章哪怕帮到你一点点， 点个赞、写评论、转发一下。 让更多开发者不再害怕从零搭建基础架构。\nsource: Medium - Level Up Coding\n","date":"2025-07-28T17:58:33+08:00","image":"https://martinliu.cn/blog/docker-jenkins-prometheus-locally-heres-the-stack/1_izxF5LhLRecc_epDuvJmhg_hu_1be583b724238b98.png","permalink":"https://martinliu.cn/blog/docker-jenkins-prometheus-locally-heres-the-stack/","title":"Docker、Jenkins、Prometheus，本地能跑？！这套技术栈你需要搞定"},{"content":"Source: Denys Vasyliev @ The New Stack\nSRE 必须构建值得信赖的 AI 系统，充分利用不断涌现的工具与标准化生态。\n当 Clayton Coleman 的这句话在 KubeCon 北美大会上被引用时，引发了强烈共鸣。仅仅五年前，问一位站点可靠性工程师（Site Reliability Engineer，SRE）他们的职责，回答通常围绕着让 Web 应用保持高性能、具备可扩展性和高可用性。而如今，整个技术格局已然发生深刻变化。AI 推理（Inference）工作负载——即训练完成的模型基于所学知识对新数据做出预测的过程——正逐渐成为像 Web 应用一样关键的核心系统。\n“Inference——是指模型在推理阶段将其学到的模式应用于此前未见的数据，以生成预测或决策。在这个过程中，模型会利用其已有的知识，对来自真实世界的输入进行响应。”\n这种演变催生了一个全新的工程领域：AI 可靠性工程（AI Reliability Engineering，AIRe）。我们面临的挑战早已不再是 HTTP 请求的延迟，而是如何减少大语言模型（LLM）在生成标记（token）时的卡顿。优化数据库查询显得有些传统，如今我们更需要关注如何提升模型的检查点（checkpoint）恢复效率和张量（tensor）处理性能。AI 模型，正如曾经的 Web 应用那样，也需要卓越的可扩展性、可靠性和可观测性——而这些能力的架构工作仍在持续进行中。\n我已经深入从事 AI 可靠性工程近两年，专注于研究、原型设计，并构建实际的推理系统。从 DevOps 各类大会到 SRE Days，再到纽伦堡和伦敦的社区聚会，我不断与行业同行交流实践经验。现在，我希望在这里将这些珍贵的洞察与你分享。\n不可靠的 AI，甚至比没有 AI 更危险。\n推理（Inference） 不仅仅是模型的运行过程，它是一门独立的运维工程学科，具备独特的架构抉择与工程范式。与训练阶段可以容忍时间与成本不同，推理处于生产的关键链路上，每一毫秒都可能影响最终体验。 实时 vs 批量：推理运行方式主要分为实时（也称在线）和批量（离线）两种。实时推理支撑着聊天机器人、欺诈检测和自动驾驶等对低延迟有严苛要求的应用；而批量推理则周期性地处理大规模数据集，用于图像识别、日志分析或趋势预测等场景。 资源特征：尽管相较训练更轻量，推理依然对性能要求极高。尤其在实时场景下，既需要快速计算，也要求基础设施具备高可用性。尽管 CPU 仍有用武之地，但现代推理系统越来越依赖 GPU、TPU，或专用芯片（如 AWS Inferentia、NVIDIA TensorRT）以实现极低延迟。 部署环境：推理部署可以无处不在，从边缘设备到云端超大规模集群。你可以在 Serverless 端点、Kubernetes 集群，甚至微型 IoT 模块中找到它的身影。SageMaker、Vertex AI、Hugging Face 和 Together.ai 等平台让部署变得更轻松，但最终选择仍需在成本、控制力和延迟之间权衡。 性能优化手册(Playbook)：性能与效率的挑战从未止步。团队广泛应用量化（例如将 FP32 精度转为 INT8）、模型蒸馏和神经架构搜索（Neural Architecture Search，NAS）等技术，以尽可能在不牺牲结果质量的前提下，打造更小、更快、更高效的推理引擎。 可观测性与监控：传统遥测系统难以满足需求。推理系统需要更精细的可观测性，涵盖预测延迟、token（标记）吞吐量、数据漂移，甚至模型幻觉（即生成虚假信息）的比率。OpenTelemetry、Prometheus 和专为 AI 打造的追踪工具如今已成为基础设施标配。 可扩展性：推理流量不可预期，经常随着用户行为剧烈波动。因此需要通过 Kubernetes HPA、Cloud Run 实现高效自动扩容，并结合 Envoy、Istio、KServe 等实现智能流量调度，以确保系统始终从容应对。 安全防线：AI 推理引入了新的安全挑战，包括对抗性输入攻击与潜在的数据泄露。工程师必须将模型端点像保护 API 端点一样严格防御，实施身份验证、访问频率限制、数据加密以及运行时完整性验证。 推理已不再是机器学习的附属过程。它就是核心应用。它就是生产环境。而它也正在重塑整套运维架构体系。\n传统的 SRE 原则虽为 AI 提供了基础，但已难以满足它的独特需求。\n模型的不确定性本质：与典型的 Web 应用不同，AI 模型不是确定性的。同一个输入可能会产生不同结果。一个模型即便系统运行稳定、没有宕机，也可能输出错误、有偏差甚至荒谬的内容——这彻底颠覆了我们对“可靠性”的传统认知。 评估标准正在变化：光靠“可用性 SLA”已远远不够。我们需要引入 准确性 SLA 的新范式，通过精确率、召回率、公平性以及模型漂移等维度，来衡量模型在实际环境下的表现。 基础设施变革：随着 AI 工作负载的出现，传统的架构设计也在演进。像 Ingress、水平 Pod 自动扩缩（HPA）这些概念，正逐步被模型网格（Model Mesh）、LoRa 负载均衡、AI 网关等新技术所取代，尤其是在 GPU 资源密集的场景下尤为关键。Kubernetes 社区也在持续演进，推动包括“Serving 工作组”、动态资源分配（DRA）以及 Gateway API 等机制，以支持 AI 推理的特殊需求。 可观测性的盲区：传统监控工具擅长监测 CPU、内存和响应延迟，但面对 AI 模型中的置信度、漂移情况，甚至幻觉（即模型生成虚假内容的倾向）等问题，常常无能为力。我们亟需构建 AI 专用的可观测性体系。 新型故障模式：现在的问题已不再是“系统崩溃”，而是更隐蔽的“模型静默退化”。这种退化通常不会立刻显现故障，但模型的准确性、公平性会在不知不觉中下降，输出越来越偏离预期。将这种变化当作严重生产事故来看待，需要全新的监测机制和响应工具。 模型衰减（Model Decay）——也称为 模型静默退化（Silent model degradation），不同于传统软件的崩溃报错，它表现为模型持续运行但输出质量悄然下降，可能变得不准确、带偏见或逻辑不一致。这种无声的“故障”，往往更难察觉也更难解决。\n我们为何将模型静默退化当作生产级事故来看待？\n因为它本质上就是\u0026quot;silent failure\u0026quot;。与崩溃的 Pod 或无法响应的 API 不同，模型静默退化是悄无声息的——系统仍能正常响应请求，但返回的答案可能越来越模糊、偏颇甚至完全错误。用户不会看到直观的 500 错误页面，而是遇到“幻觉式”输出、有害内容，或基于错误数据做出的决策。这不只是代码 bug，更是对用户信任的严重破坏。在 AI 世界里，“正确性”本身就等同于可用性（uptime）。当“可靠性”意味着输出质量时，模型退化——就是宕机。\n我们或许不仅要为 AI 扩展 Kubernetes —— 甚至终有一天，我们不得不为它另起炉灶（fork）。\n大语言模型（Large Language Models，LLMs）对流量路由、速率限制和安全防护提出了前所未有的要求，而这些功能并非 Kubernetes Ingress 机制的设计初衷。Kubernetes 架构自诞生以来就是围绕无状态 Web 应用打造的，推理场景从未被列为核心用例。尽管 Kubernetes 社区正积极适配，但关键差距依然存在。\n推理工作负载需要更紧密集成的架构支持：既包括对 GPU/TPU 等硬件加速器的原生支持，也涵盖资源编排与高并发流控能力。为此，Kubernetes 正在推进多个项目，如 WG-Serving（针对 AI/ML 推理优化）、设备管理（通过 DRA 动态资源分配集成加速器），以及 Gateway API 推理扩展，这些都在为 LLM 的规模化、可靠路由打下基础。与此同时，新一代 AI 网关也应运而生，提供专为推理定制的流量控制、可观测性和权限管理能力。\n但归根结底，我们仍是在一个“原本不是为 AI 而生”的编排平台上进行集成工作。Google 最近宣布，将 Kubernetes 的 etcd 存储引擎替换为基于 Spanner 的架构后，成功实现了单集群支持 65,000 节点的能力，这或许预示着未来我们不仅需要对 Kubernetes 进行功能扩展，甚至可能要彻底分叉（fork）一个属于 AI 推理的基础平台。\n那么，面对全新的 AI 现实，我们应如何实践 SRE 理念？\n制定面向 AI 的服务目标与承诺（SLO/SLA）： 传统的可用性指标已不足以衡量 AI 系统的可靠性。我们需要将准确性、公平性、延迟和模型漂移纳入考量，制定清晰的服务等级协议（SLA）。例如 TTFT（生成首个 token 的响应时间）、TPOT（每个输出 token 的平均生成时间）、准确率或偏差范围等，都是需要量化承诺的核心指标。 打造 AI 专属的可观测体系： 在使用 OpenTelemetry、Grafana 等常规监控工具的基础上，结合 OpenInference 等 AI 专用追踪与评估平台，实现对模型响应分布、置信度评分和错误类型（如幻觉）的深入监测。 建立 AI 故障应急机制： AI 系统可能出现特有问题，如突发的预测漂移或偏差上升。因此，我们需要制定专门的应急预案（playbook），包括模型自动回滚至稳定版本，或启用 AI 熔断机制，以保障系统稳定性。 兼顾扩展性与安全性进行架构设计： 可通过模型副本负载均衡、缓存机制、GPU 调度优化（Kubernetes 仍在演进中）及 AI 网关等技术，管理推理流量并加强安全性。安全机制可涵盖基于 token 的限速、语义缓存与访问权限控制。同时，还需通过模型来源追踪、安全交付与运行时监控，确保模型始终可信、稳定。 构建持续评估机制： 模型评估不应只在部署前完成。它应覆盖部署前的离线测试、上线前的影子测试与 A/B 测试，以及部署后的实时监控，持续检测模型是否出现性能漂移或精度退化。 AI 网关：SRE 在 AI 时代的核心工具 在 SRE 发展的初期阶段，我们依靠负载均衡器、服务网格和 API 网关来管理流量、执行安全策略，并实现系统可观测性。而如今，AI 推理带来的工作负载同样需要这些能力——但复杂度更高，规模更大，且容不得半点延迟或错误。这就是 AI 网关登场的时刻。\n你可以把它理解为现代 SRE 面对 AI 系统的一站式解决方案：它能将请求精准路由到正确的模型、在多个副本间实现高效负载均衡、实施速率限制与安全策略，并集成深度可观测性机制。像 Gloo AI Gateway 这样的项目正是这一领域的先锋，专注解决企业在 AI 落地中遇到的关键难题，如模型成本控制、基于 token 的权限机制、以及对 LLM 响应的实时追踪分析——这些都是传统服务网格难以胜任的。\n这就是当代 SRE 的新定位：不仅要调节自动扩缩容机制，还要掌控 AI 系统的控制平面（control plane），成为智能系统运行的核心操盘手。\nAI 网关不仅是 SRE 新工具箱中的一员——它或许是最关键的那一个。\nSRE 的第三个时代：AI 可靠性工程 SRE 的角色正在发生深刻转变。我们需要的是《97 条 SRE 必知法则》书中所强调的那种探索精神——对整个系统的深入理解，从芯片层的硬件架构到模型输出背后的微妙机制。我们要构建值得信赖的 AI 系统，并借助不断成熟的工具链与标准体系来实现这一目标。\nBjörn Rabenstein 曾提到 SRE 正步入“第三个时代”，一个其原则将全面融入系统建设的阶段。确实如此，但推动这个新时代到来的，不再是传统系统的演进，而是 AI 的崛起。AI 可靠性工程（AI Reliability Engineering）不仅仅是传统 SRE 的延伸，它代表了一次根本性的范式转移：从关注“基础设施是否可靠”，走向“智能系统本身是否可信”。\n","date":"2025-07-27T09:44:13+08:00","image":"https://martinliu.cn/blog/ai-reliability-engineering-welcome-to-the-third-age-of-sre/afadfd03-nasik-lababan-auk3gkpv6u-unsplash-1024x683_hu_3b6796769b0c4478.jpg","permalink":"https://martinliu.cn/blog/ai-reliability-engineering-welcome-to-the-third-age-of-sre/","title":"欢迎进入 SRE 的第三纪元 - AI 可靠性工程"},{"content":"背景 自 MacMini M4 上市来，其丐版在京东上一直很抢手，定时抢了几次，未果。然除夕大清早，见有货，遂下单，初二终于到货。所谓丐版 Mac Mini M4 有 10 核 10 线程，16GB 内存，256GB SSD，订单价格 3581.21 元，国补 + 京东 Plus 会员优惠后的价格，性价比颇高。我将抛弃之前的 HomeLab 设备，用 Mac Mini M4 来重构 HomeLab 的结构。\n运行 Deepseek-r1 大模型（7b\u0026amp;14b） 被 Deepseek 新闻轰炸了数日，必将其在 Mac Mini M4 上测一下。首先需要下载并安装 ollama 应用，然后下载并运行该模型，并于命令行问一个问题 “macmini m4 适合使用什么参数规模的 Deepseek 模型?”。\n1 2 3 4 5 6 7 8 9 10 11 12 13 martinliu@Mac-mini ~ % ollama pull deepseek-r1:7b pulling manifest pulling 96c415656d37... 100% ▕███████████████████████████████████████████████████████████████████▏ 4.7 GB pulling 369ca498f347... 100% ▕███████████████████████████████████████████████████████████████████▏ 387 B pulling 6e4c38e1172f... 100% ▕███████████████████████████████████████████████████████████████████▏ 1.1 KB pulling f4d24e9138dd... 100% ▕███████████████████████████████████████████████████████████████████▏ 148 B pulling 40fb844194b2... 100% ▕███████████████████████████████████████████████████████████████████▏ 487 B verifying sha256 digest writing manifest success martinliu@Mac-mini ~ % ollama run deepseek-r1:7b \u0026gt;\u0026gt;\u0026gt; macmini m4 适合使用什么参数规模的 Deepseek 模型? ollama 下载和运行任何模型都很简单，用下面两条命令即可：\nollama pull deepseek-r1:7b：下载 Deepseek-r1 7b 模型。 ollama run deepseek-r1:7b：运行 Deepseek-r1 7b 模型。 我的第一个问题，并未说 Mac Mini 是何配置，而且问的比较模糊，点这里查看答案全文。\n答案的结论：Mac mini M4 在适合运行 DeepSeek 的 7B 和 13B 参数规模的模型上表现良好。虽然没有独立显卡，但其强大的计算能力和 macOS 系统的支持使其能够处理这些较大的模型。然而，需考虑系统的资源和应用兼容性，并根据个人需求评估是否值得投资。\n测试失败，居然这个模型不知道：自己有 7b ，但没有 13b 这个规格的模型。此回复过程在 10 秒钟左右，并不慢。\n顺便推荐一个命令行性能监控工具 “btop” （在 macos 上安装命令 ‘brew install btop’），可以实时监控 CPU 和内存的使用情况，貌似在这 10 多秒的过程中，CPU 使用率没有丝毫的波动，内存使用率在 70%左右。\n因首个问答即失败，所以下载 14b 的模型，希望能有足够回答问题的能力。为了在 7b 和 14b 之间做对比，所以在下载 14b 模型前，先对 7b 提出这个相同的问题 “SRE 和 DevOps 的区别和相同之处是什么?一个企业应该先做哪个?”。\n7b 模型的答案点这里。很遗憾，7b 模型一开口就把 SRE 名词解释错误了“SRE（Service-Providing Software Engineering）” 14b 模型的答案点这里，不得不说 14b 模型的答案令我满意了。 为家庭局域网提供大模型服务 Open WebUI 是个不错的选项。在 Mac Mini M4 上安装 Open WebUI 也很简单，只需运行下面的命令即可：\n1 docker run -d -p 9005:8080 -e WEBUI_AUTH=False --add-host=host.docker.internal:host-gateway -v ./open-webui-data:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main 参数解释：\n-d：后台运行。 -p 9005:8080：将容器的 8080 端口映射到主机的 9005 端口。 -e WEBUI_AUTH=False：关闭 WebUI 的认证。 --add-host=host.docker.internal:host-gateway：解决容器内无法访问主机的问题。 -v ./open-webui-data:/app/backend/data：将容器内的数据目录映射到主机的 ./open-webui-data 目录。 --name open-webui：指定容器的名称为 open-webui。 --restart always：容器退出时自动重启。 ghcr.io/open-webui/open-webui:main：指定容器的镜像。 然后就可以在浏览器中访问 http://192.168.31.6:9005 来使用 Open WebUI 了。\nOpen WebUI 可以识别出我在后台容器中运行的 Deepseek-r1 14b 模型，它提供了基于网页的问答互动界面，而且对具有政治倾向的问题，回答的不置可否，体现出非常谨慎的态度。\n下面是在手机端问的另外一个问题，回答是令我满意的。\n也就是说：局域网中的任何移动设备和电脑，都可以通过浏览器访问 Open WebUI，来使用 Deepseek-r1 14b 模型。\n用 OrbStack 运行容器服务 OrbStack 在我的 MacBook Pro 上已经使用了一段时间了，已经平替了 Docker Desktop。而且和一众其它的 K8s 管理工具，包括 MiniKube、Kind 等。个人的一些使用经验总结：\nOrbStack 项目的编程语言有： Go Swift C Rust，它本身启动速度快，轻量。是苹果原生应用。比 Docker Desktop 占用的资源少非常多。 创建虚拟机的创建速度飞快，通过预下载的虚拟机镜像文件，结合 cloud-init.yaml 文件，可以在几秒钟内创建一个任意配置的新的虚拟机。 虚拟机和容器里的文件系统，都可以通过 Finder 直接访问，非常方便。而且在虚拟机内的 /mnt/ 目录下也能访问到主机的文件系统。 可以用 SSH 直接无密码登录虚拟机。 容器和虚拟机都无缝衔接 Host 上的网络，并共享科学上网的功能。在也不会下载不到容器镜像了。 自动识别 Docker 和 K8s 中的服务定义，并提供本机可信的 HTTPS 证书，实现 HTTPS 访问。可以很方便的进行开发和测试。 基于此，我决定在 Mac Mini M4 上安装 OrbStack，用它来管理所有需要长运行的服务。不过我做了一些定制化的配置：\n如果用它运行各种 HomeLab 的网络服务，那么存储空间是需要扩展的。我在 Mac Mini M4 上用雷电4 接口连了普通的硬盘盒，内置 2TB 的 NVME 硬盘，实践表明性价比足够用了。 将 OrbStack 的默认存储空间设置为外置硬盘，这样可以避免内置硬盘的频繁读写，延长其寿命。而且外置硬盘的容量更大，可以存储更多的数据。 在 K8s 和 Docker 之间，我做了一个选择，决定在 Mac Mini M4 上只运行 Docker 容器，而不运行 K8s 集群。因为我觉得 Docker 容器更加轻量，更加简单，后续软件的升级和数据迁移也都更加方便。用 Docker Compose 的方式运行服务，尽量将持久化数据和配置文件放在外置硬盘上，这样即使机器挂了，数据也不会丢失，而且更方便做升级和迁移。 娱乐功能 首先，我将使用率较低的两只立体声音箱，通过 Mac Mini M4 的耳机接口，用音频线链接起来了。这样它就变成了一个 AirPlay 推流的目标。在 MacBook Pro 或者 iPhone 上，我可以通过 AirPlay 将音乐推送到 Mac Mini M4 上，然后通过音箱播放出来。这样，房间里就可以很方便的播放各种背景音乐了。音量可音箱上，在 MacBook 上，或者在 iPhone 上都可以调节。\n从 Macbook 上推流音乐的方式是：打开苹果自家的 Music 软件，导入喜欢听的音乐文件，然后在播放界面，点击右上角的 AirPlay 图标，选择 Mac Mini M4，然后就可以听到音乐了。\n从 iPhone 上可以通过屏幕镜像的功能，将任何视频或者音频 App 的声音推送到 Mac Mini M4 上。这样就可以在 Mac Mini M4 上播放 iPhone 上的任何音乐或者视频的声音了。\n总结 Mac Mini M4 作为 HomeLab 的核心设备，性价比很高。在增加了外置磁盘空间后，它的性能和容量都可以作为长期运行的低功耗服务器使用。另外，我从即将淘汰的服务器中，拼装了一台开放机箱的 PVE 服务器，它有一颗 12 core 的 Xeon E5 CPU ，有 128GB 内存，有 1 块 520GB 的 NVME 硬盘，还有 4 块总容量为 3TB 的 SSD 硬盘。这台 PVE 上的所有虚拟机和 LXC 都可以访问到 Mac Mini M4 上的所有服务，这样就可以实现资源的共享和互通。PVE 服务器在需要使用的时候，可以开机，不需要的时候，可以关机。未来，我可能只会保留 Mac Mini M4 和这台 PVE 服务器，其它的设备都会被淘汰到海鲜市场。\n","date":"2025-01-31T10:03:16+08:00","image":"https://martinliu.cn/blog/macmini-m4-homelab-redesign/mac-mini-with-ext-nvme-drive_hu_42c2a8e3d5236dd8.jpg","permalink":"https://martinliu.cn/blog/macmini-m4-homelab-redesign/","title":"用 Mac Mini M4 重构 HomeLab 结构"},{"content":"在 Docker 环境中，容器和卷的空间占用可能会随着时间的推移而增长，导致磁盘空间不足。本文将介绍如何寻找占用空间最大的容器，并删除它们使用的卷，以释放磁盘空间。\n在 Azure 的环境中，我使用了 Portainer 来管理这个服务器上的所有容器。Portainer 在发生某种未知的故障后，在一段时间中产生了大量的错误日志，导致它所占用的数据卷空间暴涨，以至于沾满了所有可用磁盘空间，最后整个服务器上的所有其他容器都不工作了。\n下面是解决这个运维故障的过程中的一些笔记，希望对读者有所帮助。\n1. 查找占用空间最大的容器 查看容器日志文件的大小 容器的日志文件通常会占用大量磁盘空间。可以通过以下命令查找 Docker 容器日志文件的大小：\n1 find /var/lib/docker/containers/ -type f -name \u0026#34;*.log\u0026#34; -exec du -h {} + | sort -hr | head -n 10 该命令会列出所有容器日志文件的大小，并按从大到小排序。你可以通过查看输出结果，找出占用空间最大的容器日志文件。\n查看容器的挂载数据大小 除了日志文件，容器的挂载数据（例如文件系统层）也可能占用大量空间。要查看某个容器的挂载数据大小，可以使用以下命令：\n1 docker ps -a --size 该命令将列出所有容器及其占用的磁盘空间。通过 SIZE 列，你可以查看每个容器的磁盘使用情况，并根据需要找出占用空间最大的容器。\n2. 停止并删除容器 找到占用空间大的容器后，下一步是停止并删除它。\n停止容器 首先，停止正在运行的容器：\n1 docker stop \u0026lt;container-id_or_name\u0026gt; 删除容器 容器停止后，可以通过以下命令删除容器：\n1 docker rm \u0026lt;container-id_or_name\u0026gt; 3. 删除容器使用的卷 容器删除后，挂载的卷可能依然存在并占用磁盘空间。要删除容器使用的卷，请按照以下步骤操作：\n查看容器使用的卷 你可以使用以下命令查看容器使用的卷：\n1 docker inspect \u0026lt;container-id_or_name\u0026gt; | grep Mounts -A 10 这将输出容器的挂载信息，包括挂载的卷。你可以根据输出的信息找出容器使用的卷。\n删除卷 如果确定不再需要该卷，可以删除它：\n1 docker volume rm \u0026lt;volume-name\u0026gt; 如果不确定卷是否仍然被其他容器使用，可以先列出所有卷并检查未使用的卷：\n1 docker volume ls 删除所有未使用的卷 如果你想删除所有没有挂载到容器的卷，可以使用以下命令：\n1 docker volume prune 该命令将删除所有未挂载的卷，释放磁盘空间。\n4. 释放卷占用的空间 如果某个卷占用了大量空间（例如 portainer_data 卷占用了 54G 空间），可以先检查卷的内容，并根据需要删除不必要的数据。\n检查卷的内容 可以进入卷的 _data 目录查看它的内容：\n1 ls -l /var/lib/docker/volumes/portainer_data/_data 删除卷中的数据 如果确认不再需要卷中的数据，可以删除这些数据：\n1 rm -rf /var/lib/docker/volumes/portainer_data/_data/* 这将删除卷中的所有数据。\n删除卷 数据删除后，可以删除整个卷：\n1 docker volume rm portainer_data 如果你不再需要该卷，删除它将释放空间。\n5. 自动清理 Docker 系统资源 为了避免未来容器和卷占用过多磁盘空间，可以定期清理 Docker 的未使用资源。你可以使用 docker system prune 命令来删除所有未使用的容器、镜像、网络和卷。\n清理所有未使用的资源 1 docker system prune -a --volumes -a 参数表示删除所有未使用的镜像。 --volumes 参数表示删除所有未挂载的卷。 此命令会清理 Docker 系统中的所有不再使用的资源，释放磁盘空间。\n6. 检查释放后的空间 完成清理操作后，可以通过以下命令检查卷是否已经释放空间：\n1 du -sh /var/lib/docker/volumes/portainer_data 如果卷中的数据已被删除，空间占用应当会显著减少。\n总结 查找占用空间大的容器： 查看容器日志文件和挂载数据的大小。 停止并删除容器： 使用 docker stop 和 docker rm 停止并删除容器。 删除容器使用的卷： 使用 docker volume rm 删除不再需要的卷。 使用 docker volume prune 清理未使用的卷。 释放卷占用的空间： 删除卷中的数据，或者删除整个卷。 定期清理 Docker 系统资源： 使用 docker system prune -a --volumes 清理所有未使用的资源。 通过这些操作，你可以有效地管理 Docker 容器和卷，确保磁盘空间不会被占用过多，保持系统的清洁和高效。\n参考 Docker Documentation Docker CLI Reference ","date":"2024-11-13T22:44:45+08:00","image":"https://martinliu.cn/blog/identify-clean-up-large-docker-containers-volumes/91625BFA-9860-451D-B947-558D4B63D207_hu_100a194a1cc14a1c.jpg","permalink":"https://martinliu.cn/blog/identify-clean-up-large-docker-containers-volumes/","title":"如何寻找占用空间最大的容器，并删除它所使用的卷，释放占用的空间？"},{"content":" 作者 Nathen Harvey （DORA Lead），Derek DeBellis （DORA 研究项目负责人）\n下载中文版报告 PDF 文件\nDORA 研究项目已经对高绩效技术团队和组织的能力、实践和度量标准进行了长达十多年的研究。该项目基于每年对技术人员（包括软件开发人员、管理者和高管）的调查数据发布报告。\n今天，我们正式发布《2024 年 加速：DevOps 现状报告》，标志着 DORA 已经在高绩效技术团队和组织的研究领域持续了十年。DORA 在 2013 年提出的四项关键指标已成为衡量软件交付绩效的行业标准。\n每年，我们都深入研究 DORA 标准绩效指标，并探索它们如何与个人、工作流、团队和产品绩效相互作用。今年，我们还新增了 AI 采用在各个层面上对软件开发影响的分析。\n我们每年设立基准，帮助团队了解他们相对于同行的表现，并激励他们认识到每个行业都可以实现卓越的表现。DORA 过去十年的研究旨在帮助团队不断提升自身的能力，力求每年改进都能取得更大进展。\n如果想快速了解今年的报告内容，可以阅读我们的 DORA 报告摘要，聚焦于技术采用趋势、AI 的影响、平台工程的兴起，以及开发者体验的重要性。\n各行业的组织都在优先考虑将 AI 集成到应用和服务中。开发人员越来越依赖 AI 提高工作效率，并更好地履行其核心职责。今年的研究揭示了 AI 采用带来的复杂利弊和权衡。\n报告强调平台工程需要慎重实施，并指出开发者体验在实现高绩效中的关键作用。\nAI 的优势、挑战与信任建设 AI 的广泛应用正在改变软件开发方式。超过 75% 的受访者表示，他们在日常工作中至少有一个职责依赖于 AI。最常见的使用场景包括代码编写、信息总结和代码解释。\n报告显示，AI 有效地提升了开发人员的生产力。超过三分之一的受访者表示，AI 为他们带来了“中等”到“极大”的生产力提升。\nAI 采用率提升 25% 带来了几个关键领域的改进：\n文档质量提升 7.5% 代码质量提升 3.4% 代码审查速度提升 3.1% 然而，尽管 AI 有其优势，我们的研究也发现了一个重要问题：AI 采用可能对软件交付绩效产生负面影响。随着 AI 应用的增加，软件交付吞吐量估计下降了 1.5%，交付稳定性下降了 7.2%。我们的数据显示，仅改进开发流程并不足以自动提升交付绩效，尤其是在没有遵循如小批量处理和完善测试机制等基本原则的情况下。虽然 AI 对个人和组织的多个方面有积极影响，为高软件交付绩效创造了条件，但它并非万能的解决方案。\n此外，尽管生产力有所提升，39% 的受访者对 AI 生成的代码仍缺乏信任。这一低信任度表明，AI 的集成需要更加谨慎的管理。团队必须仔细评估 AI 在开发流程中的作用，以减轻潜在的负面影响。\n基于以上发现，我们提出三项核心建议：\n通过调整 AI 采用策略，使其更好地赋能员工，减少繁琐任务，从而提升员工的工作效率。 制定明确的 AI 使用规范，解决相关程序问题，并鼓励就其影响进行公开讨论。 鼓励团队持续探索 AI 工具，并提供实验时间，以通过实际操作建立信任感。 平台工程：新的转变 我们今年研究的另一个新兴领域是平台工程，专注于搭建和运营内部开发平台，以优化流程并提升效率。\n我们的研究总结了平台工程的 4 个关键发现：\n提升开发人员效率：内部开发平台能够有效提升开发人员的生产力。 更常见于大型企业：这些平台通常在大型组织中使用，表明它们更适合应对复杂的开发环境。 可能出现的性能下滑：在平台工程计划实施初期，性能可能会有所下降，直至平台逐渐成熟后才能显现出改进效果。 强调用户导向和开发人员自主性：为了达到最佳效果，平台工程应优先考虑用户导向的设计、开发人员的独立性，以及产品导向的方法。 一个重视用户需求、赋能开发人员、并能预见潜在挑战的周全策略，是最大化平台工程计划收益的关键。\n开发者体验：成功的关键 去年报告中指出，健康的工作文化有助于减少倦怠、提升生产力和提高工作满意度。今年的研究结果依然如此。那些营造稳定、支持性环境并激励开发者发挥潜力的团队，往往能够取得显著的积极成果。\n“快速行动、频繁调整”的心态会对开发者的身心健康产生负面影响，进而影响整体绩效。即便拥有强有力的领导、完善的文档以及用户导向的开发方式，若优先级不稳定，仍然可能显著阻碍团队的进展。\n创造一个支持、重视团队，并让开发者有机会展现自身价值的工作环境，是实现卓越绩效的基础。\n如何利用这些发现来帮助你的 DevOps 团队 十年的研究表明，软件开发的成功不仅依赖于技术实力，更取决于建立支持性的文化、重视用户需求和提升开发者体验。我们鼓励各团队在实际环境中验证和应用我们的研究成果。\n这些发现可以成为你团队实验和持续改进项目的依据。我们也欢迎你将这些实践分享给我们和 DORA 社区，让你的经验成为我们共同学习和进步的一部分。\n我们开展这项研究是为了为那些希望改进实践、推动创新和合作，并实现业务成功的团队和组织提供一条清晰的路径。未来十年，我们将继续开展平台无关的研究，专注于技术中的人性化因素。\n了解更多：\n下载完整报告 分享你的经验，加入 DORA 社区，学习他人的做法并获取灵感 使用 DORA 快速检查，在不到一分钟内评估你的团队的软件交付绩效 ","date":"2024-10-27T15:43:33+08:00","image":"https://martinliu.cn/blog/state-of-devops-2024-summary/state_of_dora_2024.max-2500x2500_hu_876ec58cf775d8c7.jpg","permalink":"https://martinliu.cn/blog/state-of-devops-2024-summary/","title":"《DORA 2024年 加速：DevOps 现状报告》概述"},{"content":"本快速上手指南包含的内容：\n安装和准备 Pulumi CLI 工具 准备 Pulumi Cloud 账号，并创建个人的 Access Token 准备 Azure 的账号，用交互的方式登录 Azure CLI 创建一个简单的 Pulumi 项目，用于 Python 语言的主程序部署 Azure 资源 删除环境中的所有资源 准备工作 在 MacOS 环境中安装 Pulumi CLI 可以通过 Homebrew 安装，也可以通过下载二进制文件安装。Pulumi CLI 在本地环境中用于创建、部署和管理 Pulumi 项目。它需要依赖于 Pulumi Cloud 服务，作为命令行工具交互的后端。\n1 brew install pulumi/tap/pulumi 安装完成后，可以通过 pulumi version 命令查看 Pulumi CLI 的版本信息。\nPulumi Cloud 是 Pulumi 的后端服务，用于存储 Pulumi 项目的状态信息，以及提供一些其他的服务。在使用 Pulumi CLI 之前，需要先登录 Pulumi Cloud 服务。\nPulumi CLI 在本地环境中，可以使用 ‘pulumi login’ 默认的交互方式，完成在命令行中的用户认证；我推荐使用Pulumi 的 Access Token 来在本地 完成命令行的登录认证过程。这种非交付方式，可以在后续的 CI/CD 环境中使用。\n参考下图，登录 Pulumi Cloud 服务，获取 Access Token。\n在命令行中，将 Access Token 设置为环境变量，用于后续的登录认证。\n1 2 3 export PULUMI_ACCESS_TOKEN=pul-ACT+++++++++++++++++++++++++++++++++++++++++++++++ pulumi whoami martinliu 实际上，Pulumi CLI 会先在环境变量中查找 PULUMI_ACCESS_TOKEN，如果找到了就直接使用 Token 完成登录认证的过程，可以使用 ‘pulumi whoami’ 命令确认是否登录成功，以及当前所使用的 Pulumi Cloud 的用户名。\n当然，也可以使用 pulumi login 命令，通过交互的方式登录 Pulumi Cloud 服务。\nAzure CLI 是 Azure 的命令行工具，用于在本地环境中与 Azure 云服务进行交互。本文省略了 Azure CLI 的登录认证过程，为了方便期间，可以使用 az login 命令，用网页交互的方式，完成命令行中本地 Azure CLI 的登录认证。\n可以校验一下 Azure CLI 的登录认证是否成功。\n1 az account show 在上面的信息输出中，你可以看到当前的 Azure 账号订阅等信息。Pulumi CLI 会使用 Azure CLI 的登录认证信息，来完成 Azure 云服务的资源部署。\n在完成了上述的 Pulumi CLI 和 Azure CLI 的准备工作后，我们可以开始创建一个简单的 Pulumi 项目，用于部署 Azure 资源。\n创建 Pulumi 项目 在本地环境中，使用 Pulumi 命令 ‘pulumi new azure-python’ 创建一个新的 Pulumi 项目，用于部署 Azure 资源。\n‘pulumi new\u0026rsquo; 命令会在一个空目录中初始化一个 Pulumi 项目。在初始化的过程中，Pulumi CLI 会询问一些问题，用于生成一个简单的 Python 代码文件。在下面的示例中，我只是制定了 Azure 的区域为 \u0026lsquo;East Asia\u0026rsquo;，其他的都使用默认值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 (base) ➜ first-project pulumi new azure-python Logging in using access token from PULUMI_ACCESS_TOKEN This command will walk you through creating a new Pulumi project. Enter a value or leave blank to accept the (default), and press \u0026lt;ENTER\u0026gt;. Press ^C at any time to quit. Project name (first-project): Project description (A minimal Azure Native Python Pulumi program): Created project \u0026#39;first-project\u0026#39; Please enter your desired stack name. To create a stack in an organization, use the format \u0026lt;org-name\u0026gt;/\u0026lt;stack-name\u0026gt; (e.g. `acmecorp/dev`). Stack name (dev): Created stack \u0026#39;dev\u0026#39; The toolchain to use for installing dependencies and running the program pip The Azure location to use (azure-native:location) (WestUS2): eastasia Saved config Installing dependencies... Creating virtual environment... Finished creating virtual environment Updating pip, setuptools, and wheel in virtual environment... Requirement already satisfied: pip in ./venv/lib/python3.10/site-packages (22.3.1) Collecting pip Using cached pip-24.2-py3-none-any.whl (1.8 MB) Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (65.5.0) Collecting setuptools Using cached setuptools-75.1.0-py3-none-any.whl (1.2 MB) Collecting wheel Using cached wheel-0.44.0-py3-none-any.whl (67 kB) Installing collected packages: wheel, setuptools, pip Attempting uninstall: setuptools Found existing installation: setuptools 65.5.0 Uninstalling setuptools-65.5.0: Successfully uninstalled setuptools-65.5.0 Attempting uninstall: pip Found existing installation: pip 22.3.1 Uninstalling pip-22.3.1: Successfully uninstalled pip-22.3.1 Successfully installed pip-24.2 setuptools-75.1.0 wheel-0.44.0 Finished updating Installing dependencies in virtual environment... Collecting pulumi\u0026lt;4.0.0,\u0026gt;=3.0.0 (from -r requirements.txt (line 1)) Using cached pulumi-3.136.1-py3-none-any.whl.metadata (11 kB) Collecting pulumi-azure-native\u0026lt;3.0.0,\u0026gt;=2.0.0 (from -r requirements.txt (line 2)) Using cached pulumi_azure_native-2.66.0-py3-none-any.whl.metadata (4.2 kB) Collecting protobuf~=4.21 (from pulumi\u0026lt;4.0.0,\u0026gt;=3.0.0-\u0026gt;-r requirements.txt (line 1)) Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes) Collecting grpcio~=1.66.2 (from pulumi\u0026lt;4.0.0,\u0026gt;=3.0.0-\u0026gt;-r requirements.txt (line 1)) Using cached grpcio-1.66.2-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.9 kB) Collecting dill~=0.3 (from pulumi\u0026lt;4.0.0,\u0026gt;=3.0.0-\u0026gt;-r requirements.txt (line 1)) Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB) Collecting six~=1.12 (from pulumi\u0026lt;4.0.0,\u0026gt;=3.0.0-\u0026gt;-r requirements.txt (line 1)) Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB) Collecting semver~=2.13 (from pulumi\u0026lt;4.0.0,\u0026gt;=3.0.0-\u0026gt;-r requirements.txt (line 1)) Using cached semver-2.13.0-py2.py3-none-any.whl.metadata (5.0 kB) Collecting pyyaml~=6.0 (from pulumi\u0026lt;4.0.0,\u0026gt;=3.0.0-\u0026gt;-r requirements.txt (line 1)) Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB) Collecting debugpy~=1.8.5 (from pulumi\u0026lt;4.0.0,\u0026gt;=3.0.0-\u0026gt;-r requirements.txt (line 1)) Using cached debugpy-1.8.7-py2.py3-none-any.whl.metadata (1.1 kB) Collecting parver\u0026gt;=0.2.1 (from pulumi-azure-native\u0026lt;3.0.0,\u0026gt;=2.0.0-\u0026gt;-r requirements.txt (line 2)) Using cached parver-0.5-py3-none-any.whl.metadata (2.7 kB) Collecting typing-extensions\u0026gt;=4.11 (from pulumi-azure-native\u0026lt;3.0.0,\u0026gt;=2.0.0-\u0026gt;-r requirements.txt (line 2)) Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB) Collecting arpeggio\u0026gt;=1.7 (from parver\u0026gt;=0.2.1-\u0026gt;pulumi-azure-native\u0026lt;3.0.0,\u0026gt;=2.0.0-\u0026gt;-r requirements.txt (line 2)) Using cached Arpeggio-2.0.2-py2.py3-none-any.whl.metadata (2.4 kB) Collecting attrs\u0026gt;=19.2 (from parver\u0026gt;=0.2.1-\u0026gt;pulumi-azure-native\u0026lt;3.0.0,\u0026gt;=2.0.0-\u0026gt;-r requirements.txt (line 2)) Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB) Using cached pulumi-3.136.1-py3-none-any.whl (274 kB) Using cached pulumi_azure_native-2.66.0-py3-none-any.whl (89.7 MB) Using cached debugpy-1.8.7-py2.py3-none-any.whl (5.2 MB) Using cached dill-0.3.9-py3-none-any.whl (119 kB) Using cached grpcio-1.66.2-cp310-cp310-macosx_12_0_universal2.whl (10.7 MB) Using cached parver-0.5-py3-none-any.whl (15 kB) Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB) Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB) Using cached semver-2.13.0-py2.py3-none-any.whl (12 kB) Using cached six-1.16.0-py2.py3-none-any.whl (11 kB) Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB) Using cached Arpeggio-2.0.2-py2.py3-none-any.whl (55 kB) Using cached attrs-24.2.0-py3-none-any.whl (63 kB) Installing collected packages: arpeggio, typing-extensions, six, semver, pyyaml, protobuf, grpcio, dill, debugpy, attrs, pulumi, parver, pulumi-azure-native Successfully installed arpeggio-2.0.2 attrs-24.2.0 debugpy-1.8.7 dill-0.3.9 grpcio-1.66.2 parver-0.5 protobuf-4.25.5 pulumi-3.136.1 pulumi-azure-native-2.66.0 pyyaml-6.0.2 semver-2.13.0 six-1.16.0 typing-extensions-4.12.2 Finished installing dependencies Finished installing dependencies Your new project is ready to go! ✨ To perform an initial deployment, run `pulumi up` (base) ➜ first-project 下图是初始化后的项目目录结构。\n在项目目录中，有一个 Pulumi.yaml 文件，用于描述项目的基本信息，如项目名称、描述、编程语言等。\n1 2 3 4 5 6 7 8 9 10 11 name: first-project description: A minimal Azure Native Python Pulumi program runtime: name: python options: toolchain: pip virtualenv: venv config: pulumi:tags: value: pulumi:template: azure-python 在项目目录中，有一个 Pulumi.dev.yaml 文件，用于描述项目的配置信息，如 Azure 的订阅 ID、资源组名称、区域等。\n1 2 config: azure-native:location: eastasia 在项目目录中，有一个 __main__.py 文件，用于描述项目的主程序，用于部署 Azure 资源。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \u0026#34;\u0026#34;\u0026#34;An Azure RM Python Pulumi program\u0026#34;\u0026#34;\u0026#34; import pulumi from pulumi_azure_native import storage from pulumi_azure_native import resources # Create an Azure Resource Group 创建一个 Azure 资源组 resource_group = resources.ResourceGroup(\u0026#34;resource_group\u0026#34;) # Create an Azure resource (Storage Account) 创建一个 Azure 资源（存储账户） account = storage.StorageAccount( \u0026#34;sa\u0026#34;, resource_group_name=resource_group.name, sku={ \u0026#34;name\u0026#34;: storage.SkuName.STANDARD_LRS, }, kind=storage.Kind.STORAGE_V2, ) # Export the primary key of the Storage Account 导出存储账户的主键 primary_key = ( pulumi.Output.all(resource_group.name, account.name) .apply( lambda args: storage.list_storage_account_keys( resource_group_name=args[0], account_name=args[1] ) ) .apply(lambda accountKeys: accountKeys.keys[0].value) ) pulumi.export(\u0026#34;primary_storage_key\u0026#34;, primary_key) 在项目目录中，有一个 requirements.txt 文件，用于描述项目的依赖信息，如 Pulumi 和 Azure Native SDK 的版本信息。\n1 2 pulumi\u0026gt;=3.0.0,\u0026lt;4.0.0 pulumi-azure-native\u0026gt;=2.0.0,\u0026lt;3.0.0 在使用 pulumi new 创建新项目时，可以通过指定 --language 参数来选择所需的语言。例如，默认语言确实是 Python，但你可以根据需求选择其他支持的语言，如 TypeScript、JavaScript、Go 或 C#。以下是示例用法：\n1 pulumi new \u0026lt;template-name\u0026gt; --language \u0026lt;language\u0026gt; 其中 \u0026lt;language\u0026gt; 可以是以下几种：\ntypescript（TypeScript） javascript（JavaScript） python（Python） go（Go） csharp（C#） 如果想创建一个 TypeScript 项目，命令可以如下：\n1 pulumi new \u0026lt;template-name\u0026gt; --language typescript 如果没有指定语言，则会默认使用 Python。\n当前生成了一个默认的 Python 主程序模板，Pulumi CLI 会启动本地的语言服务器，执行此 Python 程序，完成和 Azure Cloud 的交互工作，实现 Python 程序中资源部署的意图，开发人员可以在此基础上，根据自己的需求，修改和扩展 Python 代码，实现对 Azure 资源的部署和更新。模板 Python 代码中，创建了一个 Azure 资源组和一个 Azure 存储账，在最后将 ‘primary_key’导出显示在命令中，实现了 Python 程序对外的输出。\n部署 Pulumi 项目 在项目目录中，使用 pulumi up 命令，完成 Azure 资源的部署。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 (base) ➜ first-project pulumi up Previewing update (dev) View in Browser (Ctrl+O): https://app.pulumi.com/martinliu/first-project/dev/previews/539d74d9-64ec-4fb8-aa69-eb08ddbe4eea Type Name Plan + pulumi:pulumi:Stack first-project-dev create + ├─ azure-native:resources:ResourceGroup resource_group create + └─ azure-native:storage:StorageAccount sa create Outputs: primary_storage_key: output\u0026lt;string\u0026gt; Resources: + 3 to create Do you want to perform this update? yes Updating (dev) View in Browser (Ctrl+O): https://app.pulumi.com/martinliu/first-project/dev/updates/1 Type Name Status + pulumi:pulumi:Stack first-project-dev created (36s) + ├─ azure-native:resources:ResourceGroup resource_group created (3s) + └─ azure-native:storage:StorageAccount sa created (29s) Outputs: primary_storage_key: \u0026#34;key++++++++++++++++++++++++++++++++++++++++++++++++++++++\u0026#34; Resources: + 3 created Duration: 38s 以上 pulumi up 命令是一个交互式的执行过程，可以在命令行中输入 yes，确认是否执行资源的创建。在执行过程中，Pulumi CLI 会生成一个更新信息，用于展示资源的创建状态，以及资源的状态。在更新信息中，可以看到已经创建的资源类型、名称、状态等信息。在更新信息中，还会显示一个 URL，用于在浏览器中查看更新信息。\n在部署完毕之后，我们可以在 Pulumi Cloud 网页中看到此项目的部署过程，以及资源的状态信息。如下图所示。\n下面在 Azure 门户中，可以看到创建的资源组和存储账户。我们可以看到，资源组的名称是 resource_group，存储账户的名称是 sa开头的资源，后面跟随着一些随机字符。\n根据以上的操作体验，我们可以参考下图，理解 Pulumi CLI 和 Azure 云服务之间的交互过程。\npulumi 命令行工具本身是一个部署引擎，它会启动一个本地的语言服务器，用于执行 Python 程序，完成对 Azure 云服务的资源部署。\n本 Python 测试项目是一个典型的 Pulumi 项目模板，它使用 IaC 的方式，将 Azure 资源的部署和更新，通过 Python 代码的方式，实现了对 Azure 资源的管理。这个 Pulumi 项目的部署结果称为 ‘Stack’，是一个 Azure 基础设施的技术栈，本项目模板目录可以在你的业务应用项目的根目录中，作为一个子目录，用于管理 Azure 资源的部署和更新。随着业务项目的开发和迭代，可以通过 Pulumi CLI 工具，完成 Azure 多个环境资源的部署和更新，例如开发环境、测试环境、生产环境等。\n更新 Pulumi 项目 在准备好以上的环境后，假设我们收到了一个新的业务需求，需要在 Azure 存储账户中部署一个 index.html 文件，用于展示一个简单的静态网页。我们可以通过修改 __main__.py 文件，增加一个 Azure Blob 存储的资源，用于部署 index.html 文件。\n为了演示这个过程，我们现在命令，在当前的项目目录中，创建一个 index.html 文件。\n1 2 3 4 5 6 7 cat \u0026lt;\u0026lt;EOT \u0026gt; index.html \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello, Pulumi!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; EOT 当然，这个 index.html 文件是业务需求成果，是不应该放在 IaC 程序代码的目录中的。\n下面需要在 __main__.py 文件中，修改 Azure Blob 存储的资源属性，用于部署 index.html 文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Enable static website support 启用静态网站支持 static_website = storage.StorageAccountStaticWebsite( \u0026#34;staticWebsite\u0026#34;, account_name=account.name, resource_group_name=resource_group.name, index_document=\u0026#34;index.html\u0026#34;, ) # Upload the file 将文件上传到存储账户 index_html = storage.Blob( \u0026#34;index.html\u0026#34;, resource_group_name=resource_group.name, account_name=account.name, container_name=static_website.container_name, source=pulumi.FileAsset(\u0026#34;index.html\u0026#34;), content_type=\u0026#34;text/html\u0026#34;, ) # Web endpoint to the website 在命令行中导出网站的 Web 端点 pulumi.export(\u0026#34;staticEndpoint\u0026#34;, account.primary_endpoints.web) 在完成了以上的修改后，我们可以使用 pulumi up 命令，完成 Azure 资源的更新。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 (base) ➜ first-project ls Pulumi.dev.yaml __main__.py index.html venv Pulumi.yaml __pycache__ requirements.txt (base) ➜ first-project pulumi up Previewing update (dev) View in Browser (Ctrl+O): https://app.pulumi.com/martinliu/first-project/dev/previews/613fd4dc-ce8b-4a32-a8f6-713c2e4dc839 Type Name Plan pulumi:pulumi:Stack first-project-dev + ├─ azure-native:storage:StorageAccountStaticWebsite staticWebsite create + └─ azure-native:storage:Blob index.html create Outputs: + staticEndpoint : \u0026#34;https://sa4ecf74cb.z7.web.core.windows.net/\u0026#34; Resources: + 2 to create 3 unchanged Do you want to perform this update? yes Updating (dev) View in Browser (Ctrl+O): https://app.pulumi.com/martinliu/first-project/dev/updates/2 Type Name Status pulumi:pulumi:Stack first-project-dev + ├─ azure-native:storage:StorageAccountStaticWebsite staticWebsite created (5s) + └─ azure-native:storage:Blob index.html created (3s) Outputs: primary_storage_key: \u0026#34;key++++++++++++++++++++++++++++++++++++++++++++++++++++++\u0026#34; + staticEndpoint : \u0026#34;https://sa4ecf74cb.z7.web.core.windows.net/\u0026#34; Resources: + 2 created 3 unchanged Duration: 13s 在以上命令执行的过程中，我们也可以在 Pulumi Cloud 网页中看到此项目的部署过程，以及资源的状态信息。还可以在 Azure 门户中，看到更新后的资源组和存储账户。\n现在，让我们在命令行中，查看导出的 staticEndpoint 输出，用于验证所部署的静态网站。\n1 2 3 4 5 6 7 8 curl $(pulumi stack output staticEndpoint) (base) ➜ first-project curl $(pulumi stack output staticEndpoint) \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello, Pulumi!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; (base) ➜ first-project 在浏览器中，访问 staticEndpoint 输出的 URL，可以看到部署的静态网站。\n删除 Pulumi 项目 假设我们完成了今天的开发和测试工作，我们可以使用 pulumi destroy 命令，删除所有当前在 Azure 上所部署的资源。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 (base) ➜ first-project pulumi destroy Previewing destroy (dev) View in Browser (Ctrl+O): https://app.pulumi.com/martinliu/first-project/dev/previews/3d3257e7-c853-4d89-bfc0-461a37bf94ee Type Name Plan - pulumi:pulumi:Stack first-project-dev delete - ├─ azure-native:storage:Blob index.html delete - ├─ azure-native:storage:StorageAccountStaticWebsite staticWebsite delete - ├─ azure-native:storage:StorageAccount sa delete - └─ azure-native:resources:ResourceGroup resource_group delete Outputs: - primary_storage_key: \u0026#34;key++++++++++++++++++++++++++++++++++++++++++++++++++++++\u0026#34; - staticEndpoint : \u0026#34;https://sa4ecf74cb.z7.web.core.windows.net/\u0026#34; Resources: - 5 to delete Do you want to perform this destroy? yes Destroying (dev) View in Browser (Ctrl+O): https://app.pulumi.com/martinliu/first-project/dev/updates/3 Type Name Status - pulumi:pulumi:Stack first-project-dev deleted (0.69s) - ├─ azure-native:storage:Blob index.html deleted (5s) - ├─ azure-native:storage:StorageAccountStaticWebsite staticWebsite deleted (1s) - ├─ azure-native:storage:StorageAccount sa deleted (7s) - └─ azure-native:resources:ResourceGroup resource_group deleted (83s) Outputs: - primary_storage_key: \u0026#34;key++++++++++++++++++++++++++++++++++++++++++++++++++++++\u0026#34; - staticEndpoint : \u0026#34;https://sa4ecf74cb.z7.web.core.windows.net/\u0026#34; Resources: - 5 deleted Duration: 1m42s The resources in the stack have been deleted, but the history and configuration associated with the stack are still maintained. If you want to remove the stack completely, run `pulumi stack rm dev`. 在以上命令执行的过程中，我们也可以在 Pulumi Cloud 网页中看到此项目的部署过程，以及资源的状态信息。还可以在 Azure 门户中，看到删除后的资源组和存储账户。\n总结 您已成功使用 Pulumi 部署了一些云资源。在本指南中，您完成了以下操作：\n创建了一个新的 Pulumi 项目。 在 Azure 上部署了一个新的存储账户和容器。 将一个 index.html 文件添加到容器中。 将 index.html 文件托管为静态网站。 销毁了已部署的资源。 在本指南中，您了解了如何使用 Pulumi CLI 和 Azure CLI 在本地 macOS 环境中，部署 Azure 资源。您还了解了如何使用 Pulumi Cloud 服务，用于存储 Pulumi 项目的状态信息，以及提供一些其他的服务。\n参考文档：\nPulumi 官方文档 Get started with Pulumi \u0026amp; Azure ","date":"2024-10-12T11:49:22+08:00","image":"https://martinliu.cn/blog/pulumi-azure-quickstart-guide-macos-local/azure-nextgen_hu_2c4c0bab2db0fd82.png","permalink":"https://martinliu.cn/blog/pulumi-azure-quickstart-guide-macos-local/","title":"Pulumi IaC 之 Azure 快速入门指南（MacOS \u0026 Python 本地）"},{"content":"DevOps 平台提供了集成化的工具替代方案，帮助组织优化软件开发流程，减少工具链复杂性。软件工程领导者应评估这些平台，以降低开发复杂性、提升安全性，并加速软件交付进程。\n战略规划假设\n预计到 2027 年，80% 的组织将采用 DevOps 平台来简化工具链并优化软件交付流程，这一比例将从 2023 年的 25% 大幅上升。\n市场定义与描述 Gartner 将 DevOps 平台定义为能够提供完整集成功能的平台，支持通过敏捷 (Agile) 和 DevOps 实践实现软件的持续交付。该平台功能覆盖了持续集成/持续交付 (CI/CD) 管道的开发和交付生命周期，包括版本控制、测试、安全性、文档及合规性等。DevOps 平台能够促进团队协作、一致性、简化工具使用，并衡量软件交付的各项指标。\nDevOps 平台简化了现代软件应用交付中所需组件的创建、维护和管理过程。平台提供统一的工作流和数据模型，简化用户访问，保证一致的用户体验 (UX)，有效减轻用户的操作负担。这些平台还能提升软件开发过程中的可见性、可审计性和可追溯性，鼓励团队采用系统化的思维方式，并加速反馈循环。\n企业通过使用 DevOps 平台，减少因复杂工具链、手动交接和整个软件开发生命周期 (SDLC) 中可见性不足所引发的工具摩擦。这样，产品团队能够在确保质量的前提下更快地为客户交付价值。DevOps 平台市场反映了开发、安全、基础设施和运营技术的整合，旨在简化软件交付流程。\nDevOps 平台支持多种应用场景，包括但不限于：\n敏捷软件交付——实现敏捷开发实践的运营 云原生应用交付——在混合和多云环境中构建并交付云原生应用 MLOps——支持对机器学习模型的管理，包括版本控制和反馈循环 移动应用交付——构建、测试和交付本地移动应用和移动 Web 应用 平台工程——提供自助服务的内部开发者平台，扩展 DevOps 和软件工程实践 受监管的交付——支持合规、审计、可追溯性及治理 必备功能 该市场的强制性功能包括：\n持续集成——原生支持持续构建代码，并协调验证和验证流程，如测试自动化、安全性和合规扫描。 持续交付和发布协调——支持无审批的持续部署，以及通过审批机制进行的发布协调（如满足监管要求或正处于 ITIL 过渡期的组织）。 Web 应用的交付——包括但不限于容器化应用的交付。 常见功能 该市场的常见功能包括：\n团队协作与开发流程的可视化——通过统一仪表板支持多角色用户的工作流展示。 价值流分析——如吞吐量指标、DORA 指标等。 安全功能的协调——涵盖源代码、软件包和配置管理。 配置自动化——支持环境管理，包括基础设施的部署、配置管理及漂移检测。 产品规划与管理——包括功能和缺陷管理、路线图规划、待办事项管理、看板和 Scrum 方法。 源代码库、工件库和集成开发环境 (IDEs)。 软件测试自动化——支持功能性和非功能性测试的执行、测试管理、代码覆盖率分析、性能测试、混沌测试、模糊测试、渗透测试以及通过自动化工具进行的验收测试。 应用监控与可观测性——帮助提高服务质量目标 (SLO)，收集生产数据（如日志、指标、事件、跟踪），并支持自动化事故响应。 AI 辅助和 AI 驱动的持续集成与部署——优化 DevOps 流程，如软件测试自动化、基础设施部署、安全漏洞检测和操作数据分析。 集成开发者门户——提供软件目录和可定制的仪表板，帮助团队深入了解软件组件及其依赖关系和环境；此外，还可包括基础设施 KPIs、协作论坛和知识库等功能。 魔力象限 图 1：DevOps 平台魔力象限\n供应商优劣分析 Amazon Web Services 亚马逊网络服务 (AWS) 在此魔力象限中被列为具有远见的领导者。其 DevOps 平台 Amazon CodeCatalyst 集成了多项 AWS 工具，包括 AWS CodeArtifact、AWS CodeBuild、AWS CodeCommit、AWS CodeDeploy、AWS CodePipeline 和 AWS CodeStar。（评估期间，亚马逊已停止为 CodeCommit 接受新用户。）Amazon CodeCatalyst 平台正在迅速开发更多的协作和报告功能。\nAWS 拥有全球业务网络，为各类规模和行业的客户提供服务。Amazon CodeCatalyst 于 2023 年 4 月正式推出，通过支持 Amazon Elastic Kubernetes Service (EKS) 和 Terraform，增强了计划工作流和账户管理等功能。此外，AWS 进一步拓展了 CodeCatalyst 的集成功能，支持 GitHub 以外的平台，如 GitLab 和 Bitbucket，并与 Amazon Q for Developers 进行了集成。\n优势 深度集成 AWS 云服务：AWS 一直在 IaaS 和 PaaS 市场中占据领导地位，提供的工具使用户能够随时跟进最新技术。然而，过去的工具较为零散，CodeCatalyst 通过一个统一的平台简化了构建和部署流程，让用户能够更高效地使用 AWS 云服务。 价格竞争力：相比其他 DevOps 平台，CodeCatalyst 提供从规划到交付的完整功能，且价格更具优势。这是因为最终用户的应用程序将推动 AWS 云服务的收入。 安全开发环境：AWS 响应了客户对更高安全性和隐私的需求。过去一年中，AWS 添加了单点登录功能，并通过 Amazon 虚拟专用网 (VPC) 创建了隔离的开发和测试环境。AWS PrivateLink 允许 AWS CodeBuild、Amazon EC2 和本地应用程序之间建立私密安全的连接，客户无需借助额外的访问网关技术就能限制网络流量。 劣势 功能仍在发展：Amazon CodeCatalyst 推出时间较短，尽管功能全面，但仍缺少如 DORA 等 DevOps 指标的支持。此外，平台缺乏内置的 wiki，且第三方工作流的数量有限（不过用户可以使用 GitHub Actions）。 第三方集成有限：虽然 Amazon CodeCatalyst 提供了与第三方开发工具和服务的扩展，但目前只有少数供应商与其进行集成。这也是 AWS DevOps 工具链（如 AWS CodePipeline）的历史问题之一。 内置安全功能不足：在代码和应用程序安全的支持上，Amazon CodeCatalyst 相较市场仍有不足。 Atlassian Atlassian 被评为本魔力象限中的领导者。其 DevOps 平台由多个工具组成，包括 Jira、Bitbucket、Jira Service Management、Confluence、Compass 和 Jira Product Discovery。这些工具提供了从产品发现到工作管理、问题跟踪、源代码管理、发布编排、CI/CD、事故管理、变更管理和团队协作的全方位支持。\nAtlassian 的业务遍布全球，为各行各业、不同规模的客户提供服务。自 2023 年以来，Atlassian 在 DevSecOps 方面的能力得到了提升，尤其是在敏捷工作流中的漏洞管理。此外，Atlassian 还持续改进其内部开发者门户 Compass。\n优势 工作和服务管理以及协作：Atlassian 有效地将 Jira、Jira Service Management 和 Confluence 集成在一起，帮助 DevOps 团队高效协作管理工作。客户普遍认为，这些工具已经成为他们日常工作中的关键组成部分。尤其是 Confluence 作为知识管理工具，几乎没有直接竞争者，并且在许多软件开发团队中被广泛使用。 强大的平台生态系统：Atlassian Marketplace 提供了成千上万的第三方应用程序和插件，扩展了平台的功能。此外，Atlassian 还拥有一个全球合作伙伴网络，提供强大的实施、咨询和支持服务。 持续创新：Atlassian 持续推出创新功能，如集成的 DevSecOps 规划工具，进一步强化了平台的敏捷工作管理能力。通过通用数据模型，该平台还能在 AI 和数据分析领域推动更多创新。 劣势 销售模式受限：Atlassian 主要采用固定价格的销售模式，这让部分客户感到不满。一些客户希望通过合作伙伴获得更多的定制化服务和折扣，尤其是企业客户可以通过企业许可协议获得更多灵活性和价格优惠。 CI/CD 采用率较低：虽然 Atlassian 的 Bitbucket 提供了与其他产品相当的源代码管理和 CI/CD 功能，但其客户采用率相对较低。为实现功能开关（标志）管理等特定功能，客户往往需要依赖外部工具的集成。 云产品的法规合规性不足：目前，Atlassian 的云产品尚未通过如 FedRAMP 这样的重要法规认证。同时，在 2024 年初 Atlassian 停止了对本地 Server 产品的支持，这意味着一些受监管行业的客户可能只能选择更昂贵的本地 Data Center 产品。 Buildkite Buildkite 是本次魔力象限中的利基玩家。其 DevOps 平台包含 Pipelines、Packages 和 Test Analytics，支持 CI/CD 流水线、包管理（测试版）以及测试套件优化和分析功能。\nBuildkite 的主要业务位于北美，同时在亚太地区也有一定的客户基础，服务于多个行业的客户。2023 年，Buildkite 收购了 Packagecloud，一个软件制品包管理平台，从而进一步扩展了其 DevOps 平台，支持多种现代编程语言的包格式，并以 Buildkite Packages 的形式交付给用户。\n优势 高扩展性与优异性能：Buildkite 旨在帮助大型企业实现构建代理的无限并行运行，缩短构建和测试周期，提升开发效率。一些大型企业用户已经实现了超过 13 万个并行流水线的应用。 智能化工作流：Buildkite 平台支持智能化工作流，可以根据不同的运行时条件（例如分支、环境或前置步骤的结果）灵活执行构建过程中的不同步骤，满足用户的特定需求。 测试优化功能：通过 Buildkite 的测试分析工具，用户可以监控测试套件的性能与可靠性。该工具提供详细的跟踪与报告，帮助开发团队识别长时间运行或不稳定的测试，并为优化测试套件和加快测试周期提供洞见。 劣势 功能覆盖较窄：Buildkite 仅覆盖 CI/CD 流程的部分环节，用户如果需要构建完整的 CI/CD 流水线，仍需依赖其他工具或平台进行集成。 云数据中心的区域支持有限：Buildkite 的服务主要托管在美国的云数据中心，非美国用户无法在当地托管 Buildkite。需要确保 Buildkite 提供的数据驻留解决方案符合要求。此外，Buildkite 不提供备份或灾难恢复数据中心的选择。 托管服务较新：由于 Buildkite 的托管服务刚刚推出，用户需要关注其性能反馈，同时在便捷的全托管服务与需要更多运维投入的混合自管基础设施之间做出平衡选择。 CircleCI CircleCI 是本次魔力象限中的挑战者。它的 DevOps 平台同样叫做 CircleCI，提供托管和自托管的构建基础设施、自托管运行器、CI/CD 流水线、测试自动化、构建性能洞察以及支持 LLM 的应用程序。\nCircleCI 的业务主要集中在北美，同时在欧洲也有一定的客户群，覆盖多个行业，尤其是技术行业。2023 年，CircleCI 推出了新的安全功能，包括 OpenID Connect (OIDC)、组管理和配置策略，以更好地满足企业客户的需求。此外，CircleCI 还增强了其智能平台，支持成本优化，并通过改进测试执行、自愈流水线和智能发布编排器，提升了开发者体验。\n优势 FedRAMP 和 SOC 2 Type II 认证：CircleCI 是市场上为数不多的通过 FedRAMP 和 SOC 2 Type II 认证的平台之一，非常适合在高度受监管行业中的客户使用。 客户满意度高：在 Gartner Peer Insights 上，CircleCI 的 DevOps 平台获得了 4.7 分的高评分，尤其是在产品评估、合同签订和功能表现方面，得分达到了 4.8 分。客户普遍认为该平台可靠，并且与其他常见的 DevOps 工具集成良好。 操作简便：CircleCI 在使用方便性方面表现出色，客户特别赞赏其部署、管理、配置和调试的简便性。在 Peer Insights 的评审中，86% 的用户推荐使用 CircleCI。平台还集成了 AI，帮助开发者在工作流程中进行调试并提供智能建议。 劣势 功能覆盖有限：CircleCI 的主要功能是优化开发者的构建和测试流程，但在 DevOps 生命周期的 Ops 阶段功能较弱。要部署完整的 CI/CD 解决方案，用户仍需结合其他工具或平台。 数据中心覆盖不足：CircleCI 目前的云数据中心仅限于美国和加拿大，对于有数据驻留需求的国际客户来说选择有限。 定价模式复杂：虽然 CircleCI 提供免费套餐，但随着使用量的增长，费用可能迅速增加。由于定价基于点卡（信用）消耗，客户在依赖该平台时需要仔细查看定价表。 CloudBees CloudBees 是魔力象限中的挑战者，其 DevOps 平台包括 CloudBees CI、CloudBees 持续交付与发布编排 (CD/RO)、特性管理和合规工具。\nCloudBees 主要在北美运营，同时在欧洲也有一定业务，客户涵盖多个行业。2023 年，CloudBees 加强了其平台的高可用性和扩展性架构，确保大规模企业能够持续高效地运行 CI/CD 流水线，提升负载管理和流水线执行的效率。\n优势 持续合规支持：CloudBees 在支持高度合规的行业中表现出色。其合规工具帮助客户自动遵守多种安全标准，如 CIS、NIST 和 HIPAA 等，减少安全漏洞的风险。 强大的特性管理：CloudBees 是少数几家原生支持特性管理的 DevOps 平台之一，功能媲美第三方专用工具。随着用户对功能测试的需求增加，平台的简化和合规能力体现了价值，且提供区域数据保护。 客户参与度高：CloudBees 在客户参与和运营方面表现出色。这得益于其在 Jenkins 领域的深厚经验、CloudBees CI 和 University 项目的支持，以及其强大的企业客户群。客户评价也证明了这一点。 劣势 功能覆盖不足：CloudBees 平台主要优化了开发者的构建、测试和发布流程，但在 DevOps 生命周期的其他阶段（如版本控制、开发和工件管理）功能较弱，需要与其他工具整合才能实现完整的 DevOps 流程。 客户满意度较低：CloudBees 的 Peer Insights 评分为 4.3（满分 5 分），在同行中相对较低，客户对其文档质量和 Kubernetes 支持表现出不满。 Jenkins 的传统印象：尽管 CloudBees 基于 Jenkins 平台，但用户普遍认为它是一个传统工具。随着企业寻求更现代的开发工具，CloudBees 的营销策略未能有效吸引对云原生平台感兴趣的客户，这使得许多企业转向其他具有更广泛功能的平台。 GitLab GitLab 是魔力象限中的领导者，其 DevOps 平台包括 GitLab 和 GitLab Duo，涵盖了计划、源代码管理、CI、部署自动化、可观测性、应用安全测试、软件供应链安全、合规报告、价值流分析和事故管理等多项功能。\nGitLab 的业务遍布全球，客户群涵盖各行业的不同规模企业。2023 年，GitLab 对其平台进行了更新，新增了对生成式 AI、云开发环境、合规报告、价值流仪表板以及构建基础设施改进的支持。公司频繁发布新功能和安全更新，所有版本（托管、自管理和专用版）都能获得这些更新。\n优势 内置安全功能强大：GitLab 持续扩展其安全能力，并通过收购如 Oxeye 这样的公司进一步加强了这些功能。这使 GitLab 能在 DevOps 安全领域保持领先地位，并提升了其在 2023 年应用安全测试魔力象限中的表现。 广泛的市场理解力：GitLab 提供了覆盖软件开发全生命周期的工具，从任务管理、计划，到代码库创建、云开发环境、解决方案安全以及部署，全面支持开发人员的工作。GitLab 的这一战略显著提升了其在企业开发者中的价值。 客户满意度高：在 Gartner Peer Insights 中，GitLab 的客户净推荐值非常高，92% 的用户愿意推荐 GitLab。客户尤其看重其全功能平台和对 DevSecOps 的全面支持。 劣势 销售策略不够灵活：GitLab 针对企业客户的折扣策略较为保守，尤其是在其高级产品方面。这对希望获得优惠定价的客户来说是个挑战。 单一产品模式：GitLab 将其 DevOps 平台作为一个整体产品出售，这对仅需要部分功能的客户来说可能不够灵活。虽然最近有所改进，客户可以为现有的 GitLab Ultimate 许可证添加企业敏捷规划功能，但整体选择依然有限。 文档和功能支持不足：GitLab 通过整合开源软件快速扩展了平台功能，但部分新功能的文档支持较弱，且功能质量参差不齐。此外，一些新功能还处于测试版，且尚未给出明确的全面上线时间表。 Harness Harness 是本魔力象限的领导者之一，其 DevOps 平台包括代码库、持续集成、持续交付和 GitOps、特性管理、服务可靠性管理、混沌工程、软件工程洞察、内部开发者门户、安全测试编排、基础设施即代码管理、软件供应链保障和云成本管理等模块。\nHarness 的业务遍及北美、欧洲和印度，客户主要为来自多个行业的大型组织，分布在北美、欧洲和亚洲。2023 年，Harness 通过收购 Propelo 扩展了其软件工程智能分析能力。同时，Harness 推出了基于开源项目 Gitness 的代码库、基于 Backstage 的内部开发者门户 (IDP) 和基础设施即代码管理 (IaCM)。此外，通过 Harness AIDA 引入生成式 AI，使平台具备了多种应用场景，例如安全漏洞检测与修复。\n优势 云原生支持强大：Harness 为平台工程团队提供了丰富的功能，能够全面支持云原生 DevOps。近期收购的 Armory 等公司进一步增强了其平台能力，覆盖了整个产品交付生命周期。 迅速响应市场需求：在过去一年中，Harness 增加了更多 DevOps 特定功能，包括推出 Harness 代码库，减少了对其他工具的依赖；通过 IaCM 扩展了 Terraform 的使用，同时加强了安全性和管理控制；并通过 Harness IDP 更好地支持平台工程团队。 特性管理功能强大：Harness 平台自带的特性管理功能可取代专用的第三方工具。它使产品团队能够通过将发布与部署分离，实现渐进式交付，并提供特性监控和报告，帮助识别和移除不再需要的功能标志（功能开关）。 劣势 客户满意度欠佳：根据 Gartner Peer Insights 的反馈，Harness 在集成、部署、服务支持和产品功能方面的评分低于其他竞争对手。客户主要不满的是文档不完整以及客户支持的不足。 数据驻留限制：目前 Harness 仅提供美国地区的云托管服务，这对需要满足数据驻留合规要求的非美国客户来说是一个难题。 学习曲线陡峭：随着 Harness 不断扩展其 DevSecOps 支持，用户发现难以跟上新功能的更新节奏，尤其是平台的界面不够直观，且缺乏详细的最佳实践和标准使用指导。 JetBrains JetBrains 是本次魔力象限中的一个利基玩家，其 DevOps 平台由 Space、TeamCity 和 YouTrack 组成。（在本次评估过程中，JetBrains 宣布将停止支持 Space，并计划推出新产品。）此外，JetBrains 拥有多款面向不同编程语言的集成开发环境 (IDE)。YouTrack 主要提供项目管理和知识管理功能，适用于传统和敏捷开发方式；而 TeamCity 是 JetBrains 的 CI/CD 平台，可在本地部署或云上使用。\nJetBrains 的业务遍及全球，但未公布其客户的具体规模或细节。自 2023 年以来，JetBrains 推出了静态代码分析工具 Qodana，并在其 IDE 和 YouTrack 中集成了生成式 AI 功能，帮助开发者减少上下文切换，提升工作体验。\n优势 平台安全性强：JetBrains 在平台安全性方面表现突出，采用了全面的“红队”安全策略。在过去一年中，JetBrains 保持了零安全漏洞的记录。 协作功能出色：JetBrains 的 DevOps 平台在支持软件开发团队的协作与沟通方面表现优异。据 Gartner 2024 年的调查，开发人员普遍认为这类工具是提高生产力的关键。 市场认知度高：JetBrains 在 IDE 市场有很强的影响力，且是最早提供 CI 工具的厂商之一，这让其在开发者社区中获得了较高的认知度。 劣势 创新能力不足：JetBrains 的主要精力集中在其 IDE 产品上，因此在 DevOps 工具的创新上显得相对不足。公司也没有通过收购其他企业来增强创新能力。 销售执行力和定价策略存疑：与其他供应商相比，JetBrains 在销售执行和定价策略上表现一般。客户可能会通过与其合作伙伴建立联系来谈判购买条款。 市场营销战略有限：与竞争对手相比，JetBrains 的市场营销策略相对薄弱，这可能会影响其在市场上推行愿景的能力。 JFrog JFrog 是本次魔力象限中的一位挑战者，其 DevOps 平台包括 JFrog Artifactory、JFrog Pipelines、JFrog Distribution、JFrog Security Essentials（Xray）、JFrog Advanced Security、JFrog Curation、JFrog Connect 和 JFrog Catalog。\nJFrog 的业务主要集中在北美和欧洲，拥有来自各行业、不同规模的客户。自 2023 年以来，JFrog 新增了主动拦截恶意或高风险开源包的功能，并提供了这些新包的审计跟踪。此外，JFrog 还增加了机器学习模型的管理功能，并进一步提升了发布生命周期的管理能力。\n优势 工件管理的广泛认可：Artifactory 是 JFrog 最为人熟知的产品，它在二进制工件的管理和分发方面拥有广泛的用户基础。JFrog 通过新增例如 ML 模型管理等功能，不断提升其平台的能力，并借此扩大 DevOps 平台的市场。 对安全需求的快速响应：JFrog 针对软件供应链的安全性需求，推出了 Xray、Curation 和 Advanced Security 等工具，帮助客户提高安全性和可审计性。此外，JFrog Pipelines 满足了客户对于简化工具链的需求。 出色的客户支持和体验：与同类供应商相比，JFrog 在客户满意度、服务质量和技术支持方面表现突出。例如，所有客户支持问题都会自动进行总监级别的升级处理。 劣势 CI/CD 能力较弱：虽然 JFrog 主要专注于软件供应链管理，但其 CI/CD 工具 JFrog Pipelines 的能力相对较弱。大多数客户虽然使用 JFrog Artifactory，但仍选择与第三方 CI/CD 解决方案集成，而非使用 Pipelines。 协作与规划工具的缺乏：在协作和规划工具方面，JFrog 落后于竞争对手，公司的创新更多集中在 Artifactory 的功能扩展，如 ML 模型管理和安全性提升。 合作伙伴渠道发展有限：尽管 JFrog 拥有全球合作伙伴，但通过合作伙伴渠道的销售额仅占总销售额的一小部分，渠道建设还有待加强。 Microsoft Microsoft 是本次魔力象限中的领导者，提供 GitHub 和 Azure DevOps 两个独立的 DevOps 平台。当前，Microsoft 更加专注于 GitHub 平台，平台功能包括 Dependabot、GitHub Actions、GitHub Advisory Database、GitHub Codespaces、GitHub Copilot、GitHub Discussions、GitHub Issues、GitHub Packages、GitHub Projects 和 GitHub Repositories。\nMicrosoft 的业务遍布全球，服务于来自各行各业的客户。在 2023 年，Microsoft 扩展了 GitHub Copilot 的功能，改进了 GitHub Codespaces 的所有权和计费管理，新增了 GitHub Projects 的模板和 Copilot 集成，并提升了与 Azure DevOps（例如 Azure Boards）的集成。为提升性能和能源效率，Microsoft 还增加了 macOS runners 和对 ARM64 的支持。此外，GitHub 在安全功能上继续提升，并成为 Gartner 2023 年应用安全测试魔力象限中的挑战者。\n优势 庞大的开发者社区：Microsoft 拥有强大的开发者基础。根据 Gartner Peer Insights 数据，96% 的评测者推荐使用 GitHub，这在所有平台中得分最高。GitHub 也是全球最大开源项目的集合地，Microsoft 利用其强大的开发者社区，通过反馈和测试项目来持续改进产品功能。 生成式 AI 的创新：通过 GitHub Copilot，Microsoft 引入了大量创新功能，推动了生成式 AI 在 DevOps 流程中的应用。GitHub Copilot 的吸引力也是许多用户选择投资 GitHub 平台的重要原因之一。 协作功能的突出表现：GitHub 平台高度重视团队协作，其功能如 Discussions、支持自动化工作流的 Actions、强大的代码审查工具和移动设备操作支持，凸显了其社交编码的理念。 劣势 平台选择的困惑：GitHub 和 Azure DevOps 是两个独立平台，某些功能有所重叠，另一些则各有特色。虽然 GitHub 是创新的核心，但对于 Azure DevOps 的大批用户来说，平台定位信息可能并不清晰。Azure DevOps 的发展方向主要集中在与 GitHub 的功能整合上。 使用复杂度：与某些 CI 工具相比，GitHub 缺乏可视化的管道构建界面，因此如果用户不熟悉 YAML 语言，学习曲线较为陡峭。尽管 GitHub 支持多种集成，但其设置和管理过程可能较为复杂。 缺少高层次管理功能：虽然 GitHub 适合大型团队使用，并专注于提升开发者体验，但它在满足工程管理或项目组合管理者的需求方面相对不足，例如缺少对价值流指标或企业级敏捷开发的支持。用户通常需要结合使用 Azure Boards 才能获得这些功能。 Red Hat Red Hat 是本次魔力象限中的挑战者。它通过 Red Hat OpenShift 和 Red Hat Ansible Automation Platform 提供 DevOps 功能支持，涵盖 CI/CD 和基础设施自动化。这一平台利用云开发环境、标准模板和 playbooks，支持平台工程的实施，基于 Kubernetes、Tekton、Ansible 和 Argo CD 等开源技术构建。\nRed Hat 的业务遍布全球，客户来自各个行业和不同规模的企业。在 2023 年，Red Hat 发布了 Red Hat Developer Hub，这是一个基于 Backstage 的内部开发者门户。同时，Red Hat 将 IBM watsonX 集成到其 DevOps 平台中，提供基于大语言模型的代码辅助功能。Red Hat 还推出了 Event-Driven Ansible，并增加了集成功能，帮助应对实时自动化场景，减少重复工作。\n优势 全球覆盖：Red Hat 的 DevOps 平台作为 SaaS 服务在全球范围内（除中国外）均可使用。 支持混合云与多云：借助 Red Hat Ansible Automation Platform 和 Red Hat OpenShift，用户可以将应用程序部署到各种云平台，支持自动扩展，并拥有从边缘设备到 IBM 主机的强大管理工具。 服务承诺：Red Hat 提供的服务质量协议（SLA）相较于其他供应商，具备更快速的响应时间和更高的服务可用性。 劣势 OpenShift 定向：Red Hat 的 DevOps 平台主要围绕 OpenShift 容器平台构建。使用其他容器管理平台的用户可能会觉得它比本次象限中的其他供应商更难实施。 报告功能有限：虽然 Red Hat 的各个组件能够收集丰富的数据，但缺乏一个统一的报告系统。它集成了 Prometheus 来进行数据收集，需要通过 Grafana 来构建可视化仪表板。 Ansible 与第三方工具集成较少：尽管 Red Hat Ansible 可以与多种第三方工具集成，但与其他供应商的 DevOps 平台相比，其直接支持的集成数量较少。 供应商的新增与删除 随着市场的不断变化，我们会定期审查并调整魔力象限的纳入标准。因此，魔力象限中的供应商组合可能会随时间变化。某个供应商在某一年出现，下一年没有出现，并不一定意味着我们对该供应商的看法发生了变化。这可能更多反映了市场的变化，从而导致评估标准的调整，或是供应商自身业务重心的改变。\n新增 Buildkite 删除 Bitrise：Gartner 将 2024 年的魔力象限焦点收窄至不包括专注于单一 DevOps 用例的供应商，例如 Bitrise 专注于移动开发，而是更多关注具有通用功能的平台。 Codefresh：该供应商未能在 Gartner 定义的客户兴趣指标（CII）中进入前 20 名，因此未被纳入。 Google Cloud Platform：该供应商已停止提供专门的 DevOps 平台服务。 VMware：该供应商未达到客户数量和收入增长的相关标准。 纳入与排除标准 为了确保魔力象限集中评估市场上最具影响力的供应商，Gartner 将供应商数量限制为 20 家。\n以下为本次评估中，供应商必须满足的纳入标准。\n市场参与标准 截至 2024 年 1 月 1 日，入选魔力象限的 DevOps 平台供应商需要满足以下条件：\n提供一个正式发布的、可供购买的 DevOps 平台，并且在公开的定价页面中可以找到该产品。 直接向客户销售解决方案，并提供至少一级的支持，无需客户购买额外的专业服务支持。 展示积极的产品规划和市场销售策略。 提供全面的客户支持，包括电话、邮件和网络服务，且支持英语。 客户群体至少有 10% 分布在以下三个地区中的两个： 美国和加拿大 欧洲（包括英国和爱尔兰） 亚太地区 平台功能标准 DevOps 平台需要具备以下功能：\n持续集成（CI）：支持代码的持续构建和验证，包括自动化测试、安全性和合规扫描。 持续交付（CD）与发布管理：支持无门槛的持续部署以及满足合规性要求的门控审批机制。 集成的安全开发与团队协作平台，能够在多个用户角色之间提供统一的工作流可视化。 提供价值流度量工具：用于衡量整个软件交付过程中的工作流效率和价值传递（例如，吞吐量指标、DORA 指标）。 安全软件交付：将安全功能作为软件开发生命周期（SDLC）中的核心部分进行管理和协调。 表现纳入标准 供应商必须满足以下财务标准（以美元为单位）。默认采用公认会计准则（GAAP）：\nDevOps 平台在截至 2024 年 1 月前的 12 个月内，年收入需达到至少 6000 万美元。同时，该平台应拥有至少 200 名付费的实际生产环境用户（不包括托管服务提供商），每个客户平均需使用至少 75 个席位的 CI/CD 功能。 或者，DevOps 平台在 2023 日历年内年收入需至少达到 1500 万美元，并且与 2022 年相比，新增了 35 名净新客户，这些客户均使用了 CI/CD 核心功能。 此外，供应商必须在 Gartner 定义的客户兴趣指标（CII）中位居前 20 名。CII 基于以下平衡的指标计算：\nGartner 客户的搜索、查询量和价格请求。 在 Gartner 同行洞察论坛中，作为其他供应商的竞争对手出现的频率（截至 2024 年 1 月 1 日）。 在 Gartner 同行洞察中的评分和提及频率。 主要市场创新、产品更新、行业奖项等方面的表现。 企业的重大动态（如并购活动）。 在美洲、欧洲和亚太地区的招聘网站上，相关岗位的发布数量。 排除标准 以下供应商不被纳入分析：\n主要用于低代码应用程序、业务应用程序或 SaaS 应用交付的 DevOps 平台（如 Salesforce、Microsoft Dynamics 365、Oracle、SAP、ServiceNow 的开发或定制）。这类平台的市场需求和功能与本魔力象限定义的不同。 平台仅作为定制软件开发或专业服务的一部分销售。 荣誉提名 Alauda：Alauda 提供基于 Kubernetes 的 DevOps 平台，称为 Alauda Container Platform (ACP)，利用开源组件为云原生开发和交付提供集成功能，适合平台工程应用。功能还包括容器管理、Kubernetes 集群管理、服务网格、多云管理等。Alauda 未满足 Gartner 的 CII 标准，因此未入选本魔力象限。 Bitrise：Bitrise 提供专为移动平台构建应用的 DevOps 平台，但未能满足本魔力象限的市场定义要求。 CodeNOW：CodeNOW 通过开源组件提供云原生持续交付 (CD) 平台。CodeNOW 未达到本魔力象限的最低收入和增长要求。 华为：华为 CodeArts 是一个 DevSecOps 平台，覆盖整个软件开发生命周期，具备需求管理、源代码管理、自动化测试等功能。尽管 CodeArts 在中国市场表现突出，但其未能满足全球化扩展要求。 Opsera：Opsera 提供一个统一的 DevOps 平台，覆盖整个 SDLC，集成了开源工具和预配置工作流，提供软件交付指标的可视化。Opsera 未达到最低收入和增长要求，因此未入选本魔力象限。 ","date":"2024-09-20T09:49:13+08:00","image":"https://martinliu.cn/blog/2024-magic-quadrant-for-devops-platforms/66da11103b54e7739f860dd8_blog-gartner-mq_hu_13bc3ed06b3e291e.png","permalink":"https://martinliu.cn/blog/2024-magic-quadrant-for-devops-platforms/","title":"2024 年 Gartner DevOps平台魔力象限"},{"content":"可观测性平台通过分析、可视化、自动化以及 AI 技术，将遥测数据转化为可执行的洞察。虽然大多数平台都包括应用性能监控（APM）功能，但仅靠 APM 是不够的。I\u0026amp;O 领导者可以参考此研究，探索相关供应商及解决方案。\n市场定义与描述 Gartner 将可观测性平台定义为：能够从日志、指标、事件和追踪等多种来源获取遥测数据（运营数据）的产品。它们旨在帮助企业了解应用、服务及基础设施的健康状况、性能表现，及行为趋势。可观测性平台可以通过人工操作或机器智能分析遥测数据，识别影响终端用户体验的系统行为变化，例如服务中断或性能下降。这些平台可以让问题在早期，甚至是预防阶段就得到解决。可观测性解决方案被广泛的应用于 IT 运营/运维、站点稳定性工程师/SRE、云与平台团队、应用开发人员，以及产品负责人。\n现代企业高度依赖关键的数字应用和服务，这些应用和服务不仅是创收工具，还直接影响客户体验和企业运营效率。中断、性能下降和不稳定现象都会直接冲击企业的营收、客户满意度及品牌形象。\n可观测性平台能帮助企业提升关键应用和服务的可用性、性能和恢复力。成功投资和部署可观测性平台能够避免收入损失，同时加快产品开发周期，改善品牌形象。\n以下是可观测性平台解决的一些典型场景或业务问题：\nIT 运营：IT 运营团队负责确保生产环境中的应用和服务始终可用、迅速响应且性能卓越，尤其是在高峰期。可观测性平台可以在问题出现时及时发出告警，并帮助团队通过数据分析找到根本原因。 平台工程：平台工程师的工作类似于 IT 运营和软件开发。可观测性平台帮助他们确保生产环境始终达到服务质量目标 (SLO)，同时推动持续的数据驱动改进与平台优化。 软件开发：开发团队将可观测性平台集成到 CI/CD 流水线中，提供新代码部署的快速反馈，加快新功能发布，同时提高产品的恢复力。 业务分析：业务分析师利用可观测性平台分析企业的关键业务指标，例如零售商可能会评估放弃购物车的成本和客户的平均消费金额。 必备功能 可观测性平台至少应具备以下基本功能：\n获取、存储并分析运营遥测数据流，数据来源包括但不限于指标、事件、日志和追踪信息。 识别并分析应用、服务或基础设施的行为变化，从而判断是否存在可用性中断、性能下降，或是否对终端用户体验产生了影响。 通过提供拓扑依赖关系映射和业务服务之间的关联，为遥测数据增加上下文信息，进一步丰富数据内容。 常见功能 可观测性平台通常具备以下功能：\n监控通过浏览器、移动应用和 API 提供的应用与服务的用户体验。 与其他运营管理、服务管理和软件开发技术集成，如 IT 服务管理、配置管理数据库、事件与事故响应管理、编排与自动化及 DevOps 工具。 从公有云平台（如 Amazon CloudWatch、Microsoft Azure Monitor 和 Google Cloud Operations）收集遥测数据。 支持多种遥测数据类型（如追踪、指标和日志）的交互式分析，帮助深入了解用户与应用行为。 借助高级分析与机器学习，提供基于数据的洞察，超越手动查询或分析的能力。 自动发现并映射相关的基础设施、网络和应用组件及服务。 支持成本管理功能，能够度量和优化应用工作负载成本，或优化可观测性平台的利用率和支出。 业务流程与活动监控，例如用户的登录到结账流程、转化率追踪漏斗分析、客户注册或贷款申请的流程。 提供应用安全功能，能够识别受监控应用中的已知漏洞，并阻止对这些漏洞的攻击尝试。 魔力象限 供应商优势与注意事项分析如下。\nAmazon Web Services Amazon Web Services (AWS) 在此次魔力象限中被归类为挑战者。AWS 的可观测性解决方案包括 Amazon CloudWatch、AWS X-Ray、Amazon Managed Service for Prometheus、Amazon Managed Grafana 和 AWS Distro for OpenTelemetry，支持端到端的 observability 使用场景。这些服务是 AWS Cloud Operations 的一部分，涵盖治理和财务管理。AWS 的业务遍布全球，其客户主要为大型企业，并且 AWS 定期发布和更新产品。\n优势 应用信号：AWS 于 2023 年末推出了 CloudWatch Application Signals，这是第一个专注于应用程序监控的 CloudWatch 服务。通过此服务，运维人员可以通过设定服务质量目标 (SLO) 并使用服务视图来管理系统健康和性能，同时对出现的问题进行分类。 统一的可观测性平台：AWS 支持 OpenTelemetry、Prometheus 和 Selenium 等行业标准，提升了跨平台的互操作性。即使没有使用代理，AWS 之外的工作负载也可以通过 Managed Grafana 服务进行监控和可视化。 全球影响力：AWS 在全球范围内扩展迅速，已宣布新增四个地区和 18 个本地区域。Observability 服务全球可用，客户可以根据需求决定如何设置遥测数据在生命周期中的存储策略。 注意事项 竞争环境：尽管 AWS 可观测性工具近年来有所改进，如推出 CloudWatch Application Signals 和 Internet Monitor，但 AWS 也为本研究中的许多供应商提供托管服务，并通过 AWS Marketplace 与其合作。此种合作关系在时间上优先考虑客户选择，但与 AWS 平台的统一性存在矛盾。 成本管理：与 AWS 其他服务类似，observability 按需付费，基于多种消费模式，可能不完全适应所有运营模式或使用场景。 服务复杂性：AWS 提供多达 28 种监控与 observability 服务，尽管这展示了广泛的产品线，但也容易引起客户混淆。改进的文档有助于客户根据实际需求区分 CloudWatch 的功能。 BMC BMC 在本次魔力象限中被归类为利基参与者。其 BMC Helix Operations Management 平台提供了丰富的 ServiceOps 和 observability 功能，涵盖 BMC Helix Discovery 及其他组件。BMC 在 IT 服务管理领域中拥有重要地位，其 BMC Helix ITSM（前称 Remedy）产品以及主机解决方案有着广泛的应用。BMC 的业务覆盖全球主要市场。\n优势 广泛的客户基础：作为传统的“四大” IT 运营技术供应商之一，BMC 在大型企业和政府机构中具有重要影响力。这种既有的影响力使 BMC 在向 observability 过渡时具备优势。 服务运营集成：BMC 的可观测性解决方案可以与第三方工具兼容，同时与其自身的 ITSM、发现工具和 CMDB 紧密集成，具有潜在的工具整合优势。 故障分析工具：该平台提供健康时间线和健康评分功能，帮助用户了解应用程序或服务的性能变化，还支持快速检查变化情况。它还具备“情况解释”功能，通过 BMC HelixGPT 等 AI 技术，解释问题可能的根本原因。 注意事项 产品组合复杂性：BMC 的解决方案依赖其众多产品组件，尽管可以单独授权使用，但某些功能仍需依赖自定义仪表板。例如，SLO 功能并非开箱即用。 定价不透明：BMC 未公开其定价，除非是针对政府客户或云市场的定价。这与 observability 行业的趋势不符，客户通常希望在早期获取价格信息以进行成本评估。 现有 BMC 环境：BMC 的大部分客户仍在使用其旧有技术，如 BMC PATROL 和 TrueSight。BMC 已对其产品进行现代化改造，如推出云原生的 Helix 平台，并收购了 Netreo。因此，客户需要明确的升级路径指导，以顺利过渡到新平台。 Chronosphere Chronosphere 在此次魔力象限中被评为领导者。其可观测性平台解决方案包括 Chronosphere Observability Platform 和 Chronosphere Telemetry Pipeline，业务主要集中在美国和 EMEA 地区，客户大多来自北美。\nChronosphere 的创始人在 Uber 工作期间开发了 M3DB 时间序列数据库，如今公司仍在支持这一开源项目。近期，Chronosphere 收购了遥测管道供应商 Calyptia（Fluent Bit 的创建者），并与 CrowdStrike 建立了合作，作为其日志获取和分析产品的基础。\n优势 遥测数据管理与治理：Chronosphere 提供一个控制平面，客户可以使用该平台分析遥测数据的使用情况，并在数据收集时制定策略与规则。这使得成本优化和数据治理变得更加高效，这是其他供应商难以提供的功能。 依托开源技术：Chronosphere 支持 Prometheus 风格的指标采集以及 OpenTelemetry，用于收集指标、日志和追踪数据。这为那些不愿继续自行管理 Prometheus 或 Jaeger 环境的组织提供了迁移便利。收购 Calyptia 也带来了 Fluent Bit 这一开源工具，进一步丰富了 Chronosphere 的遥测管道能力。 单租户架构：Chronosphere 为每位客户提供独立的租户环境和专属存储空间。这有效避免了不同客户之间的资源争用，同时提高了数据安全性。 注意事项 地理覆盖范围：尽管 Chronosphere 的服务可以在全球使用，但其平台目前仅托管在美国的公有云区域。这可能会引发某些客户对数据主权的担忧，或在某些地区导致延迟问题。公司计划于 2024 年在 EMEA 地区部署托管服务。 数字体验监控功能缺乏：Chronosphere 目前不提供专门的数字体验监控功能，如合成监控或真实用户监控（RUM）。虽然客户可以将数字体验监控的遥测数据上传至 Chronosphere 进行分析，但这些数据的生成和传输需要客户自行解决。 缺少自带代理：Chronosphere 不包含自带的埋点代理，因此被监控的系统需要以与 Prometheus 或 OpenTelemetry 兼容的方式进行埋点，或使用 Fluent Bit 支持的格式。Chronosphere 也支持从其他供应商的代理获取遥测数据，客户可选择兼容的代理进行使用。 Datadog Datadog 在此次魔力象限中被评为领导者。其 SaaS 平台不仅提供可观测性解决方案，还覆盖云安全领域。Datadog 的业务主要集中在美国和 EMEA 地区，同时在亚太和拉丁美洲市场逐步扩展，服务的客户从初创企业到大型企业。近期，Datadog 对其平台进行了多项改进，包括升级仪表板、笔记本和 Watchdog AI 功能，推出了 Flex Logs、移动应用测试、数据流监控以及动态埋点功能。此外，还推出了事件管理功能，将 Datadog 和其他 可观测性工具中的事件整合到统一视图中进行管理。\n优势 战略愿景与销售执行力：Datadog 迅速构建了多项新功能，涵盖 APM、日志管理、数字体验监控（DEM）、安全和软件交付等领域，赢得了许多寻求高端解决方案的企业的青睐。其产品驱动增长（PLG）模式帮助企业在大中小规模的组织中扩大客户基础并提升客户参与度。 可视化能力：Datadog 提供了强大且用户友好的可视化功能，使用户能够在一个界面中查看所有遥测数据，并支持通过小部件轻松定制仪表板。 产品发展路线：Datadog 具备强大的产品发展规划，专注于提升 observability、DevSecOps、自动化修复、软件交付以及遥测数据的治理。其策略是打造一个将所有功能无缝整合在一起的平台。 注意事项 定价问题：虽然 Datadog 在官网上提供了详细的定价信息，但一些客户反映，随着使用量的增长，成本可能迅速上升。为了应对这一问题，Datadog 提供了可配置的遥测数据获取控制，帮助客户在预算范围内管理成本。 复杂的业务模式：随着产品线的扩展，Datadog 目前在其官网上提供 20 个独立的产品模块，每个模块都有独立的定价结构，这可能让客户在理解和谈判价格时感到困惑。为了简化流程，Datadog 已开始推出捆绑产品选项。 代理管理功能缺乏：目前，Datadog 缺乏针对代理群组的管理和自动化部署功能，这给大规模部署带来了一定的复杂性。该公司表示，相关功能正在开发中，并已进入测试阶段。 Dynatrace Dynatrace 在此次魔力象限中被评为领导者。其 observability 和安全平台包含多个模块，包括基础设施与应用可观测性、安全分析与防护、数字体验管理、自动化功能以及业务分析。Dynatrace 的客户遍布全球，尤其集中在拉丁美洲、亚太地区等各大市场，主要为大型企业和科技驱动型公司。Dynatrace 最近收购了开发者工具供应商 Rookout 和安全厂商 Runecast，进一步扩展其产品线。\n优势 广泛的产品组合：Dynatrace 提供全面的 observability 和安全解决方案，尤其受到大型企业的青睐。其覆盖范围包括现代架构（如 Kubernetes、容器、云函数）的可观测性，及主机和 SAP 等传统企业解决方案的监控。 AI 技术创新：Dynatrace 对其 Davis AI 引擎进行了重大升级，全面采用 AI 技术进行因果分析和预测建模，并且推出了基于生成式 AI 的智能助手，显著提升了平台的智能化水平。 平台的灵活性与扩展性：Dynatrace 的 AppEngine 和 AutomationEngine 使平台具备更强的扩展能力，用户和第三方开发者可以针对特定行业或业务需求开发定制应用和自动化流程，超越了简单的健康监控和性能分析。 注意事项 采购的复杂性：Dynatrace 于 2023 年引入了新的订阅模式 Dynatrace Platform Subscription（DPS），要求客户承诺年度最低消费额度并使用递减率定价机制。虽然很多客户接受了该模式，并能够使用所有的 Dynatrace 产品，但一些采购部门对最低承诺和新组件的定价模式保持谨慎。 日志管理应用的进展缓慢：尽管 Dynatrace 在 2023 年推出了新机制，能够高效处理大量日志数据，客户对此技术表示出浓厚兴趣，但目前并未出现广泛采用 Dynatrace 进行大规模日志管理的趋势。 对中小企业的适应性：Dynatrace 主要为大型企业设计，虽然通过公有云市场可以降低部分门槛，但中小企业可能因为成本原因，选择将其用于监控最核心的业务系统。 Elastic Elastic 在此次魔力象限中被评为领导者。Elastic Observability 基于广泛使用的 Elastic Search AI 平台（原 Elasticsearch）构建，同时支撑其搜索和安全产品。Elastic Observability 可以通过 SaaS 提供，也可自托管使用。公司总部位于北美，客户主要分布在美洲和 EMEA 地区，并在亚太地区实现了显著增长。Elastic 的未来发展规划包括通过新查询语言和 AI 助手提升分析能力和站点稳定性工程（SRE）效率。\n优势 深度 AI 集成：Elastic 在其平台中深度集成了 AI，提供 30 多种机器学习模型、定制模型集成，并配备了基于检索增强生成（RAG）的 AI 助手，增强了传统数据分析能力。 开放性与灵活性：Elastic Observability 源自开源的 Elasticsearch 数据平台，能够在大规模下处理多样化的高基数数据。其开放架构为平台提供了极高的灵活性和可扩展性。 多样化的部署选择：Elastic Observability 支持全球多个区域的部署，涵盖所有主要云服务提供商，并提供自托管选项。这使得它能够满足不同客户的数据主权需求，并符合区域性法规要求，例如美国政府的 FedRAMP 认证。 注意事项 市场认知度低：尽管 Elastic 的搜索和安全产品知名度较高，但其可观测性产品的市场认知度和应用率仍有待提升。公司正在积极推动其可观测性产品的市场销售和推广。 学习曲线较陡峭：作为开源软件，Elastic 可能需要更多的学习和培训时间，尤其是对于计划自托管的组织，需确保有足够的技术能力支持。 定价模型复杂：Elastic 采用基于计算资源的定价模型，与其他厂商的定价模式不同。尽管 Elastic 提供了定价计算器，但在采购、成本评估和预算预测过程中，可能较难进行直观比较。 Grafana Labs Grafana Labs 也是本次魔力象限中的领导者。公司创建于开源项目 Grafana 之上，并推出了诸如 Loki、Tempo、Mimir 等其他开源项目。Grafana Labs 的可观测性平台包括 Grafana Cloud 可视化、指标、日志、配置文件以及机器学习功能，客户遍布全球，主要集中在美洲和 EMEA 地区。\n优势 全球托管灵活性：Grafana Cloud 目前在全球 19 个 AWS、Azure 和 GCP 区域托管，使客户能够根据延迟需求和数据主权选择合适的托管位置。 持续功能更新：在过去的 12 个月里，Grafana Labs 显著增强了 Grafana Cloud 的功能，特别是在应用程序监控、SLO 管理和自适应指标方面，这些功能可以帮助企业更有效地管理成本。 灵活的数据集成：Grafana 平台能够连接不同的遥测收集系统，并实现跨系统的数据可视化和告警，避免了数据迁移或存储在 Grafana Cloud 中的需求，极大增强了其组合能力。 注意事项 学习曲线较高：随着功能的不断扩展，掌握 Grafana 平台变得更加复杂，配置可能需要手动编辑 YAML 或 JSON 文件，这对初学者来说具有挑战性。 成本预测困难：新用户可能会发现难以预测在 Grafana Cloud 上的指标支出，尤其是活动系列和每分钟数据点等度量标准并不容易获得。使用免费的 Grafana Cloud 版本可能有助于缓解这一问题。 合作竞争关系的复杂性：Grafana Labs 与其他 observability 供应商之间的合作关系可能会变得复杂，尤其是在其自身业务快速扩展的情况下。尽管与 AWS、Google 和 Microsoft 的合作有助于缓解这一问题，但仍需保持关注。 Honeycomb Honeycomb 是本次魔力象限中的远见者。其 observability 服务基于优化的数据存储和查询引擎，专注于探测应用和基础设施中的模式和异常。Honeycomb 作为可观测性平台，支持 APM 使用场景，并以 SaaS 形式提供服务。其客户遍布全球，主要集中在北美和 EMEA 地区。\n最近的更新包括推出了 Kubernetes 监控功能和前端可观测性功能（现阶段为早期访问版本）。\n优势 Kubernetes 专用工具：2023 年，Honeycomb 推出了 Kubernetes 监控工具，使 SRE 能够更快速地诊断容器化环境中的问题。 高度参与的客户社区：Honeycomb 与其用户群保持紧密联系，定期举办研讨会，活跃的 Slack 社区以及社交媒体互动，让客户能够直接提供反馈。 全球化扩展：2024 年初，Honeycomb 在欧洲部署了基于 SaaS 的新实例，使客户能够根据数据主权要求选择将 observability 数据存储在美国、欧盟，或同时存储在两者之间。 注意事项 企业市场的影响力有限：虽然 Honeycomb 在云原生和技术驱动型企业中很受欢迎，但在更广泛的企业市场中其影响力相对较小，Gartner 客户较少将其作为可观测性平台的候选供应商。 技术导向的聚焦：Honeycomb 的宣传主要面向技术专家，特别是 SRE 和平台团队，可能忽略了提供商业和客户行为洞察的潜力，而这些内容往往是 I\u0026amp;O 预算持有者更关心的。 定价难以预测：Honeycomb 的定价基于摄取到平台中的事件量，客户难以预测事件数量以及未来 12 个月的增长。 IBM IBM 是本次魔力象限中的远见者。IBM 的 Instana可观测性平台既可以作为 SaaS 提供，也可以通过自托管方式部署，使用单代理架构。其客户主要为中大型企业，集中在北美和西欧。IBM 的监控产品覆盖从主机到现代云架构。IBM 还计划收购基础设施自动化公司 HashiCorp，该公司的 Terraform 产品与许多可观测性平台都有集成。\n优势 精确的遥测数据：Instana 以每秒级别的精度收集指标，并在三秒内生成通知，这为提升可用性和确保服务质量目标 (SLO) 达成提供了支持。 简单的定价模式：IBM Instana 采用按主机计费的简单定价模式，在市场中具备竞争力。 AI 集成优势：Instana 提供自动化 observability，利用 AI 生成洞察并辅助决策。IBM 最近推出了 watsonx 和 Concert，这些生成式 AI 技术将进一步扩展 Instana 的智能化功能。 注意事项 有限的安全功能：Instana 的安全功能较为有限，更多依赖 IBM 其他产品提供这方面的支持。虽然 Gartner 认为安全功能是可选的，但客户需要根据需求决定是否需要集成安全解决方案。 市场认知度不足：IBM Instana 在市场中的知名度较低，很多现有的 IBM 客户甚至不知道这一产品的存在，即使他们正在寻找可观测性解决方案。虽然 IBM 为使用其传统 IT 工具的客户提供了升级到 Instana 的路径，但很多客户对此并不知情。 日志摄取的限制：目前 Instana 的日志摄取仅限于应用日志和容器化环境。扩展到更广泛的环境是其 2024 年的发展计划之一。 LogicMonitor LogicMonitor 是本次魔力象限中的远见者。其 LM Envision 平台从混合基础设施监控发展为可观测性解决方案。LogicMonitor 提供无代理的 SaaS 平台，涵盖基础设施、网络、SD-WAN、云和应用监控，并具备 AI 功能。客户主要来自美洲和 EMEA，且在亚太地区业务不断扩展。过去一年内，LogicMonitor 发布了多项新工具，包括 Edwin AI（用于事件摄取与关联）、生成式 AI 聊天机器人 LM Copilot 以及用于云成本管理的 LM 成本优化。\n优势 高扩展性：LogicMonitor 使用无代理收集器来监控资源，这些收集器可根据服务器容量和数据需求进行自动负载均衡，确保高数据处理能力，并支持故障切换。其平台提供 99.9% 的可用性 SLA，确保监控始终可用。 容器支持广泛：LogicMonitor 对 Kubernetes 容器环境提供了强大的支持，无需修改容器代码即可进行监控。 简单定价：LogicMonitor 的定价模式简洁明了，适用于各种规模的企业，尤其适合托管服务提供商（MSP）模式下的企业。 注意事项 observability 功能有限：尽管 LogicMonitor 近年来有所投资，但它仍然主要专注于基础设施和网络监控，缺乏数字体验监控和威胁检测等功能，与同行相比存在差距。 仪表板和用户界面：尽管提供了多种监控模板，但 LogicMonitor 的用户界面在市场上相对落后，操作时需要多次点击才能深入分析数据和获取上下文信息。公司正在发布新界面，预计将有所改善。 市场影响力：尽管投入了大量市场宣传，但 LogicMonitor 在市场上的认知度仍然有限，特别是在 observability 领域的扩展上，客户认知度仍需提升。 Logz.io Logz.io 作为远见者，基于开源技术提供其 Open 360可观测性平台，涵盖应用、Kubernetes 和基础设施监控，支持日志管理和云安全信息及事件管理（SIEM）。Logz.io 的客户多为开源技术友好的中小型企业，主要分布在美洲和 EMEA 地区。其未来规划包括进一步利用生成式 AI 增强平台能力，并引入业务导向功能，如 SLO 管理。\n优势 成本优化：Logz.io 专注于降低 observability 成本，其数据优化中心提供强大的遥测成本管理功能，如数据过滤、分层存储、追踪采样等。 从开源到企业的无缝衔接：对于已经使用开源监控工具的企业，Logz.io 提供了快速实现企业级 observability 的路径。 全球化业务：Logz.io 的 Open 360 平台在全球多个 SaaS 实例上运行，支持多语言并符合区域性数据安全法规，客户遍布全球。 注意事项 缺乏前端监控：Logz.io 主要专注于通过开源技术收集后台遥测数据，但在前端用户监控和会话回放等功能方面支持不足。 技术导向过强：Logz.io 平台过于关注技术细节，缺少业务监控和漏斗分析等更贴合商业需求的功能。 市场知名度不足：尽管 Logz.io 的客户基础在增长，但主要集中在中小型企业，与其他供应商相比，其市场可见度较低，较少出现在客户的候选名单中。 Microsoft Microsoft 在此次魔力象限中被评为挑战者。其 Azure Monitor 是一款原生的 Azure 可观测性平台，专注于中大型企业。公司业务遍布全球。除了引入生成式 AI 功能外，Microsoft 的未来计划还包括一种低成本的日志存储机制和基于服务组的应用建模。\n优势 AI 集成：Microsoft 与 OpenAI 的合作带来了生成式 AI 能力，如通过 Copilot 接口集成到 Azure Monitor 中。Kusto Query Language (KQL) 也支持机器学习，并可以创建处理日志数据的机器学习流水线。 Prometheus 支持：Azure Monitor 引入了 Prometheus 托管服务，支持从 Azure Kubernetes Service (AKS) 等服务摄取数据，利用 PromQL 进行分析，并通过 Grafana 实现可视化和告警功能。 安全监控集成：Microsoft 的 Sentinel 和 Defender 产品与 Azure Monitor 无缝集成，提供跨运营和安全功能的统一分析和事件响应能力。 注意事项 SLO 管理缺乏：Azure Monitor 尚未提供直接的 SLO 管理功能，相关功能预计在 2024 年推出。当前的 SLO 管理流程相对繁琐。 OpenTelemetry 支持延迟：尽管 Azure Monitor 可以摄取 OpenTelemetry 数据，但尚不支持直接通过收集器接口处理 OpenTelemetry Protocol (OTLP) 数据。相关功能在 2024 年进入公测。 Prometheus 兼容性问题：Azure Monitor 对 Prometheus 的支持目前与开源版本存在一些不兼容问题。 New Relic New Relic 在此次魔力象限中被评为领导者。其可观测性平台以 SaaS 形式提供，涵盖 APM、AI 监控、数字体验、基础设施监控、日志管理和安全功能。客户主要为中大型企业，遍布美洲、EMEA 和亚太地区。最近，New Relic 在日志存储优化、AI 监控和应用安全方面进行了增强，并在 2023 年 11 月被 Francisco Partners 和 TPG 收购。\n优势 灵活的定价：New Relic 提供基于摄取量和用户数量的定价模式，以及新的基于计算量的定价，客户可以根据使用量灵活调整成本。 AI 监控：New Relic 的 AI 监控功能使工程师能够监控 AI 模型的性能，并比较大语言模型（LLM）的成本和效率。 统一的数据平台：New Relic 的遥测数据平台 (TDP) 专为高效管理遥测数据而优化，支持高基数数据，并原生支持 OpenTelemetry。 注意事项 实施复杂性：一些客户反映，初始设置和配置过程较为复杂，特别是对于不熟悉该平台的用户。 地理覆盖有限：New Relic 的服务交付平台主要位于美国和 EMEA，特别是依赖 AWS 托管的 SaaS 平台。亚太地区的企业可能需要确保其服务符合区域性要求。 收购影响：New Relic 被收购后，客户对其产品路线图和稳定性有所关注。公司表示已加大平台创新投资，但未来发展仍有待观察。 Oracle Oracle 在本次魔力象限中被评为利基参与者。其 Oracle Cloud Observability and Management (O\u0026amp;M) 平台支持混合和多云环境中的应用、日志、基础设施和数据库监控，尤其侧重于 Oracle Cloud Infrastructure (OCI) 和企业应用。Oracle 客户遍布全球，涵盖各行业的中大型企业，包括政府机构。未来，Oracle 计划进一步提升 O\u0026amp;M 为 SRE 团队的体验，集成 ITSM，并专注于日志管理和分析。\n优势 全球覆盖：Oracle 拥有全球化的业务，支持多种语言，并符合区域性法规要求。通过欧盟主权云、FedRAMP 认证以及 OCI 专用区域，Oracle 提供了符合数据主权要求的解决方案。 全面的 Oracle 集成：Oracle 的 O\u0026amp;M 不仅适用于 OCI，还支持 E-Business Suite 和 PeopleSoft 等应用，客户可以使用定制仪表板和自动化监控，提升用户体验。 多云支持：Oracle 一直致力于提供支持多云环境的 O\u0026amp;M 解决方案，不局限于自家生态，适应多云工作负载的需求。 注意事项 市场认知度较低：虽然 Oracle 将 O\u0026amp;M 定位为多云解决方案，但该产品在现有客户群之外的认知度较低，较少出现在 Gartner 的客户咨询中。 生成式 AI 发展较慢：虽然大多数供应商在 2023 年都引入了生成式 AI，Oracle 在这方面的进展较为缓慢，目前相关功能仍在开发中。 缺乏业务导向功能：尽管支持 Apdex 评分，O\u0026amp;M 尚未引入全面的 SLO 管理或错误预算管理功能，难以完全满足 SRE 团队的需求。 ServiceNow ServiceNow 是本次魔力象限中的远见者。其可观测性平台包括 Cloud Observability（原 Lightstep）以及 IT 运营管理 (ITOM) 和 IT 服务管理 (ITSM) 功能。ServiceNow 客户遍布全球，涵盖各行业，其产品路线图侧重于全面引入生成式 AI 功能。\n优势 支持 OpenTelemetry：ServiceNow Cloud Observability 从设计上就支持 OpenTelemetry 数据的摄取和分析，包括基于 Open Agent 管理协议 (OpAmp) 的收集器管理功能。 强劲的市场影响力：ServiceNow 在企业市场中拥有稳固的基础，特别是在大型企业中，其 ITSM 产品的广泛应用使其能够推动 Cloud Observability 的使用。 全面的产品组合：Cloud Observability 正逐步与 ServiceNow 的 ITOM 和 ITSM 产品整合，成为 ServiceNow 客户寻求可观测性平台的一个自然选择。 注意事项 认知度不足：Gartner 的客户反馈表明，许多企业对 ServiceNow 的 Cloud可观测性解决方案并不熟悉，市场推广力度不及专注于 observability 的供应商。 产品组合复杂性：Cloud Observability 与 ServiceNow 的其他产品组合并行但独立存在，功能如 SLO 管理属于 ITOM，需要额外购买，增加了复杂性。 路线图缺乏创新：与市场领导者相比，ServiceNow 在 Cloud Observability 上的创新较少，未来发展方向较为保守。 Splunk Splunk 在本次魔力象限中被评为领导者。其可观测性平台包括 Splunk Platform、Splunk IT Service Intelligence 和 Splunk Observability Cloud。Splunk 的客户主要为全球的大型企业。2024 年 3 月 18 日，Cisco 完成了对 Splunk 的收购，并将 AppDynamics 整合到 Splunk 的可观测性产品中。本报告中的参考信息收集于收购完成之前，因此仍然使用 Splunk 的名称。\n优势 支持 OpenTelemetry：Splunk 强大的 OpenTelemetry 支持使其在可观测性平台中表现出色，提供对 Linux、Windows 和 Kubernetes 的全方位支持。 SLO 管理功能：Splunk Observability 提供了便捷的工作流，帮助客户通过 UI 或自动化工具如 Terraform 管理 SLO，还支持 SLO 消耗率分析告警。 一体化解决方案：Splunk 通过紧密集成的可观测性平台，能够无缝地支持 IT 运营、工程和网络安全领域的多种使用场景。 注意事项 收购带来的不确定性：Cisco 收购 Splunk 后，产品线整合尚未完成，未来销售流程可能存在不确定性。 地理覆盖差异：Splunk Cloud 的覆盖范围大于 Splunk Observability Cloud，前者在北美、EMEA 和亚太地区有更广泛的分布。对于有严格数据主权要求的客户，需详细检查其具体位置。 定价复杂：Splunk 的定价模式较为复杂，可能会给客户带来预测成本的难题，特别是在数据摄取和使用量变化较大的情况下。 Sumo Logic Sumo Logic 在此次魔力象限中被评为利基参与者。其可观测性平台专注于提供可用性、性能和安全分析，主要服务于全球中小型企业。Sumo Logic 最近推出了基于 AI 的异常检测和优化功能，客户主要分布在美洲和亚太地区。\n优势 灵活的定价模式：Sumo Logic 的定价基于分析而非数据摄取，这意味着客户只需为数据分析付费，而数据摄取成本为 $0。 支持 OpenTelemetry：Sumo Logic 为所有客户提供 OpenTelemetry 支持，简化了遥测数据的收集和分析。 全球覆盖：Sumo Logic 平台在全球多个 AWS 区域可用，支持数据驻留和主权要求。 注意事项 日志为中心：Sumo Logic 主要定位为日志分析工具，尽管支持追踪和指标，但对于需要深入应用监控的企业可能不够全面。 市场增速缓慢：尽管 Sumo Logic 总体收入有所增长，但可观测性平台的收入增长自 2022 年以来几乎停滞不前。 缺乏原生合成监控：Sumo Logic 没有提供原生的合成监控功能，客户需要使用其他工具来实现此功能，尽管它支持与 Catchpoint 的开箱即用集成。 添加和删除的供应商 随着市场变化，我们会不断审查和调整魔力象限的纳入标准。因此，魔力象限中的供应商组合可能会随时间发生变化。一年中出现的供应商在次年消失，并不意味着我们对该供应商的看法发生了改变。这可能反映了市场的变化，进而调整了评估标准，或是供应商自身的重点发生了转移。\n新增 以下供应商符合纳入标准，并被添加至魔力象限：\nBMC Chronosphere LogicMonitor 删除 Broadcom 被删除是因为未能达到市场的客户兴趣指标 (CII) 门槛。 Cisco 被删除是因为 Cisco Observability Platform 产品已停用。 ManageEngine 被删除是因为未能达到 CII 门槛。 Riverbed 被删除是因为未能达到 CII 门槛。 SolarWinds 被删除是因为未能满足本次研究的纳入标准。 纳入和排除标准 魔力象限的研究通过识别并分析市场中最具相关性的供应商及其产品，帮助客户了解市场状况。为了支持市场识别，通常我们会选择不超过 20 个最具代表性的供应商进行研究。要符合纳入标准，供应商必须满足以下要求：\n市场参与标准 截至 2024 年 3 月 14 日，产品或服务必须普遍可用，能够通过常规销售渠道提供给所有客户。 供应商必须直接销售可观测性平台，并提供至少一线的客户支持服务，包括产品文档、安装指南和参考示例。 供应商应展示清晰的产品路线图和市场策略。 性能门槛 -可观测性平台必须在两个或多个地理区域拥有至少 50 位付费的生产环境客户。 -可观测性平台在最近 12 个月内的年收入至少达到 7500 万美元，或者年收入至少达到 1000 万美元，并且年收入增长率达到 25%。\n此外，供应商必须在 Gartner 的客户兴趣指标 (CII) 中位居前列。CII 指标通过反映客户兴趣、供应商互动和客户反馈的加权组合来计算。\n荣誉提名 我们正在观察超过 40 家供应商的表现，虽然此次研究重点分析了 17 家供应商，但未被纳入并不意味着它们不具备实力。\nObserve：这家公司是最早基于 Snowflake 数据平台构建可观测性平台的供应商之一，在其 2024 年 B 轮融资后表现强劲，尽管未达到此次研究的非功能性要求，但仍是市场中的重要力量。 评估标准 执行能力 Gartner 分析师根据供应商的质量和效率来评估其执行能力。我们评估供应商的过程、系统、方法或程序是否能够使其在市场中保持竞争力、运营高效且富有成效，并能够带来积极的收入增长、客户留存率和声誉。最终，供应商的表现评估将依据其利用自身愿景实现成功的能力。\n产品 此标准主要关注供应商在可观测性平台市场中的核心技术竞争力，涵盖当前产品功能、质量和特性。此外，还考虑其产品的可扩展性、稳定性、集成性以及安全特性。\n整体可行性 评估供应商整体财务状况及其业务单元的财务健康度，考虑盈利能力、收入来源的地理分布以及研发投入。\n销售执行/定价 评估供应商在市场中的销售表现，重点关注其定价模式的透明度、价值以及复杂性。还包括对定价与折扣、新老客户业务以及与竞争对手的动态对比。\n市场响应能力 衡量供应商根据客户需求变化和市场动态调整策略的灵活性，评估其应对竞争和响应客户反馈的能力。\n市场执行 评估供应商的市场推广活动，关注其传递信息的清晰度、质量、创意和效果，以及其品牌影响力、产品知名度和客户认同感的提升。\n客户体验 重点评估客户通过供应商产品和服务实现预期结果的体验，包括客户支持计划、售后服务和区域内合作伙伴的支持情况。高端客户的特别支持项目也在评估范围内。\n运营 衡量供应商实现目标并履行承诺的能力，评估其组织结构、技能和合作关系的质量，特别是其遵守服务级别协议 (SLA) 的表现。还考虑其与云服务提供商的合作以及处理停机事件的能力。\n表 1 列出了魔力象限中关于执行能力的具体评估标准。\n评估标准 权重 客户体验 高 市场响应能力/记录 高 市场推广执行 中 运营 低 整体可行性 中 产品或服务 高 销售执行/定价 中 愿景的完整性 Gartner 分析师通过评估供应商对当前市场机会的理解能力，以及其阐述未来市场方向、创新和客户需求的能力来衡量其表现。最终，供应商的愿景展望和其实现未来目标的能力将作为评估依据。\n市场理解 此标准衡量供应商对客户需求的把握，以及如何将这些需求转化为产品。具有清晰市场愿景的供应商能够倾听和理解客户需求，并通过其创新推动市场发展。供应商对 observability 领域的深入理解及其与 APM 的区别也是评估的重要因素。\n营销策略 评估供应商是否具备清晰的差异化营销信息，以及是否通过社交媒体、广告和客户项目等渠道有效传递这些信息。创新的市场推广策略和真实的差异化也在考量范围内。\n销售策略 评估供应商的销售策略是否能够利用直接和间接销售、营销、服务和合作伙伴网络，扩大市场覆盖和客户基础。渠道策略及对购买决策者的理解也是关键考量因素。\n产品策略 评估供应商在产品开发和交付上的策略是否满足当前及未来的市场需求，是否具备差异化功能和持续创新的能力。产品路线图的质量及投资优先级也在评估范围内。\n商业模式 评估供应商的商业模式是否设计合理且执行有效，能否持续取得成功。考量因素包括对定价模式的预判、业务逻辑以及与开源社区的关系。\n创新 评估供应商在新兴技术领域的创新能力，以及对 AI/ML 等新技术的运用，是否能推动产品开发，并与第三方和合作伙伴建立协同效应。\n地理战略 评估供应商是否具备针对全球市场的战略，能否通过本地资源、合作伙伴和 SaaS 平台满足各地区的需求。考量因素包括区域员工数量、SaaS 平台位置及地区化市场策略的调整。\n本次魔力象限中使用的愿景完整性评估标准列于表 2。\n评估标准 权重 市场理解 高 市场策略 中 销售策略 中 产品策略 高 商业模式 高 垂直行业策略 未评级 创新 高 地理策略 中 象限描述 领导者 领导者象限中的供应商提供强大的可观测性产品，能够满足市场的广泛需求，并在扩展客户基础方面非常成功。他们拥有广泛的产品组合，提供卓越的分析能力和可见性，且能够与其他 ITOM 技术无缝集成。领导者具备优异的愿景与执行力，能够满足当前和未来市场的需求，同时持续在创新和客户体验方面表现出色。\n挑战者 挑战者象限中的供应商通常具备广泛的市场覆盖和大规模的客户部署。他们在执行方面表现强劲，得益于公司整体的销售和品牌影响力。这些供应商通常提供广泛的产品组合，部分供应商可能正处于产品转型阶段，逐步调整其市场焦点。\n远见者 远见者象限中的供应商具备创新计划，能够应对市场需求，但其产品组合尚不成熟。他们在执行方面的能力略低，通常在应对市场变化、整合产品功能以及扩大市场份额方面相对较弱。\n利基参与者 利基参与者象限中的供应商主要专注于特定市场或垂直领域，或仅满足有限的使用场景需求。由于他们无法在所有核心功能上表现出深度，通常无法满足更广泛市场的需求。纳入该象限并不意味着其在所竞争市场中的价值受到质疑。\n背景 可观测性平台：未来展望\n过去几年里，observability 市场一直在快速发展，竞争激烈，供应商背景和规模各异，开源产品的比例也逐渐增加。虽然产品质量和功能不断提升，但随之而来的成本也在上涨。许多客户开始质疑是否值得为 observability 支付高昂的成本。\nIT 运营同样受到了 AI 技术的深刻影响，尤其是在本次魔力象限项目中，这一现象尤为明显。客户常常询问 AI 在 IT 运营中的角色，以及它与 AIOps 的关系。\n可观测性平台本质上是数据管理和分析工具，越来越多的工具开始将 AI 技术作为基础功能，包括自适应阈值、异常检测等。AI 在可观测性平台中的作用将继续演进，但 Gartner 鼓励客户根据具体的用例评估产品的适用性，而非仅仅关注特定技术的有无。\n市场中的可观测性产品种类繁多，几乎总有一个产品能够满足客户的独特需求。由于魔力象限的篇幅限制，许多优秀的供应商未能被纳入本次研究。如果有任何问题，欢迎联系我们。\n市场概览 从 APM（应用性能管理）到可观测性平台的发展，反映了市场的更广泛趋势。随着商业数字化、云的普及以及技术在日常生活中扮演的核心角色，工作负载和遥测数据的复杂性和规模都在不断增长，这对理解系统健康、性能和用户体验的能力提出了更高的要求。\n市场扩展 现有客户中的扩展：过去，APM 工具主要用于监控少量关键应用。但随着可观测性平台功能的提升、部署的简化以及价格下降，更多的应用开始使用这些工具。面对经济波动，组织更倾向于选择能够全面覆盖遥测数据的“全栈”解决方案。 新行业的扩展：APM 和 可观测性工具最初多应用于 IT 系统成熟的大型企业。如今，中小企业也逐渐采用这些工具，特别是那些基于开源技术的解决方案，帮助他们更轻松地转向现代可观测性平台。 云服务商的竞争：随着企业在 observability 上的投入增加，云服务商（CSP）也开始推出具备竞争力的原生 可观测性工具，尤其在多平台环境中，它们的吸引力越来越大。 未来趋势 未来几年，可观测性平台市场将继续受到以下趋势的推动：\n数据整合需求：用户需要在不切换工具的情况下，整合和分析来自不同源的遥测数据。 AI 驱动的自主功能：随着 AI 的进步，监控工具将逐渐融入自适应阈值、异常检测等自动化功能，甚至具备更高层次的优化能力。 网络安全集成：可观测性平台开始增加网络安全功能，未来可能成为此领域的重要竞争者。 AI 和 LLM 监控：随着 AI 和大语言模型工作负载的部署，可观测性平台将优先支持这些新兴领域。 集中式 observability 团队：越来越多的组织成立专门团队来集中管理 SLO、遥测数据和事故响应。 SaaS 和云服务监控：随着更多关键业务依赖 SaaS 和云服务，可观测性平台供应商将继续扩展对这些领域的支持。 并购与整合：市场的重组仍在继续，未来将有更多并购、产品更新和整合，这将改变供应商格局。 证据 本次研究基于过去 12 个月中超过 1000 次客户互动。此外，我们还结合了来自 Gartner Peer Insights、客户咨询以及公开资料的信息，以补充供应商提供的数据。\n评估标准定义 执行能力 产品/服务：评估供应商为市场提供的核心产品和服务，包括当前产品功能、质量、特性、以及是否通过 OEM 协议或合作伙伴提供。 整体可行性：衡量供应商整体的财务健康状况及其业务单元的成功，评估其继续投资、创新和提供产品的能力。 销售执行/定价：评估供应商在销售中的能力，包括交易管理、定价策略、售前支持和销售渠道的整体效率。 市场响应能力/记录：评估供应商根据市场机会、客户需求变化和竞争对手行为的响应能力，以及其在应对市场变化中的灵活性。 市场执行：评估供应商推广其品牌、提升产品知名度和影响客户心智的能力。包括宣传、促销、思想领导力等活动的效果。 客户体验：衡量供应商通过产品和服务帮助客户取得成功的能力，特别是技术支持、客户服务以及服务级别协议等方面的表现。 运营：评估供应商是否具备有效管理和运营其业务的能力，包括组织结构、项目管理、系统和其他运营工具的质量。 愿景完整性 市场理解：衡量供应商理解客户需求并将其转化为产品和服务的能力，展示出清晰的愿景，并能够通过这些愿景引领市场发展。 营销策略：供应商的营销信息是否清晰、具有差异化，并通过多种渠道有效传达。 销售策略：评估供应商的销售策略是否覆盖全面，包括直接和间接销售渠道的利用，以及市场覆盖的深度和广度。 产品策略：供应商在产品开发和交付中的策略是否能够满足当前和未来的市场需求，并体现差异化。 商业模式：评估供应商的商业模式是否合理且具备可持续性。 垂直/行业策略：供应商在特定市场细分中的资源配置和产品战略。 创新：供应商在新技术、整合和协同创新方面的能力和投资力度。 地理战略：评估供应商是否具备全球扩展的战略，能够根据不同地区的需求调整资源和产品策略。 原文：https://www.gartner.com/doc/reprints?id=1-2HXS17MG\u0026ct=240627\u0026st=sb\n❤️ Feature Photo by Pavel Danilyuk: https://www.pexels.com/photo/a-bearded-man-with-a-hat-using-binoculars-9143804/\n","date":"2024-08-15T10:04:45+08:00","image":"https://martinliu.cn/blog/2024-magic-quadrant-for-observability-platforms/pexels-pavel-danilyuk-9143804_hu_2c9ba35021e8a3ef.jpg","permalink":"https://martinliu.cn/blog/2024-magic-quadrant-for-observability-platforms/","title":"2024 年 Gartner 可观测性平台魔力象限"},{"content":"Azure 支持嵌套虚拟化 嵌套虚拟化是一种经常在物理服务器实验环境中所使用到的场景。例如，你可以在 VMware ESXi 或者 Hyper-V 虚拟机中运行 ESXi，KVM，Hyper-V 等一种或者多种虚拟机管理服务器，然后最内层的 Hypervisor 上运行虚拟机。在 Azure 的虚拟机中，运行 VirtualBox ，重建 VirtualBox 的虚拟机测试环境，就这种情况。\nAzure 是在 2017 年 1 月，宣布支持两个新的可支持嵌套虚拟化的机型 Dv3 和 Ev3。「参见：https://azure.microsoft.com/en-us/blog/nested-virtualization-in-azure/」；在创建虚拟机时，你需要在 Azure CLI 或者 Azure PowerShell 中设置 --nested-virtualization 参数。或者在 Azure 门户中，需要在创建虚拟机时选择 Dv3 或者 Ev3 系列的虚拟机。\n注意：如果没有选择合适于嵌套虚拟化的机型，你依然可以在虚拟机中安装 VirtualBox，可以创建虚拟机，但是无法正常启动运行嵌套的虚拟机。\n创建 Azure 虚拟机 在 Azure 门户中，选择 虚拟机，然后选择 创建，选择 Dv3 或者 Ev3 系列的虚拟机，其它相关选项如下图所示。\n安全类型：这里选择 “Standard” ，这里默认的是 “Trusted launch virtual machines” , 如果选择了默认选项，嵌套虚拟机的虚拟机是无法正常启动的。 在选择机型的时候，选择 D 或者 E 开头的，并且是 v3 结尾的系列。 这里操作系统的选择的是 Ubuntu Server 22.04 LTS，Ubuntu 操作系统可以使用 VirtualBox 或者 Kvm 等虚拟化技术。 在使用了上面的选项之后，你就可以在 Azure 虚拟机中正常安装和使用虚拟化软件了。就可以使用你所选择的虚拟机管理软件，在 Ubuntu 操作系统中运行虚拟机测试环境。当然你也可以使用 Windows Server 系列操作系统中的 Hyper-V 虚拟化技术。\n用 Vagrant 管理虚拟机环境 Vagrant 是一个用于构建和管理虚拟机环境的工具，它可以用于在虚拟机中自动化的安装软件，配置网络等操作。Vagrant 使用 Ruby 语言编写，使用 Ruby 的 DSL 语言来描述虚拟机的配置。\n请参考 Vagrant 的官方文档，学习如何安装和 Vagrant 来管理虚拟机环境。\n在 Ubuntu 系统中，可以通过以下命令安装 VirtualBox 和 Vagrant。\n安装 VirtualBox 和 Ansible 更新系统软件包列表： 1 sudo apt-get update 安装 VirtualBox： 1 sudo apt-get install virtualbox ansible 安装 Vagrant 下载 Vagrant 的 Debian 安装包。请访问 Vagrant 官方下载页面 获取最新版本的链接。例如： 1 wget https://releases.hashicorp.com/vagrant/2.3.4/vagrant_2.3.4_x86_64.deb 使用 dpkg 安装 Vagrant： 1 sudo dpkg -i vagrant_2.3.4_x86_64.deb 如果安装过程中出现依赖问题，可以使用以下命令解决： 1 sudo apt-get install -f 验证安装 安装完成后，可以通过以下命令验证安装是否成功：\n检查 VirtualBox 版本： 1 virtualbox --help 检查 Vagrant 版本： 1 vagrant --version 检查 Ansible 版本： 1 ansible --version 通过这些步骤，你可以在 Ubuntu 系统中安装并配置好 VirtualBox、ansible 和 Vagrant。\n创建 Vagrantfile Vagrantfile 是 Vagrant 的配置文件，用于描述虚拟机的配置。你可以使用 Vagrantfile 来定义虚拟机的操作系统、网络、共享文件夹等配置。\n以下是一个简单的 Vagrantfile 示例：\n1 2 3 4 5 6 7 8 9 10 11 # -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;geerlingguy/rockylinux8\u0026#34; # Provisioning configuration for Ansible. config.vm.provision \u0026#34;ansible\u0026#34; do |ansible| ansible.playbook = \u0026#34;playbook.yml\u0026#34; end end z这个 Vagrantfile 使用 geerlingguy/rockylinux8 作为基础镜像，并使用 Ansible 来配置虚拟机。你可以根据自己的需求修改 Vagrantfile。\n下面创建一个简单的 Ansible playbook 文件 playbook.yml：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 --- - hosts: all become: yes tasks: - name: Ensure chrony (for time synchronization) is installed. dnf: name: chrony state: present - name: Ensure chrony is running. service: name: chronyd state: started enabled: yes # The same as the above play, but in super-compact form! - hosts: all become: yes tasks: - dnf: name=chrony state=present - service: name=chronyd state=started enabled=yes 这个 playbook 会安装 chrony 时间同步服务，并启动该服务。\n这个测试示例的目的是：在 Ubuntu 虚拟机中运行 Vagrant，使用 Vagrantfile 来配置虚拟机，使用 Ansible playbook 来配置虚拟机。\n启动 Vagrant 在包含 Vagrantfile 的目录中，运行以下命令启动 Vagrant：\n1 vagrant up Vagrant 会根据 Vagrantfile 的配置创建虚拟机，并使用 Ansible playbook 配置虚拟机。\n连接到虚拟机 使用以下命令连接到虚拟机：\n1 vagrant ssh 登录到虚拟机后，你可以验证 chrony 服务是否已经安装并运行：\n1 systemctl status chronyd 如果一切正常，你应该看到 chronyd 服务已经启动。\n使用 vagrant 查看虚拟机的状态。\n1 vagrant status 使用 virtualbox 查看虚拟机的状态。\n1 vboxmanage list vms 使用 virtualbox 查看虚拟机的详细信息。\n1 vboxmanage showvminfo \u0026lt;vm-name\u0026gt; 到目前为止，我们成功的完成了 Azure Ubuntu 虚拟机 + virtualBox 虚拟化 + vagrant + Ansible 的环境搭建。这是一个非常好的学习和开发环境，你可以在这个环境中学习DevOps技术，Ansible 自动化运维管理的知识。\n推荐学习资源 强烈推荐这本书《Ansible for DevOps》，这是一本非常好的 Ansible 入门书籍，作者 Jeff Geerling 是一位非常有经验的 DevOps 工程师，他在这本书中详细介绍了 Ansible 的基本概念和高级用法，非常适合初学者学习。\n书的代码库：https://github.com/geerlingguy/ansible-for-devops.git 书的全文：https://github.com/geerlingguy/ansible-for-devops-manuscript.git 经过我的测试，Azure 的 Ubuntu 虚拟机中运行的 VirtualBox 虚拟机，可以正常运行，但是性能会有所下降。请选择具有足够内存和 CPU 的机型，加快 Ansible playbook 的执行速度。在有些时候也发现：嵌套虚拟机的网络下载速度非常慢，这可能是 Azure 的网络问题，或者是虚拟机的网络配置问题。在网络速度上应该还有优化的空间。\n❤️ Photo by cottonbro studio: https://www.pexels.com/photo/2-blue-and-yellow-ceramic-owl-figurines-4966171/\n","date":"2024-08-02T16:28:51+08:00","image":"https://martinliu.cn/blog/nested-virtualization-ubuntu-run-virutalbox-azure-vm/pexels-cottonbro-4966171_hu_51a96cd5ef46a553.jpg","permalink":"https://martinliu.cn/blog/nested-virtualization-ubuntu-run-virutalbox-azure-vm/","title":"嵌套虚拟化：在 Azure Ubuntu VM 中运行 VirtualBox 虚拟机"},{"content":" 原作者：Rick Branson；原文链接\n航空事故和死亡人数随着时间推移而减少。上图告诉了我们这一点。它还揭示了另一点：每次事故的死亡人数差异很大！仅仅统计事故报告数量会掩盖这一非常重要的事实。\n高效的互联网服务团队都有一个共同点：有效的事故管理和无责后期分析流程。然而，这样的流程往往会导致一个不幸的结果——有人会提出一个看似合理的建议：将事故报告数量作为衡量产品质量的标准。\nFacebook 坚决反对统计事故报告——至少在我在那里的时候是这样。似乎基础设施团队的负责人 Jay Parikh 的一项重要任务就是不断提醒大家不要统计事故报告。当有这样的仪表板或报告出现时，他会在极短的时间内发现。\n如果你是始作俑者，你的手机会很快响起 Messenger 标志性的“PING！”声。你会低头看通知。“哦，糟了。” 是 Jay Parikh 本人，他礼貌但坚定地请求“请将其撤下。” 自然地，你会感受到潜在的“否则后果自负”的威胁。\n为什么如此激进呢？有三个主要原因说明这个看似不错的想法为何如此危险。\n1. 这是一个借口 有有效的方法来衡量服务质量，但绝对不是通过事故的数量。因为数据已经存在，所以很容易让人产生更多事故不好，少事故好的想法。\n问题在于，这成为了衡量实际客户体验的借口。推导出这些指标需要大量精力，所以人们容易选择走捷径。选择正确的客户体验指标完全取决于特定产品或服务的细节，需要对产品有深刻的理解以及对客户重视内容的敏锐洞察。\n对于 web 应用程序的后端服务，一个与客户体验直接相关的质量指标可能是客户端观察到的不可恢复请求错误的频率。客户不应该遇到这种错误，如果遇到了，就表明存在实际的体验问题。这种指标特别强大，因为它综合了各种潜在原因。\n高层通常希望将质量汇总成每个产品领域的总分。这可能看起来有点偷懒，但他们的工作是确保改进集中在最需要的地方。我已经写了一个简要的草图来实现这一点。\n2. 反向激励 摘自《哈佛商业评论》：你可能会争辩说，这不可能这么简单——但心理学家和经济学家会告诉你，事实就是如此。人类会根据被评估的指标调整行为。你衡量什么，人们就会努力优化该指标的得分。你测量什么，就会得到什么。就是这样。\n行为必然会符合测量的证据是压倒性的。测量事故报告的数量会导致提交的事故报告减少。\n我已经听到有人说：“但是，我们公司的价值观是诚实和合作，所以情况不同。” 尽管有类似的压倒性证据，相信化学尾迹阴谋论的人还是很多。\n一个精心安排的事故管理和事后分析流程的根本目标是学习和改进。事故报告正是实现这一目标的工具。通常，报告越少，流程的效用就越低。实际上，应该鼓励人们尽早为任何可验证的严重事故提交报告。\n虽然事故确实需要分配严重等级，但其目的是为了明确传达在事故期间适当的响应措施。如果一个团队根据提交的事故报告数量来评估，他们不可避免地会在提交或升级时犹豫不决。测量带来的寒蝉效应不应该在生产事故的压力环境中发生。\n3. 实际上并无用处 事故报告的频率与组织的成功或失败并没有什么有意义的相关性。因为严重等级通常表示事故期间的最高影响值，所以它并不能准确反映总影响。因此，十小时的 SEV2 不一定比十分钟的 SEV2 更好或更差——这是模糊的。\n然而，有一些非常有用的指标可以在事故报告过程中收集。以下是每个事故报告中应包含的四个通用数据点：\n影响开始的时间 团队意识到问题的时间 事故影响被缓解的时间 团队如何意识到问题（例如，通过机器警报、员工报告、客户报告或《纽约时报》头版） 这些数据点可以用来推导出以下指标：\n从影响开始到意识到问题的延迟 从意识到问题到解决问题的延迟（即 MTTR） 响应的主动性 这些指标对于推动改进非常有用。任何改善这些指标的服务团队都将提供更高的质量……这是可以保证的。尽管每份报告都需要准确的损害评估，但这些数据通常无法在不同的事故之间进行普遍比较。\n“但是 Rick，你不是刚刚提到测量带来的反向激励吗？这不会激励人们篡改这些数据吗？” 首先，尽量避免与撒谎者共事。考虑提交事故报告是否合适与篡改客观事实之间有很大的道德差异。\n其次，事后审查的一个重要部分是将报告中的数据点与现有数据进行验证。这不是某种“信任但验证”的偏执行为。这是关于过程的完整性。人们会犯错误，他们可能因为事故而疲惫不堪，并希望尽快恢复正常生活。即使在最极端的情况下，事故报告也是相对罕见的，因此，确保每一份报告的准确性是必不可少的，如果改进是真正的目标。\n但需注意 最高的事故严重等级应保留给“所有东西都出问题了”的情况。在这种影响水平下，没有人会犹豫提交报告。\n你可能会想到一些可靠地表明这种情况的警报。Facebook 最具行动力的警报之一是可怕的出口流量下降。我从未遇到过出口流量下降警报是误报的情况。\n网络团队会跟踪每个边缘路由器的全球总吞吐量。如果这个数字突然大幅下降，比如 50%，那么“所有东西都出问题了”的阈值已经达到。虽然仍需要人类提交报告，但这主要是形式上的。每次这种情况都是 SEV1，最糟糕的情况——所有人都得参与。\n如果你的流程中的最高严重等级并不等同于“所有东西都出问题了”，那么可能是时候调整等级以达到这种程度了。\n这些事故是绝对不应该发生的。没有地方可以隐藏，所以没有任何测量会对报告机制产生寒蝉效应。甚至 Jay Parikh 也曾引用 SEV1 的频率来证明公司优先事项的调整。\n最后的忠告 事故报告的价值在于收集到的数据。\n回到衡量质量的问题，记住事故报告最终是在最糟糕的情况下捕获的数据是很有帮助的。我们可以承认事故的不可避免性和从中学习的价值，同时也要认识到绝大多数的质量改进不会来自这个过程。改进质量不应该依赖于事故的发生。\n事故应当被视为神圣的，所以不要破坏这个神圣的过程。不要为了统计而降低其价值。停止统计生产事故！\n❤️ Photo by Oleksandr P: https://www.pexels.com/photo/hand-stopping-domino-effect-12955678/\n","date":"2024-07-13T20:11:14+08:00","image":"https://martinliu.cn/blog/stop-counting-prod-incidents/pexels-freestockpro-12955678_hu_25280c7d50144035.jpg","permalink":"https://martinliu.cn/blog/stop-counting-prod-incidents/","title":"停止统计生产事故"},{"content":" 原作者：Jennifer Mace ；from https://www.oreilly.com/content/generic-mitigations/\n亲爱的读者，你好！试想你是否负责一项你和你的用户希望一直正常运行的服务？如果是这样，我在这里要告诉你，你的服务应该准备好至少一两个通用的缓解措施。如果没有，你可能会遇到麻烦。如果有，请珍惜它们，维护它们，并使用它们，否则它们可能会失效。\n什么是通用缓解措施？ 好的，从头开始：缓解措施是你可能采取的任何行动，以减少故障的影响，通常在生产环境中。热修复是一种缓解措施。通过 SSH 登录进入实例，并清除缓存也算是一种缓解措施。用胶带把备用电池固定在破旧的笔记本电脑上也算。我猜切断数据中心的电源，以关闭漏洞也是一种缓解措施，就像用断头台治疗普通感冒一样。\n漫画中，值班的 Macey 用滑稽的大剪刀剪断数据中心机架的电缆，同时竖起大拇指。\n通用缓解措施是指那些在缓解各种故障中都很有用的措施。\n例如，二进制回滚可能是最常见的通用缓解措施。许多多宿主服务都会有一个紧急按钮，用于将流量从故障副本中排除，这是基于查询服务的一个很好的通用缓解措施。其他的可能有单独的数据回滚工具，或快速增加大量额外容量的工具。\n通用缓解措施最重要的特征是：你不需要完全了解你的故障就可以使用它。\n难得不应该排查故障吗？ 不。\n好吧，让我详细解释一下：你应该在故障被缓解后，再去排查理解它。让我们画一个典型故障的简图。\n漫画中，时间轴图示了两种不同的处理故障的方法。时间轴开始相同，从“问题产生”到“损害开始”（此时出现红色的“用户影响”条）到“值班人员接到通知”，但在决策点上分叉：如果选择“应用通用缓解措施”，用户影响停止，时间轴继续到“调查”、“最终修复”和“应用修复”。如果选择不缓解，用户影响继续——通过“调查”、“找到完美修复”，最后在“应用修复”时停止。时间轴上装饰有火山岛爆炸的插图；显然，在“早期缓解”时间轴中，岛民要快乐得多，而如果选择先调查，岛屿最终被灰烬覆盖，居民悲伤。\n构建好的通用缓解措施的目标是尽早在时间轴上准备好一个武器。如果你能使用的缓解措施都是特定于问题的，那么在你详细了解问题之前，你将无法帮助你的用户。减少了解问题所需时间是非常困难的；如果我们能轻松找到问题，那么我们很可能一开始就不会引发这些问题。\n所以假设团队的事故管理成功的衡量标准不是“修复时间”，而是“缓解时间”，我们想要最小化的是用户完全崩溃的时间。构建广泛适用的缓解措施比加快根本原因分析要容易得多。\n漫画，中的 Macey 高举一把标有“不是太特定问题的！！！”的剑。她站在一团复杂的电缆上。\n难点是什么？ 具有讽刺意味的是，通用缓解措施非常具体。\n这句话听起来很矛盾。再解释一下。一个好的、通用的“快速修复”按钮在紧急情况下使用应该是简单且安全的；但一个稳固的通用缓解工具需要在事前做大量工作，并需要仔细调整以适应所缓解的服务。\n然而，有一些非常好的通用缓解模式可以学习，虽然这些需要仔细调整以适应你的特定服务。\n通用缓解模式有哪些？ 很高兴你问了！这里有一些可以让你开始使用的模式。\n回滚: 将你的服务恢复到已知的良好状态，通常是恢复二进制文件，但也有其他选项。几乎每个服务都可以实现这个策略的版本。很多服务以为自己有安全的回滚措施，但在故障期间才发现并非如此。 数据回滚：这是前一种情况的一个子案例——它只恢复你的数据。内容密集型服务特别需要这个，尤其是那些依赖数据管道的服务。 降级：你的服务过载了吗？能减少工作但保持运行总比崩溃好得多。在系统崩溃时尝试创建新的降级机制总是让人头疼。 扩展/扩容：流量太大？或者所有东西无缘无故地运行过热？增加更多副本。这虽然昂贵，但比因为故障而惹恼用户要便宜。注意，这通常不像“扩展一个二进制文件”那么简单；系统扩展是复杂的。 屏蔽：有致命查询？单个垃圾用户导致一个区域瘫痪？屏蔽他们。 引流/切流：将你的流量转移到其他地方。如果你是多宿主和流量驱动的服务，这个方法效果很好：如果一个区域看到高错误率，将请求转移到其他地方。 隔离：一个好方法是隔离“问题实例”。将一个使用单元隔离开来——一个热点数据库行、一个垃圾用户、一个有问题的流量——这样它碰到的任何问题都不会影响其他部分。 漫画中的 Macey，看起来在深思，头上有“嗯”的字样，思考四个可能的缓解选项。顺时针从左上角开始，泡泡中有：Macey 将一个小鱼缸倒入一个大鱼缸；Macey 将一块巨石推上山；一个写着“NOPE！”的大红色停止标志；一辆飞驰的救护车。\n什么不是通用缓解措施？ 没错，如果你因为最近的发布触发了错误而排空了一个实例，却在 30 分钟后下一个实例升级时再次看到相同的错误，你会显得很愚蠢。没有什么是魔法：你需要诊断到能够理解你所处理的故障场景的程度。\n漫画中，一台数据中心的服务器机架看起来很痛苦，它着火了，前面贴了一块创可贴。显然这个解决方案不足以解决问题。\n这些模式对所有服务的用处也不尽相同。例如，对于很多固定在单一物理区域的本地化产品来说，排空实例是没有意义的。当你的工作负载无法分离或已经完全隔离时，隔离也没有用。降级模式并不总是可行的。\n所以问问自己哪些策略对你的服务有意义。把它作为生产就绪评审（ https://landing.google.com/sre/sre-book/chapters/evolving-sre-engagement-model/ ）的一部分——记录现有的通用缓解措施，如果不够，就计划添加更多。（但不要太多！质量胜过数量！）缓解措施越好、越标准化，支持的扩展就越容易；如果缓解措施能撑到早上，就不需要在凌晨 2 点叫醒专家。\n另外？如果你不使用它们，它们就不会工作。\n即使是熟练的值班人员，使用不熟悉的工具也是危险的。无论你选择哪种方法——进行演练、添加自动化测试、编写新团队成员必须完成的小清单以获得生产凭证——确保你的团队接触过你的缓解措施。毕竟，如果没人练习过恢复磁带备份，当有人在生产环境中运行 rm -r /* 时，它们就只能是高级的纸镇。\n四个磁带备份堆叠在凌乱的桌子上的文件上，标签分别是“古老备份 #1”到“2020 年备份”。附近的一张便签写着“恢复你的备份！”\n通过定期演练你的缓解措施，你还可以验证它们的行为。我们的系统足够复杂，只有在真正使用你的通用缓解措施时，才能知道它们的连锁效应。\n目标是为你的服务创建易于使用、安全、无摩擦的紧急按钮，让任何值班人员在稍有怀疑时都能安心使用。这并不容易构建。但提前构建它们比忍受没有缓解措施的长时间停机要便宜得多。\n总结 简而言之：故障中最昂贵的阶段是用户能看到的时候。一个快速到达“基本正常”的路径比等待“完全修复”对用户来说要好得多。如果你开的是一辆老款的丰田卡罗拉，有时最好的策略是确保手套箱里有胶带，这样当后视镜掉下来时，你可以开到修理厂。\n知道你的胶带是什么。你会需要它。\n漫画中一个快乐的值班人员 Macey 从一辆极其破旧的红色轿车的车窗外挥手。这辆车由胶带固定，车牌上写着“MTIG8”。\n这篇文章是 O\u0026rsquo;Reilly 和 Google 的合作。请参阅我们的编辑独立声明。( http://www.oreilly.com/about/editorial_independence.html )\n本文所有图片均由 Emily Griffin 绘制。( https://www.daybrighten.com/ )\n","date":"2024-07-13T19:02:57+08:00","image":"https://martinliu.cn/blog/generic-mitigations/07-2048x1024_hu_4c7994e5813fcac2.png","permalink":"https://martinliu.cn/blog/generic-mitigations/","title":"SRE 故障应急实践：通用缓解措施"},{"content":"前言 摘要 评估由于流程变化、产品采购或技术变革所产生的提升改进是一种常见的工作。在可靠性工程中，通常会测量平均恢复时间（MTTR）或平均缓解时间（MTTM）等指标。这些指标有时用于评估上述变化所带来的改进效果或跟踪其发展趋势。\n在本报告中，我通过一个简单的蒙特卡洛模拟过程（可应用于许多其他情况）和统计分析，展示了这些指标在生产事故管理的背景下，并不适用于决策或趋势分析的方面。为此，我提出了一些：在特定情况下会更有效的替代方法。\n介绍 站点可靠性工程师（SRE）的主要职责之一是管理其负责的生产系统所发生的事故。在事故发生时，SRE 负责调试系统，选择合适且即时的缓解措施，并在需要时组织更大范围的事故响应。\n然而，SRE 的职责不仅限于事故管理，还包括预防工作，例如：制定在生产环境中执行变更的稳健策略，或自动响应问题，并将系统恢复到已知的安全正常运行状态。这些工作还包括改进沟通流程、提升监控能力，或开发有助于事故调试的工具。实际上，有一些产品都是专门用于改进事故响应流程。\n希望事故（如果必须发生的话）对业务的影响尽可能小。这通常意味着事故的持续时间要短，这是我将在这里重点讨论的内容。了解流程变化或产品采购会怎样缩短事故持续时间是重要的，尤其当事故涉及实际成本时。然而，我们不能仅凭一次事故就得出结论，需要对多个事故进行综合分析。\n用搜索引擎搜索一下，你可能会发现：许多文章声称的 MTTx 指标（包括平均恢复时间和平均缓解时间）应被视为服务可靠性的关键性能指标。这些文章有时由：拥有良好服务口碑或提供可靠性相关工具的知名公司撰写的。但这些指标真的是良好的可靠性管理指标吗？实际上，它们能否作为有效的指标来使用？该如何判断？\n应用 MTTx 指标的目的是了解系统可靠性的演变。但实际情况是，应用这些指标比看起来要复杂得多，而且在大多数情况下，这些流行指标往往具有误导性。\n本报告将展示 MTTx 在大多数典型 SRE 环境中无效的原因，这些原因适用于许多总结性统计数据，与公司规模或生产实践的严格程度无关。不论选择何种指标，重要的是测试它在不同的事件持续时间分布下是否能够提供可靠的见解。尽管可能没有一种通用的“银弹”指标能替代 MTTx，但通过根据具体问题定制指标，您可能会在度量方面取得更好的效果。在本报告的最后，我将探讨一些替代方法来实现这些测量。\n事故生命周期和时间节点 在分析事故的总体情况前，我想先介绍一些相关术语。这些术语可能因公司而异，但基本原则是一致的。\n图 1 展示了一个简单的事故时间线模型，我将在后续内容中使用这个模型。在这个模型中，事故经历以下关键阶段：\n首次产品影响：对产品产生严重影响的第一个时刻。 检测：系统操作员意识到正在发生的问题。 缓解：产品不再受到严重影响，但系统可能仍存在着部分的功能退化。 恢复：系统完全恢复正常运行；有时缓解和恢复是同一时间点，但有时恢复时间之后，具体会有所不同。 我将分析事故的持续时间周期，并探讨应用统计数据的有效性。有几个公开的资源库汇集了事故复盘回顾，展示了时间线和关键事件1。在这次分析中，我特别关注事故对用户影响的时间窗口。\n图 1 的事故时间线模型简化了现实，就像所有模型一样。“浅层事故数据”存在一些问题。例如，在这次分析中，一个问题是：“如果你已经消除了 90% 用户的影响，但还有 10% 仍然受影响，你会认为事故已经缓解了吗？” 如果还有 5% 或 20% 呢？使用这个模型，你需要做出一个二元决策。这种分类方式常常因为主观性和不一致的原则而受到批评。\n你可能不会太在意事故数据中2的这些不准确之处。对于许多实际应用——包括我将重点关注的总体分析——更高的精确度并不是必须的，而实现这种精确度的成本可能超过提高数据质量的潜在好处。著名统计学家 George Box 说过：“所有模型都是错的，但有些是有用的”，我认为这个模型可以用来理解 MTTR 和类似指标的可行性。\nMTTR 和 MTTM 指标，探讨与应用 一次事故可能会提供其相关数据，但你需要分析整体情况3。平均恢复时间 (MTTR) 是行业中常用的术语。类似于平均故障间隔时间 (MTBF) 的术语也很常见，特别是在分析硬件组件的可靠性时。\n在这里，MTTR 被定义为所有适合分析的事故中，从首次产品影响到恢复的平均时间。同样，平均缓解时间 (MTTM) 被定义为从首次产品影响到缓解的平均时间。\n事故持续时间的分布 要分析事故持续时间的统计数据，需要多样化的数据来源，以避免仅依据一个公司或产品得出结论。我收集了三家知名互联网公司的公共事故状态仪表板数据（员工数量在一千到两千之间）。图 2 展示了事故持续时间的分布。\n我没有区分事故类型：如果公司认为事故值得向用户公布，我就将其纳入分析。这些事故的持续时间代表了从首次影响到最后影响的用户沟通时间。我简化称之为恢复时间，虽然这种叫法并不完全精确。因为恢复时间和缓解时间通常相同，我发现它们遵循类似的分布，这种不精确性不会影响分析结果。\n行的顺序依次为公司 A (N = 798；2019 年 173 起)，公司 B (N = 350；2019 年 103 起)，和公司 C (N = 2,186；2019 年 609 起)。列显示了每家公司在短期和长期内分布的尾部。\n我还收集了 Google 的事故数据（见图 3），在我的分析中，Google 的数据集代表了一家专注于互联网服务的巨型公司。这个数据集是在一年的时间内收集的，时间比图 2 中的任何数据集都短，但它还包括内部事故（例如，仅影响开发人员生产力的事故）。虽然我不能分享具体的数字，但可以预见，Google 的事故数据集比三个公共数据集中任何一个都大好几倍。\n得出的关键观察是：在每种情况下，事故都呈现出正偏分布，大多数事故能迅速解决。图 4 显示，这些分布大致接近对数正态（或伽玛）分布，但我没有对经验数据进行概率分布拟合。所有数据集都显示了事故持续时间的巨大差异。这与我的经验相符：大多数事故能相对较快解决，但一些更复杂且持续时间较长，还会有少数灾难性的“黑天鹅事件”发生。4\n显示它们如何接近对数正态分布5。请注意，这不能用来得出对数正态分布是最佳拟合的结论，仅供参考。\n我排除了公共数据集中持续时间少于三分钟和超过三天的事故，这些事故占每个数据集的约 1-2%。对数据集中随机选择的事故进行手动检查，确认这些异常值是有效的，并且我也知道，从事故回顾中可以得知确实存在影响重大的多天事故，甚至更长时间的事故6。但是，我认为包括这些异常长的事故，即使它们在实际中发生，可能会对分析带来不必要的质疑。\n从这些经验数据中，可以看到事故持续时间的分布，但仅根据事故数量或持续时间来判断公司的可靠性实践是错误的。这些数据集来自不同业务模式、可靠性需求和事故沟通方式各有差异的公司。7\n分析改进 现在你已经清楚了解了事故持续时间的情况，是时候缩短事故时间了！\n假设你获得了一款可以提高可靠性的产品，能够将事故的缓解和解决时间缩短 10%。例如，一个持续一天的事故可以缩短到约 21.5 小时。你有机会进行试用来评估该产品的效果。如何确认产品能兑现其承诺呢？这份报告将探讨使用 MTTR 和类似指标，因此我们将使用这个指标。\n我故意选择了这个模拟场景，因为它适用于许多现实中的情况。无论是更改策略、开发软件，还是引入新的事故管理流程，目标往往是缩短事故时间，并评估这些改变所带来的效果。\n判定 MTTR 的改进 那么，你如何测试该产品是否真正兑现了承诺呢？一个简单直观的测试方法是：“如果每次事故的持续时间，都能按产品所述的减少了，我们就能看到 MTTR 指标的改进。”\n然而，这仍然相当不精确。“我们能够看出改进”具体意味着什么？最终，你需要做出一个明确的判定。在这种情况下，你需要判断产品是否取得了成功，并选择是否购买。\n为了评估产品是否实现了缩短事故持续时间 10% 的承诺，你可以设置一个阈值，即 MTTR 与使用产品前相比减少 10%。一个更宽松的标准是：只要有任何改进就算成功。如果你看到任何事故时间的缩短，无论幅度大小，你就会认为产品成功了。\n你需要明确了解你期望指标的表现，并确信所选指标（如 MTTR）能够准确衡量你想要的内容。如果依赖于一个不佳的指标，可能会带来实际且严重的风险和成本。这些风险可能是直接的，例如因为错误的原因购买产品，但也可能非常微妙。例如，员工意识到：他们的事故管理工作是通过未经验证，或有问题的指标进行评估时，士气可能会受挫。\n在平行宇宙中模拟 MTTR 你只能在一个宇宙中生活，因此在这个场景中你只有一次机会评估产品。但直觉告诉你，事故是多变的，你希望确保能看到改进，且不是随机巧合。\n为了更确定这一点，你可以进行蒙特卡洛模拟8。假设事故遵循获得的数据集的经验分布，并评估在一定数量的事故后你会看到哪些改进及其置信水平。\n模拟过程如下：\n从事故持续时间的经验分布中随机抽取两个样本，样本量为 N1 和 N2（N1 = N2 以实现完美的 50/50 分割）。 修改其中一个样本的事故持续时间，缩短 10%。 计算每组的 MTTR，即 MTTRmodified 和 MTTRunmodified。 计算差值，观察到的改进 = MTTRunmodified − MTTRmodified（负差异意味着 MTTR 恶化）。 重复这个过程 100,000 次。 你正在进行两个样本的实验，样本大小为 N1 和 N2，其中 N1 = N2。50/50 的分割能提供最强的分析；在第 18 页的“分析方法”中，我将简要讨论原因。\n简单来说，你访问成千上万个平行宇宙，模拟产品兑现其承诺，并将结果的 MTTR 与未处理的事故进行比较。从操作上讲，这可以使用 Python 脚本和包含数据的 CSV 文件或足够强大的 SQL 引擎来完成，不需要任何专业工具或额外知识。\n现在你在操作概率，所以需要为测试添加一个条件：对随机巧合的某种容忍度。假设你容忍最多 10% 的平行宇宙误导你。更正式地说，这意味着你需要统计显著性 α = 0.10。这个值可以说是比较宽松的。\n场景模拟与评估\n在这个场景中，我选择了两个等量的事故样本（N1 和 N2，其中 N1 = N2）。我选择的 N1 + N2 等于 2019 年的事故数量（见表 1）9。具体来说，公司 A、B 和 C 的事故数量分别为 173、103 和 609 起。\n表 1. 三个数据集的事故数量、均值和方差。\n公司A 公司B 公司C 事故(所有) 779 348 2157 事故（2019） 173 103 609 均值 2h26m 2h31m 4h31m 方差 5h16m 5h1m 6h53m 进行模拟后，我绘制了图表来观察结果（见图 5）。\n如果改进实际发生，模拟的 MTTR 变化分布，作为相对改进。\n即使在模拟中改进总是有效，38% 的模拟中公司 A 的 MTTR 差异低于零，40% 的公司 B 和 20% 的公司 C 也是如此。观察 MTTR 的绝对变化，看到至少 15 分钟改进的概率分别只有 49%、50% 和 64%。即使场景中的产品有效并缩短了事故，检测到任何改进的几率也远超出 10% 随机误差的容忍度。\n不改变事故情况下统计数据的变化\n更糟糕的是，你可能会看到 MTTR 的显著减少，甚至超过产品的承诺。这可以通过运行与之前相同的模拟更清楚地证明，但在这种情况下，产品对事故没有任何影响。将步骤 2 替换为 new_duration = old_duration。\n果然，图 6 显示公司 A 有 19% 的几率 MTTR 改进半小时（或更好），公司 B 有 23%，公司 C 有 10%……即使在这个模拟中，你没有对事故做任何改变10。换句话说，即使假设的产品对你没有任何作用，你也会认为它有效并决定购买产品。\n注意：对此发现，一个愤世嫉俗的回应是开始销售虚假的缩短事故时间的产品。这种商业行为会设定价格，使得部分客户仅凭运气看到宣传的改进并购买产品，从而盈利。我绝不支持这种商业计划。然而，这确实突出了使用低质量指标可能带来的问题。\n在事故没有变化的情况下，模拟的 MTTR 变化分布。\n我们了解到，即使没有对事故持续时间进行任何有意的改变，许多模拟的场景仍然会让你认为 MTTR 大大缩短或延长，而实际上没有任何结构性的变化。如果你无法辨别出事故没有变化的情况，那么当它们真的发生变化时，你也会难以判断。\n改变思维实验 之前的场景假设有一个产品可以缩短事故持续时间，你想了解这种变化如何反映在 MTTR 中。但实际上，预测和建模潜在的改进非常困难。\n可以通过换个角度来解决这个问题。与其寻找特定的改进，不如观察在事故没有结构性变化的情况下 MTTR（或其他统计数据）的变化。换句话说，你的事故持续时间依旧来自相同的分布（未受任何事故处理改进的影响），你评估的是统计数据的典型变化。\n接下来，我将简化讨论，只关注在事故没有变化的情况下 MTTR 变化的场景，不再分析改进。因此，最有趣的是结果分布的形状：简单来说，我们想知道它有多平坦。\n通过更多事故进行更好的分析 你可能会直觉上理解为什么观察到的 MTTR 会有如此广泛的变化：事故的方差太大。这种直觉有统计学依据。\n中心极限定理告诉我们，随着样本数量的增加，样本和的分布趋向于正态分布11。你可以在之前的分析中看到一些证据（例如图 6），这些分布看起来有些正态。虽然不能自动假设结果分布总是正态的（稍后会详细说明），但这也意味着在极限情况下方差会趋于收敛。\n这与直觉一致，表明随着样本大小（即事故数量）的增加，观察到的 MTTR 值的方差会减少。这很容易证明。表 2 显示了多个事故数量下 MTTR 的 90% 置信区间。\n回想一下，你是从事故持续时间分布中抽取两个样本。因此，如果你想知道用 N 个事故总数进行分析的效果，你需要抽取两个样本，样本大小为 N1 和 N2，其中 N1 = N2。\n表 2. 基于 100,000 次模拟，从两个随机抽样的事故集合（N1 = N2）中计算出的两个 MTTR 差异的 90% 置信区间。\nCompany A Company B Company C 原始数据TTR的均值 2h 26m 2h 31m 4h 31m 2019的事故数据 173 103 609 N1 + N2 = 10 mean difference ≅ 0 90% CI [−5h41m; +5h42m] mean difference ≅ 0 90% CI [−5h25m; +5h18m] mean difference ≅ 0 90% CI [−7h4m; +7h15m] N1 + N2 = 100 mean difference ≅ 0 90% CI [−1h44m; +1h44m] mean difference ≅ 0 90% CI [−1h39m; +1h39m] mean difference ≅ 0 90% CI [−2h16m; +2h16m] N1 + N2 = 1,000 mean difference ≅ 0 90% CI [−33m; +33m] mean difference ≅ 0 90% CI [−31m; +31m] mean difference ≅ 0 90% CI [−43m; +43m] 随着样本数量的增加，标准差会下降，从而提高检测较小显著变化的能力。在原始场景中，你评估的产品承诺将事故持续时间减少 10%；即使有一千起事故，这仍然会落入 90% 置信区间。即便有一年的数据，你也无法得到一个有信心的结论。\n公司 A 和公司 B 的相似结果是巧合。这两家公司提供的服务非常不同，但它们的平均事故持续时间和标准差却相似。如果只考虑一年的事故数据，差异会很大：公司 A 的平均事故持续时间是 4 小时 35 分钟，而公司 B 是 2 小时 38 分钟。它们的其他统计数据，如中位数，也比平均值差异更大。\n即使事故数量很多（超过每年的总数），方差仍然太高。图 7 显示，即使 MTTR 观察到的变化很大，仍然在 90% 置信区间内。虽然增加事故数量有助于获得更好的信号，但这与可靠性工程的整体目标相违背。\n随着样本数量增加，90% 置信区间的宽度减少。\n超越平均值 对算术平均值的一个常见且合理的批评是它对异常值过于敏感。尽管已经排除了最严重的异常值事故（如少于三分钟或超过三天的事故），这一点依然成立。我们可能需要考虑其他统计方法，让我们来探讨一下。\n中位数和百分位数\n中位数常用于避免少数极端异常值过度影响结果，这里也可以使用——大多数事故不会持续几天。\n需要注意的是，如果要分析中位数，你也需要调整你的分析方式。如果你在寻找任何类型的相对差异，它应该是相对于中位数的。例如，用 MTTR 的一部分进行测试可能会非常误导。\n如表 3 所示，即使在 N = 1,000 起事故的情况下，90% 置信区间相对于中位数统计数据仍然很大，并且涵盖了讨论中的 10% 中位数 TTR 目标。问题不仅限于 MTTR 的“平均值”；中位数 TTR 也无法解决。\n表 3. 基于 100,000 次模拟，从两个随机抽样的事故集合（N1 = N2）中计算出的两个中位数 TTR 差异的 90% 置信区间。\nCompany A Company B Company C Median TTR of original data 42m 1h 7m 2h 50m Incidents in 2019 173 103 609 N1 + N2 = 10 mean difference ≅ 0 90% CI [−1h46m; +1h46m] mean difference ≅ 0 90% CI [−2h13m; +2h12m] mean difference ≅ 0 90% CI [−4h8m; +4h7m] N1 + N2 = 100 mean difference ≅ 0 90% CI [−29m; +29m] mean difference ≅ 0 90% CI [−29m; +29m] mean difference ≅ 0 90% CI [−1h20m; +1h19m] N1 + N2 = 1,000 mean difference ≅ 0 90% CI [−11m; +11m] mean difference ≅ 0 90% CI [−9m; +9m] mean difference ≅ 0 90% CI [−29m; +29m] 较高的百分位数，如第 95 百分位，表现更差。直观上，这是合理的。较高百分位数的事故持续时间会受到最严重事故的影响，而这些事故又非常罕见。因此，它们的方差非常高。表 4 列出了一些具体数值。\n表 4. 基于 100,000 次模拟，从两个随机抽样的事故集合（N1 = N2）中计算出的第 95 百分位 TTR 差异的 90% 置信区间。\nCompany A Company B Company C 95th percentile TTR of original data 10h 45m 8h 48m 12h 59m N1 + N2 = 100 mean difference ≅ 0 90% CI [−12h19m; +12h22m] mean difference ≅ 0 90% CI [−8h34m; +8h36m] mean difference ≅ 0 90% CI [−12h29m; +12h30m] N1 + N2 = 1,000 mean difference ≅ 0 90% CI [−5h23m; +5h25m] mean difference ≅ 0 90% CI [−3h18m; +3h17m] mean difference ≅ 0 90% CI [−3h33m; +3h32m] 虽然公司 A 和公司 B 的 MTTR 在这些百分位数测量中的结果相似，但你可以看到事故持续时间差异的影响。\n几何平均数\n你可能感兴趣的另一个汇总统计量是几何平均数，其计算公式为。\n鉴于事故持续时间分布与对数正态分布相差不远，几何平均数在这里特别有吸引力。几何平均数对于对数正态分布而言，就像算术平均数对于正态分布一样。同样，这可以快速模拟（见表 5）。\n表 5. 基于 100,000 次模拟，从两个随机抽样的事故集合（N1 = N2）中计算出的两个几何平均数差异的 90% 置信区间。\nCompany A Company B Company C Geometric mean TTR of original data 54m 1h 9m 2h 24m N1 + N2 = 100 mean difference ≅ 0 90% CI [−24m; +25m] mean difference ≅ 0 90% CI [−27m; +27m] mean difference ≅ 0 90% CI [−56m; +56m] N1 + N2 = 1,000 mean difference ≅ 0 90% CI [−7.2m; +7.2m] mean difference ≅ 0 90% CI [−8.5m; +8.7m] mean difference ≅ 0 90% CI [−18m; +17m] 到目前为止，我们在实际数量的事故中还没有得到足够好的结果。在有一千起事故的情况下，90% 置信区间仅刚好超过指标变化的 10%。\n事故持续时间总和\n你可能更感兴趣的是减少事故持续时间总和，而不是单个事故的持续时间。这是直观的：你想提供可靠的服务，但服务的可靠性更多取决于总的不可用时间，而不是平均事故持续时间。12\n我们已经进行过这样的分析！算术平均数是事故持续时间总和除以事故数量，因此你可以简单地将 MTTR 模拟结果乘以 N/2（即两个样本中任意一个的元素数量），就能得到总和的模拟结果。为了确认这一点，我生成了一些总和模拟，显示置信区间等于 MTTR 置信区间乘以相应的 N（见表 6）。\n表 6. 基于 100,000 次模拟，从两个随机抽样的事故集合（N1 = N2）中计算出的两个事故持续时间总和差异的 90% 置信区间。\nCompany A Company B Company C N1 + N2 = 100 mean difference ≅ 0 90% CI [−87h; +87h] mean difference ≅ 0 90% CI [−82h; +82h] mean difference ≅ 0 90% CI [−113h; +113h] N1 + N2 = 1,000 mean difference ≅ 0 90% CI [−275h; +274h] mean difference ≅ 0 90% CI [−260h; +259h] mean difference ≅ 0 90% CI [−359h; +357h] 事故数量对总和的观察值有很大影响。让我们简要看一下事故数量。\n统计事故\n本报告讨论了你是否能够检测到事故处理的改进，重点分析事故的解决过程。从发生事故到完全没有事故超出了本文的讨论范围。\n然而，既然我已经收集了所有这些数据，至少可以简要查看这些数据集，以了解事故数量随时间的变化。我不会在这里进行更深入的分析。\n事故数量和事故持续时间一样不稳定。即使按全年汇总，如图 8 所示，数值也会大幅波动。在月度或季度的分辨率下，这种波动更为严重。最多可以从这个图表中看到一些明显的趋势：公司 C 的事故数量在 2019 年急剧增加（这一趋势在 2020 年继续，但图中未显示），与之前的年份相比。这一趋势只有在多年时间尺度上才明显，尤其是与公司 A 和公司 B 的不稳定趋势相比时更为明显。\n每年每个公司的事故数量，占总事故数量的比例。排除了数据不完整的年份（2020 年和每个数据集的第一年）。\n但这种趋势可能根本无法反映系统可靠性。可能是由于外部世界事件导致的使用模式变化？还是产品组合的变化？或者是相同生产事件的事故报告方式变化，例如法规要求的变化？我只能猜测，但这些通常无法避免的因素可能会影响甚至使你自己公司的分析无效。\n过去也提出了其他反对统计事故数量的观点13。我不会再花时间进一步分析这些数据，但我期待未来更多关于这一主题的研究。现在我们快速浏览了事故数量，让我们利用这些知识回到分析事故缩短的主题。\n分析方法 到目前为止，我一直在使用蒙特卡洛模拟。然而，你也可以采取分析方法。能否依靠中心极限定理来计算置信区间，而不是通过模拟来实现呢？答案是，有时候可以。\n中心极限定理指出，样本均值的分布在极限情况下会趋向于正态分布。然而，由于事故发生频率低，数量可能不足以使中心极限定理适用。\n你的团队或公司可能没有足够的事故数量来使样本均值的分布趋向于正态分布。\n一种测试方法是运行模拟以生成样本均值分布的正态概率图（Q-Q 图）。14 在图 9 中，我对公司 A 的数据进行了这样的模拟。随着样本量的增加（例如一年的事故数量），图表趋向于正态分布。但对于仅三个月的事故数量，图表明显偏离正态分布。 假设持续时间是正态分布的可能会误导并影响后续的计算。\n公司 A 样本均值事故持续时间的正态概率图，由 1,000 次模拟生成，模拟事故数量为 2019 年的全年事故数和大约一个季度的事故数。\n一旦确定样本均值分布是正态的，你可以使用标准工具，例如 z 检验或 t 检验来建立置信区间15。我们特别关注的是两个分布之间的差异。既然它们来自同一总体，均值差异（以及样本总体差异的正态分布的众数）将趋于零，正如我们在模拟中所见。更有趣的是标准差，它决定了置信区间。\n样本均值的方差收敛到：16\n两个正态分布差异的方差是：17\n在这种情况下，两个样本均值正态分布的方差和样本量相同，结果是：\n这也解释了为什么 50/50 分割是最佳选择，因为不同的样本比例会导致更大的方差，从而得到更差的结果。\n然后你可以应用双尾 z 检验。你可以扩展 z 检验公式；知道分布均值是 0，你可以寻找 MTTR 的特定变化，同时扩展方差计算：\n你也可以反过来：查找相应的 z 分数（双尾检验在 α = 0.10 时的 z 分数约为 1.644），找到 MTTR 变化的置信区间：\n对于公司 A，事故持续时间的标准差为 5 小时 16 分钟，使用 N1 = N2 = 100/2 = 50 的样本来计算 90% 置信区间：\n这个结果与模拟结果中看到的 90% 置信区间相对应。\n虽然有时你可以使用公式来进行事故统计分析，但我更喜欢模拟方法。我发现用模拟来讨论这个话题比用公式更容易理解。它还提供了更多的灵活性，可以进行建模和分析。计算 95 百分位恢复时间的解析解决方案可能非常具有挑战性，但在模拟中，这只需要一行代码的改变。\n你可能也对模拟不同的变化和情况感兴趣。如果提议的事故缩短比简单的 10% 减少更复杂怎么办？也许你期望根据事故类别有不同的减少？如果 SRE 团队由狼人组成，他们只在满月后开始处理事故怎么办？你的场景可能没有那么奇幻，但模拟可以让它们更容易实现。\n大型公司事故数据集 之前的分析显示，随着样本数量的增加，方差会下降。Google 拥有的员工数量约是三家匿名公司总和的一百倍，事故数量也显著多于这些公司。这是否有助于获得更可靠的事故指标？\n我们将以相同的方法分析 Google 的事故数据，并利用更丰富的数据集（包括内部元数据）进一步细分数据。\n图 10 显示了所有重大事故和最严重事故的持续时间分布。这两个数据集中还包括内部事故，例如仅影响 Google 员工及其生产力的事故，甚至是对任何用户（内部或外部）完全不可见的事件。最严重事故的数据集中包含了更高比例的面向用户的事故（例如，会在服务状态仪表板上列出）。\n2019 年 Google 所有事故的持续时间分布。\n除了更广泛的事故集中有更多非常短的事故外，图表显示这两个分布大致相似。所有 Google 事故的数据集大约是所选的面向用户的 Google 服务事故数据集的 15 倍，这也是公司范围内的分布图显得更平滑的原因。\n在三个公共数据集中，排除超过三天的事故去除了约 1% 的事故，但两个 Google 数据集中都有相当多的事故持续时间超过三天。与之前的公共数据集一样，由于事故跟踪方式不同，得出关于可靠性的结论是不正确的。我尝试了两种方法：在三天处截断和排除长度排名前 5% 的事故。结果显示，相对 MTTR 的置信区间仅有略微差异，结论相同。表 7 显示了以三天为截断点的模拟数据，与其他模拟一致。\n表 7. 基于 100,000 次模拟，从 Google 事故数据集中两个随机抽样的事故集合（N1 = N2）中计算出的两个平均 TTR 和中位数 TTR 差异的 90% 置信区间。事故数量对应每个数据集中一年中的一部分。\n2019 年 Google 最严重的事故（通常但不总是面向用户） 所有重大事故（通常不面向用户） Incidents in 2019 (approximate relative size) 1 * X 15 * X Mean TTR N1 + N2 = ¼ year mean difference ≅ 0 90% CI [−35%; +35% of MTTR] mean difference ≅ 0 90% CI [−11%; +11% of MTTR] Mean TTR N1 + N2 = ½ year mean difference ≅ 0 90% CI [−25%; +25% of MTTR] mean difference ≅ 0 90% CI [−7.6%; +7.6% of MTTR] Mean TTR N1 + N2 = 1 year mean difference ≅ 0 90% CI [−18%; +18% of MTTR] mean difference ≅ 0 90% CI [−5.3%; +5.4% of MTTR] Median TTR N1 + N2 = ¼ year mean difference ≅ 0 90% CI [−53%; +52% of median TTR] mean difference ≅ 0 90% CI [−20%; +20% of median TTR] Median TTR N1 + N2 = ½ year mean difference ≅ 0 90% CI [−35%; +35% of median TTR] mean difference ≅ 0 90% CI [−14%; +14% of median TTR] Median TTR N1 + N2 = 1 year mean difference ≅ 0 90% CI [−25%; +25% of median TTR] mean difference ≅ 0 90% CI [−10%; +10% of median TTR] 从数学上讲，在所有重大事故的一年数据中事故数量（虽然具体数字无法分享，但比我们之前测试的 1,000 起更多）有助于获得更可信的结果，这与之前的发现一致。然而，你需要注意你所看的数据和所应用的测试。事实证明，虽然在数学上成立，但这一发现实际上并没有特别实用。\n所有事故的数据集包含各种类型的事故，从面向用户的服务系统故障到长期存在的处理管道问题、网络配置和公司设备软件安装——这些通常对终端用户是不可见的。对于一些事故，解决时间也可能相当长（例如，事故本身就很长或可以等到周末之后），这会推高 MTTR 值。\n在如此广泛的事故中，我没有任何实际的开发工作可以保证实现这种程度的事故持续时间减少。在一年事故数据中，能够自信地检测到 5.3% 的均值变化，并没有使 MTTR 成为一个实际有用的事故统计数据。\n这与数据质量有关吗？ 汇总事故分析的挑战似乎并不在于事故元数据的质量。提高元数据收集准确性的努力不太可能引起显著变化。在检查 Google 内部事故元数据时，我发现那些有更严格事故报告要求的团队（例如，直接由 SRE 支持或运行高可用性、对收入至关重要服务的团队），在事故持续时间分析上并没有显著改进。所有三个公共事故数据集也显示出类似的行为。\n你也可以通过生成完全合成的事故分布来验证这个问题。如果假设事故遵循某种分布（例如伽马分布或对数正态分布），你可以选择参数，使其在主观判断中“看起来正确”，然后进行评估。\n这种方法可以应用于任何分布，但需要谨慎。假设事故持续时间呈正态分布或均匀分布可能并不现实。从这种分布的分析中得出的结论可能会产生误导。\n这就是为什么 MTTx 可能会误导你 像收集到的事故数据（也可能包括你公司的事故数据）这样的分布具有非常高的方差，以至于均值、中位数或总和都无法很好地汇总统计来理解事故趋势。事故问题领域固有的高方差和小样本量使得进行稳健的事故持续时间分析变得不可取，如在三个示例数据集中所示。这里的分析是在理想条件下进行的，现实中的表现可能更差。\n从可靠性角度来看，缓解和恢复之间确实存在差异，但在本分析范围内，这并不重要18。我称之为“MTTx”，因为只要实际测量遵循类似的分布属性和样本量（即事故数量），它对分析没有影响。许多其他事故指标，例如检测时间，也存在同样的问题。19\n这意味着 MTTx 不适合用于评估典型变更对 TTx 的影响：\n它不能很好地衡量系统的整体可靠性。仅仅得出这一结论不需要这种分析，我可以总结《实施服务质量目标》中的一个论点：如果事故数量翻倍，而事故分布大致相同，系统的可靠性显然变差了，但你的指标却没有发生太大变化。 它无法提供任何关于事故响应实践趋势的有用见解。模拟显示，即使事故性质没有变化，你也能看到大量变化。 无法通过 MTTx 评估事故管理过程或工具变更的成功或失败。方差使得难以区分任何改进，并且即使承诺的改进实现了，该指标也可能会恶化。 这些结果适用于典型的可靠性工程情况，例如网络服务上的事故。默认情况下，应拒绝将 MTTx 指标用于上述目的。然而，也有例外情况。例如，如果你有大量数据可以进行汇总 MTTx 分析。一个实际例子是大规模硬盘驱动器采购，如 Backblaze 公司定期发布的每个型号的硬盘驱动器可靠性统计数据，覆盖了数万个设备20。此外，同一型号硬盘之间的相似性比事故之间更大。同样，数量和较低的方差是你能够自信地看到典型服务系统平均延迟变化的原因。21\n另一个例外情况是剧变，例如将事故持续时间缩短到原来的 20%。如前所示，你很可能能够自信地在数据中检测到它。然而，你也可能通过其他方式检测到它，因此不需要使用仍存在问题的 MTTx 指标。\n更好的分析选项 MTTx 的挑战在于它是一个错误的观察指标。这个指标的行为特性使得分析变得困难。\n另一个挑战在于，这个指标可能根本没有测量到你真正关心的内容。当我们谈论 MTTR 改进时，通常是在问：“我们的可靠性提高了吗？”或者，“我们在应对事故方面变得更好了？”选择一个更准确地代表决策目标的指标是其他文献中也讨论的重要话题。22\n我没有找到任何可以像 MTTx 那样被普遍应用的“银弹”指标。然而，我们可以探讨在特定背景下选择更好指标的一些方法。\n根据问题定制指标 我用模拟测试产品是否影响 MTTx。然而，现实中的产品或流程变更并不是这样运作的。相反，它们改善了事故的某些方面，可能是事故沟通过程，或是自动事故分析工具提出的假设。23\n如前所述，事故是由不同持续时间的步骤组成的。24这些步骤在各种出版物中都有研究。如果你在改进事故过程中的某一步，将所有其他步骤包括在内会使你更难理解变更的影响。\n尝试分析每个事故的具体行为可能并不实际。你无法依赖人类输入元数据，也难以紧密观察每个事故。相反，实际的解决方案可以是对选定的事故样本进行用户研究。这些研究可以专注于你感兴趣的事故方面，并提供比汇总统计数据更丰富的理解。正确构建这些研究并不总是容易的，如果可能，建议寻求专家意见。考虑到这一点，有些文献在建立低成本用户测试方面提供了帮助，我已经成功地将这些经验应用于构建实际系统。25\n考虑直接的可靠性指标 也许你在问：“作为公司，我们的可靠性在变好还是变坏？” 这时可用性的概念就显得尤为重要。在 SRE 实践中，服务质量指标（SLIs）和服务质量目标（SLOs）是常用的术语。理想情况下，这些指标应该反映用户感知的产品可靠性，而 SLOs 则应该设定为符合业务权衡的目标。通常，这两者并不完全准确，有时甚至与理想情况相去甚远。\n即使你的 SLIs 和 SLOs 尽可能真实地反映业务目标，这仍不意味着它们可以用汇总统计数据来分析，例如每年消耗的错误预算总和。由于 SLI（即使是接近理想属性的 SLI）可以通过多种方式实现，这里给出的答案可能不具有普遍适用性。我在这方面没有进行过分析，但这是一个有趣的未来研究方向。你可能可以在公司内部使用前面讨论过的工具轻松完成这项工作。\n根据你的业务，另一个衡量标准可能是已打开的支持案例总数，或因服务不可靠而导致的客户电话，或其他更高级的综合指标。\n测试你的选择指标 可能有比这里建议的更好的方法，我期待该领域未来的工作。关键在于，分析应关注你真正关心的问题；明智地选择你的指标。 可靠性事故是多种多样的，需要回答的关于可靠性度量的问题也同样多样。关键是以批判的眼光看待你的指标。它们是否真的在测量你想要测量的内容？它们在面对随机性时是否稳健？你是否有证据支持你的答案？ 我用来研究 MTTx 的工具同样可以用于其他你正在考虑的指标。过程大致相同：确定对你有意义的变化水平（这取决于指标，也取决于你的业务），然后分析你是否可以在数据中自信地看到它。\n结论 我已经证明，即使在有利的分析设置中，MTTx 也不能用于许多被宣传为有用的实际用途，例如评估可靠性趋势、评估政策或产品的结果，或了解整体系统可靠性。系统运营者、DevOps 或 SRE 应该不再默认 MTTx 是有用的。除非在特定情况下已证明其适用性，否则应对其应用持怀疑态度。\n问题并不仅限于使用算术平均数作为指标；我已经证明，中位数和其他指标也存在同样的问题。这是由于事故数量通常较少且持续时间方差较大的结果。在三家匿名公司的实际数据集中以及 Google 的混淆数据集中都观察到了这种分布。\n与其使用 MTTx 分析整体事故统计数据，你可以专注于事故生命周期中的更具体问题，更贴近你想要评估的内容。这可能会导致选择不同的指标或完全不同的测量过程。选择更好的指标应当带来更好和更稳健的决策过程。例如，可以专门测量和研究检测时间，或在一些常见事故响应活动上花费的时间。\n也许还有其他统计数据可以提供更多的价值。事故持续时间的方差本身可能也是有用的，因为它可以证明响应能力的一致性。无论情况如何，有一点是肯定的：你应该批判性地思考你的指标并对其进行测试（或许可以使用本报告中提到的一些工具）。超越依赖假设、直觉或行业趋势，寻找证据证明你选择的指标可以指示你希望它们指示的内容。\n致谢 作者感谢 Kathy Meier-Hellstern 的审阅、建议和意见；感谢 Ben Appleton 审阅此作品以及一些初步工作的贡献，这些工作促成了本文的完成；感谢 Michael Brundage 进一步审阅并激发了额外的分析；感谢 Scott Williams 的进一步审阅；感谢 Cassie Kozyrkov 为使统计思维成为一个越来越易于理解的主题所做的努力。\n关于作者 Štěpán Davidovič 是 Google 的一名站点稳定性工程师，目前致力于内部自动监控基础设施的开发。在之前的 Google SRE 职位中，他开发了金丝雀分析服务，并参与了许多共享基础设施项目和 AdSense 可靠性工作。他于 2010 年毕业于布拉格捷克技术大学，获得学士学位。\n❤️ Photo by Kevin Bidwell: https://www.pexels.com/photo/firefighter-holding-hose-with-water-flowing-3013676/\n请参阅，例如，《A List of Post-mortems!》https://github.com/danluu/post-mortems 和《Postmortem Index》https://postmortems.app/。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJohn Allspaw，《Moving Past Shallow Incident Data》，Adaptive Capacity Labs，2018 年 3 月 23 日。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n《Mean time to recovery》，Wikipedia。https://en.wikipedia.org/wiki/Mean_time_to_recovery\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLaura Nolan，《What Breaks Our Systems: A Taxonomy of Black Swans》（视频），SREcon19 Americas，2019 年 3 月 25 日。https://www.usenix.org/conference/srecon19americas/presentation/nolan-taxonomy\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n《Normal probability plot》，Wikipedia。https://en.wikipedia.org/wiki/Normal_probability_plot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n请参阅，例如，《A List of Post-mortems!》https://github.com/danluu/post-mortems 和《Postmortem Index》https://postmortems.app/。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n请注意，例如，公司 C 的事故持续时间通常对齐到整小时，这在图表上表现为一些峰值。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n通过重复抽样来模拟行为的过程——在这种情况下，是模拟事故解决时间的行为。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n截至 2020 年夏末，我认为仅使用过去 12 个月的数据可能会受到世界事件的影响，从而导致数据集不寻常。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n针对这种特定情况，事故被缩短了 10%。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见《在线统计教育》中的“均值的抽样分布”，“均值差异的抽样分布”，“均值的检验”等章节，项目负责人 David M. Lane，莱斯大学。https://onlinestatbook.com/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n根据你的业务，这种推理可能存在缺陷。考虑到每月一次一小时的事故对用户和业务的影响，与 60 次一分钟的事故非常不同。这同样适用于常用的服务质量目标（SLO）语言。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRick Branson, \u0026ldquo;Stop Counting Production Incidents\u0026rdquo;, Medium, 2020 年 1 月 31 日。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n“Normal probability plot”，Wikipedia。https://rbranson.medium.com/why-you-shouldnt-count-production-incidents-38616d8e6329\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见《在线统计教育：多媒体学习课程》中的“均值的抽样分布”，“均值差异的抽样分布”，“均值检验”等章节，项目负责人 David M. Lane，莱斯大学。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见《在线统计教育》中的相关章节，以及 Wikipedia 上的“样本均值分布”。https://en.wikipedia.org/wiki/Mean#Distribution_of_the_sample_mean\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEric W. Weisstein，《正态差异分布》，来源于 MathWorld—A Wolfram Web Resource，更新于 2021 年 3 月 5 日。https://mathworld.wolfram.com/NormalDifferenceDistribution.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJennifer Mace, \u0026ldquo;Generic Mitigations: A Philosophy of Duct-Tape Outage Resolutions\u0026rdquo;, O\u0026rsquo;Reilly, 2020 年 12 月 15 日。https://www.oreilly.com/content/generic-mitigations/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAlex Hidalgo, Implementing Service Level Objectives, O\u0026rsquo;Reilly, 2020。https://www.oreilly.com/library/view/implementing-service-level/9781492076803/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n“Hard Drive Data and Stats”，Backblaze。 https://www.backblaze.com/cloud-storage/resources/hard-drive-test-data\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n尽管其他统计数据（例如更高的百分位数）通常是衡量服务系统延迟的更好指标。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDouglas W. Hubbard，《How to Measure Anything》第三版（新泽西州霍博肯：John Wiley \u0026amp; Sons，2014 年）。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAndrew Stribblehill，“Managing Incidents”，载于 《SRE Google 运维解密》（O\u0026rsquo;Reilly，2016）。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJohn Allspaw，“Moving Past Shallow Incident Data”；Charisma Chan 和 Beth Cooper，“Debugging Incidents in Google’s Distributed Systems: How Experts Debug Production Issues in Complex Distributed Systems”，Queue 第 18 卷第 2 期（2020 年 3 月-4 月）。https://queue.acm.org/detail.cfm?id=3404974\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSteve Krug，《Rocket Surgery Made Easy》（加利福尼亚州伯克利：New Riders，2010）。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-07-12T17:03:39+08:00","image":"https://martinliu.cn/blog/incident-metrics-in-sre/pexels-kevinbidwell-3013676_hu_9fe3c56d729816f4.jpg","permalink":"https://martinliu.cn/blog/incident-metrics-in-sre/","title":"Google SRE 白皮书：《SRE 视角的事故管理指标》"},{"content":" 下载中文版 PDF 文件 【译者注】Google Cloud 的客户可靠性工程团队（Cloud CRE）是一支专业团队，致力于帮助客户提高其 Google Cloud 平台上的可靠性。Cloud CRE 团队的使命是帮助客户建立可靠的服务，以便他们可以专注于创新。为了实现这一目标，Cloud CRE 团队开发了一种生产成熟度评估方法，以帮助客户评估其生产环境的成熟度，并提供指导，以帮助他们提高其生产环境的可靠性。\n谷歌 Cloud CRE 生产成熟度评估 (Cloud CRE Production Maturity Assessment)\n监控和指标 【Monitoring \u0026amp; Metrics】确定期望的服务行为，度量服务的实际表现，并纠正差异。示例指标包括响应延迟、错误率或未答复查询率、资源的峰值利用率。\nSLO 定义和度量 【SLO Definition and Measurement】拥有一个代表用户需求的，已发布的服务水平目标 (SLO)，并根据这些已发布的 SLO 进行评估、报表和总结。\n您的服务/应用程序是否有明确定义的 SLO？ SLO 是对服务行为的度量目标，例如 95% 的查询请求延迟低于 500 毫秒。 SLO 是否反映了客户的体验？ 即，满足 SLO 是否意味着客户体验是可以接受的？反之，未能满足 SLO 是否意味着客户体验是不可接受的？ SLO 是否发布给用户？ 这并不常见，但有时如果您的服务有一个主要的大客户，您可能会发布您的 SLO，以便他们可以根据您的服务性能进行计划。 您是否有对 SLO 进行良好定义的度量？ 度量过程是否有文档记录？ 度量过程是否自动化？ 即，您是否能自动获得 SLO 的报告或图表，还是必须手动运行命令或填写电子表格，以查看您对 SLO 的满足情况？ 您是否有修订/优化 SLO 的流程？ 例如，如果您一直未能满足 SLO，但用户似乎没有投诉，您如何决定是否修订 SLO 目标水平？ 成熟度等级描述 1 - 未管理 服务没有 SLO 或 SLO 不代表用户需求。 2 - 已管理 服务有定义的 SLO，但 SLO 的度量是临时的或没有文档记录。 3 - 已定义 服务有定义的 SLO，并且度量过程有文档记录且有明确的负责人。 4 - 已度量 SLO 发布给用户，并且 SLO 自动度量，代表用户需求。 5 - 持续改进 与用户一起对 SLO 进行持续评估和改进。 仪表板与可视化 【Dashboards \u0026amp; Visualization】用清晰的数据展示来支持服务的管理、决策和行动事项调整。\n您是否采集相关服务的数据？ 您使用了哪些采集方法？ 日志处理 白盒监控：检查内部系统状态 黑盒监控：模拟实际用户请求的人工流量事务/拨测 从客户端设备采集指标 其他： 您能简要描述您的采集方法吗？ 是否为自动化采集？ 您管理的服务是否都有仪表板？ 仪表板通常是一个显示图表或其他关键监控信息的网页，使您可以一目了然地看到服务的性能状态。 仪表板是否包含关键服务指标？ 例如：QPS，延迟，容量，错误预算消耗情况 仪表板是否包含关键业务指标？ 例如：访问量，用户，浏览量，共享次数 仪表板是否可集中式的分享给相关业务部门使用？ 仪表板在应用程序/服务/团队之间是否以统一的 UI / UX 共享？ 企业是否有用于临时数据探索的工具？ 例如：钻取仪表板，Splunk / BigQuery，数据仓库，以满足定制化分析需求。 成熟度等级描述 1 - 未管理 没有仪表板。数据采集是临时的、不一致的，没有文档记录。 2 - 已管理 可能有关键指标的仪表板，但仅以静态形式存在（不可定制）。仪表板没有集中管理，用途没有标准化，所有权不明确。 3 - 已定义 仪表板存在并支持常见的技术用例，所有权明确。支持临时查询的工具存在，但使用起来有些复杂（需要培训或长时间的试验才能得到结果）。 4 - 已度量 仪表板支持技术和业务用例。临时数据探索工具是可定制的，支持常见用例，无需培训（例如，按照手册文档操作）或通过直观的界面使用。 5 - 持续改进 仪表板在各业务单元之间标准化。 用户关注 采集准确反映用户体验的数据，并使用这些数据来维护服务质量。区分人工流量指标和关键用户旅程的度量；例如，如果服务器的“正常运行”，但用户仍然无法使用产品，则该指标无法提供用户体验的认知。\n服务是否采集任何未从服务器导出的数据？ 通常是探针或关键用户旅程探测脚本。 探针覆盖是否涵盖复杂的用户旅程？ 例如，对于电商业务：主页 =\u0026gt; 搜索产品 =\u0026gt; 产品列表页 =\u0026gt; 产品详情页 =\u0026gt; “加入购物车” =\u0026gt; 结账 是否为特定的用户旅程/流程提供 SLO？ 是否有针对用户旅程度量性能回归的既定响应流程？ 例如，每当用户完成帐户创建流程的监控度量时间超过 5 分钟时，既定响应是：先暂停功能发布工作，并优先进行次问题的补救工作。 如有，响应是什么？ 回滚发布 触发告警 开发临时修复 其他 您能简要描述您的响应方法吗？ 是否评估用户旅程 SLO 的状态以推动服务改进？ 成熟度等级描述 1 - 未管理 没有采集用户体验数据，或仅有服务器端指标数据（如服务响应延迟）。 2 - 已管理 存在探针来测试特定用户端点（如站点主页、登录），但缺少对复杂用户旅程/流程的探测覆盖。探针通常是单步的，而非多步旅程。 3 - 已定义 复杂用户旅程得到度量（通过复杂探测或客户端实时流量报告）。服务改进是被动的，而非主动的。 4 - 已度量 SLO 明确涵盖特定的用户旅程。不只是“服务器是否正常运行”，而是产品是否正常工作，能够让用户执行特定的产品功能。用户旅程的 SLO 违反会导致发布回滚。 5 - 持续改进 持续评估服务延迟和可用性，并用于推动服务改进。 容量规划 【Capacity Planning】预测未来需求，并确保服务在适当资源水位工作，并有足够的容量来满足这些需求。\n业务指标预测 【Business Metric Forecasting】预测服务关键业务指标的增长。业务指标的示例包括用户数量、销售数据、产品采用率等。预测需要准确且长期，以便有意义地指导容量规划。\n您的应用程序是否有关键业务指标？ 例如，用户数量、图片数量、交易数量等。 您是否有关键业务指标的历史趋势数据？ 保留时间是多少个月？ 您是否预测关键业务指标的未来增长？ 您预测的未来时间范围是多少个月？ 您是否通过将预测与度量期间的实际值进行比较分析，来衡量预测准确性？ 6 个月预测的数字与观测值的误差百分比是多少？（0-100+） 您的预测是否考虑了可能导致业务指标快速变化的发布或其他非有机事件？ 成熟度等级描述 1 - 未管理 没有定义容量单位，或定义了单位但没有历史趋势数据。 2 - 已管理 定义了业务单位，有单位的历史趋势数据，但预测能力有限。预测要么不准确，要么是短期的（\u0026lt;=1 个季度）。 3 - 已定义 有可靠的历史趋势数据，有 4-6 个季度的预测。有一个复杂的预测模型。 4 - 已度量 已衡量过去预测的准确性。使用 6-8 个季度的预测。 5 - 持续改进 定义并度量且准确的预测，知道如何准确预测并不断提高准确性记录；实际需求的准确性在 6 个月预测内误差在 5% 以内。 供给指标建模 【Supply Metric Modeling】通过经验转换模型计算一组业务指标的容量需求。一个基本的示例模型：服务 1000 名用户需要 1 台虚拟机。预测显示用户每季度增长 10%，因此虚拟机也必须每季度增长 10%。\n您是否有一个将业务指标转换为逻辑容量指标（虚拟机、pods、分片等）的模型？ 一个简单的模型示例可能是：“每 1000 名新用户我们需要增加一个 VM-large-1。” 该模型是否有文档记录？ 您是否验证容量模型的各个方面？ 对于上述示例模型：我们如何知道 1000 名用户放在一台 VM-large-1 上是合适的？我们有压力测试吗？ 验证是否是自动化的？ 该模型是否考虑了资源规格或成本的变化？ 例如，不同地点的 CPU 成本效率或可用虚拟机规格的差异。 实际需求的持续度量是否反馈到容量模型的修订中？ 成熟度等级描述 1 - 未管理 没有将业务指标转化为逻辑供给的模型。服务是资源过度配置的（购买并希望使用模型），没有花费大量时间进行容量规划。 2 - 已管理 使用简化的经验规则/指导方案，例如每 1000 用户/虚拟机。 3 - 已定义 有压力测试，知道可能的扩容时间点。例如，压力测试的数据表明，1200 名用户确实适合在一个虚拟机上。使用经过验证的经验法则。模型验证可能是临时的（未自动化）。 4 - 已度量 有一个记录在案的服务模型，并定期验证（例如，通过了在发布验证期间的压力测试）。模型简单，维度上存在差距（例如，涵盖 CPU，但不包括带宽）。模型没有考虑不同地点的资源成本/规格差异，例如 CPU 类型、资源成本、虚拟机规格等。 5 - 持续改进 有一个定义良好的模型，将需求单位转化为供给单位组合，并使用实时系统的反馈。制定了改进关键维度的计划。理解并在模型中考虑CPU平台/区域/网络之间的差异。如果存在非线性，则理解非线性。 容量获取 【Acquiring Capacity】为服务配置额外资源：知道何时何地需要什么资源，了解必须满足的约束条件，并有满足这些需求的流程。\n团队每月在资源管理上花费多少总时间？ 获取更多资源的流程是否有明确定义？ 流程是否有文档记录？ 流程是否自动化？ 资源请求的发起是否由预测程序自动生成？ 您是否知道哪些约束条件决定了服务的位置？ 例如，您的服务器是否必须位于特定的云区域（az）或地区（region）？如果是，为什么？您的服务、处理流程和数据存储是否必须共址或在同一区域（az）或地区（region），为什么？您是否有数据区域化要求？ 这些约束条件是否有文档记录？ 您是否监控对这些服务约束的遵守情况？ 成熟度等级描述 1 - 未管理 资源是手动且临时部署的。系统组件之间的关系没有文档记录。不确定部署的资源是否足够。 2 - 已管理 存在服务约束的经验法则（例如数据库和 Web 服务器需靠近），但这些约束没有被度量（未验证）。有定义的资源获取流程，但流程是手动的。 3 - 已定义 获取资源的过程大部分是自动化的，但何时获取资源仍是手动过程。 4 - 已度量 系统约束被建模，但缺乏评估。随着时间推移，服务变动可能导致模型中的约束与现实脱节。何时获取资源由预测驱动。 5 - 持续改进 模型不断评估和维护，即使在服务变动的情况下也是如此。获取容量的位置由模型驱动，获取容量的时间由预测驱动。 容量利用率 【Capacity Utilization】监控服务资源的使用情况，理解容量和利用率之间紧密而复杂的关系，设定有意义的利用率目标，并实现这些目标。\n您是否为服务定义了任何利用率指标？ 例如，现在有多少总资源在使用？ 您是否持续度量利用率？ 您是否有公认的利用率目标？ 即，您是否有特定的利用率指标阈值，这些阈值被记录，并认可为所需的最低值，未达到该目标会触发响应处理流程？ 利用率目标是否在驱动服务改进？ 您是否定期审查利用率目标，及服务对该目标的符合情况？ 例如，每季度审查一次。 您是否了解服务的资源瓶颈是什么？ 对于上面的示例（每台虚拟机 1000 用户）：如果我们将 1200 用户放在一台虚拟机上，哪个资源会首先耗尽？（CPU、RAM、线程、磁盘等） 您能简要描述一下吗？ 您是否测试新版本的利用率回归情况？ 显著的利用率回归是否会阻止发布？ 成熟度等级描述 1 - 未管理 没有定义系统利用率指标。 2 - 已管理 定义了利用率指标和目标，但度量是临时的（非持续）。每季度/每年进行。 3 - 已定义 持续度量利用率，并定期审查（每月/每季度）。 4 - 已度量 利用率是发布健康状况的指标（利用率显著回归的新版本会被阻止发布）。 5 - 持续改进 持续评估利用率指标，并用于推动服务改进（例如，保持服务成本的可持续性）。 变更管理 【Change Management】在保持所需服务行为的同时更改服务行为。示例：金丝雀发布、1% 实验、滚动升级、快速失败回滚、季度错误预算。\n发布过程 标志、数据和二进制程序文件的变更流程。\n术语澄清 不同上下文中的发布术语可能有所不同，因此在本次评估中我们将使用以下定义。\n服务版本：一组代码、二进制文件和/或配置，封装一个定义明确的服务状态。\n候选版本：一个用于部署到生产环境的新服务版本。\n发布：准备和部署一个新的发布候选版本到生产环境。\n候选版本准备：创建一个可行的候选发布版本。这包括编译和所有测试、分级或在与生产环境接触之前必须进行的其他验证活动。\n部署：转换到新服务版本的过程。例如，将二进制文件推送到其生产位置，并重新启动相关进程。\n增量部署：以一系列连续逻辑划分的方式结构化地部署到多个生产位置。例如，一次部署到多个不同站点中的一个站点，或者在总共 1000 台虚拟机的环境中，每次在其中的 100 台虚拟机子集进行部署。\n金丝雀发布：战略性地部署到生产环境的有限子集，以测试版本的可行性，必须满足明确的健康检查才能继续更广泛的部署。\n您是否有定期的发布节奏？ 即，您是否有固定频率执行发布流程？\n以下哪项最接近您的发布节奏？ 构建成功即发布（Push-on-green） 每日 每周 每两周 每月 一次典型发布需要多少工程师工时（小时）？ 从发布候版本选准备到部署完监控配置结束，总共需要多少人力时间？\n发布的成功率是多少？ 成功的发布通常是指达到完全部署，且不需要回滚或产品补丁的发布。\n发布成功率是否满足您的业务需求？ 例如，发布是否足够可靠，不会阻碍开发进度，或削弱对功能交付的信心？\n您是否有回滚部署的流程？\n您是不是进行的增量部署？ 例如，将新版本先暴露给 1% 的用户访问，然后 10%，然后 50%\u0026hellip;（参见上面的定义。）\n对版本发布结果，您是否有明确的失败条件检查？ 例如，由人类或机器人评估的指标，以查看发布结果是否存在问题。\n您是否使用金丝雀发布（或一系列金丝雀发布）来验证每次部署？ 即，少量真实请求被发送到新版部署，以查看其是否能正确处理，然后再接收所有请求。（参见上面的定义。）\n发布过程的所有部分是否都是自动化的？\n哪些部分？ 发布候选版本准备 部署 失败检测 部署回滚 金丝雀发布 发布过程的所有部分是否都有文档记录？ 即，如果您让一个新团队成员执行发布，他们是否能找到，并遵循该过程的说明文档？\n哪些部分？ 发布候选版本准备 部署 失败检测 部署回滚 金丝雀发布 成熟度等级描述 1 - 未管理 发布没有固定的节奏。发布过程是手动且无文档记录的。 2 - 已管理 发布过程有文档记录。尝试定期发布。有应对不良发布的流程。 3 - 已定义 拥有自动化的持续集成/持续交付 (CI/CD) 流水线。发布是可预测的，成功率满足业务需求。发布过程设计允许在预先与业务约定的参数范围内，尽量降低对客户的不良影响。 4 - 已度量 完全自动化的发布过程，包括自动化测试、金丝雀发布过程和自动回滚。发布满足业务需求。展示出可在不显著消耗错误预算的情况下，进行回滚的能力。 5 - 持续改进 标准的质量保证（Q/A）和金丝雀发布过程。发布快速、可预测，且需要最少的人工监督。过程完全按标准操作落地，并可发布完成。自动化的发布验证和测试，全面的与监控集成。健全的回滚和异常处理程序。发布和发布频率符合业务需求。发布过程符合产品需求。 设计与发布 【Design \u0026amp; Launch】通过早期参与、设计审查、引入最佳实践等方式，设计一个成功的服务。\n团队是否有重大代码变更的评审流程？ 例如，设计评审或发布评审。 评审是否自助进行？ 评审是否有特定的批准人？ 团队是否有执行重大变更的最佳实践？ 例如，如果您知道您正在发布一个新功能，会添加一个新组件，是否有关于如何以标准方式配置、监控、部署和操作该组件的协议？ 这些实践是否有文档记录？ 最佳实践是否是通过代码和/或自动化方式强制执行的？ 是否可以因未遵循最佳实践而拦截发布？ 团队是否有高风险发布的强制性流程？ 成熟度等级描述 1 - 未管理 团队没有新代码或新服务的设计或评审流程。 2 - 已管理 团队有一个轻量级的引入新组件或服务的评审流程。团队有一套最佳实践，但它们是临时的且记录不完整。 3 - 已定义 团队有高风险发布的强制性流程。该流程涉及应用发布的记录最佳实践，可能包括设计/发布审查。 4 - 已度量 大多数发布的评审是自助进行的（例如，通过简短的调查，可以触发对边缘情况的审查）。最佳实践通过共享代码模块和调优自动化来应用。团队有记录的重大服务变更流程，这些设计有指定的评审者/批准人。 5 - 持续改进 最佳实践通过自动化强制执行。允许通过特例申请，来请求忽略最佳实践。包含1-4中的所有内容。 变更流程自动化 【Change Process Automation】自动化了与服务运维相关的手动工作。\n您是否有变更流程自动化？ 即，当需要执行生产操作（如重启一组作业或变更一组虚拟机的配置）时，是否有脚本或其他工具或服务来帮助更安全和轻松地进行变更？ 您的自动化是否使用了“基础设施即代码 (Infrastructure as code)”？ 与命令执行（命令式）自动化流程相对的。 您的自动化是否支持“差异”（diffing）或“干运行 (dry-run)”功能，以便操作员可以看到操作的效果？ 您的自动化是否幂等？ 您的自动化是否具有弹性？ 即，很少因服务、政策或基础设施变化而中断。 您的常规流程是否有文档记录？ 例如，如果让新团队成员升级所有虚拟机上的 Linux 版本，他们是否能找到并遵循操作说明？ 您的常规任务中有多少百分比是自动化的？ 您是否有启动或关闭服务的流程？例如，在新的 GCP 区域部署。 该流程是否有文档记录？ 该流程是否自动化？ 需要多少工程师工时（小时）？ 成熟度等级描述 1 - 未管理 团队花费大量时间在操作上，或有一个“运维团队”花费大量时间在操作上。任务记录不足（例如，流程仅特定个人知道，但没有文档记录）。 2 - 已管理 手动任务有文档记录。高负担任务部分为自动化，并且了解操作时间的花费。 3 - 已定义 许多高负担任务已自动化。团队在操作上花费的时间不到一半。自动化不灵活，易受政策或基础设施变化的影响。 4 - 已度量 所有高负担任务均已自动化。团队在操作工作上花费的时间少于 20%。 5 - 持续改进 所有可自动化的任务均已自动化，团队专注于更高层次的自动化和可扩展性。现有自动化可以快速适应服务或政策变化。 紧急响应 【Emergency Response】注意并有效响应服务故障以保持服务符合SLO。示例：值班轮换、主要/次要/升级、操作手册、不幸之轮、告警审查。\n组织值班轮换 响应告警\n您是否有应对重大事件的事件管理协议（流程）？ 例如，指定事件经理、启动跨公司通信/沟通、定义其他管理危机的角色。 您的服务是否有特定情况的操作手册？ 操作手册是描述如何响应特定类型故障的文档，例如将服务从一个区域切换到另一个区域。 大多数操作手册条目是否提供明确且有效的响应操作？ 即，能够减轻问题并帮助诊断或解决原因的操作。 您的服务是否有例行遵循的升级流程？ 即，如果无法解决问题，是否有流程可以找到并联系能够解决问题的人？ 升级流程是否有文档记录？ 一线响应者能否在不求助的情况下解决90%的事件？ 例如，事件在不升级到主题专家或同事的情况下解决？ 值班轮换结构\n【Oncall Rotation Structure】关于值班责任的程序和期望，明确识别受过训练的工程师团队，能够可持续地快速响应事件以维护服务的SLO。\n您的服务是否有值班/通知触达的轮换？ 您的值班轮换是否有文档记录的响应时间？ 响应时间是“到键盘时间”而不是“解决时间”。 响应时间是多少分钟？ 您的值班团队成员是否在轮班时进行交接？ 您的团队是否有将新响应者加入值班轮换的流程？ 例如，培训过程、指导、跟班主要响应者。 培训材料是否有文档记录？ 您的团队是否有“值班配对”计划，即由有经验的响应者与新响应者配对进行在岗培训？ 您的团队是否进行“厄运之轮”或其他值班培训演习？ 厄运之轮：生产灾难角色扮演，用于培训和审查及维护文档。 成熟度等级描述 1 - 未管理 临时支持：尽力而为，仅限白天，无实际轮换，手动告警，无定义的升级流程。 2 - 已管理 有文档记录的轮换和响应时间。告警自动化并与监控集成。培训是临时的。 3 - 已定义 存在培训流程制度（幸运之轮、值班跟班在岗培训等）。轮换人员充足，但有些告警需要升级到高级团队成员才能解决。 4 - 已度量 度量事件的平均修复时间 (MTTR) 和平均检测时间 (MTTD)。轮班之间有交接。大多数事件需要最小的升级（可以由值班人员单独处理）。 5 - 持续改进 每周回顾审查事件并改进策略、交接、班次间的沟通，大多数问题无需升级即可解决，回顾审查轮换的价值和规模，评估范围。建立了事件响应协议。 告警分析 【Alert Analysis】回顾审查实际接收到的告警，覆盖现有系统，管理告警的实践和流程，可操作告警的数量，按原因、位置和条件对事件进行分类的能力。\n您的告警是否基于监控数据自动化？ 您的团队收到的告警量是否一致？ 如果答案为“是”表示大多数值班轮班的告警数量相当。 您的团队是否有维持告警增长低于线性增长的流程？ 即，随着服务数量的增长，是否采取措施来防止告警量成比例的增加？ 您的团队是否有自动化的告警抑制规则或依赖关系，以减少告警数量？ 例如，当负载均衡服务器被排空时，该服务器的告警会自动被抑制；或者，细粒度的告警（如特定延迟阈值）可能依赖于粗粒度的“无法访问”告警的静音状态。 您的团队是否经常忽略或手动抑制任何告警，因为它们噪音大、垃圾多、假告警或不可/无需操作？ 例如，是否有某个告警每几天都会触发一次，但通常无需采取任何行动就关闭了？短期内有垃圾告警是可以的，只要在持续修复它们。 您的团队是否在值班轮班之外花费大量时间处理轮班期间发生的事件？ 您的团队是否有定义的超负荷处理流程，以应对告警触发率达到不可持续水平的时期？ 您的服务是否经历过未被告警初期检测到的重大故障？ 即，没有触发任何告警的故障，或只有在通过其他来源发现事件后才触发的告警。 您的团队是否收集告警统计数据（原因、采取的行动、告警解决方案）以推动改进？ 您是否有定期审查评估会议，审查评估告警或事件以进行模式匹配、发生率、操作手册改进等？ 成熟度等级描述 1 - Unmanaged Pager 过载，告警被忽略，告警长时间静音，无操作手册，告警量增加或不可预测，事件发生时无告警（手动检测事件）。 2 - Managed 事件率不可持续（值班成员报告过劳）。虚假告警被静音。有操作手册，但指导操作较少。许多告警是“信息性”的，无明确操作。告警量不可预测。 3 - Defined 大多数告警有明确人类操作的操作手册。告警量在轮班/周之间无显著变化。告警量在可持续水平（由值班团队测量），有处理告警量过载的流程（如开发人员停止开发并致力于可靠性）。 4 - Measured 大多数告警有有用的操作手册条目。几乎所有告警都需深思熟虑的人工反应。定期分析并处理告警主要原因。积极使用告警抑制以消除重复告警和已提醒其他团队的告警。维持服务增长下的低于线性增长的告警量。 5 - Continuous Improvement 识别告警模式，定期审查故障率，修剪告警，审查基本服务故障模式，所有告警需深思熟虑的人工干预，告警操作手册提供适当的调试入口。 事后复盘分析 【Postmortems】撰写事后复盘分析的制度，格式和行动项目，以及后续行动的期望。通过根本原因分析和发现结果推动服务可靠性改进的实践。\n您的团队是否有事后复盘分析流程？ 事后复盘分析也称为事件回顾、回顾。 事后复盘分析流程是否仅针对大型/重大事件？ 您的事后复盘分析流程是否会为团队生成行动项目？ 您的团队是否有优先处理并完成事后复盘分析行动项目的流程？ 大多数事件是否进行了彻底的根本原因分析，并有明确的结果？ 您的服务是否有优先修复或减轻已识别根本原因的流程？ 以下哪些是您的事后复盘分析流程的一部分？ 检测时间 从事件发生到检测到的时间。 修复时间 从事件发生到解决的时间。 以上均无 您的公司是否有在组织/团队之间共享事后复盘分析的流程？ 您的公司是否收集事后复盘分析元数据（如根本原因分类，MTTR，MTTD）？ MTTD：平均检测时间。事件从发生到检测的平均时间。 MTTR：平均修复时间。事件从发生到解决的平均时间。 您的公司是否有使用这些数据识别问题区域的流程？ 例如，是否对数据进行分类和/或汇总以识别故障模式或高风险服务方面，以指导风险缓解投资？ 您的团队或公司是否有事后复盘分析流程的所有权或审核周期？ 即，是否有人标准化格式并定期评估其有效性和价值？ 成熟度等级描述 1 - Unmanaged 无跟进或系统错误识别，无根本原因分析，事件得到控制但未分析，同类事件不断发生，未识别长期趋势。 2 - Managed 有定义的事后复盘分析流程和行动项目，但行动项目跟进差（仅处理 P0 项目）。根本原因分析（RCA）不足（“为什么”问得不够多）。由于行动项目跟进不力或 RCA 不充分，类似事件重现。 3 - Defined 事后复盘分析流程应用于所有重大事件（包含行动项目）。优先处理 P0 级别的行动项目。RCA 广泛且正确归因于大多数事件的根本原因。 4 - Measured 事后复盘分析附有注释元数据以促进分析。事后复盘分析结果在受影响团队之间广泛分享，从错误中学习。 5 - Continuous Improvement 所有行动项目及时完成，由相关团队和其他团队审查以便学习，识别问题区域，有流程确保行动项目完成，标准化格式，审查事后复盘分析流程以评估其价值。 ❤️ Photo by PNW Production: https://www.pexels.com/photo/a-black-calculator-near-a-ruler-8250929/\n","date":"2024-07-07T21:12:04+08:00","image":"https://martinliu.cn/blog/cloud-cre-production-maturity-assessment/pexels-loan-patru-1487385115-27000643_hu_f7134b4116cf932d.jpg","permalink":"https://martinliu.cn/blog/cloud-cre-production-maturity-assessment/","title":"Google SRE 白皮书：Cloud CRE 生产成熟度评估"},{"content":" 下载中文版 PDF 文件 下载英文版 PDF 文件 从 Google 下载白皮书 我们探讨了事故的基础知识，并详细了解了事故管理生命周期的三个阶段：准备、响应和恢复。这涵盖了很多内容，但你现在可能会想，“接下来该怎么做？”\n首先，要学会在适当的时候使用事故管理。事故响应需要大量人力资源。通常需要一个或多个人参与其中，从最初的告警，到问题解决的整个过程中。事故响应的目的是在问题发生时实施缓解措施，以争取时间来做出优先级决策。这意味着常规的产品修复可能会被推迟，长期计划和改进可能不会被优先考虑。事故响应可能导致服务质量目标 (SLO) 被违反或客户承诺无法履行，并且参与事故响应的员工都会感受到较大压力。\n有研究表明，现实世界中的第一事故响应者更容易出现倦怠和疲劳；同样的趋势也适用于处理非现实事故的人——即那些工作与生活不平衡、活动极端或可能缺乏控制的员工。这些因素在技术事故管理工作中很常见，意味着员工可能会感受到倦怠的影响和职业后果。这里的风险包括，最好的情况下是工作表现不佳，最坏的情况下是员工流失。由于这种倦怠产生的相关风险，公司必须尽量做好事故管理，并尽可能减少事故管理的频率。\n你的下一个行动是将事故管理视为一项关键运维学科，并努力在这方面取得出色的表现。那么，什么是“擅长”事故管理呢？这意味着你的团队（而不仅仅是个别人员）需要积极改进这一循环的所有部分。虽然这听起来不像是：有几个超级英雄消防员冲了进来，他们拯救世界的场景那么戏剧化，但英雄主义心态是有害的。缓慢而仔细地改进事故准备，开发响应事故的工具、技术和通信渠道，并优先考虑可持续和可扩展的工程工作，才是强大事故管理实践的核心。\n通过将所有内容视为一个连续且相互关联的循环，每个人都变得重要，并且可以避免将责任归咎于任何一个人或系统组件。无责文化的实践营造了一个心理安全的工作环境，让员工能够在其中蓬勃发展，并创造出色的产品。这些方法帮助谷歌度过了最近全球历史上的巨大不确定时期，也可以帮助提高贵公司的韧性。\n总体而言，不要将事故管理应用于每一个潜在问题或类型问题。谨慎而合理地使用事故管理，以避免让团队成员感到倦怠。当你完成事故管理时，停止管理事故，开始进行解决长期问题或风险所需的工程工作。识别并使用其他可能有用的工具。\n进一步阅读 来自《Google SRE 工作手册》的监控 https://sre.google/workbook/monitoring/ 来自《Google SRE 工作手册》的事故响应 https://sre.google/workbook/incident-response/ 来自《Google SRE 工作手册》的事后分析文化：从失败中学习 https://sre.google/workbook/postmortem-culture/ 事后分析行动项目：计划工作并执行计划 https://research.google/pubs/postmortem-action-items-plan-the-work-and-work-the-plan/ 使用 SRE 原则减少生产事故影响——CRE 实战经验 https://cloud.google.com/blog/products/devops-sre/shrinking-the-impact-of-production-incidents-using-sre-principles-cre-life-lessons 缩短生产事故缓解时间——CRE 实战经验 https://cloud.google.com/blog/products/management-tools/shrinking-the-time-to-mitigate-production-incidents 参考书目 “Google Data Center FAQ”。《Data Center Knowledge》，2017 年 3 月 19 日。https://www.datacenterknowledge.com/hyperscalers/google-data-center-faq Aleksandra. “63 Fascinating Google Search Statistics”。《SEOtribunal》，2018 年 9 月 26 日。https://seotribunal.com/blog/google-stats-and-facts/ “Incident Command System Resources”。美国联邦紧急事务管理局，美国国土安全部，2018 年 6 月 26 日。 Beyer, Betsy, Chris Jones, Niall Richard Murphy 和 Jennifer Petoff 编辑。 《Site Reliability Engineering: How Google Runs Production Systems》。O’Reilly Media，2016 年。 “Data Access and Restrictions”。《Google Workspace Security Whitepaper》，2021 年 10 月。 https://workspace.google.com/learn-more/security/security-whitepaper/page-7.html Treynor Sloss, Benjamin. “An Update on Sunday’s Service Disruption”。《Inside Google Cloud (博客)》，Google Cloud，2019 年 6 月 3 日。 https://cloud.google.com/blog/topics/inside-google-cloud/an-update-on-sundays-service-disruption 致谢 作者感谢 Jennifer Mace, Hazael Sanchez, Alexander Perry, Cindy Quach 和 Myk Taylor 对本报告的贡献。\n作者简介 Ayelet Sachto 是 GKE SRE 的站点可靠性工程师，曾在 Google UK 担任战略云工程师，并领导 EMEA 地区的 PSO-SRE 项目。在她 17 年的职业生涯中，她开发和设计了大规模应用程序和数据流，同时实施了 DevOps 和 SRE 方法。她是众多技术文章、演讲和培训的作者，包括 O’Reilly 课程 “SRE Fundamentals in 3 Weeks”，并在数十个会议上发言和领导了数百个工作坊。Ayelet 还是技术社区的积极成员和导师。在空闲时间，她喜欢创造各种东西，无论是厨房中的一道菜、一段代码，还是有影响力的内容。\nAdrienne Walcer 是谷歌 SRE 的技术项目经理，专注于提高弹性，减少大规模事故对谷歌服务、基础设施和运营的影响。Adrienne 曾为谷歌的 O’Reilly 出版物 《A Practical Guide to Cloud Migration》作出贡献，并在最后一次 USENIX LISA 会议 (LISA21) 上就规模化事故管理发表演讲。在加入谷歌之前，Adrienne 曾在 IBM Watson Health (前身为 Explorys Inc.) 担任数据科学家，并在 Strong Memorial Hospital 和 Cleveland Clinic 从事生物统计工作。她拥有乔治华盛顿大学的系统工程硕士学位和罗切斯特大学的学士学位。在空闲时间，Adrienne 喜欢玩龙与地下城游戏，并在 Second Harvest 食品银行做志愿者。\n来源： https://sre.google ；本白皮书一共有 7 章，后续章节将陆续发布。完整中文版白皮书即将发布，敬请期待。\n❤️ Photo by Pixabay: https://www.pexels.com/photo/photo-of-a-2-fireman-killing-a-huge-fire-69934/\n","date":"2024-07-06T12:46:48+08:00","image":"https://martinliu.cn/blog/anatomy-of-an-incident-ch7/pexels-pixabay-69934_hu_57836b5a2f2392b0.png","permalink":"https://martinliu.cn/blog/anatomy-of-an-incident-ch7/","title":"Google 白皮书 《事故管理剖析》第七章 总结与展望"},{"content":" 下载中文版 PDF 文件 下载英文版 PDF 文件 从 Google 下载白皮书 为了看到前文所讨论的一些原则在实践中的应用，我们将深入探讨一个谷歌重大宕机事故的现实例子。我们将回顾事件的经过，了解规模化组织结构的运作方式，并展示如何解决这个问题以及我们从中学习到的经验。\n对于谷歌来说，玛雅末日并不是2012年的新纪元现象。相反，玛雅末日发生在2019年6月2日，与一个名为Maya的网络自动化工具有关。Maya负责标记管理和网络流量调度，一个微小的代码改动导致了实体类型持续被错误标记。\n大约在中午，我们正在进行计划中的维护，确定了一系列将在多个服务器上运行的操作和配置变更（包括在Maya上）。当这个错误标记与我们的作业调度逻辑冲突时，我们“发现”了一种新的故障模式，与流量调度相关的作业被大规模取消调度。出入这些区域的网络流量试图将重新调度的任务塞入剩余的网络容量中，其中流量调度功能仍然有效，但最终未能成功。网络变得拥挤，我们的系统正确地对流量过载进行了分级，并自动排空了较大、对延迟不敏感的流量，以保留较小、对延迟敏感的流量。\n流量拥塞开始了。结果，我们的监控系统启动了事故管理流程的第一步：告警。当组件响应者从监控系统收到告警时，这反映了其负责的系统中发生的变化。我们的监控系统注意到错误率阈值被突破了，并向负责该网络组件的值守人员发送了自动通知，值守人员开始评估情况。\n与此同时，受影响区域的网络容量减少导致溢出，这种网络拥塞引发了我们网络和计算基础设施中的级联故障。总体来说，我们的网络优先考虑用户流量高于内部流量，包括员工的流量。这实际上是合理的，因为我们宁愿从无法解决问题的99.9%的员工那里重新分配容量，并尽最大努力为我们的用户服务。参与事故响应的0.1%的员工通常知道如何继续处理并绕过这个限制。但是，这次级联故障的一个影响是我们的内部工具出现了重大中断，扰乱导致了大量告警的发送，导致大量人收到了呼叫短信。当每个值守人员都切换到事故响应模式时，他们注意到了：由于网络问题导致的服务不可用。网络组件值守人员迅速确定了网络拥塞的原因，但同样的网络拥塞导致服务降级，也减缓了他们恢复正确配置的能力。\n每个人都想尽最大努力支持他们的用户，并了解服务恢复的预期轨迹，因此原本负责网络组件的值守人员团队突然新加入了很多同事。\n我们在谷歌将组件分为三类：\n基础设施组件，如网络管道或存储服务。 产品服务组件，如 YouTube 流媒体或 Google 搜索的前端。 内部服务组件，如监控、零信任远程访问、Maya 和算力管理。这些内部服务组件都在经历困难。 由于网络具有广泛的依赖性，所以在网络组件值守人员解决完问题之前，其他人都无法继续工作。其他值守人员开始提供帮助，并询问他们的服务何时能开始恢复。很多不同响应者预期的并行性，并没有加速问题的解决。根本原因和次生效应开始变得模糊不清；一个团队的原因是另一个团队的结果，每个人都在尝试贡献他们的知识。虽然每个人都是其系统栈的专家，但大多数人都没有对整体系统全面的大局观，不知道哪些工具路径变得不可用。\n为什么？未触及拥堵网络的路径是正常的。如果路径在那时看起来像外部用户，则拥堵网络的路径也是正常的，因为我们优先考虑了它们。因此，我们向外部用户提供的服务是可用的——例如视频通话或编辑文档。然而，如果路径是内部服务，如作业控制或 Maya 配置，它就被降级并卡住了。\n我们都在观看此次火山爆发，然而，在 20 分钟后，我们得出了问题的结论 “可能与熔岩有关。”\n宕机一小时后，一位组件响应者注意到，影响我们基础设施的系统级问题过于普遍，围绕事故的协调沟通变得混乱不堪。此时，已有超过40位队友加入了事故响应通信频道，试图提供帮助。监控数据显示出：当前事故影响了半个地球。Google Cloud、Gmail、Google Calendar、Google Play等服务都受到了影响——导致企业都无法运作，大量员工无法高效工作，人们无法相互沟通。一些员工试图使用那些不依赖受损网络的零星服务，而另外的人们都已经放弃了。\n近40人卷入了本次事故，网络英雄并没有足够的时间和精力，用来制定和协调实施适当的缓解措施，向所有利益相关者广泛沟通，并管理各方期望。因此，他们进行了升级。我们的网络组件值守人员向技术事故响应团队（Tech IRT）发出了求助请求；他们的请求触达到了许多处于合适工作时段时区里的Tech IRT成员，能够处理事故的成员表示了他们的可用性。由于事故影响如此广泛，许多人已经参与了事故。一些Tech IRT响应者没有担任事故指挥官的角色，因为他们是处理网络问题的团队成员或经理，可以帮助解决主要根本原因，所以他们选择了协助操作的工作。\n接受事故指挥官角色的 Tech IRT 的成员，以前没有处理过受故障影响的网络组件，但他们能够评估系统状态和响应人员的情况。利用他们的训练有素，这位指挥官运用一种机制访问到了生产系统，该机制立即将他们的行动标识为“事故响应”，并绕过了“内部流量降级”的标志。一旦内部流量得到了一些空间，他们就指挥网络值守人员开始介入并解决问题。\n在此过程中，他们迅速对正在进行的沟通，以及所有试图“提供帮忙”的人进行了组织和结构化。一旦这种混乱的工程能量被组织起来之后，每个人都开始一起取得到了进展。他们能够更清楚地跟踪不同系统的当前状态，并看到缓解措施的实施速度。随着这些繁琐的管理工作不再让网络组件响应者们不堪重负，他们和他们的团队有了实施适当缓解计划的空间，包括丢弃大量负载，为健康重启和一些紧急强行配置变更腾出系统空间。\n一旦开始步入了缓解事故的路径，Tech IRT 成员就专注于将事故推向结束。他们设定了一些退出标准，以便我们可以关闭事故，确保其他系统在任何需要执行的恢复操作中得到支持，然后确保被卷入的响应团队都能够顺利交接并离场。\n事故结束后，服务都恢复正常，我们进行了深入的事后分析复盘，以分析事故，并理解根本原因的细微之处，以及这些故障模式所揭示的新兴属性。自那以后，参与的网络团队已经开展了一些非常酷的工作计划，重新构建了 Maya，来防止这种故障模式，以及类似的，但以前未考虑到的故障模式，预防它们再次困扰我们的系统。\n最后，我们用内部的个人档案徽章、荣誉性的表情包和奖金等方式奖励了相关参与的人员。对大多数人来说，这次非常严重的事故，是他们职业生涯中最艰苦的一天。也为每个参与事后分析复盘的人提供一些小奖励，是他们帮助我们从中得到学习，让我们持续的增长韧性。\n来源： https://sre.google ；本白皮书一共有 7 章，后续章节将陆续发布。完整中文版白皮书即将发布，敬请期待。\n❤️ Photo by Pixabay: https://www.pexels.com/photo/photo-of-a-2-fireman-killing-a-huge-fire-69934/\n","date":"2024-07-05T12:46:48+08:00","image":"https://martinliu.cn/blog/anatomy-of-an-incident-ch6/pexels-pixabay-69934_hu_61995c5e89db7a3d.png","permalink":"https://martinliu.cn/blog/anatomy-of-an-incident-ch6/","title":"Google 白皮书 《事故管理剖析》第六章 真实事故案例：玛雅末日事件"},{"content":"完全没有想到，上一篇鱼缸的介绍文章，居然是最近一年里最受欢迎的文章之一。这鼓励我继续更新一篇，也把这个过程中的一些关键点分享给大家。\n从实用性方面看，鱼缸的价值其实并没有什么，主要是满足兴趣爱好的需求。想想近两年来，除了这一个鱼缸之外，我还放弃了另外两个比这大两到三倍的鱼缸。用那两个鱼缸测试了很多想法，水泵，滤材，折腾完了之后，剩下两个纸箱的剩余物。最近放弃的 60cm 的大白玻璃缸可能会在下次心血来潮的时候重新启用。\n当我拍摄视频的时候，这个鱼缸在书架上的效果和没有也差不多。不过那根长期并没有啥变化的绿萝也是有一点装饰效果。绿萝的根系在水下并没有长得很多，但是基本上在底纱中扎根了，在水中的一些根须之间，有时候成为小鱼的避难所。\n小鱼是水中氧气的消费者，而且它们应该可以产生一些水草所需要的二氧化碳。这7 条小鱼是我从最近放弃的 60cm 大缸里迁移过来的，没想到它们在这个新家里活的很滋润。\n小灯基本上是不开的，这个房间的窗户朝东，上午有几个小时的直射阳光。有一次我离开家好几天，忘了关小灯，回家之后，发现水里的绿藻疯长的一弹糊涂。但是保持关灯了一周多以后，绿藻就慢慢退去，并且消失不见了。所谓流水不腐，这个内置的小水泵发挥着至关重要的作用。之前的侧挂式小水泵不如这个效果好，更重要的是，这个内置的水泵提升了鱼缸外部的观感，没有了那个挂在鱼缸外面的水泵，鱼缸看起来更加简洁。但是还是损失了一定的有限的内部空间。内置小水泵入水后就没有再取出来过。感觉水质长期这么清澈的情况下，它保持水循环流动，增氧这一项功能就足够了。水已经干净到不用过滤的程度。\n当水里的硝化细菌建立起来之后，水质就清澈到不用刮擦鱼缸内壁的程度了。原因可能有一下几点：\n底沙、鱼缸里的石头提供了足够大的细菌培养的表面积。 底纱的体积和水的总体积的比例是恰到好处的，这样硝化细菌的密度就足够大。 消化细菌前期是非常弱的，所以必须两周左右换一次水，用晒过一周的自来水，换掉一半的浑水，来保持水质的清澈。 在当前硝化细菌充分的情况下，每周就不需要换水了，只需要加 1~3 升自然蒸发掉的水就行了。\n而且，我还从大缸中迁移过来一直田螺，实际证明它的工作非常努力，它是从野河里带回来的，它会不停的吸附在鱼缸内壁，水泵外侧，水草，石头，底沙上寻找事物吃。它会擦玻璃，会在底沙表面清理鱼的排泄物或者吃剩的鱼食。总之活动非常活跃，超出了我预期的效果。正所谓无心插柳。\n田螺在鱼缸的内侧工作，我们可以清晰的看到最外侧缸壁上的水渍，其实这说明了外壁已经非常干净和透明了。\n消化细菌很久都没有加过了，它是大缸换外置水泵的时候买的。放弃大缸的原因，还是水一直没有养好，现在觉得原因是底沙和火山石的体积总量太少了。\n当时，每周给大缸中加两盖子消化细菌，给这个小缸加一盖子。对比测试发现，小缸的水质越来越好，越来越清澈，加了五六次以后，就不需要在加了。其实小缸开缸的时候在底沙里埋放了硝化细菌的胶囊，只是没有达到预期的效果。而这次加的液体的硝化细菌算是这个鱼缸一年后的最大转折点。我在也不用为它的水质担心了。\n当前这款鱼食，小鱼们非常喜爱。成分蛋白质含量高，入水后会迅速沉底，水面上的少量漂浮。小鱼会迅速聚焦在水下，在底沙的表面，快速将鱼食颗粒搜寻完毕，然后迅速消灭水面上的剩余。ß\n最后，看下鱼缸在书架上的效果。算是给书架增加了一些生机。给居室里带来了一点点的自然气息。ß\n总之，上篇文章里所说的是愿景。而这篇文章里描述了一个实现后的效果。希望这个鱼缸能保持下去，目前的维护工作是非常低的：每周加一次水和投喂一次鱼食。免任何清理和维护。\n","date":"2024-07-04T12:01:26+08:00","image":"https://martinliu.cn/blog/aquarium-eco-systems-1-5-years-later/my-Aquarium_hu_707615b46f4a15bd.jpg","permalink":"https://martinliu.cn/blog/aquarium-eco-systems-1-5-years-later/","title":"鱼缸里的生态系统在一年半后"},{"content":" 下载中文版 PDF 文件 下载英文版 PDF 文件 从 Google 下载白皮书 在前一章中，我们介绍了几种减小客户影响的方法，包括技术和人员方面，因为两者都会影响检测时间、缓解/恢复时间和故障间隔时间。在本节中，我们将讨论事故结束后的工作：撰写事后复盘分析，并将其作为强大的工具来分析问题并从错误中学习。\n在事故结束后，应该确保集中精力在如何减少未来的事故上？为了解决这个问题，我们建议采用数据驱动的方法（图 5-1）。这些数据可以来自风险分析过程，或者是我们之前提到的度量数据。依靠从事后复盘分析中收集的数据，以及对之前影响客户的事故的学习非常重要。\n一旦你积累了足够多的事后复盘分析，就可以识别出模式。让事后复盘分析成为你的指南非常重要；在失败分析上的投资可以引导你走向成功。为此，我们建议创建一个共享库，并在内部团队中广泛分享事后复盘分析。\n心理安全 在谈论事后复盘分析时，不可避免地要讨论心理安全(Psychological Safety)。因此，在深入探讨撰写事后复盘分析的细节之前，我们先来谈谈事故管理文化中固有的心理安全，并讨论早期升级的价值。\n如果客户受到影响，应该尽快解决问题。如果组织内的人们不觉得升级或扩大事故规模是安全的，那么问题就难以解决。如果公司环境阻止人们质疑，或因升级事故而受到惩罚，响应者可能会犹豫是否质疑。如果是这样，事故只会在改善之前变得更糟。\n失败是正常的，需要接受这一点。这就是为什么实施 SRE 原则需要支持性和赋权文化的原因。关键在于理解，在不断通过新功能和系统改进服务的过程中，事故和中断是不可避免的。因此，如果不从事故中学习，就错失了改进的机会。正如合气道创始人植芝盛平所说：“失败是成功之钥，每一个错误都教会我们一些东西。”\n将运维问题视为软件工程问题，当事情出错时（而且确实会出错），要寻找的是系统中导致问题的缺陷。你要改进系统，以帮助避免人为错误。\n人类永远不是事故的原因，而是“允许”事故发生的系统和流程。\n如果发生了中断，那是系统的错误，而不是人类的错误，因为人为错误是不可避免的。目标不是消除人为错误。【译者注：带有缺陷的系统导致了人为错误，或者人类遭遇到了事故；这里我们要把人的原因摘除的干干净净，这一点需要依靠大家构建心理安全的企业团队文化。】\n实施事故管理实践时的心理安全 实施事故管理实践是一项组织变革，需要一些文化前提条件才能让团队从错误中创新和学习。拥有心理安全和无责流程是至关重要的。(Psychological Safety When Implementing Incident Management Practices)\n心理安全是一种信念，即谁不会因为提出想法、问题、质疑、担忧，或遭遇到了错误而受到惩罚或羞辱。 ——艾米·埃德蒙森，哈佛商学院诺华教授，领导力与管理学博士\n心理安全促进了绩效导向型组织的一些主要特征，特别是将失败视为学习机会和接受新想法。例如，Westrum 的组织文化模型预测了基于心理安全的软件交付绩效：生机型组织比其他两种类型更有可能成为顶级绩效者。1\n具有较高心理安全的团队更能利用成员多样化的想法，销售目标超额完成17%（相比之下，不安全的团队错失目标19%），并且被高管评为有效的概率是其两倍。2\n处理事故时的心理安全 在风险管理中，每个人都知道自己可以表达意见和识别问题，而不会受到惩罚或嘲笑，这是至关重要的。当发生事故时，必须报告并宣告为事故【译者注：声明发生了事故，开始进入事故应急管理流程】。在事故期间，可能需要分享以前事故的信息，如果这样做可以揭示过去的错误（这与无责原则有关）。你还可能需要将事故移交给下一位值班工程师，并提出改进内部流程、工具和功能的建议。\n没有心理安全和无责原则，人们会避免提出可能揭示事故根本原因的正确问题。因此，团队无法学习或创新，因为他们忙于管理形象，并且害怕承担个人后果。\n为了在团队中培养心理安全和无责原则，关注学习机会：将每次事故视为学习机会，鼓励多样化的观点，邀请每个人（尤其是那些发表不同意的人）表达意见和想法。作为领导者，你还应该承认自己的不足【译者注：没有人是全知全能和权威的，大家都要从发问，和假设开始分析故障】，通过提问来展示好奇心。\n不归咎于个人\n无责原则和心理安全是相辅相成的，一个可能自然导致另一个。假设发生了一次中断。如果经理问的第一个问题是“是谁造成的？”，这会造成一种互相指责的文化，使团队害怕冒险，从而阻碍创新和改进。相反，你应该提倡无责原则：\n无责原则是将责任从个人转移到系统和流程上。3\n指责文化会妨碍人们迅速解决事故和从错误中学习的能力，因为他们可能会隐藏信息，避免因害怕受罚而宣告事故。而无责文化允许你专注于改进。你要假设个人是出于善意行事，并根据现有的最佳信息做出决策。调查误导性信息的来源对组织比归咎于人更有益。因此，支持团队的设计和维护决策，鼓励创新和学习，当事情出错时，关注系统和流程，而不是个人。\n从错误中学习\n错误是宝贵的学习和改进机会，但前提是正确识别错误的程序性和系统性原因。例如，在谷歌，Ben Treynor Sloss 发送季度工程报告《谷歌的成与败》，以培养一种能够从错误中学习的赋权文化。4\n促进心理安全环境的其他提示 事故响应者需要一定的信心才能有效应对事故。尽管他们可能处于压力大的情况下，但在处理事故时，响应者必须感到心理安全。\n这种心理安全涉及多个层面：\n来自队友\n响应者不应该担心他们的行为会被同伴评判，尤其是在犯错误时。 说“我需要帮助”应该得到奖励，而不是质疑或责备。 来自合作团队\n有些团队可能会觉得 X 团队的成员有居高临下的坏名声，因此不愿与他们交流。更糟糕的是，有些团队接受这种文化，或者利用它来避免与其他团队互动。5这种态度不应被容忍——它会增加紧张情绪，并延缓事故响应。 来自管理层 (From management)\n经理负责团队的心理安全。在事故期间，经理通常不做技术工作，而是专注于确保团队的福祉——观察压力和倦怠的迹象，也许在团队处理事故时订购披萨。有时经理可能只是简单地对事故响应者说，“休息五分钟，清理一下头脑。” 经理也可以在获取组织其他部分的额外帮助方面发挥重要作用。 经理为团队提供与组织其他部分之间的缓冲，并在发生冲突时介入解决。 来自组织 (From the organization)\n心理安全只有在组织文化中得到认可时才能蓬勃发展。应该有一种无责文化，重点是修复导致事故的流程。 业界有诸如“三振出局”政策，这种政策要求对涉及三次影响生产的错误的个人进行解雇或严厉的训诫。虽然这种政策旨在鼓励响应者在事故期间格外小心，但它往往导致响应质量降低（“我不想成为那个做出错误决定的人”）、推卸责任（“我们没有弄坏它，是另一个团队弄坏的”）或隐藏有价值的信息（“不要透露我们已经知道这个问题的事实”）。 如果领导者希望他们的团队——以及整个组织——蓬勃发展，他们必须培养一种尊重、信任和协作的文化。这必须从组织的高层开始。 如前所述，心理安全环境的一个明显好处是缩短了升级时间。如果一个组织接受协作文化，事故响应者更有可能寻求额外的帮助，无论是来自自己的团队还是公司中的其他团队。\n在审查事故时，一个反复出现的主题总是“如果我们早些升级，就可以节省 $XXX 的收入损失”，即使是在拥有健康、心理安全环境的团队/组织中。对于事故响应者来说，请求帮助很难，因为这可能被视为软弱或准备不足的表现。我们被训练去隐藏不安全感（即使是感知到的不安全感），并且通常被教导要成为英雄，全力以赴为团队贡献。这些行为在事故响应中实际上是负担，一个不堪重负或疲惫的响应者更容易犯错。因此，升级应该是廉价且快速的，不应有任何附加条件。始终假设最好的意图。如果事实证明升级是不必要的，找出为什么会发生升级，可能是因为文档不完整或缺失，并修复有缺陷的流程。\n事故响应者应该高度警惕尝试独自完成所有工作的倾向，而是应该尽早且频繁地升级。在谷歌的一个事故响应团队中，有一句格言：“我们告诉其他团队，我们不介意被频繁呼叫，但我们仍然没有被足够频繁地呼叫。”\n撰写事后复盘分析 现在我们已经深入讨论了心理安全，让我们转向撰写事后复盘分析。当事情出错时，这是你从中学习并改进未来的机会。虽然“糟糕的工程师”可能会想“希望没人看到”，但优秀的工程师会注意到问题并想“太好了！告诉大家！”这就是撰写事后复盘分析的意义所在。\n撰写事后复盘分析是一种系统分析形式：它是深入研究导致事故的故障，并识别改进工程和工程流程的过程。撰写事后复盘分析不仅仅是一种额外的实践，而是一种在服务中实践系统工程的核心方式，以推动改进。\n在撰写事后复盘分析时，创建一个无责文化和假设事故会发生的流程是很重要的。如前所述，防止失败很重要，但要意识到日常失败是不可避免的，特别是在大规模系统中。事故为你和你的团队提供了共同学习的机会。事后复盘分析是你们集体从错误中学习的系统解决方案，并帮助分享这些知识，以及从他人的错误中学习——例如，通过阅读他人的事后复盘分析。\n事后复盘分析提供了一种正式的从事故中学习的过程，以及一种防止和减少事故、其影响和复杂性的机制。例如，你可能会学到避免使用补丁作为永久解决方案。事后复盘分析突出趋势并优先考虑你的努力。它们应该是无责的——这可以防止关于问题、谁做了什么以及谁可能有错的侧面讨论。事后复盘分析不是为了归咎于谁，而是专注于从事故中学到了什么以及未来的改进。\n每个事后复盘分析都应该包括一些信息。例如，好的事后复盘分析包括明确的行动项（AI action item），以及这些行动项的负责人和截止日期。记住，这不是为了归咎，而是为了增加责任感，消除模糊性，并确保行动得到跟进。此外，重要的是要有一个清晰的时间线，包括中断开始时间、问题检测时间、升级时间（如果适用）、缓解时间（如果适用）、影响和中断结束时间。如果发生了升级，说明为什么以及如何发生的。为了避免混淆，澄清事故和中断的术语，以及事故开始和事故检测的术语。我们建议在事故发生期间保持一个“实时文档”，作为调试和缓解的工作记录，稍后可以用于事后复盘分析。该文档有助于正确记录时间线，并确保不会遗漏重要的行动项。\n在事后复盘分析中避免责备性语言，并实践心理安全。以身作则，问很多问题，但绝不要寻求归咎于谁。这是关于理解事件的现实、采取的行动以及未来如何防止重发。\n谷歌的最佳实践是将事后复盘分析分享给可能受益于所传授教训的最大范围受众。透明的分享使他人能够找到事后复盘分析并从中学习。6\n我们发现，建立一种无责的事后复盘分析文化会带来更可靠的系统，并且对于创建和维护一个成功的 SRE 组织至关重要。\n用于组织改进的系统分析 我们已经讨论了无责的事后复盘分析，并提到事后复盘分析是一种系统分析形式。然而，你是否真正深入了解你的系统，充分理解发生了什么以及为什么？事件应该被分析以得出结论，而不仅仅是叙述。事故之后或在事后复盘分析中，分析的深度在于是否对事件和系统各方面进行了深入分析，以揭示和解释结论。这很重要，因为它增加了团队在事故之后解决正确问题的概率。\n在撰写事后复盘分析时，你应该力求对系统有最完整和准确的了解，以确保所做的修复是正确的。在图 5-2 中，标有“你认为的问题是什么”的圆圈反映了你在事故期间对系统的理解——这是你能控制的部分。标有“实际问题是什么”的圆圈反映了事故期间系统的实际状态。在复杂技术生态系统中，理解所有细微差别是极其困难的（实际上，我们曾有一位高级工程师花了整整一个月时间来理解一个20分钟的事故！）。然而，事故之后的分析越深入，圆圈的重叠部分越大，你越接近理解根本问题（图 5-3）。\n即使事故已经缓解，系统再次稳定，理解真正的问题仍然重要。这涉及可操作性——即你在事故之后有能力修复或更改的内容。事故后的系统增量改进有助于随着时间的推移建立恢复力。这是第三个重要的圆圈，代表你可以控制并可以实施修复的系统中的事物（图 5-4）。这个圆圈无法移动，因为总有一些你无法控制的事情会影响系统的健康（例如天气、地球的大小、光速）。\n在中心的那个小交集（在集合理论中表示为 1 ∩ 2 ∩ 3）是你团队在事故之后可以做的最好的工作。“你认为的问题是什么”和“你能修复什么”的重叠部分 [(1 ∩ 3) – 2] 是危险的：这些是你认为在长期内会有帮助但实际上不会解决真正问题的解决方案。你可能正在解决与主要问题相关的某些事物，或者你可能正在处理另一个隐藏问题的表现症状。假设你已经解决了一个实际上没有解决的问题是一个危险的境地——因为缺乏对这一风险的认识，这种情况变得更加严重。如果特定事故再次发生，你将面临客户信任的降低和本可以更有效利用的时间的浪费。\n通过更深入的系统分析，中心的那个小片段（1 ∩ 2 ∩ 3）在两个不动的圆圈中被最大化（图 5-5）。换句话说，你正在最大化你优先考虑的修复措施的有效性。如果你想确保你正在针对正确的问题，移动圆圈是值得的。关键是要在系统分析上投入足够多的时间，以便你和你的团队能够以高概率选择最适合的工程项目来提高系统的恢复力。但要注意收益递减——例如，花一个月时间调查每一次中断并不是明智的资源使用。在以下部分中，我们提出了一些关键点，可能有助于思考如何移动圆圈。\n根本原因与触发因素 让我们从两个关键术语开始：根本原因和触发因素。\n根本原因 (Root cause)\n系统中的潜在危险，或者系统为什么变得脆弱。危险可能在系统中存在无限期——系统环境需要某种变化，才能将这种危险转化为中断。明确一点：在复杂系统中，事故很少只有一个根本原因。熟练的从业者认为，事故的根本原因是相互作用的一系列因果因素，导致危险状态。\n触发因素 (Trigger)\n使根本原因转变为事故的情况。这是相关但独立的概念！为了防止中断再次发生，有时重要的是解决根本原因。有时更合理的做法是围绕这些触发因素建立预防措施。\n根本原因和触发因素共同作用造成了事故。当然，这是一种简化的说法。借用医学术语，根本原因与触发条件相互作用，产生了结果情景（即事故）。在复杂系统中，根本原因和触发因素与事故类型之间并不存在一一对应的关系，复杂性使得各种结果都有可能发生。让我们来看一些例子：\n房屋火灾\n根本原因：煤气泄漏 触发因素：靠近漏气炉子的电插头产生火花，引燃了泄漏的煤气并引发了房屋火灾 事故：房屋火灾（但这个根本原因可能导致其他事故） 蚂蚁入侵\n根本原因：温暖的季节适合虫子和害虫在自然环境中繁衍生息 触发因素：随意吃东西，留下大量的碎屑 事故：蚂蚁入侵 内存不足 (OOM)\n根本原因：配置文件更改引入了内存泄漏 触发因素：出人意料的大量请求 事故：OOM 在第三个 (OOM) 场景中，根本原因可能在触发条件存在之前的几年就已经存在了——这是技术债务最终比预期更昂贵的一种方式。而这个根本原因甚至可能不是一个错误，它可以是对系统行为的任何约束。约束本身并不是危险的，直到系统面临某种环境条件，将其转变为危险。需要澄清的是，触发因素可能不是二元的。触发条件可能存在于动态范围内，只有当系统的环境条件和根本原因相互作用时才会成为事故。这两者可以看作是创建事故生命周期的关键组成部分。\n事后复盘分析中的根本原因部分应详细说明事故的根本原因和触发因素。为了防止中断再次发生，有时重要的是解决根本原因，有时更合理的是围绕触发因素建立预防措施。\n然而，仅仅将根本原因和触发因素分开讨论并不会提高团队事后复盘分析的质量。所有部分都有适当的内容是最低要求，但事后复盘分析还应包括深入的分析，便于团队外的工程师理解，并且是可操作的。这是一个经常出现的问题吗？是否记录了缓解步骤，或者需要查找错误？事后复盘分析是否适当地解释或量化了系统的正常运行情况，以显示故障的对比和影响？如果你说产品 89% 的用户受到了影响，这具体意味着什么？\n孤立的系统与整体堆栈 事故影响的系统不太可能在真空中存在（除非你来自 Hoover、Dyson 或 Roomba）。不幸的是，一个常见的反模式是将系统分析的范围限制在看似损坏的部分，而不考虑系统上下文（系统功能相关的环境部分）。以下是一些可以扩展系统分析深度的思考点：\n（如果适用）这个事故是作为单一事件进行审查，还是讨论了相关的/关联的/子事件？ 你或任何主要的内部客户是否发现了以前未知的依赖关系？ 端到端通信的效果如何？ 虽然事故可能只发生在整体堆栈的一个子部分，但这并不意味着你的事故是孤立发生的。查看事故是否以及如何影响整体堆栈和公司的成员，可以揭示系统故障的见解。这可能包括你的事故是否引发了其他事故或级联故障，或者你的公司在事故期间是否能够有效沟通。\n时间点与发展轨迹 在研究中，元分析技术是将多个研究汇总成更大的整体结论。如果你将每个事后复盘分析视为一个展示系统在某个时间点状态的研究，那么将这些分析综合起来可以帮助识别新兴的模式和见解。我们建议利用每个事后复盘分析作为检查系统随时间变化的机会。考虑以下几点：\n这个事故是否从系统的长期轨迹进行审查？ 是否存在相同类型的故障重复出现？ 是否存在任何长期的强化或平衡循环？ 整体系统思维的一部分是考虑系统随时间的变化。一般来说，避免同样的事故发生两次是件好事。\n我们已经探讨了系统分析在组织改进中的应用及其对你和你的团队的好处。现在让我们来看一个实际的例子。\n来源： https://sre.google ；本白皮书一共有 7 章，后续章节将陆续发布。完整中文版白皮书即将发布，敬请期待。\n❤️ Photo by Pixabay: https://www.pexels.com/photo/photo-of-a-2-fireman-killing-a-huge-fire-69934/\n参见《DevOps 文化：Westrum 组织文化》。https://cloud.google.com/architecture/devops?hl=zh-cn\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n谷歌的 Project Aristotle 项目。https://rework.withgoogle.com/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见 Coursera 的“Developing a Google SRE Culture”课程。 https://www.coursera.org/learn/developing-a-google-sre-culture\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n要了解更多关于从错误中学习的信息，请参见《Site Reliability Engineering》第 15 章，“Postmortem Culture: Learning from Failure”。https://sre.google/sre-book/postmortem-culture/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n同上，参见《Site Reliability Engineering》第 15 章，“Postmortem Culture: Learning from Failure”。https://sre.google/sre-book/postmortem-culture/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n欲了解更多信息，请参见《Site Reliability Engineering》附录 D，“Example Postmortem” https://sre.google/sre-book/example-postmortem/，以及关于 Google Compute Engine 事故的公开通信。https://status.cloud.google.com/incident/compute/16007\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-06-30T22:46:48+08:00","image":"https://martinliu.cn/blog/anatomy-of-an-incident-ch5/pexels-pixabay-69934_hu_3062f0a938b61074.png","permalink":"https://martinliu.cn/blog/anatomy-of-an-incident-ch5/","title":"Google 白皮书 《事故管理剖析》第五章 事后复盘分析及其应用"},{"content":" 下载中文版 PDF 文件 下载英文版 PDF 文件 从 Google 下载白皮书 我们已经讨论了如何扩展事故管理，使用组件响应者和 SoS 系统级响应者来帮助公司扩展时管理事故。我们还介绍了成功的事故响应组织的特征，并讨论了管理风险和防止值守人员倦怠。现在，我们来谈谈事故发生后的恢复工作。我们将从紧急缓解措施开始。\n紧急缓解措施 之前我们提到在服务事故期间“止血”。恢复工作中包括必要的紧急缓解措施(Urgent Mitigations)1，以避免影响或防止影响加剧。现在我们来谈谈这意味着什么，以及如何在紧急情况下，更容易的实施缓解措施。\n假设你的服务遇到了一个严重的问题。中断已经开始，并已经被检测到了，用户正在受到着影响，而你负责解决这个问题。你的首要任务应该是：立即停止或减轻对用户的影响，而不是立即找出问题的原因。想象一下，你在家里，屋顶开始漏水。你首先会放一个桶在漏水处，以防止进一步受到水的损害，然后再去拿出需要的工具，去修补屋顶（稍后我们会发现，如果屋顶问题是根本原因，雨水就是触发因素）。桶的作用是减小影响，直到修复好屋顶。为了在服务中断期间减轻对用户影响，你需要准备好一些应急措施。我们称这些应急措施为通用缓解措施。\n通用缓解措施是指在你找出具体问题之前，可以采取的减小各种中断影响的行动。\n适用于你服务的缓解措施可能会有所不同，取决于用户受影响的方式。基本的措施包括：回滚代码、重新分配流量，以及增加服务器容量。这些临时措施旨在：为你和你的服务争取更多时间，以便找到彻底解决问题的方法。换句话说，它们修复的是中断的症状，而不是根本原因。你不需要等到完全的理解了中断的原因，就可以使用通用缓解措施。\n考虑进行研究并投资开发一些快速“一键修复”（即比喻中的桶）。记住，尽管桶是一个简单的工具，但它仍然可能被误用。因此，为了正确使用通用缓解措施，重要的是要在定期的恢复力测试中进行演练。\n减小事故的影响 除了用于应对紧急情况或事故的通用缓解措施外，还需要考虑从长远角度减小事故的影响 (Reducing the Impact of Incidents)。事故是一个内部术语。实际上，客户并不真正关心事故或事故的数量，他们关心的是可靠性。为了满足用户的期望，并实现用户所需的可靠性水平，需要设计和运行可靠的系统。\n想要实现这一点，需要在事故管理生命周期的每个阶段中协调的行动：准备、响应和恢复。考虑在事故发生前、发生期间，和发生后可以做些什么，从而改进系统。\n虽然很难直接衡量客户信任，但可以使用一些代理指标来评估提供可靠客户体验的效果。我们称客户体验的度量为服务质量指标 (SLI)。SLI 告诉你在任何时刻服务的表现如何，是否达到预期。\n在这个范围内，客户可以是终端用户、人类或系统（如 API），或另一个内部服务。内部服务类似于为其他内部服务提供核心功能，而这些服务最终面向终端用户。你需要确保关键依赖项的可靠性（即硬性依赖或不可缓解的依赖——如果它失败，你也会失败）。这意味着如果面向客户的服务依赖于内部服务，这些服务需要提供更高水平的可靠性。\nSLI 的可靠性目标称为服务质量目标 (SLO)。SLO 将目标汇总到一段时间内：它表示在某个管理时间窗口中，这是你要去实现的目标，体现了你的管理水平如何（通常以百分比衡量）。2\n可能大多数人都熟悉服务质量协议 (SLA)。SLA 定义了你向客户承诺的服务内容；即如果未能达到目标，你愿意采取的措施（如退款）。为了实现这一点，需要使 SLO（你的目标）设定的比 SLA 要更严格一些。3\n我们用来检查和衡量用户满意度的工具称为用户旅程。用户旅程是以文本形式编写的陈述，用来描述用户的视角。用户旅程探讨了：用户如何与服务互动的过程，以实现自己想要的目标。那些最重要的用户旅程被称为关键用户旅程 (CUJ)。4\n一旦定义了对你和用户或客户重要的目标，就可以开始考虑：当未能达到这些目标的时候，都会发生什么。\n计算事故的影响 事故会影响可靠性目标，影响的大小：取决于故障的数量、持续时间、影响范围和规模。因此，想要减小事故的影响，首先需要了解可以采取哪些措施。让我们先看看应该如何量化和衡量事故的影响。\n图 4-1 显示了衡量影响的方法：计算不可靠的时间，包括检测到问题的时间和修复（缓解）问题的时间，然后将其乘以事故的次数，即事故的频率。\n关键指标是检测时间、修复时间和故障间隔时间：\n检测时间（TTD）是从中断发生到某个人被通知或告警的时间。 修复时间（TTR）是从某人被告警到问题缓解的时间。关键是缓解！这指的是响应者采取措施减轻客户影响的时间，例如通过将流量转移到其他区域。 故障间隔时间（TBF）是从一次事故开始到，同类型事故下一开始的时间。 想要减小事故的影响，并使系统恢复到已知正常的状态，需要技术和“人”的因素的结合，例如：流程和支持。在谷歌，我们发现一旦涉及人为干预，中断至少会持续 20 到 30 分钟。通常，自动化和自愈系统是很好的策略，因为它们会有助于缩短检测时间和修复时间。\n需要注意的是，使用的方法也很重要。简单地降低告警阈值可能导致误报和噪音，过度依赖自动化快速修复可能减少修复时间，但会忽略根本问题。在下一节中，我们将分享几种策略，这些策略可以更有效地减少检测时间、修复时间和事故频率。\n缩短检测时间 减小事故影响的一种方法是缩短检测事故的时间(Reducing the Time to Detect)（图 4-2）。在起草 SLO（可靠性目标）时，需要我们进行前置的风险分析，并确定出那些优先的待办事项，识别可能阻止实现 SLO 的因素，这也有助于缩短检测到事故的时间。此外，你可以采取以下措施来最小化检测时间：\n将 SLI（客户满意度指标）尽可能与用户的期望对齐【译者注：考虑用户体验的好坏，以及关键用户旅程的可用性】，这些用户可以是实际用户或其他服务。将告警与 SLO（你的目标）对齐，并定期回顾评审，确保它们仍然能代表用户的满意度。 使用最新的信号数据。选择最佳的数据获取方式：流、日志或批处理。在这方面，在告警速度与噪音数之间找到合适的平衡度也很重要【译者注：SLI 告警的灵敏度高情况下，考虑到所选择 SLI 信号数据源的质量，如果假性告警越少，则噪音数量越低。】。噪音告警是 Ops 团队（无论是传统的 DevOps 团队还是 SREs）最常见的一个抱怨。 使用有效的告警以避免告警疲劳。在需要立即采取行动时使用呼叫【译者注：短信、电话外呼等任何快速触达的通知方式】。只有正确的响应者——特定团队和所有者——才应该收到告警。另一个常见的投诉是收到不可操作的告警【译者注：与事故无关的人员也经常会在半夜被值守的人喊醒，冤】。 随之而来的问题是：“如果只对需要立即采取行动的事情进行呼叫，那其余的问题如何处理？”一个解决方案是：为不同情况使用不同的工具和平台。可能“正确的平台”是，一个工单系统或仪表板，或者仅需要根据该指标，用拉取的处理模式，进行相应的故障排除和调试。\n缩短修复时间 我们已经讨论了：用缩短检测时间作为减小事故影响的一种方法。另一种方法是：缩短修复时间(Reducing the Time to Repair)（图 4-3）。缩短修复时间主要涉及“人”的方面。使用事故管理协议和组织事故管理响应可以减少事故管理的模糊性，缩短对用户影响的时间。除此之外，你还需要培训响应者，制定明确的程序和手册，并降低值守的压力。让我们详细探讨这些策略。\n培训响应者\n未准备好的值守人员会导致更长的修复时间。考虑对值守人员进行灾难恢复测试培训，或者进行我们之前提到的“厄运之轮”演习。另一种方法是通过导师指导进行值守准备。让值守人员成对工作（“配对值守 pair on call”），或者让新人在他们的轮班期间与有经验的值守人员一起工作（“跟班 shadowing”），有助于增强新队员的信心。记住，值守可能是有压力的。制定明确的事故管理流程可以减少这种压力，因为它消除了任何模糊性，并明确了所需的行动。5\n建立有组织的事故响应程序\n事故管理中存在一些常见问题。例如，缺乏责任感、沟通不畅、缺乏层次结构和自由发挥/英雄主义，可能导致更长的解决时间，也会增加值守人员和响应者的额外压力，并最终影响到客户。为了解决这个问题，我们建议通过建立一个层次结构明确的结构、任务和沟通渠道来组织响应。这有助于保持清晰的指挥链，并指定明确的角色。\n在谷歌，我们使用 IMAG（谷歌事故管理），这是一个基于消防员和医护人员使用的事故指挥系统（ICS）的灵活框架。IMAG 教你如何通过建立层次结构明确的结构、任务和沟通渠道来组织紧急响应。它建立了一种标准、一致的方式来处理紧急情况和组织有效的响应。6\nIMAG 协议为解决事故的人提供了一个框架，使紧急响应团队能够自我组织和高效工作，通过确保响应者和相关利益相关者之间的沟通，控制事故响应，并帮助协调响应工作。它规定事故指挥官（IC）负责协调响应并分配职责，而其他人向 IC 报告。每个人都有一个具体的、明确的角色——例如，操作负责人负责解决问题，沟通负责人负责处理沟通。\n通过使用这样的协议，你可以减少模糊性，明确团队合作，并减少修复时间。7\n建立明确的值守政策和流程\n我们建议记录你的事故响应和值守政策，以及在中断期间和之后的应急响应流程。这包括明确的升级路径和责任分配，以减少处理中断时的模糊性和压力。\n编写有用的运行手册/操作手册\n文档很重要，它将工作经验转化为所有队员都能访问的知识，无论工作年限。通过优先记录和安排时间编写文档，并创建记录程序的操作手册和政策，队员们可以更容易识别事故的表现形式——这是一项宝贵的优势。操作手册一开始不必完备；从简单的开始，提供一个明确的起点，然后逐步改进。一个好的经验法则是谷歌的“看到问题，立即解决 see it fix it”的方法，并让新队员在入职时就来更新这些操作手册。\n将编写操作手册作为事后复盘分析的重要行动项目之一，并将其视为个人对团队的积极贡献，这通常需要领导的优先支持和资源分配。\n减轻响应者的疲劳\n如第二章所述，响应者疲劳的心理成本是有据可查的。如果响应者疲惫，他们的解决问题能力会受到影响。确保班次平衡，如果不平衡，使用数据来找出原因，并减少琐事。8\n投资于数据收集和可观测性\n做出基于数据的决策很重要，缺乏监控或可观测性是一种反模式。如果你无法看清路况，你就不知道前进方向。因此，鼓励组织内的度量文化，收集贴近客户体验的指标，并衡量你在目标和错误预算消耗率方面的表现，以便及时反应和调整优先级。还要衡量团队的琐事工作量，并定期审查你的 SLI 和 SLO。\n尽可能收集高质量的数据，特别是更贴近客户体验的数据；这有助于排除故障和调试问题。收集应用程序和业务指标，以便拥有关注客户体验和关键用户旅程的仪表板和可视化。这意味着为特定受众和目标设计的仪表板。管理者对 SLO 的视角，将与用于在排查事故和故障过程中使用的仪表板非常不同。\n如你所见，有许多方法可以缩短修复时间，并最大限度地减小事故的影响。现在让我们看看延长故障间隔时间来减少事故影响的另一种方法。\n延长故障间隔时间 为了延长故障间隔时间并减少故障次数，可以重构架构，并解决在风险分析和流程改进中识别出的故障点（图 4-5）。此外，还有一些措施可以帮助延长 TBF（故障间隔时间）。\n避免反模式\n我们在本报告中提到了几种反模式，包括缺乏可观测性，缺乏正反馈回路，这会导致系统发生过载，并引发级联问题，如崩溃。这些反模式需要避免。\n分散风险\n通过冗余、解耦责任、避免单点故障，和用全局优化来分散风险，并采用高级部署策略。考虑渐进式的滚动和金丝雀发布，将更新工作分布在数小时、数天或数周内，这样可以在所有用户受到影响之前，减少风险并识别问题。同样，进行自动化测试、滚动发布和自动回滚，以便及早发现任何问题。主动发现问题，总要比让问题来骚扰你会更好；那就要通过实践混沌工程和引入故障注入，以及自动化灾难恢复测试（如 DiRT，见第二章）来实现这一点。\n采用开发实践\n采用促进质量文化的开发实践，并创建集成代码审查和健壮测试的过程，这些过程可以集成到持续集成/持续交付（CI/CD）流水线中。CI/CD 可以节省工程时间，并减小对客户的影响，使你能够自信地部署。\n以可靠性为设计原则\n在 SRE 中，我们有一句话：“碰运气不是一种策略。” 当谈到故障时，问题并不是会不会发生，而是什么时候发生。因此，从一开始就以遵循：可靠性为设计原则，构建能够应对故障的健壮架构。通过以下问题来了解你如何应对故障：\n我的系统能够应对哪种类型的故障？ 它能容忍意外的单实例故障或重启吗？ 它如何应对区域性AZ或地区性Region故障？ 意识到风险及其潜在影响范围后，进入风险缓解阶段（如在风险分析中所做的那样）。例如，为了缓解单实例问题，使用持久磁盘和配置自动化，并且备份数据。为了缓解区域和地区故障，可以在各个地区和区域分配资源并实施负载均衡。还可以进行横向扩展。例如，将单体架构解耦为微服务，更容易独立扩展它们（“做好一件事”）。横向扩展还可以意味着地理上（Region）的扩展，例如拥有多个数据中心以利用弹性。我们建议尽可能避免手工配置和特殊硬件。\n优雅降级\n在你的架构中实现优雅降级(Graceful degradation)方法非常重要。将降级视为一种策略，例如限流和负载分流。问自己，如果不能为所有用户提供所有功能，我能否可以最小功能为所有用户服务？能否限流用户流量并丢弃高成本的请求？当然，什么是可接受的降级程度，要依赖于服务和用户旅程。返回 x 个产品和返回未更新的账户余额之间存在差异。但作为经验法则，能提供降级的服务，总比停止服务的好。9\n深度防御\n深度防御(Defense-in-depth)是构建系统以应对故障的一种方式，更准确地说，是容忍故障。如果依赖某个系统获取配置或其他运行时信息，确保有一个备用或缓存版本，当依赖项不可用时，而它们仍能继续工作。10\nN+2 资源\n在分布式系统中，拥有 N+2 资源是实现可靠性的基本原则。N+2 意味着：你有 N 的容量来处理高峰期的请求，并有另外 2 的实例，其中一个可用于应对意外故障，另一个可用于计划升级。如前所述，你的可靠性取决于关键依赖项的可靠性，因此在架构中选择正确的构建块（Building block）。在云平台上构建时，确保使用服务的可靠性水平，并将它们与你的应用目标相关联。注意它们的范围（例如，在 Google Cloud Platform 中，范围可以是区域性的、区域间的或全球的[zonal, regional, global]）。记住，在设计时就主动解决可靠性问题，可以降低后期的成本。11 并不存在一刀切的解决方案，应让需求指导你来做出因地制宜的设计决策。\n非抽象大型系统设计 (NALSD)\n在讨论可靠性和 SRE 的设计时，我们不能不提到非抽象的大型系统设计。在谷歌，我们发现，在设计阶段解决可靠性问题可以降低未来的成本。如果采用迭代式系统设计和实施风格，可以用更低的成本，开发出健壮且可扩展的系统。我们称这种方法为非抽象大型系统设计 (NALSD)，它描述了谷歌用于生产系统的迭代式设计过程。你可以在谷歌的 SRE 课堂栏目中了解更多相关内容。\n从失败中学习\n最后，你可以从失败中学习，使未来更好（更多内容请参见第40页的“心理安全”）。如前所述，事后分析是实现这一目标的工具。确保你有一致的事后分复盘析流程，能够产出错误修复（bug fix）、缓解措施和文档更新的后续跟踪落地行动项。像跟踪其他错误（bug）一样跟踪事后 复盘分析的行动项（如果还没有这样做），并应该优先考虑事后复盘分析工作，而不是“常规日常”的工作。12 我们将在下一节中更详细地讨论事后复盘分析。\n来源： https://sre.google ；本白皮书一共有 7 章，后续章节将陆续发布。完整中文版白皮书即将发布，敬请期待。\n❤️ Photo by Pixabay: https://www.pexels.com/photo/photo-of-a-2-fireman-killing-a-huge-fire-69934/\n推荐阅读：Jennifer Mace 的《通用缓解措施》https://www.oreilly.com/content/generic-mitigations/。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见《SRE Google 运维解密》（O\u0026rsquo;Reilly）中的第 4 章，“服务质量目标 (SLOs)”。https://sre.google/sre-book/service-level-objectives/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见 Adrian Hilton 2021 年 5 月 7 日的文章《SRE 基础 2021：SLIs vs SLAs vs SLOs》。https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-sli-vs-slo-vs-sla\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见《Google SRE 工作手册》（O\u0026rsquo;Reilly）中的第 2 章，“实施 SLOs”。https://sre.google/workbook/implementing-slos/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见 Jesus Climent 2019 年 12 月 5 日的文章《缩短生产事故缓解时间—CRE 生活教训》。https://cloud.google.com/blog/products/management-tools/shrinking-the-time-to-mitigate-production-incidents\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见《Google SRE 工作手册》中的第 9 章，“事故响应”。https://sre.google/workbook/incident-response/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见《SRE Google 运维解密》中的第 14 章，“管理事故”。https://sre.google/sre-book/managing-incidents/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见 Eric Harvieux 2020 年 1 月 31 日的文章《使用 SRE 原则识别和跟踪琐事》。https://cloud.google.com/blog/products/management-tools/identifying-and-tracking-toil-using-sre-principles\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n关于负载分流和优雅降级的更多内容，参见《SRE Google 运维解密》中的第 22 章，“解决级联故障”。https://sre.google/sre-book/addressing-cascading-failures/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见 Ines Envid 和 Emil Kiner 在 Google 博客上的文章《深入了解 Google Cloud 网络：确保环境安全的三项深度防御原则》，2019 年 6 月 20 日。https://cloud.google.com/blog/products/networking/google-cloud-networking-in-depth-three-defense-in-depth-principles-for-securing-your-environment\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见《Google SRE 工作手册》中的第 12 章，“引入非抽象大型系统设计 (NALSD)”。https://sre.google/workbook/non-abstract-design/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n参见 Google Research 的 Betsy Beyer、John Lunney 和 Sue Lueder 的文章《事后分析行动项：计划工作并完成计划》。https://research.google/pubs/postmortem-action-items-plan-the-work-and-work-the-plan/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-06-28T22:46:48+08:00","image":"https://martinliu.cn/blog/anatomy-of-an-incident-ch4/pexels-pixabay-69934_hu_d1dec3d8e7646af7.png","permalink":"https://martinliu.cn/blog/anatomy-of-an-incident-ch4/","title":"Google SRE 白皮书： 《事故管理剖析》第四章 缓解和恢复"},{"content":" 下载中文版 PDF 文件 下载英文版 PDF 文件 从 Google 下载白皮书 我们已经讨论了通过事故响应演习、角色扮演和定期测试来练习事故响应准备。这些策略能帮助你在真实事故发生时做好准备并开始管理（见第31页“建立有组织的事故响应程序”）。但是，当你的组织开始扩展时【译者注：扩展是指将事故管理的流程在更大范围的业务系统上逐步应用推广的过程。】，如何管理事故呢？在本节中，我们讨论如何在大量的系统之上扩展事故管理（流程/实践）。\n在 Google，我们为所有系统提供了最佳的事故管理覆盖。Google 规模庞大，每年处理超过 2 万亿次搜索，需要大量的数据中心、至少一百万台计算机和超过 80000 名员工。所有这些活动都通过一个庞大且高度互联的系统系（ system-to-system 简称 SoS）进行，依赖其技术堆栈保持生产运行。支持这个技术堆栈意味着适当的人员随时待命，以便在问题出现时进行故障排除和修复。这些人员是我们站点可靠性工程团队中的响应人员，他们为系统提供事故管理覆盖，并在事故发生时进行响应。\n组件响应者 在站点可靠性工程团队中，我们还拥有组件响应者，他们负责 Google 技术基础设施中某个组件或系统的响应（图 3-1）。\n组件响应者是某个单一系统的专家，精通该问题领域，是优秀的故障排除专家，并在危机期间实践缓解策略。他们可以持续访问执行紧急响应所需的工具和系统，能够很好地应对压力，并在危机期间保持清晰的思路。\n单个组件响应者的责任范围有限，这使他们能够深入了解其领域及相关系统。这些响应者是防止故障从一个组件蔓延到整个堆栈的第一道防线。这些单独的组件比整体的系统体系级 SoS 堆栈要小，正如我们将在下面描述的“系统体系（SoS）响应者”一节中讨论的那样，通常具有明确且独立的系统边界。因此，可以设置合理的监控和告警机制，使组件响应者始终了解其系统的故障模式。\n当技术堆栈的范围超出一个人可理解和维护的能力时，我们将技术堆栈拆分，以便多个响应者可以分别对整个堆栈的单个组件提供覆盖。随着时间的推移，这些组件变得更加复杂，并进一步分解。通过保持有限的范围，主要响应者可以在任何给定时间解决小范围内的问题。然而，也存在风险，即忽视了跨多个组件的生产故障，或者如果问题超出其专业范围，则无法为组件响应者提供足够的支持。\n例如，假设一个底层故障在技术堆栈的显著部分发生级联效应。这种级联效应的速度超过了人类自我组织的速度。在一次影响范围广泛的事故中，我们很快就会达到每个组件团队都被呼叫、分配了响应人员并管理自己的状态。这些组件团队并行工作，但这些响应人员可能彼此并不知情（图 3-2）。其中一个响应人员处理的事故可能是根本原因，而其他则是后果。但究竟是哪一个呢？\n在一个足够大且复杂的技术堆栈中，一个主要响应人员几乎不可能同时驱动缓解并维护所有依赖关系和被依赖关系的状态。为了缓解这种风险，除了出色的组件响应人员之外，我们还建立了一个二级响应人员的结构。我们在 Google 称这些二级响应人员为系统响应人员，接下来我们将讨论这一部分。\n系统响应人员 系统响应人员（SoS 响应人员）负责处理跨多个组件系统、跨系统边界或复杂情况的事故。这些 SoS 响应人员经过专业培训，具有适当的权限和地位，并有权领导有组织的协调响应。他们是第二道防线，更全面地关注问题，并在应对分布式计算故障时提供关键优势支持（图 3-3）。\n我们认为 SoS 响应人员是多系统事故管理者，技术全能，关注整体；他们在处理需要更广泛视角的事故方面有专业知识。通常，这些事故需要多个团队的参与；例如，一次重大系统级 SoS 故障会导致许多服务中断。这些事故可能会引发或已经引发下游故障，并可能扩展到服务边界之外。此外，这些事故可能已经持续了 30 分钟或更长的时间，且没有解决迹象，影响客户。\nSoS 响应人员适合应对这些影响广泛的事故，因为他们知道如何组织他人并掌控复杂局面。他们还擅长诊断系统行为，找出根本原因，专注于扩展响应并广泛沟通事故情况。\n在 Google，我们有两种类型的 SoS 响应人员。尽管每种类型都有其独特的功能，但它们经常协同工作：\n产品专注的事故响应团队（IRTs）：这些团队保护特定产品领域的可靠性。例如，广告 IRT 和 YouTube IRT。并不是每个产品领域都需要事故响应团队，但随着产品不断推出新功能、变得更加复杂，并积累了技术债务，这些团队将非常有帮助。这些团队的成员不一定了解产品堆栈的每一个细节，但他们了解产品的整体运营和依赖关系。 技术事故响应团队（Tech IRT）：这是我们最广泛关注的事故响应团队。该团队专注于跨产品的事故、责任不明的事故或根本原因不清的普遍事故。Tech IRT 是我们的最后一道防线。成员是资深的 Google 员工，他们至少在两个不同的团队中担任过组件响应者，广泛了解系统运行，最重要的是，他们具备出色的事故管理技能。 Tech IRT 的成员继续为原团队工作，同时轮流进行全球 24/7 的值守/值班。他们能够在这些重大紧急情况下继续工作，因为他们经常练习这项专门技能。\nTech IRT 成员每年两次接受为期两周的生产培训，深入了解系统运行和故障的细节。他们还需要每季度展示有效使用紧急工具的能力。 图 3-4 描绘了 Google 的事故响应组织架构。随着架构级别的增加，产品日常功能的细节变得更加抽象。每个角色同样重要——金字塔的每个后续级别都承受较少的寻呼负载。如果组件响应人员无法解决问题且威胁到产品稳定性，他们可以将问题升级到产品专注的 IRT。\n如果一个问题威胁到多个产品，或通过共享基础设施的解决方案可以更快缓解，Tech IRT 将被激活，作为所有下级问题的升级点，负责最广泛范围的操作。\n那么，是什么使得这个组织架构能够无缝运行呢？答案是共同的协议、信任、尊重和透明度。接下来我们将详细探讨这些。\n事故响应组织架构 成功的事故响应组织有四个特征：统一协议、信任、尊重和透明（见图 3-5）。\n统一协议 在 Google，我们广泛使用 FEMA 事故指挥系统（ICS）的内部变体，其中事故响应人员有明确的角色，如事故指挥官、记录员和通信员。通过使用共享且明确定义的流程，我们建立了有效的紧急响应习惯，包括保持活跃状态、明确的指挥链和减少整体压力。每个人都了解交接流程，知道应该交接给谁，以确保知识的有效传递。就像象棋不能在麻将桌上玩，在紧急情况下，所有人都必须按照同一个规则行事。\n信任 在事故发生期间，事故指挥官需要行使权威。他们需要指挥他人、组织混乱的能量，并判断合适的行动方案。对于许多组织来说，将权威级别与操作职责对齐是一个挑战，但我们的标准操作程序避免了只有高层业务主管才有权做出服务变更决策的惯例：我们将这种权威赋予具有背景知识和实时状态信息的主题专家（SME）。\n尊重 确保所有响应人员在认为有必要时能够放心地升级情况非常重要。如果响应人员因为升级事故而受到审查、批评或被认为无能，他们可能不会在适当的时候进行升级。除了基本的礼貌，我们必须相信每个人在现有信息的基础上做出最佳决定。如果出现问题，关键不是责备某人，而是找出如何提供更准确和可操作的信息，以确保未来不再出错。这部分工作在事后分析过程中进行，Google 坚持严格的无责政策（稍后会详细介绍）【译者注：对事不对人策略】。\n透明度 我们不进行信息隔离。当事故发生时，所有细节对所有人开放。如果禁止访问事故信息，就无法进行升级和互操作性——我们在事故解决后撰写的事后分析会在公司范围内的每周通讯中分享。我们鼓励通过阅读其他团队和产品领域发生的事故来进行跨团队学习。\n风险管理 除了事故响应组织结构的特征外，还需要考虑如何管理风险。从识别到解决事故的时间不应超过三天。正如之前所说，事故管理在时间和人力上都非常昂贵。长时间保持在事故管理的活跃状态会导致疲劳和倦怠，可能促使你开始考虑跳槽。事故是已经升级并需要立即有组织响应的问题。这种紧急状态并非自然状态——人类的大脑延髓不应该被长时间刺激，他们的身体也不应该长期分泌大量皮质醇。\n如果史前人类不断狩猎或被剑齿虎追捕，无法感到安全或休息，我们的进化会截然不同。如果你预计长时间处于战斗或逃跑模式，最终会导致团队成员的持续流失。\n事故管理与风险的功能 为了减少事故管理的时间，重要的是认识到事故管理和风险的功能。事故管理是一项短期任务，旨在迅速纠正危险情况。事故的严重程度可以分为几个简单的类别。在 Google，我们根据组织的产品适当地量化了这些类别（见表 3-1）。\n表 3-1. 严重性定义\n严重性 定义 试金石 重大 面向用户的重大故障，产生负面新闻或对 Google 或特定 Google 客户造成巨大的收入影响。内部生产力故障只有在产生可见外部后果（如负面新闻周期）时才视为重大。 可能或已对 Alphabet/Google 品牌和业务造成损害。 严重 对用户可见的故障，但不会对 Google 服务或特定客户造成持久损害，或对 Google 或其客户造成可观的收入损失，或 50% 或更多的 Google 员工受到显著影响。 此类故障如果持续发生且未得到缓解，可能或将对 Alphabet/Google 品牌和业务造成损害。 中等 从差一点到重大/严重故障。大量内部用户受到显著影响。存在已知的解决方法，减轻了影响。 此类故障如果持续发生且未得到缓解，可能会随着时间推移导致越来越多的不稳定性和更高的维护成本。 轻微 外部用户可能未注意到故障。内部用户受到不便。导致网络、数据中心、实例等之间的流量发生意外波动。 此类故障如果持续发生且未得到缓解，不太可能随着时间推移导致更多不稳定性，但代表正常操作条件。 微不足道 事故对用户没有任何可见影响，对生产几乎没有实质性影响，但从中学到了宝贵的教训，需要以低优先级跟踪一些后续行动项目。 此类事故如果持续发生且未得到缓解，不会被视为过程失效。 忽略测试 这甚至不是一次事故。去做其他事情吧。 虚惊一场。 事故的规模大致反映了情况的“风险性”（根本原因/触发/影响）。事故管理旨在缓解短期影响，为组织的决策者争取时间来决定下一步措施。事故管理并不意味着要持续到避免所有短期和长期影响。对于庞大的技术堆栈或积累的技术债务，可能需要数月甚至数年才能彻底解决根本原因/触发条件。事故应只在短期影响尚未缓解时保持“开放”状态，并进行积极的管理。\n在医院中，这相当于评估出血患者的紧急风险，并为其止血。那么接下来呢？医院会确定出血的原因并防止其复发。可能需要为患者制定长期计划，如避免再次遇到剑齿虎，或治疗引起出血的皮肤病。无论是哪种方式，一旦立即的危险消除，就会制定长期计划，包括必要时的全天候支持，以确保患者安全并防止再次出血。同样地，在你的技术堆栈中，一旦立即的危险解除，就应转向制定长期行动计划。\n在事故管理中，通常可以在几分钟内重现事故的时间线。如果处理的是紧急问题，每一分钟都可能影响用户或造成收入损失。因为每一分钟都很重要，事故管理对经理们造成了很大压力——正如本节前面提到的，这不是一种长期的积极体验。当处理事故的长期后果（解决根本原因或触发因素）时，理想情况下，不再有立即的用户伤害或重大利润损失。这很好。这些高优先级工作需要立即执行，但不需要像管理事故那样紧迫。这些工作的时间线可以按天或周来衡量，而不必像之前提到的事故时间线那样不超过三天。在不需要的情况下，不要保持战斗或逃跑模式。关闭事故，转向恢复。\n来源： https://sre.google ；本白皮书一共有 7 章，后续章节将陆续发布。完整中文版白皮书即将发布，敬请期待。\n❤️ Photo by Pixabay: https://www.pexels.com/photo/photo-of-a-2-fireman-killing-a-huge-fire-69934/\n","date":"2024-06-26T22:46:48+08:00","image":"https://martinliu.cn/blog/anatomy-of-an-incident-ch3/pexels-pixabay-69934_hu_126759ee0c5aa275.png","permalink":"https://martinliu.cn/blog/anatomy-of-an-incident-ch3/","title":"Google SRE 白皮书： 《事故管理剖析》第三章 扩展事故管理响应"},{"content":" 下载中文版 PDF 文件 下载英文版 PDF 文件 从 Google 下载白皮书 我们已经讨论了管理事故的三个阶段和事故管理生命周期。现在，让我们讨论如何实战演习事故管理，以便在实际事故发生时，确保我们已经做好了准备。\n灾难角色扮演和事故响应演习 为了增强恢复力，测试和演练事故响应准备是非常有价值的。我们建议在团队中进行灾难角色扮演来训练事故响应的全过程。在谷歌，我们通常称之为“厄运之轮 (Wheel of Misfortune)”。这是一种重现过去在生产环境中曾经遇到的真实事故场景的一种方法。\n定期进行事故响应演习有许多现实的好处。在谷歌灾难恢复测试 (DiRT) 计划的早期，有些测试被认为风险过高而无法执行。然而，多年来，通过专注于这些由高风险测试所暴露出来的领域，许多暴露出来的风险已经得到了彻底解决，以至于这些测试现在是自动化执行的，并且被认为是无聊的测试。\n如果想要实现这一点，效果既非立竿见影，过程也不会轻松愉快——这需要投入时间，需要多个团队付出巨大的协同努力；但我们已经能够极大的降低全球系统中的重大风险，以至于“风险只是另一个定期运行的自动化测试”。\n定期测试 (Regular Testing) 执行定期的测试具有很多显著的好处。多年来，谷歌一直在进行 DiRT 测试，以发现并修复生产系统中的问题。随着团队不断测试他们的服务，高风险测试的数量减少了。这实际上是个好迹象——团队已经使系统更加具有恢复力，以至于发现暴露系统的弱点，也变得越来越难。\n测试失败——由于某种原因导致的测试失败——也变得更加罕见。即使发生，这些系统也往往能以预期的方式失败，并因此能得到迅速缓解。故障响应者现在更加自如地启动故障应急预案，能够在压力下保持头脑冷静，并且由于这些测试，撰写事后复盘报告的次数也减少了。谷歌多年的努力已经得到了回报——大家的心态已经从“灾难测试是对我个人的挑战”转变为“灾难测试是大家共同的任务”。\n细化的测试和自动化 测试正在逐渐从解决纯粹的技术问题（例如“我们是否知道如何从完全损坏的数据库中恢复？”）转向更细化的“修复流程”的一系列挑战。\n技术测试较易讨论和自动化：基本上就是编写一些代码来执行一系列命令，并检查预期的响应。而想要找到有问题的流程，则更加困难——例如“只有一个人有权批准这个，但他们并不回复电话/邮件”——尤其是对于那些那么不经常执行的陌生流程。\n准备响应者 (Preparing Responders) 进行事故响应测试——即使只是理论测试——也可以帮助我们识别出有问题的流程，评估其概率和风险因素，并增强响应者的信心。即使测试未按计划进行，你也能更好地发现事故响应流程中的弱点。事故响应者也将会更好地做好在技术、心理和情感上的准备，以应对未来会发生的实际事故。\n情感上的准备并不可低估。如前所述，事故管理会给响应者带来巨大压力，导致疏忽大意、反应变慢和判断力模糊。压力还可能引起焦虑、疲劳、高血压和睡眠质量差等健康问题。\n进行事故响应测试不仅可以减少这些不良影响，更重要的是识别暴露出这些问题，以便采取纠正措施——如请求帮助、休息，甚至完全移交事故的处理。管理人员和领导也应该：时刻关注响应者的压力、疲劳和倦怠的迹象，并尽可能的提供必要的帮助。\n编写事故响应测试 编写事故响应测试(Writing Incident Response Tests)的一个良好起点是：查看并回顾最近发生的事故。在谷歌，我们在每次事后复盘分析中都会问这些标准问题：\n出了什么问题？ 哪些方面做得好？ 我们在哪里是凭运气？ 首先查看出了什么问题，因为这是需要改进的地方。这些往往是容易解决的具体问题——例如，监控发现了问题但并没有通知任何人。一旦识别并修复了问题，就需要测试这个修复结果。这一点不能忽视：仅仅修复问题是不够的；修复可能不完整，或在其他地方又引起了回归。\n在测试正确性时，从小而简单的测试案例开始。随着对响应过程信心逐步增加，就可以开始研究更复杂的问题，包括那些不完全是技术性的（如人员流程方面）。\n当这些小范围测试进行了一段时间后，开始查看“我们在哪里是凭运气？”的那些方面。通常，这些问题更微妙，解决它们可能也不会容易。再次，从小处着手，将问题分解成更小、更易解决的部分。\n这些测试应保持缓慢的进行，但要保证稳定的节奏——既不想让团队淹没在测试工作中，也不想失去进度。举例来说，每四周进行一次一小时的测试，要比花费 10% 的运营预算在这些测试上更容易被接受。随着这些程序的发展和测试价值的显现，你会找到适合的测试频率和深度。\n来源： https://sre.google ；本白皮书一共有 7 章，后续章节将陆续发布。完整中文版白皮书即将发布，敬请期待。\n❤️ Photo by Pixabay: https://www.pexels.com/photo/photo-of-a-2-fireman-killing-a-huge-fire-69934/\n","date":"2024-06-25T22:46:48+08:00","image":"https://martinliu.cn/blog/anatomy-of-an-incident-ch2/pexels-pixabay-69934_hu_4224e2ac9c38fb4e.png","permalink":"https://martinliu.cn/blog/anatomy-of-an-incident-ch2/","title":"Google SRE 白皮书： 《事故管理剖析》第二章 实战演习事故响应准备"},{"content":" 下载中文版 PDF 文件 下载英文版 PDF 文件 从 Google 下载白皮书 如果没有猜错的话 ———— 在接下来的几周里，我们将会在个人和工作上面临巨大的压力，我们需要快速应对各种不断变化的状况。但我们已经为应对危机准备了十多年，并且已经做好了准备。在全球比以往任何时候都更需要信息、沟通和计算的时候，我们会确保 Google 能够提供帮助。\n——Benjamin Treynor Sloss，Google 站点可靠性工程团队工程副总裁，2020 年 3 月 3 日\n中断是不可避免的（这确实让人沮丧）。作为科学家和工程师，你们需要从长远角度看待问题，设计系统以实现最佳的可持续性、可扩展性、可靠性和安全性。但是，你们只能基于现有的知识进行设计。在实施解决方案时，你们也无法完全预知未来。你们不能总是预见到下一个零日事件、头条热搜话题、天气灾害、配置管理错误或技术变革。因此，你们需要随时准备应对这些可能影响系统的事件。\n谷歌在过去十年中最大的技术挑战之一是 COVID-19 新冠疫情爆发所带来的。新冠疫情引发了一系列快速出现的事故，我们需要迅速应对以继续为用户服务。我们必须大幅提升服务容量，让员工在家高效工作，并在供应链受限的情况下找到新的服务器修复方法。正如 Ben Treynor Sloss 所言，谷歌能够在这一系列重大变故中持续提供服务，因为我们已经为此做好了准备。十多年来，谷歌积极投资于事故管理，这种准备是提高事故响应能力最重要的事情。准备工作能增强恢复力。恢复力和处理中断的能力是衡量技术长期成功（以数十年为单位）的关键因素。除了做好工程设计，还需要时刻准备应对业务服务的中断。\n恢复力是公司运营的关键支柱之一。因此，事故管理是公司必不可少的流程。事故不仅对客户有影响，也对操作人员造成了负担。事故带来压力，通常需要人工干预。因此，有效的事故管理应该优先的考虑：预防性和主动性的工作，而不是被动应对。\n我们知道管理事故压力大，找到和培训响应人员也很困难；我们也知道有些事故不可避免，中断会发生。与其问“如果发生事故你会怎么做？”，不如问“事故发生时你会怎么做？”。通过减少这种模糊性，不仅能减轻操作人员的负担和压力，还能缩短解决时间，减少对用户的影响。\n我们写这份报告（白皮书）是为了总结一份：技术事故响应实践的指南。我们首先构建一些讨论事故的常用语言，然后深入探讨如何鼓励工程师、工程领导者和高管在组织内部思考事故管理。我们旨在涵盖从准备事故、响应事故、恢复事故，到保持健康组织的所有内容，以便大规模地应对各种突发情况。让我们开始吧。\n什么是事故？ 事故(incident)是一个含义广泛的词。其含义可能因不同群体而异。例如，在 ITIL 中，事故是指任何计划外的中断，如工单、报错或告警。无论这个词如何使用，重要的是要在其特定的定义上达成一致，以减少信息孤岛，确保每个人都在说同一种语言。\n在谷歌，事故是指：\n被升级的问题（因为影响太大，而无法单独处理） 需要立即响应的问题 需要有组织的进行响应的问题 有时，事故可能由服务中断引起，即服务在一段时间内不可用。中断可以是计划内的，例如在维护窗口期间系统故意不可用以进行更新。如果中断是计划好的并且已通知用户，则就不算是事故——并不需要开展立即、有组织的响应的事情。但通常情况下，我们指的是由未预见的故障引起的意外中断。大多数的意外中断都是事故，或最终会发展成为事故。\n事故可能对客户造成影响。它们还可能造成收入损失、数据损坏、安全漏洞等，这些都可能影响客户。当客户受到事故影响时，他们对你的信任可能会动摇。因此，你需要避免过多或过于严重的事故，以保持客户满意；否则，他们会选择离开。\n频繁的事故也会影响事故响应人员，因为处理事故的压力很大。找到具备适当技能来处理事故的站点可靠性工程师 (SRE) 既具挑战性又昂贵，因此你不希望通过让他们只负责事故响应来使其疲惫不堪。相反，你应该通过主动预防事故来提供他们技能成长的机会。在这份报告的后面，我们将进一步讨论这一点，以及减少压力和改善值班健康的方法。\n并非所有问题都是事故 区分事故和中断很重要，同样重要的是区分指标、告警和事故。如何区分指标和告警，告警和事故？并不是每个指标都会成为告警，也不是每个告警都是事故。为了帮助你理解这些术语的含义，我们将首先讨论监控和告警在维护系统健康中的作用。\n监控 监控是保持系统健康的最常见方法。根据《SRE Google 运维解密》的定义，监控是指收集、处理、汇总和展示系统的实时定量数据，例如查询计数和类型、错误计数和类型、处理时间和服务器在线时间。监控是一种度量。\n在度量方面，我们建议采取以客户为中心的方法来制定服务质量目标 (SLO；在第 26 页的“减少事故的影响”中有更详细的讨论) 和优化客户体验。这意味着收集能准确反映客户体验的指标，并尽可能收集多种度量，如黑盒、基础设施、客户端和应用程序指标。使用不同方法测量相同的值可以确保冗余和准确性，因为不同的测量方法各有优势。以客户为中心的仪表板也能很好地反映客户体验，对于故障排除和事故调试至关重要。\n重要的是，要专注于度量可靠性和对用户的影响，而不是度量已确认的事故个数。如果专注于后者，员工可能会因为害怕被惩罚而犹豫声明事故。这可能导致事故声明延迟，不仅浪费时间和丢失数据，还因为事后处理效果不佳。因此，声明事故并及时关闭比事后补救要好。\n在这方面，有时人们会将可靠性和可用性混用，但可靠性不仅仅是“服务可用性”，特别是在复杂的分布式系统中。可靠性是指在大规模下提供一致服务水平的能力，包括可用性、延迟和准确性等方面。这在不同服务中可能（也应该）有不同的体现。例如，YouTube 和 Google 搜索的可靠性是否相同？根据你的服务，不同用户的期望会有所不同，可靠性也可能有不同的定义。\n一般来说，如果系统的中断更少、更短、更小，它就更可靠。因此，最终取决于用户能容忍的停机时间。采用以客户为中心的方法，用户定义了你的可靠性。因此，需要尽可能接近地度量用户体验。（我们在第 26 页的“减少事故的影响”中对此进行了更详细的讨论。）\n告警 我们已经讨论了系统健康监控。现在让我们谈谈监控的关键组成部分：告警(Alerting)。当监控发现系统行为异常时，会发送一个信号，这个信号就是告警。告警可能意味着两件事：某些东西已经损坏，需要有人修复；或者某些东西可能即将损坏，需要有人检查。紧急程度——即何时需要采取行动——应指导你选择如何响应。如果需要立即采取（人工）行动，应发送紧急通知。如果在接下来的几个小时内需要人工行动，应发送告警。如果不需要立即行动——例如信息是用于分析或故障排除——则信息保持为指标或日志的形式。\n需要注意的是，告警的方式可能因组织偏好而异。例如，它可以在仪表板上显示，或以工单形式呈现。在谷歌，通常采用后者；监控系统在 Google 问题追踪器中创建一个具有不同优先级的“错误-bug”，这就是我们的工单形式。\n现在你已经了解了基础知识，让我们深入探讨可操作的告警。\n可操作告警的重要性 如前所述，当特定条件满足时，告警会触发。但你必须谨慎，只针对真正重要和可操作的事项发出告警。考虑以下场景：作为当班人员，你在凌晨 2 点被呼叫，因为过去 5 分钟内 QPS 增加了 300%。这可能是一个流量波动大的服务，有时流量稳定，但偶尔会有大客户发出大量查询。\n这种情况下半夜叫醒你有何意义？实际上毫无意义。这个告警是不可操作的。只要服务没有崩溃的风险，就没有必要叫人起床。查看历史数据会显示服务需要应对这样的流量峰值，但这些峰值本身并不构成问题，不应生成告警。\n再考虑一个更微妙但更常见的可操作告警问题。你的公司需要每晚备份生产数据库，因此设置了一个每四小时运行一次的 cronjob 进行备份。一次备份由于瞬时错误失败——用于备份的副本发生了硬件故障，并被负载均衡器自动移出了服务模式——但随后几次备份都成功了。结果还是创建了一个工单。\n因为一次备份失败而创建工单是不必要的。这只会产生噪音，因为系统在无人干预的情况下自行恢复了。\n这种情况经常发生。虽然最终只需简单地关闭工单并附上“处理时已经好了”的信息，但这种行为存在一些问题：\n琐事 (toil) 有人不得不花时间查看工单、分析图表和报告，最终发现他们不需要采取任何行动。 告警疲劳 (alert fatigue) 如果 95% 的“数据库备份失败”告警只是被简单关闭，实际问题被忽视的风险会显著增加。 如前所述，事故是具有特定特征的问题。告警只是一个信号，表明可能有事故正在发生。你可能会遇到很多告警但没有实际事故。虽然这种情况不理想，但并不意味着你需要启动正式的事故管理技术；也许这是计划中的维护，你预期会收到这些告警。\n同样，你也可能有事故但没有任何告警——例如，你从安全团队得知他们怀疑生产系统被入侵，但你的团队没有触发任何相关告警。\n实际上，人们对告警和事故的感知有所不同：\n正式的事故管理比简单处理告警要更有压力。 经验较少的响应者比经验丰富的响应者更不容易启动事故管理流程。 事故更可能需要额外的团队资源，因此其他团队成员可以更早判断是否需要介入。 这种情况不仅限于你的团队，事实上，它适用于整个组织。\n告警通常比事故多。获取告警的基本指标（例如，每季度有多少告警）是有用的，但事故需要更详细的分析（例如，上季度的五个重大事故都是由于新功能在预生产环境中测试不足）。你不希望这些报告被所有收到的告警信息淹没。考虑到受众——告警指标主要对团队有用，而事故报告可能会被高层阅读，因此需要管理适用的范围。\n希望这能澄清何时你可以更自信地说“这不是事故”。然而，这也带来了一个二分法：如果有些事情不是事故，那意味着有些事情是事故。你该如何处理这些事故？我们将在下一节探讨。\n事故管理生命周期 最佳的事故管理不仅仅意味着尽可能快速地处理事故。良好的事故管理意味着关注事故的整个生命周期。在本节中，我们讨论一种系统化的事故管理方法。将事故视为系统中持续存在的风险。处理这些风险的过程称为事故管理生命周期。事故管理生命周期涵盖了准备、响应、恢复和缓解事故所需的所有活动。这是运营服务的持续成本。\n所谓生命周期，我们指的是事故存在的每个阶段。这些阶段如图 1-1 所示，具体如下：\n准备 Preparedness ：包括公司或团队为应对事故发生而采取的所有措施。这可能包括工程上的安全措施（如代码审查或发布流程）、事故管理培训，以及识别错误的实验或测试演习。这还包括设置监控和告警。 响应 Response ：当触发因素导致潜在风险变为实际问题时的应对措施。这包括响应告警、决定问题是否是事故，并与受影响的人员沟通。 缓解和恢复 Mitigation and recovery ：使系统恢复到功能状态的一系列行动。这包括为了避免影响或防止影响扩大的紧急缓解措施。恢复阶段还包括进行事后分析和反思，撰写事后报告。事后报告是一份关于事故的书面记录，包含采取的措施、影响、根本原因和防止再次发生或减少未来影响的后续行动。 一旦恢复阶段结束，你将重新进入准备阶段。根据系统的复杂性，所有这些阶段可能同时进行——但可以确定的是，至少总有一个阶段在进行中。\n来源： https://sre.google ；本白皮书一共有 7 章，后续章节将陆续发布。完整中文版白皮书即将发布，敬请期待。\n❤️ Photo by Pixabay: https://www.pexels.com/photo/photo-of-a-2-fireman-killing-a-huge-fire-69934/\n","date":"2024-06-25T22:46:48+08:00","image":"https://martinliu.cn/blog/anatomy-of-an-incident-ch1/pexels-pixabay-69934_hu_a475962600551438.jpg","permalink":"https://martinliu.cn/blog/anatomy-of-an-incident-ch1/","title":"Google SRE 白皮书： 《事故管理剖析》第一章 概述"},{"content":"作为 SRE，您需要确定服务的初始资源需求，并确保服务在意外需求下仍能稳定运行。容量管理是指确保您的服务拥有足够的资源，从而实现可扩展性、高效性和可靠性。无论是用户端服务还是公司内部服务，都必须应对预期和意外的增长。我们将利用率定义为资源使用的百分比。确定初始资源利用率并预测未来需求并不容易。我们提供了一些估算利用率和识别盲点的方法，并讨论了构建冗余以避免故障的好处。利用这些信息，您可以设计架构，使每个组件的资源分配增加能够有效地线性提升整个服务的容量。\n容量管理原则 在本文中，服务被定义为提供一组功能的所有二进制文件（服务栈）的集合。成功的容量管理需要从两个复杂的角度出发：资源制备，即现在运行服务所需的初始容量；以及容量规划，以保障未来服务的可靠性。\n容量管理的核心原则包括以下三点，以保持服务的可扩展性、可用性和可管理性：\n服务必须高效利用资源。大型服务需要大量资源，部署和维护成本高。 服务必须可靠运行。限制资源容量以提高效率可能导致服务故障和停机风险，因此需要在效率和可靠性之间找到平衡。 必须预见服务的增长。增加服务资源可能需要较长时间，且存在实际部署限制。这可能涉及购买新设备或建设新数据中心，也可能需要增加其他依赖系统和基础设施的容量。 容量管理的复杂性 大型服务如同复杂的生命体，其行为有时难以预期。做出可能改变服务范围的工程决策时，需要考虑以下几个方面：\n服务性能。了解不同组件在负载下的表现。 服务故障模式。考虑已知故障模式下服务的表现，以及面对未知故障模式时的可能行为。通过列出可能的瓶颈和服务依赖项，做好准备。 需求。首先要确定预期的用户数量和流量、用户分布的位置以及他们的使用模式。 自然增长。估计随着时间推移，需求可能会如何增长。 功能扩展。考虑新增功能或服务比预期更成功时，对长期资源需求的影响。 扩展能力。了解在增加资源分配时，服务的扩展情况。 市场分析。评估市场变化对获取额外资源能力的影响。研究新技术，这些技术可以提高服务的性能、可靠性或效率，以及实施这些技术的成本。调查如何快速采用新技术，例如用 SSD 替换 HDD。 容量管理的目标是控制不确定性。在未知环境中，服务必须现在可用，并在未来继续运行。这是一种充满挑战但值得追求的微妙平衡：在效率与可靠性、准确性与复杂性、努力与收益之间做出权衡。\n使用数据来驱动容量决策。尽管你仍然会犯一些不可避免的错误，并需要创造性地解决问题，但最终的结果是一个可靠的关键业务服务。\n资源制备解决的是战术问题：“如何保持服务马上能立即运行起来？” 而容量规划解决的是战略问题：“如何在可预见的未来保持服务运行？”\n以下章节将详细讨论这些主题。\n资源制备 我们将讨论集中在服务系统上，即通过查找数据来响应用户请求的服务。不过，这些原则同样适用于数据存储服务、数据转换服务以及其他大多数计算机任务。\n资源制备涉及确定服务所需资源的目标利用率并分配这些资源。目标利用率被定义为在保证服务可靠运行的情况下，特定资源类别的最高可能利用率。资源类别指的是特定类型的计算资产，比如 CPU、RAM 和存储。\n要为你的服务进行资源制备，需要使用需求信号作为输入，并创建包含具体资源分配的生产布局，如图 1 所示。服务通常使用多种资源类别。\n资源短缺的影响\n资源短缺会导致服务以不同方式失败，这取决于资源类别。\n当资源成为服务关键路径中的瓶颈时，用户会遇到延迟增加的情况。在最糟糕的情况下，瓶颈会导致请求积压，延迟不断增加，最终导致排队请求超时。如果没有缓解计划，服务将无法处理请求，进而发生故障。故障将持续，直到传入流量减少使服务恢复，或者服务重新启动。\n经常在关键路径中出现的资源包括：\n处理能力 网络 存储吞吐量 当资源成为非关键路径中的瓶颈时，服务的一些非时间关键功能（如维护或异步处理）会出现延迟。如果这些任务被延迟过长，它们可能会影响服务性能、功能、数据完整性，甚至在极端情况下导致故障。\n当服务用尽存储时，写入操作会失败。如果某些读取依赖于写入操作，例如服务或存储解决方案存储 Paxos 状态以进行一致性读取，或者存储解决方案跟踪所有访问的数据及其访问时间，这些读取操作也可能会失败。\n当其他资源（如内存或网络套接字）不足时，服务可能会崩溃、重启或挂起。资源不足的服务可能会因为垃圾收集而陷入频繁操作，或者以其他方式表现异常。这些故障会降低服务的容量，并可能触发需要人工干预的级联故障。\n有关缓解策略，请参见下文的“减少故障影响”部分。\n估算利用率\n由于服务和资源类别的不同，每个服务的资源使用率和目标利用率都不同。为了准确估算特定服务的目标利用率，需要考虑以下几个方面。\n峰值使用率\n峰值使用率是指在特定时间段内的最高使用率，取决于服务的性质和用户群体。例如，业务相关服务在工作日早晨可能达到使用高峰，而社交相关服务则在下午晚些时候、晚上、周末或社交活动期间达到峰值。突发事件也可能导致使用率骤降或飙升。全球服务的用户群分布在不同国家和时区，形成更复杂的日流量模式。\n假设负载不恒定，资源利用率在峰值流量期间不应超过服务分配资源的100%。这样，服务在应对峰值时不会因过度制备而浪费资源。\n最大峰值利用率\n即使在峰值时，也不应让服务以100%的利用率运行。一些软件、语言或平台在CPU使用率接近100%时会出现性能问题或垃圾回收抖动。如果某个组件的内存利用率达到100%，服务可能会因内存不足（OOM）错误而崩溃。\n调整监控以捕捉足够小时间帧（微秒或秒）内的精确资源利用率是件繁琐的事情。因此，很难确定低延迟应用程序的资源使用峰值。\n冗余\n发布问题、硬件故障、软件错误甚至计划维护都会导致服务组件失败或重启。这可能导致从单个组件崩溃到整个服务下线的各种故障。\n冗余是一种系统设计原则，指在替换失败组件时激活的重复组件。冗余程度由N+x表示，其中N是活动组件的总数，x是备份组件的数量。例如，N+3表示系统可以有三个组件故障，因为有三个备份组件可以替换它们。这样，无论组件总数（N）是多少，服务都能正常运行。\n冗余可以在区域内或跨区域应用。区域是位于不同物理地点的独立故障域，这样网络问题或自然灾害不会同时影响多个区域。\n可用区域内冗余\n实现可用区域内的冗余相对简单。在一个区域内，需要保护服务免受二进制文件或物理机器故障的影响。通常，可以通过在每个区域运行额外的服务二进制文件实例，并使用负载平衡解决方案在出现故障时重定向流量来实现。冗余程度与基础设施的服务质量协议 (SLA) 相关。SLA 考虑了可同时处于故障状态的机器总数以及在新机器上重新启动二进制文件实例的速度。\n需要注意的是，可用区域内冗余无法保护服务免受导致整个区域瘫痪的故障（如电力、网络或自然灾害）的影响。\n跨区域冗余\n跨区域冗余更加复杂。为了防止整个区域的中断，需要在多个区域部署副本或完整的服务堆栈副本，以实现跨区域的冗余，从而应对高峰期的服务负载。注意，每个副本必须有足够的容量，以便在声明的冗余情况下，任何数量的副本停机时都能服务所有预期负载。无论副本的数量（N）是多少，服务的区域冗余程度定义如下：\nN+0：服务运行但无法容忍任何区域中断 N+1：服务能承受单个区域中断 N+2：服务在两个区域中断时仍能运行 等等 虽然部分冗余涉及容量，但也与服务架构本身有关。例如，一致性存储服务通常要求大多数副本处于运行状态，以确保写操作不会被回滚。 为 N+2 制备服务对可靠性有积极影响：可以计划整个区域的维护，但在维护期间会将冗余降至 N+1。服务仍然可以容忍另一个区域的意外事件。这将冗余降至 N+0，但不会导致中断。需要注意的是，切换到另一个区域可能会对可见的延迟产生影响。\n当冗余为 N+0 并且无法容忍进一步的故障时，优先任务是尽快缓解或解决意外事件。一个选项是完成或回滚计划的维护工作，以将服务恢复到 N+1。否则，任何其他区域出现事件都可能导致面向用户的中断。\n以上算法解释：\n【需求】预期负载：每秒 100 次请求 (rps)\n在 3 个副本上运行 N+2\n允许 2 个副本宕机 (N+2) 3 - 2 = 1 个副本继续运行，处理 100 rps 每个副本被配置处理 100 rps / 1 个副本 = 100 rps/副本 总制备容量为 100 rps/副本 x 3 个副本 = 300 rps 在平稳状态下，N+2 的最大利用率为 100 rps / 300 rps = 33% 在 5 个副本上运行 N+2\n允许 2 个副本宕机 (N+2) 5 - 2 = 3 个副本继续运行，处理 100 rps 每个副本被配置处理 100 rps / 3 个副本 = 34 rps/副本 总制备容量为 34 rps/副本 x 5 个副本 = 170 rps 在平稳状态下，N+2 的最大利用率为 100 rps / 170 rps = 59% 【方案对比】在 5 个副本上运行该服务的成本是运行在 3 个副本上的成本的 56.6%。这个比率是通过计算 170/300 得出的。\n冗余的成本\n服务在越多的区域运行，运行任何级别冗余的成本就越低。考虑图 2 中描述的服务。它需要运行在 N+2 冗余模式下。在第一个设置中，它运行三个副本（N=3），在第二个设置中，它运行五个副本（N=5）。两种配置都有两个备用副本（+2），因此可以承受两个副本的故障。 接下来，检查五个副本的设置。其副本较小，即使两个副本失败并且两个备用副本都在使用中，仍有三个活动副本共享负载。这导致五个副本的 N+2 设置成本是三个副本服务使用相同冗余级别成本的 56.6%。参见图 2 中提供的计算。\n同质和异质服务\n实现同质大小副本的服务冗余比实现异质大小副本的服务冗余更容易。您的服务必须准备好处理最大的区域故障。如果区域容量不同（即异质），在每个区域中，承受其他最大区域不可用的容量需求是不同的。结果是，较小的区域需要更多的资源，整体所需的资源来提供相同的负载更高。\n复制和分布式流量\n为冗余制备资源还取决于服务流量的特性。无状态服务（如处理用户请求的 Web 服务器）接收分布在副本之间的流量。从存储服务读取的请求也可以分布在不同区域的副本之间。为这些服务制备 N+1 或 N+2 冗余是简单的，遵循前面例子的逻辑。处理跨区域复制请求（如写入）的服务行为不同。每次写入实体的请求需要最终写入每个副本，以保持服务数据在副本之间的一致性。当副本变得不可用时，复制写入请求不会对保持可用的副本产生额外的负担。然而，当不可用的副本重新上线时，会产生成本。此副本需要赶上停机期间错过的未完成写入。这一操作增加了其负担。保持运行的副本提供了同步恢复副本所需的数据，在恢复期间增加了所有副本的负载。理想情况下，应限制这一操作以避免影响整个副本集的低延迟流量。每个服务和每个组件接收的复制和分布流量的比例不同，这需要在资源制备时考虑。\n对延迟不敏感的进程\n服务通常有对延迟不敏感的进程，如批处理作业、异步请求、维护和实验。然而，这些进程在处理生产负载（对延迟敏感）时给服务带来额外的压力。因此，服务需要额外的资源来容纳更高的峰值，增加了其成本。您可以通过分配较低优先级或在低负载期间调度来最小化对延迟不敏感请求的额外成本，以减少整体峰值。注意，这两种解决方案都需要经过适当测试并仔细部署以防止服务中断。\n未知的额外资源\n最后一个要考虑的方面是未知因素。制备服务时有许多正当理由添加额外资源：例如，由另一个团队支持的底层库的性能回归，或实施外部团队要求（如加密所有 RPC）。如果出现问题，备用容量可以保持服务在延迟和错误方面按预期运行。然而，请记住，这一决定可能很昂贵，因此请确保在可靠性、可预测性和扩展性之间的权衡是值得的。\n容量规划 资源制备是指确定当前保持服务运行所需的资源量，而容量规划则是预测未来的资源需求以确保资源供应。\n容量规划概述\n与资源制备类似，容量规划旨在确定维持服务所需的每种计算资源的数量。然而，容量规划需要在多个时间点上做出预测，例如三个月、六个月或一年的资源需求。\n对于现有服务，容量规划通过分析历史需求来预测增长，并在此基础上考虑服务的最大峰值利用率、冗余需求、对延迟不敏感的进程以及未知因素进行资源制备。通常，您还需要在预测中加入计划中的新资源消费者，如新服务、营销活动和新功能等。\n您需要为服务中的每个组件分配不同数量的每种资源。例如，对于 RAM，Web 服务器可能需要大量 RAM，而代理服务器可能只需要很少的 RAM。为了在规划未来容量时确定每种资源的需求量，需要考虑以下因素：\n您服务中的不同组件数量（如数据库、代理、应用） 每个组件的实例数量（如 1 个数据库，2 个代理，2 个应用） 您的服务运行的区域（如跨区域 N+1 或 N+2） 您的预测所需的数据点数量 虽然这是复杂公式的一个简单示例，但像 RAM 这样的资源类别可能需要按照以下公式进行计算：\n（不同组件的数量）×（每个组件的实例数量）×（区域数量）×（数据点数量）×（其他影响因素）\n由此可见，当您考虑所有区域中所有服务器类型的所有资源类别并加入冗余时，所需确定的容量值数量将呈指数增长。\n预测资源\n容量规划是一个极其复杂的过程，因为有无数因素在起作用，而且每个因素都可以独立变化。基于上述高级概述，预测时请考虑以下因素：\n按组件分类的资源类别 ：除了确定组件的总数外，还必须考虑每个组件使用的各种资源类别：例如 RAM、CPU、存储、网络等。一个组件可能使用一组资源类别，而其他组件可能使用完全不同的资源类别。如果您的服务包含许多组件，那么需要跟踪的资源类别会迅速增加。 多个区域 ：如果需要在全球多个区域运行，可以想象预测各种机器（如 Web 服务器、数据库服务器、应用服务器、代理服务器等）CPU 等单一资源类别的难度会更大。再加上所有机器的其他资源类别，以及跨所有区域的冗余，在给定的时间段内（如六个月或一年后）进行规划时难度更大。 服务需求：需求取决于新服务的成功和采用率，只有在服务推出后才能知道。需要随时间更新预测并修正长期预测。需要为突然的未计划负载增加做好准备，否则可能会导致服务中断。 其他意外事件如自然灾害、网络中断或停电会大幅改变流量模式。即使是计划中的事件，如社交活动或假期的开始或结束，也会以意想不到的方式影响服务。随着新功能的推出或用户基础的变化，这些事件每年的变化影响难以推测。\n不同时区的用户分布变化也会对服务产生影响。流量可能会在一天内分布更多或更少，意外地增加或降低峰值需求。\n增长\n服务的增长取决于其成功与否。用户可能需要一些时间（以及营销活动）来了解您的服务并对其产生兴趣，而这种兴趣可能会随着时间慢慢增加或迅速飙升。其他互联网服务可能依赖于您的服务，它们的成功或失败可以直接影响您的服务。成功的外部服务可以为您带来更多流量，反之亦然。\n社会、经济、政治或其他因素可能会增加或减少您的用户流量。您需要确定您的增长率，并在容量规划会议中考虑这些因素。\n预测示例\n为了说明服务所有者必须正确预测的各种资源类别值，我们使用一个简单的示例：\n两组件服务的资源类别：假设您有一个小型服务，如社交媒体应用。该服务由两台机器组成，一台 Web 服务器和一个数据库。Web 服务器使用 CPU 和 RAM，数据库使用 CPU、RAM、HDD 存储、HDD 吞吐量和 SSD 存储。这一共是六个独特的资源类别值。这远不是现实应用中的完整值集合。如果有三个副本，您需要定义 18 个值。如果按季度预测未来 12 个月，则需要定义 72 个值（每年四个季度 × 18）。 影响您服务的趋势：您了解到，您的社交媒体服务受季节性趋势影响。在假期开始时（11 月至 12 月），流量会增加，春假和夏季开始时也会有流量高峰。预测时，不能只考虑资源的线性增长，还要考虑一年中高峰时段的流量峰值。每个月批处理任务（如数据清理或数据库压缩）期间，负载可能也会有所不同，甚至每周负载也会变化，这使得预测更加复杂。 最佳实践 我们提出了一些容量管理的最佳实践，帮助您预见和解决常见问题和陷阱。\n负载测试\n在目标利用率及以上运行服务的小副本，进行故障切换、缓存失效、发布等操作。评估服务如何应对和恢复过载，通过实验证实资源分配是否足以应对定义的负载。在从数据中推断估计值时要小心。如果一个分配有一个 CPU 的二进制实例每秒可以处理 100 个请求，那么通常可以假设两个分配有一个 CPU 的二进制实例总共每秒可以处理 200 个请求。但不能假设一个分配有两个 CPU 的二进制实例每秒可以处理 200 个请求，因为可能存在其他瓶颈。\n全面评估容量\n尽管需要为未知情况添加额外容量，但要避免堆积过多资源而无意中使服务过度制备。应提供足够的备用资源，使服务能够应对突发问题。这可以在服务比预期更成功且资源不足时，争取一些额外时间来获取资源。\n降低停机影响\n可以对服务进行准备，使其在资源耗尽时停机的影响降到最低。建议的预防措施包括：\n优雅降级：当服务负载过大时，禁用一些非关键功能以减少资源使用。 拒绝服务 (DoS) 攻击保护：防止流量增加来自恶意方。 有效超时：请求最终超时，服务放弃这些请求而不再浪费资源。 负载分流：当服务负载过大时，快速拒绝请求，允许上层路由层重试请求或使其快速失败。这样可以避免服务落后并浪费资源在最终会超时的请求上。 配额管理和限流\n部署配额系统有助于限制服务与后端之间的吞吐量，为使用同一后端的其他服务提供隔离。当服务发送的请求超过预期并达到配额限制时，后端会限制服务，而不是让自己过载并影响其他使用同一后端的服务。\n监控\n通过监控服务收集的相关指标为资源制备和容量规划决策提供数据。使用我们上面的示例服务作为模型，以下是非常有用的：\n负载指标\n每秒的传入请求数 对延迟不敏感的负载 活跃用户数 总用户数 资源指标\n资源分配 实际资源使用情况 配额使用情况 被限制的请求数量 性能指标\n延迟 错误 高阶健康指标（用于过滤其他受污染的指标数据）\n服务受到停机影响的时间 服务正在进行维护的时间 告警\n通过告警进行资源制备和容量规划，以防止停机。一些有用的告警示例包括：当服务未达到预期的冗余水平时触发的告警，表示资源不足的告警，以及性能问题的告警等。\n资源池化\n资源池化是将资源分组，使多个服务共享它们，而不是为每个服务单独分配。池化通常用于减少规划复杂性和资源碎片化，从而提高服务效率。实施该策略时，大型服务的规划仍需详细且精确，但小型服务可以共享一个大致和保守制备的资源池。这种方法减少了容量规划的工作量，但牺牲了服务的隔离性。\n一般 SRE 最佳实践\n遵循适用于所有服务的基本 SRE 原则。例如，将容量状态作为配置存储在版本控制系统中，并要求对任何更改进行同行评审。自动化执行、逐步推出所有更改、持续监控服务，并准备在需要时进行回滚。\n在发生故障或其他问题时，进行无责后事件审查，诚实地从错误中吸取教训，并致力于改进系统，以避免重复这些错误。\n评估服务容量 在评估新服务或现有服务的容量时，我们建议按照以下步骤来确定其资源需求：\n硬件 规格 处理器 CPU 类型和核心数量 图形处理单元 GPU 类型和数量 存储 HDD（硬盘驱动器）和 SSD（固态硬盘）： • 存储容量（TB） • 带宽 • IOPS（每秒输入输出操作） 网络 数据中心内部、数据中心之间、ISP 访问： • 延迟 • 带宽 后端 所需的服务和容量 其他 AI 加速器及其他特殊硬件 估算服务所需的资源，以应对预期负载。使用表 1 的模板，填写不同资源类别的预期服务需求。 计算并考虑服务各组件的目标利用率。您可能需要进行负载测试来评估： 峰值使用率 最大峰值利用率 冗余 对延迟不敏感的过程 未知情况下的备用资源 考虑以下因素： 优先级 地区 服务组件 具体时间点及未来时间（如每月、每季度、六个月、一年等） 进行预测，考虑是否需要按以下方面规划容量： 优先级 地区 服务组件 每年的时间点数量 持续学习容量管理： 观看视频《分布式服务的容量管理复杂性》，了解该主题的详细技术讲解 [1]。 阅读 ;login: 文章《容量规划》 [2]。 查看 Google 的《Site Reliability Engineering》中的《软件工程在 SRE 中的应用》、《管理关键状态》和《大规模可靠产品发布》章节 [3]。 结论 在本文中，我们探讨了容量管理的组成部分及其复杂性。我们将这个主题分为两个部分：资源制备和容量规划。资源制备解决了战术问题，即“如何保证服务现在能正常运行？”；而容量规划则关注战略问题，即“如何确保服务在未来也能持续运行？”回答这些问题并不简单，每个问题都需要仔细审查服务的不同方面。\n在进行资源制备时，需要检查各种需求信号（输入）及其对资源分配（输出）的影响。了解服务可能面临的预期高峰需求以及需要构建的冗余量非常重要。你是否考虑过资源短缺和供应商供应的影响？\n容量规划迫使你尝试预测服务及其负载在不断变化的未来会是什么样子。为了做到这一点，你必须充分了解你的服务。例如，你需要确定高峰周期及其发生时间，确定需要运行的地点数量及每个地点的不同能力，并预测可能影响服务的自然、社会甚至法律事件。当需要增加容量时，你是否有批准或资金来支持这一增长？\n虽然我们提出的许多最佳实践都很重要，但遵循可靠的 SRE 原则有助于简化容量管理：进行适当的负载测试，实施广泛的监控和警报，使用源代码控制系统，了解服务的优点和缺点，制定容量计划，并准备在需要时预测增长和扩展。\n致谢\n作者感谢 JC van Winkel、Michal Kottman、Grant Bachman、Todd Underwood、Betsy Beyer 和 Salim Virji 的建议。\n作者：\nLuis Quesada Torres 是谷歌的一名站点可靠性工程师和经理，他负责确保谷歌云的人工智能 (AI) 产品可靠高效地运行。在业余时间，Luis 拥有多种爱好：他在多个音乐流派中作曲和制作音乐，他喜欢玩滑板，并且他会说西班牙语、英语、德语、瑞士德语和世界语。他很快还会学习日语。你可以通过 luis@google.com 联系他。 Doug Colish 是谷歌在纽约市的一名技术作家，支持站点可靠性工程 (SRE) 团队。他为谷歌的《构建安全可靠系统》一书的多个章节做出了贡献。Doug 拥有超过三十年的系统工程经验，专注于 UNIX 和安全。他的爱好包括对汽车进行细节处理和改装，参加音乐会，以及观看和讨论优秀电影。你可以通过 dcolish@google.com 联系他。 参考文献\n[1] L. Quesada Torres, “Complexities of Capacity Management for Distributed Services,” Google Tech Talk: https://www.youtube.com/watch?v=pOo0oKNM9I8. [2] D. Hixson and K. Guliani, “Capacity Planning,” ;login:,vol. 40, no. 1 (February 2015): https://www.usenix.org/system/files/login/articles/login_feb15_07_hixson.pdf. [3] B. Beyer, C. Jones, N. R. Murphy, and J. Petoff, eds., Site Reliability Engineering, Chapters 18, 23, and 27: https://landing.google.com/sre/sre-book/toc/index.html. 原文地址: https://static.googleusercontent.com/media/sre.google/en//static/pdf/login_winter20_10_torres.pdf\n❤️ Photo by FOX: https://www.pexels.com/photo/clear-drinking-glass-with-brown-liquid-9097039/\n","date":"2024-06-17T13:23:28+08:00","image":"https://martinliu.cn/blog/sre-best-practices-for-capacity-management/pexels-fox-58267-9097039_hu_d58f7dc6e7452b5e.jpg","permalink":"https://martinliu.cn/blog/sre-best-practices-for-capacity-management/","title":"Google 白皮书：SRE 容量管理最佳实践"},{"content":" 作者：Carl Crous, Parker Roth 和 Victoria Hurd； 译者：刘征 原文：https://sre.google/resources/practices-and-processes/product-focused-reliability-for-sre/\n介绍 站点可靠性工程师（SRE）传统上通过其服务间接支持产品，负责服务质量目标（SLO），并提高服务的可靠性。然而，这种方法存在一些局限，有可能影响产品和用户体验：\n服务仅能部分满足用户需求和业务目标。度量服务的可靠性只是对用户需求或业务目标的近似。 用户界面（UI）越来越复杂。在 UI 和 SRE 度量的服务之间存在许多层次，导致产品覆盖的显著差距。 服务增长可能轻易超过组织的工程增长，导致服务被忽视或团队负担过重。 服务支持优化了产品整体可靠性和性能的一小部分，而在这些服务范围之外存在显著风险。 服务本质上是同步的。异步流程常常被忽视或难以优先处理，因为其成功无法通过单一服务来度量。 本文探讨了这些限制，并讨论了一些 Google SRE 团队如何通过将支持重新聚焦于产品和最终用户需求来解决这些问题，而不是集中于基础设施和服务。我们还讨论了 SLO 策略，描述了 Google SRE 如何定义产品，并解释了如何决定哪些因素对实现产品可靠性至关重要。\n产品参与度\n为了支持产品，SRE 需要熟悉产品及其功能的设计和开发。同时，还需要了解终端用户在使用产品时的目标。\n为了获取产品和用户信息，SRE 需要与产品经理和用户体验研究人员合作。这些人根据“要完成的工作”（Jobs to be Done）和 Google 的关键用户旅程（CUJ）等框架定义产品和功能，这些框架识别终端用户的目标和期望结果。\n使用这些信息，SRE 可以识别出对产品及其用户重要的内容，并用定义产品的相同语言来定义可靠性。\n服务支持模型 SRE 的核心责任是“负责其支持服务的可用性、延迟、性能、效率、变更管理、监控、应急响应和容量规划”[3]。\n在这种模型中，服务是 SRE 团队的主要“所有权单位”和“工作对象”。这种对服务的关注是 SRE 团队从传统上所建立的方式。它驱动了 SRE 按怎样的优先级别处理工作、度量性能，并扩大范围，从而能支持到更多的服务。\n从传统上看，SRE 在基于服务的工作中表现出色，能确保他们所支持的服务具有高可用性。然而，服务的可用性并不总是能等同于：用户对产品的满意，原因如下：\n产品仍然会发生超出 SRE 团队范围的故障，例如 Web端 或移动应用中的问题。 SRE 团队花时间响应了可能对用户并没有影响的状况。例如，HTTP 404 错误可能并不会影响用户。 当 SRE 的职责范围仅限于某一组服务时，SRE 团队通常并没有足够的信息来有效解决以上问题。相反，SRE 被迫在并不了解服务应如何表现的情况下，来评估这些服务。\nSRE 团队其实可以接受对产品本身的责任，而不仅限于对服务可靠性的责任。这种在更高层面上的 优先考虑产品，而不是服务 的承诺。我们称其为产品支持模型，它开启了一种新的可靠性思维方式。\n产品支持模型 这种新产品支持模型的核心是: SRE 负责产品关键功能的可靠性。过去，SRE 会被分配了一组服务，它们在彼时都是受到重视的关键服务。现在，SRE 会被分配了一组功能和用户想要的结果。在没有传统服务所有权固定边界的情况下，SRE 团队可以将其优先事项与业务和用户结果对齐，并在每一层服务堆栈中处理更广泛和更有影响力的工作。\n“如果你不能度量它，你就不能改进它。” — 彼得·德鲁克\n在工程团队能够管理产品的可靠性之前，必须先能够度量其可靠性。建立一套提供足够广度和深度覆盖的度量标准是至关重要的，这有助于团队识别最具影响力的工程工作，同时避免想要过度优化任何特定系统的诱惑。\n在团队能够度量产品的可靠性之前，必须先知道要度量什么，以及如何度量。需要度量的内容：来自于将产品建模为一组用户可见的行为或功能，并根据它们给用户带来的价值，对这些用户行为进行优先级排序。在掌握了这份优先级列表后，团队可以开始从支持团队/服务，转型为支持产品及其用户。\n图 1 说明了如何通过与利益相关者对齐、产品建模和度量的坚实基础，来实现提高产品可靠性的终极目标。同在这些概念上达成的共识，能使团队能够将资源投入到对最终用户和业务最具影响力的问题上。\n开始 在本节中，你将学习如何实施以产品为中心的可靠性参与（engage），包括以下关键步骤：\n与利益相关者对齐 建模产品 度量性能 管理可靠性 每个步骤列出了为 SRE 团队带来价值的中间交付物及其解锁的机会。我们鼓励你按顺序进行，但也指出了可以利用现有指标和关系的领域。\n1. 与你的利益相关者对齐 与任何 SRE 参与过程类似，第一步是确定相关的利益相关者。在基于服务的参与中，依赖于 SRE 和开发团队之间的合作，而以产品为中心的参与则需要更多样化的合作伙伴。这里的更广泛的合作伙伴通常包括以下角色：\n产品经理：定义产品策略和需求。 UX 设计师和研究人员：将需求转化为用户体验。 工程团队：开发必要的功能和基础设施以实现用户体验。【译者注：在以服务为支持对象的模式中，SRE 仅重点关注\u0026amp;合作此方】 支持专家：通过直接或书面沟通与最终用户互动。 为了成功的管理产品可靠性，关键是要确定每个角色的责任。\n交付物：记录角色和职责的文档，例如 RACI 矩阵[7]。\n在确定了所有的利益相关者后，与他们会面沟通，启动 SRE 的合作伙伴关系。\n2. 建模产品 人们（用户）使用产品是为了实现他们在现实世界里的目标。为了帮助产品团队构建能够促进用户目标的产品和服务，你需要了解产品用户的目标。\n本节介绍了两个关键概念：用户目标和步骤。用户目标描述了用户的意图和他们想要实现的目标。例如，邮件服务的一个目标可能是“与人交流”。步骤是用户为实现其目标而采取的各个独立操作。\n“要完成的工作”（JTBD）[1,5] 框架将用户目标建模为工作，而 Google 的关键用户旅程（CUJs）[2] 将用户目标建模为伴随一系列任务或步骤的目标。\n了解用户在使用产品或功能时的目标是软件开发的有力工具，因为它为你提供了关于产品最重要方面的清晰信号。用户的意图也是 SRE 可以利用的强大可靠性工具。\n假设你的产品是使用“要完成的工作”框架构建的，那么你将拥有一份有待促进的用户目标列表。产品经理、UX 设计师和其他非工程学科角色，也都可能拥有这份列表。这份列表提供了用户期望目标的高阶描述，基于跨职能的数据，为涉及软件开发生命周期的许多学科提供了共同的语言。利用这些共享的用户目标作为产品支持的基础是建模产品可靠性的基础第一步。\n然而，如果你还没有用户目标列表，可能就需要自己开发这份列表，这将带来显著的工程成本，并导致只有 SRE 愿意使用该列表。更好的方法是与产品经理合作，并鼓励他们采用某种框架，并来负责定义用户目标。\n用户目标被分解为：用户为实现其总体目标，所要采取的一系列步骤。每个步骤都是独立的工作单元，与其他步骤无关。这些步骤提供以下信息：\n解释当用户在使用产品时，他们在做什么，或用户目标是什么。 定义每个步骤的开始条件和多个成功或失败条件。 可以与产品界面或基础设施相关联的具体操作列表，例如用户发送电子邮件时调用的 RPC。 以上用户目标只是：一个将步骤组合在一起的组织元素。\n基于这些步骤，你可以确定完成这些步骤所需用到的产品界面和基础设施的哪些部分。某个界面或基础设施服务的某些部分可能会涉及到不同的目标，因此它们可以具有不同的重要性级别。\n交付物：一个产品的用户目标登记表，包含了所有用户目标和步骤的高阶描述。\n邮件服务产品定义示例\n让我们考虑一个允许用户发送和接收电子邮件的邮件产品，还具有一些增值功能。我们将根据表 1 中描述的目标和步骤来建模此产品，并在图 2 中进行了说明。表 1 提供了可以被产品开发和支持中涉及的多个学科使用的基本产品模型。\n表 1: 用户目标和步骤示例\n目标 步骤 描述 撰写邮件 登录 用户在登录页面进行身份验证。 打开撰写对话框 用户点击**“撰写”**按钮，撰写对话框被显示出来。 查找地址 用户开始输入收件人的电子邮件地址，系统显示匹配的地址供选择。 检查拼写 当用户输入消息时，系统会突出显示拼写错误。 发送邮件 用户点击**“发送”**按钮，邮件被排队等待发送。 阅读邮件 登录 用户在登录页面进行身份验证。 打开收件箱 用户打开收件箱页面，显示所有邮件。 打开邮件 用户选择一封邮件，系统显示邮件内容。 接收邮件（异步） 当邮件服务收到新邮件时，它们会自动显示在用户的收件箱中。 产品重要性和优先级\n在转型到产品支持模型时，请记住，SRE 团队在学习这种新方法时会面临更大的认知负荷。请通过战略性选择支持的方式和位置，来管理 SRE 团队的额外工作量。\n例如，你可能希望将大量支持集中在核心用户目标及其步骤上，并用高成本但准确的端到端 SLO 对其进行监控。在这种情况下，你还可以通过更便宜和传统的基于服务器的 SLO 支持较不重要的目标。\n安排 SRE 工作的优先级本身就是一个具有挑战性的问题。我们通过基于特定目标与产品关键绩效指标（KPI）之间的关系，来定义重要性来解决这个问题。这些指标通常已被用来评估停机的严重性，因此使用这些 KPI 来安排 SRE 任务的优先度，可以确保 SRE 跟上不断变化的产品需求。\n在 Google，我们使用特定产品的严重性指南（如 Google Cloud 重大事故 [6] 的场景）来指示停机对产品的严重性和影响。在 Google Ads 中，收入是评估停机严重性的关键指标，而在 YouTube 中，严重性指南包括用户观看视频的时间。参见邮件服务严重性示例，了解如何为典型的邮件服务定义严重性指南。这种分类主要用于衡量停机的影响，但也提供了一个明确的重要性信号，你可以将其应用于其他领域。\n严重性指南通常以对用户的影响为准，因此与用户目标和步骤密切相关。使用严重性指南，你可以根据严重停机对产品或功能的影响来组织用户目标和步骤，这被定义为产品重要性。参见邮件服务产品重要性示例，了解如何为典型的邮件服务定义产品重要性。\n这种重要性定义为优先安排 SRE 工作提供了明确的指导方针。确保整个基础设施有良好的基本覆盖，并制定评估更有针对性努力的投资回报的原则。考虑在关注不太重要的目标之前，你希望为最重要的目标实现什么级别的可靠性。\n通常，团队会陷入寻求一种新方法来解决可靠性问题的陷阱，然后试图将这种方法应用于所有场景，而不考虑适用性。然而，监控的初始化成本和在各处部署改进的持续维护成本的总和其实并不都合理的。例如，离线或批处理流量与互动用户流量相比，具有不同的可用性和延迟需求，因此每类流量需要不同的 SLO。\n更深入地了解对产品重要的内容还具有许多优势，从知道测试覆盖的重要性，到更好的事故响应。如果 SRE 知道问题很严重，他们会更快地反应和升级，从而更快地解决问题。\n交付物：一套与产品的用户目标和步骤一致的严重性和重要性定义。\n邮件服务严重性示例\n继续邮件服务产品定义示例，我们定义了产品的事故严重性分级如下：\n表 2: 事故严重性分级示例\n严重性 描述 重大 任何影响接收或发送邮件的情况。对核心功能有 \u0026gt;20% 的影响。 中等 对核心功能有 \u0026gt;5% 的影响。对辅助功能有 \u0026gt;20% 的影响。 轻微 对任何功能有 \u0026gt;0% 的影响。 在这个例子中，核心功能是用户需要用来阅读和撰写邮件的功能，例如认证系统或地址簿是辅助功能，例如拼写检查和自动补齐等，虽然增加了价值，但并不是产品使用的关键。\n影响的定义因产品而异，取决于独特的用户和业务需求。一些产品可能只关注技术影响，例如失败请求的百分比或延迟超过可接受阈值的请求百分比。其他产品可能关注收入损失、品牌损害或其他与业务 KPI 更直接相关的概念。无论为产品选择哪些标准，考虑以下关键原则是很重要的：\n结果集合应覆盖用户感知行为和业务优先级的所有方面。 应能够以及时和可持续的方式确定事故的严重性。 产品和工程领导层之间应对事故严重性非分级有广泛一致的意见。 邮件服务产品重要性示例\n使用邮件服务严重性示例中的严重性分级，下面我们来定义产品的重要性如下：\n表 3: 产品重要性定义示例\n重要性 描述 用户目标 \u0026gt; 步骤 关键 负责邮件传输和投递的服务，是核心功能的关键（非可有可无）依赖项。 撰写邮件、 阅读邮件 重要 非关键的核心功能依赖项（优雅降级）或辅助功能的依赖项。 撰写邮件 \u0026gt; 检查拼写 、 阅读邮件 \u0026gt; 过滤垃圾邮件 无 所有其他服务，通常是内部或未发布的功能。 所有未被识别为产品优先级的其他产品功能。 你可以看到，重要性定义是围绕用户目标（例如撰写和发送邮件）建模的，而不是系统如何实现这些需求。一些具体步骤（例如检查拼写和过滤垃圾邮件）如果不被视为目标的关键组成部分，其重要性可能会有所不同。一些方面没有明确列出，例如身份验证，因为这是大多数目标中的一个步骤。\n附加价值\n虽然 度量性能 讨论了如何使用这个产品模型作为衡量产品性能的基础，但这不是该模型提供的唯一价值。对产品的用户目标有清晰的理解，可以在对用户需求的达成共识的基础上，协调测试策略、产品使用指标和其他生产问题。\n3. 度量性能 服务质量目标（SLO）是任何 SRE 团队工作的关键组成部分，提供反映系统可靠性的实际指标。《Google SRE 工作手册》[4] 是定义 SLO 和服务质量指标（SLI）的详细资源，并描述了如何使用它们，特别是针对服务。\n基于服务的 SLO 通常无法提供足够的产品覆盖。一些问题无法通过对某个服务器的监控覆盖，例如网络间或移动应用程序中的问题，或异步操作产生的问题等。\n当 SRE 团队发现基于服务的 SLO 存在不足时，他们会开始以多种方式扩展 SLO。从而提供更广泛产品覆盖的 SLO 主要有三类：服务 SLO、客户端埋点和端到端 SLO。\n服务 SLO\n服务 SLO 是最常见的 SLO 类型。它们通过服务本身的指标进行监控，例如应用服务器日志或实时监控指标【译者注：包括后台服务埋点的 APM 数据】。也可以通过服务上层的日志进行度量，例如负载均衡器。你还可以使用黑盒监控（如拨测）结果来度量服务正常运行时间。\n以下是服务 SLO 的主要特征：\n表格 4: 服务 SLO 特征\n特征 描述 低成本 服务 SLO 常见且广泛使用。 高信心 服务 SLO 的数据在你的控制之下，可以提供非常高的可用性保证，例如对 SLO 数据的 SLO 保证。 低延迟 你可以以非常低的延迟收集和处理数据，从几秒到几分钟。 覆盖范围狭窄 这些 SLO 仅涵盖服务能看到的内容。通过在服务堆栈的更高层次度量 SLO，可以改善这一点。如果返回结果被服务视为成功，则 SLO 不受影响。然而，成功（正常）的结果并不总是保证结果有用（用户不受影响），例如返回空响应或向旧客户端返回不兼容的新数据。 客户端埋点\n随着网络和移动应用程序的用户界面变得越来越复杂，越来越多的 SRE 团队开始直接支持这些界面。这可以通过直接从用户界面获取遥测数据来实现【译者注：包括真实用户监控-RUM】。\n这种遥测需要记录事件的日志或监控侧通道，这些事件可以处理并用于定义 SLO。\n这些数据通常需要批处理，并在后台发送，与交互式 RPC 请求分开。当应用程序关闭或失去网络连接时，一些遥测数据可能会丢失。所有这些因素都会影响数据的可靠性，预计会有一些个位数百分比的损失。此外，度量客户端设备上的信号还包括：测量设备的性能和互联网连接。\n然而，客户端 SLO 提供了用户实际体验到的产品性能的有用洞察信息。你可以使用这些 SLO 为连接较不可靠的用户提供更好的体验。当可以从用户界面度量开始和结束条件时，界面行为的复杂性，例如缓存、重试和异步 RPC 请求，都是透明的。\n在决定何时以及如何使用客户端 SLO 时，请考虑以下所有特征：\n表格 5 : 客户端 SLO 特征\n特征 描述 中等成本 客户端 SLO 的埋点需要在用户界面中添加埋点探针功能以获取 RUM 数据，并需要一个系统来接收、处理数据，并设置 SLO 管理。 低信心 预期会有数据丢失。监控可能会受到性能较差的客户端设备和互联网连接的影响。 中等延迟 信号通常从客户端设备批量传输。这些信号量数据需要进行额外的处理后，才能用于 SLO 管理，从而导致 15 分钟到 1 小时的延迟。 广泛覆盖 来自客户端设备的指标允许 SLO 直接衡量用户对产品性能和可靠性的体验。 端到端 SLO\n有些产品功能和业务指标不能通过服务或客户端埋点直接度量。这些通常需要结合来自多个来源的数据，并涉及异步任务。\n例如，用户可能要求生成报告。用户界面发送一个 RPC 请求，该请求在报告被排入系统队列后成功。但这并不意味着报告成功生成。某些后台系统从队列中取出报告并生成它，或未能生成。要度量报告是否成功生成，你需要将用户的原始 RPC 请求与最终的报告生成结果结合起来。\n端到端 SLO 通常根据用户交互来度量其 SLI，因此可以提供相当准确的结果。\n实现端到端 SLO 需要相当多的工程工作量，因为你需要完成以下任务：\n确定度量 SLI 所需的数据集。 采集和存储所需的数据。 汇总并结合来自多个来源的数据。 端到端 SLO 的主要特征如下：\n表格 6: 端到端 SLO 特征\n特征 描述 非常高的成本 端到端 SLO 的埋点可能需要数月的工程工作。每个 SLO 都可能带来独特的工程挑战和约束。 高信心 你可以使用多个数据源，并且可以通过交叉引用来跟踪任何数据源中的丢失数据。 高延迟 结合来自多个来源的信号可能既耗时又复杂。持续处理新数据成本高，因此通常优先选择离线批处理解决方案（通常每天或每几小时运行一次）。 覆盖范围窄 端到端 SLO 旨在覆盖非常特定的功能或业务指标，并且以最高的信心度进行。 优先级\n网络、移动应用程序和其他互联网连接设备变得越来越复杂，这推动了微服务架构的兴起，简化和扩展了运行现代应用程序所需的服务。\n全球服务器数量呈指数级增长，这在 GCP 等公共云提供商的增长中可以看到。然而，全球软件工程师的数量增长较为缓慢。\n需要认识到，每个 SLO 都有维护其底层数据，以及响应 SLO 失效的持续成本。某些产品功能也可能会随着时间的推移变得不那么重要，而其他功能可能在产品的整个生命周期中保持关键地位。\n软件工程师和站点可靠性工程师需要优先考虑哪些 SLO 仍然相当重要，它决定了 SRE 要在哪些方面投入时间以提高产品的可靠性。\n产品 SLO\n产品级 SLO 是围绕用户实现目标的步骤定义的。通过利用用户目标步骤信息注释（编者注：打标签或者元数据）和扩展，任何 SLO（如服务、客户端或端到端）都可以转换为产品级 SLO。\n进行将 SLO 与用户目标相互关联的工作看似比较简单，却能够使你理解 SLO 对用户的意义何在，以及它对产品的重要性。\n当 SLO 是以服务和基础设施为框架时，设置目标或延迟阈值存在一定挑战。但当 SLO 带有了用户目标的附加背景信息时，度量的内容会变得更加清晰。例如，与其问“用户数据服务器上的地址查找服务应该有多可靠和快速？”，不如问“用户在查找电子邮件地址时可以容忍多少错误，这些地址应该多快返回？”\n结合产品功能的关键性，你可以验证 SLO 设置是否合适，且不过于严格。这种方法为你提供了更宽的 SLO 目标范围，反应出了什么对产品重要。\n交付物：列出覆盖不同 SLO 类型（可用性、延迟）和监控方法（服务端、客户端、端到端）的产品 SLO 的优先级排序清单。实施最高优先级的 SLO，并将较低优先级的 SLO 创建为待办事项，稍后再进行优先级排序。\n遥测\n在实施产品 SLO 之前，必须先采集相关指标（也称为 SLI），从而跟踪相关的产品功能。为开发出这些指标，需将产品 SLO 模型的概念世界与实际基础设施生产环境对应起来。这是实施产品可靠性模型的关键价值驱动因素。\n例如，团队对 SLO 性能的理解曾经仅限于“数据库写入的可用性为 98%”。而专注于产品的 SLO 需要说明清楚，这 2% 的错误是否导致了 100% 的“保存电子邮件草稿”步骤的失败。\n将概要的可用性度量指标转化为：准确且可操作的产品性能指标的关键在于，理解每个请求所支持的产品功能。除了简单的可观测性需求外，功能请求级信息还可用于流量路由和负载分发策略，确保低优先级功能不会损害更关键的功能。\n虽然你可以通过多种方式将请求与产品功能关联起来，但有需要考虑这样两种主要的方式：客户端注释和服务器端注释。\n表 7: 客户端注释和服务器端注释的比较\n注释类型 描述 用例 客户端注释 更新用户界面（网页和移动应用程序），将用户目标步骤的元数据附加好，并传播到后端服务的 RPC 请求上。这在技术上具有挑战性，需要 UI 团队协助设计，并最终负责维护这些注释。 使用客户端注释是最准确的映射用户通过界面实现目标的方法。注释是由单个的 RPC 请求携带传播的，因此具有最高的保真度。 服务器端注释 分析后端服务器所接收到的 RPC 请求，并推断用户的目标步骤。 当修改客户端的成本太高或你不拥有客户端（如 REST 服务）时，必须使用此方法。服务器端注释不如客户端注释准确，因为服务器需要做出许多假设来推断 RPC 请求所服务用户步骤（功能）。 你可能无法注释所有流量。根据产品的关键性分级，你可以决定哪些地方值得添加注释；你可能只注释那些最关键的用户目标。\n注释一个 RPC 请求后，你的服务需要在整个基础设施堆栈中传播该注释。这有助于你在许多 SRE 工具和流程中理解用户的目标及其重要性，包括以下内容：\n在监控仪表板和应用程序日志中，通过用户目标步骤了解问题及其影响。 快速确定哪个用户目标受到了问题影响，从而确定事故的严重性。 识别只考虑特定的用户目标步骤的服务质量目标 (SLO)，并忽略不重要请求（如批处理和测试流量）。 4. 可靠性管理 现在你已经确定了利益相关者、用户目标和步骤、关键性定义以及产品 SLO，你已准备好支持产品。\n我们建议你从小规模开始支持一个产品或服务。可以先为一些 SLO 启动某一个目标或步骤，然后迭代扩展团队的责任和范围。支持产品是一个持续进行的过程。在每个阶段，你将与利益相关者一起确定在下列投资领域之间的权衡：\n改进支持目标集的指标，以增加这些目标符合预期的信心。 扩展支持目标集，确保产品的所有方面都符合预期。 解决由投资领域 #1 和 #2 产生的指标所突显的性能差距。 确保在所有三个领域都有所投资。在领域 #1 和 #2 投资不足会导致团队错过领域 #3 中最有影响力的问题。另一方面，仅在领域 #1 和 #2 投资不会导致对用户和组织业务目标有帮助的改进。使用在关键实施步骤中收集和产生的信息，帮助组织确定在每个领域投资多少。\n纳管\n纳管是 SRE 团队评估其将承担责任的产品或服务的接手的过程。此过程通常包括了解产品或服务以充分支持，并确保其符合 SRE 团队定义的一系列要求。\n在 SRE 团队承担产品的用户目标和步骤责任之前，团队需要定义一个正式的纳管流程，以确保以下内容：\n目标和步骤足够重要。 步骤映射到所使用的服务，并在这些服务中进行了注释。 潜在的 SLO 已被识别，并在整体产品优先级中进行了优先排序。 SLO 稳定，支持它们不会对团队或服务所有者构成过度负担。 SRE 团队推动这个过程，与相关利益相关者会面，并与产品团队合作解决任何不足之处。\n迭代\n在完成一个目标和其部分步骤的纳管过程之后，你可以通过以下方式迭代和改进团队的覆盖范围：\n纳管更多的用户目标和步骤。 优化已经纳管的用户目标和步骤的覆盖范围。 改进工具，以更好地支持用户目标和步骤。 我们建议不要试图支持每一个用户目标，而是为你支持的产品中最重要的方面设定一个门槛。同样，我们建议你决定哪些用户目标使用更昂贵的 SLO 方法进行埋点。一些用户目标可能只需要基于服务的 SLO，而其他用户目标可能会受益于客户端或端到端的埋点。\n最后，为了确定在哪里和何时投资改进工具，请评估支持的可持续性。工具不足会导致扩展受限，使团队在支持目标集的无效分类、调试和缓解工作中不堪重负。\n离岗\n为了确保团队专注于产品的正确部分，我们建议团队定期重新评估支持的用户目标、步骤和 SLO。一些 SLO 可能随着时间的推移变得不那么重要，而一些用户目标可能会变得过时。\n维护一个所有支持的用户目标、步骤和 SLO 的优先列表是很重要的。使用此列表来验证团队是否在最重要的领域上花费时间和资源。当列表中的项目不再重要（或远不如不支持的项目重要）时，请考虑将它们离岗，以便团队可以重新专注于产品的最重要方面。\n服务器支持\n在关注产品的同时，不能忽视支撑产品的基础设施服务器。始终需要确保服务器及其提供的服务保持健康。无论服务器对产品有多么重要，确保服务器健康是必要的，因为你花费了资源来运行它们。\n在 Google 专注于产品之前，提出了提供基础支持的概念。基础支持是一组由 SRE 定义的标准和最佳实践，使他们能够在不了解服务器具体用途的情况下为任何服务器提供一般支持。例如，基础支持可以要求某些库和框架提供常见功能，如负载平衡、服务间通信（RPCs），甚至是由主要负责服务器的开发团队拥有的最小 SLO。在这种情况下，平台而不是 SRE 提供基础可靠性支持，从而使 SRE 能够专注于不包含在基本策略中的更具影响力的可靠性改进。\n对于最关键的基础设施，可能需要额外的支持，但这不是强制性的。如果 SRE 主要负责最关键的用户目标，关键基础设施中的重大故障将导致产品级别 SLO 失败。此外，基础设施层面上的故障如果不影响产品 SLO，将不会提醒 SRE，可以由拥有该服务的开发团队处理（如未发布的功能和不太关键的批处理服务的问题）。\n将 SRE 支持集中在产品 SLO 上而不是服务上，可以使 SRE 支持更多产品，并将这种支持与产品最重要的部分对齐。\n产品可靠性模型的前提条件 产品导向支持模型并不适用于所有用例。在实施前，建议你评估项目是否满足以下要求，以确定模型的适用性。\n明确的角色和责任\n该模型需要比传统以服务为导向的参与，需要牵扯更多的利益相关者。传统的 SRE 参与通常局限于工程团队，而产品导向的参与则需要与更多角色（如 PM 和 UX）协作。与利益相关者进行有效的互动需要明确的角色和责任分工。即使是加载主页这样简单的操作，也需要有人明确速度标准。如果无法达成共识，就无法用这些结果来度量和管理产品的可靠性。\n用户目标和步骤定义\n正如在“建模产品”中提到的，采用产品导向支持模型需要明确的用户目标和步骤定义。\nSRE 可以尝试为现有产品重新调整和推导用户目标，但失去了组织级别的支持，它的许多其他优势也将丧失。如果决策者不接受产品的定义，也不及时维护，它将很快过时且不准确。\n因此，拥有正确的利益相关协作，并维护好产品模型是关键要求。\n易于维护的服务器\n服务器支持需要提供产品支持模型所需的详细信息。\n基本要求是单个服务器必须相对容易支持。这需要足够的标准和框架，使开发团队能够自行部署和维护，并在必要时由 SRE 提供帮助。\n如果 SRE 大部分时间都在支持某个服务器，他们将没有精力关注产品级别的问题。\n与用户功能的直接映射\n必须尽可能在接近用户的地方度量用户目标和步骤（例如，在用户界面或处理用户界面请求的服务器中），因此更紧密地与堆栈入口点的服务器对齐。\n提供服务API的基础设施服务通常解决特定问题，可能与用户目标无关。例如，数据存储服务可能有一个低级API，仅包含与用户目标无关的简单加载和存储命令。\n以下是将产品支持模型应用于基础设施服务的几种选项：\n表 8: 基础设施服务的产品支持模型的应用选项\n选项 描述 用例 将基础设施客户端视为用户，并为基础设施的API定义用户目标和步骤。 这是最不理想的选项，因为它等同于没有用户目标的产品。然而，在某些情况下，基础设施本身可以被视为一个产品。在这些情况下，产品决策者必须定义该产品，而不是SRE的责任。 可能适用于基础设施本身被视为产品的情况。 配置基础设施客户端，根据其终端用户的输入提供用户目标信息。 此选项通过以下方式帮助基础设施团队：提供有关终端用户目标的有价值信息；帮助基础设施团队识别对终端用户重要的RPC请求。 提供有关终端用户目标的有价值信息；识别对终端用户重要的RPC请求。 不采用产品聚焦方法。 基础设施服务由其服务API定义，可能会从传统的服务支持模型中受益。如果你希望获得产品支持模型的好处，考虑通过其他方式实现这些好处。 传统的服务支持模型可能更适合基础设施服务。 结论 产品支持模型为 SRE 团队提供了一种框架，使他们能够将支持工作集中在对用户和业务最重要的方面。该模型使 SRE 团队与组织的其他团队保持一致，并支持统一的术语和目标。\n该模型通过帮助 SRE 团队理解产品的关键点，并利用这些知识更好地填补服务支持模型的空白，解决了传统服务支持模型的许多问题。最终，产品支持模型让 SRE 团队专注于用户，确保产品满足最终用户的实际需求。\n参考文献 [1] Ulwick, A.W. 和 Osterwalder, A. (2016). Jobs to be done: Theory to practice. [在线] Idea Bite Press. 可在： https://jobs-to-be-done-book.com/\n[2] chang, austin (2017). What To Do If Your Product Isn\u0026rsquo;t Growing. [在线] Initialized Capital. 可在： https://medium.com/initialized-capital/what-to-do-if-your-product-isnt-growing-7eb9d158fc\n[3] Beyer, B., Jones, C., Petoff, J. 和 Murphy, N. (2016). Site reliability engineering: How Google runs production systems. Sebastopol, Ca: O\u0026rsquo;reilly Media.\n[4] Beyer, B., Murphy, N., Rensin, D.K., Kawahara, K. 和 Thorne, S. (2018). The site reliability workbook: Practical ways to implement SRE. Cambridge O\u0026rsquo;reilly.\n[5] Kalbach, J. (2020). The jobs to be done playbook: Align your markets, organizations, and strategy around customer needs. New York: Two Waves Books.\n[6] Google Cloud. (n.d.). Incidents and the Google Cloud Service Health Dashboard | Support Documentation. [在线] 可在： https://cloud.google.com/support/docs/dashboard#major_incident [访问时间：2023 年 4 月 20 日]。\n[7] Wikipedia Contributors (2019). Responsibility Assignment Matrix. [在线] Wikipedia. 可在： https://en.wikipedia.org/wiki/Responsibility_assignment_matrix\n❤️ Photo by Pavel Danilyuk: https://www.pexels.com/photo/group-of-people-discussion-on-a-wooden-table-7868970/\n","date":"2024-06-12T13:25:58+08:00","image":"https://martinliu.cn/blog/product-focused-reliability-for-sre/pexels-pavel-danilyuk-7868970_hu_3d8a3b3519b25502.jpg","permalink":"https://martinliu.cn/blog/product-focused-reliability-for-sre/","title":"Google 白皮书：产品导向的 SRE 可靠性"},{"content":" 本文来源 Dynatrace：《State of SRE in 2023》\n站点可靠性工程（SRE）在组织中变得越来越重要，因为它们希望跟上快速数字化转型的步伐。现在比以往的任何时候，客户更期望高质量、可靠的数字服务，提供无缝的用户体验。SRE 确保了整个数字环境的可靠性和一致性，为组织提供了框架，使其能够持续为客户交付这些理想的体验。\nDynatrace 产品营销总监 Saif Gunja 主持了 2023 年 SRE 状态网络研讨会。参加研讨会的专家成员包括 Kyndryl 的 Danne Aguiar、Red Hat 的 Hilliary Lipsig 和 SquaredUp 的 Stephen Townshend。他们讨论了最佳实践、新兴趋势、建立服务质量目标（SLO）的有效思维方式等。主持人和小组成员共同分享了他们的见解，探讨了组织如何增强其 SRE 努力。\n有效的站点可靠性工程需要企业范围的转型 如果没有对 SRE 实践的统一理解，部门之间很快会形成孤岛。缺乏协作会导致观测数据的分散，使团队在交付价值时几乎没有信息可依赖。没有成熟的 SRE 应用实践，生产力会因此受到影响。\n接受 SRE 的文化转变是打破这些孤岛的关键。研讨会专家成员强调了：整个组织向 SRE 采用的文化转变的必要性。他们还强调了高层支持对于文化转变的重要性。Townshend 说：“没有高层支持，你会遇到瓶颈，由于优先事项的竞争，你根本无法取得任何 SRE 的进展。”\nGunja 表示同意。他说：“如果这不是一种文化变革，如果不是自上而下的变革，那么很可能会失败。即使是自上而下的变革，仍然会有很多障碍需要克服。”\nLipsig 从另一个角度看到了这种现象。在她的组织中，自上而下的 SRE 采用显著改善了孤岛的文化。她说：“我看到很多以前不存在或者有些紧张的关系在过去 12 个月里有了很大的改善。”显然，高层的支持简化了各团队对 SRE 的理解，增加了组织内的协作和教育。\n然而，尽管这种转型对于实现业务目标是必要的，许多高层管理人员仍然犹豫是否采用 SRE 实践。这往往是由于缺乏对 SRE 在实现关键绩效目标（服务质量目标，SLO）中的作用的理解。\n为克服这一障碍，研讨会专家成员建议：工程师通过业务数据向高层管理人员传达 SRE 的价值。在收集这些指标后，工程师可以展示：在企业内大范围的应用 SRE 实践，如何有助于减少琐事、员工倦怠（各种卷）、运营费用和未达标的服务质量目标（SLO）数量。\n服务质量目标（SLO）应聚焦，并由高阶业务目标驱动 在创建 SLO 以度量 SRE 成功时，重要的是要考虑这些目标将如何为组织带来益处。有时，工程团队可能会专注于技术细节，而忽视了整体业务目标。团队应确保即使是最小的 SLO ，也能使之与业务增长相关。\n然而，想要理解技术 SLO 如何影响业务结果，其实并不总是那么直观。例如，减少平均修复时间（MTTR）对收入的影响有多大？要回答这些问题，跨职能合作对于组织的成功至关重要。不同技能团队之间的沟通可以帮助澄清 SLO 与业务结果之间的联系。\n需要注意的是，创建以业务为中心的 SLO 并不意味着仅关注高阶目标。实际上，研讨会专家成员强调了创建更小的 SLO 以更好地度量进展的重要性。通过识别小的胜利，团队可以避免被实现更大目标的压力所压垮。这些小的胜利，如实施无责根本原因分析过程，可以采取多种形式，不一定涉及数字指标。\n对于构建以业务为中心的 SLO 的组织，Aguiar 提出了一些建议。他说：“如果你的公司有服务质量协议（SLA），就从那里开始。你可以用这个由 SLA 设置的特定 SLO 进行实践，然后再定义其他的。”\nLipsig 也提供了一些建议。她说：“选择一项衡量客户在使用你的产品时是否成功的指标，然后研究如何度量它。” 以业务为中心的 SLO 是由客户成功驱动的：当客户成功时，业务也会成功。因此，仔细考虑客户需求是创建有效 SLO 的关键。\n客户同理心是优化站点可靠性工程（SRE）实践的关键 软件工程往往是一门缺乏人情味的学科。SRE 通常不直接面对客户，因此容易误解客户的痛点。这种缺乏了解会导致缓慢的故障解决时间和无效的方案。此外，客户可能会因组织内协作不佳而感到沮丧，导致客户留存率下降。\n在 SRE 中，跨部门合作对于建立客户关系至关重要。研讨会专家成员鼓励工程师与客户成功团队协作，以更好地了解客户的情况，并满足关键需求。Lipsig 分享道：“我与我们的客户成功工程师建立了非常好的合作关系。” 但她也强调了内部合作的重要性：“与客户建立信任并不是我一个人可以完成的。”\n了解客户需求有助于在组织与客户之间建立信任，从而让客户更愿意接受 SRE 团队的建议，这也赋予工程师更多的主动权。\n小组成员还强调了在处理客户互动时“软技能”的重要性。尊重和耐心地与客户沟通是建立信任的关键。他们还指出，这种做法不仅适用于客户，也适用于组织内部的同事。\n生成式 AI 与站点可靠性工程的未来 “AI 在应用性能管理（APM）领域并不新鲜，”Aguiar 提醒道。最近在生成式 AI 方面的突破可能为各种组织中的 SRE 团队提供优势。例如，生成式 AI 具有提供更直观的数据查询方法的潜力。通过其自然语言处理能力，这样的能力使得在不使用格式化查询语言的情况下，获取数据分析洞见。成为可能。减少了数据访问的障碍和孤立。\n生成式 AI 还可以通过允许用户提出有关架构和数字环境的具体问题来优化根本原因分析。快速、可靠的答案获取，促进了团队之间的快速学习。这将减少平均修复时间（MTTR）并提高生产力。\n研讨会专家成员推测，AI 将通过高效执行任务改善 SRE 团队的生活质量。Aguiar 预测，生成式 AI 的一个关键功能是基于过去的经验创建操作手册（Playbook）。这将有可能在很大程度上消除手动干预和冗长的流程，以解决常规发生的事故。然而，Lipsig 提醒小组成员，SRE 在各个组织中的表现 有所不同。她说：“我们会看到很多不同类型的影响，而不是生成式 AI 带来的一个确定性的影响。”\n生成式 AI 是 SRE 团队可以独特应用于其实践中的一种有前途的新手段。它可以实现更高的效率，但它并不能完全替代某些现有的可靠性措施。\n成功的站点可靠性工程重在预防而非被动响应 意外的系统中断、服务器过载和其他不可预见的事件，不仅会严重影响 SRE 的生产力，还会对组织的盈利能力造成潜在的灾难性影响。这些问题可能导致大量计划外的工作，使 SRE 处于被动状态，效率和进展受到阻碍。在这种被动模式下进行根本原因分析，通常时间漫长且代价昂贵，使 SRE 资源紧张。为了改变这种情况，SRE 团队必须启动计划内的工作，开始采取主动的防范措施。\n主动 SRE 模型的一个关键组成部分是实施端到端监控，包括不直接由 SRE 团队管理的系统。通过保持对客户和供应商系统的强大可观测性，团队可以在软件问题扩散之前识别出潜在问题。强大的黑盒监控、负载均衡分析和定期系统检查，都是有效的主动措施，可以显著提高生产力和预防事故。\n随着组织在数据收集和存储上投入大量资源，SRE 团队更有动力从被动工作模式转变。宝贵的数据在被动模式下未被充分利用，仅用于应急响应而非预防。组织应通过创建强调预防的工作流程，充分发挥数据驱动见解的潜力，而不是仅仅依赖于应急处理。\n“我们开始在服务质量指标（SLI）违反时响应警报，以便始终保持我们的服务质量目标（SLO），”Lipsig 说道，谈到 Red Hat 的 SRE 如何处理事故时。“我们从不会超出我们的错误预算。” 一旦团队开始主动使用数据，“他们可以用这些数据做有意义的工作，而不仅仅是用于应急响应。”\n提升协作是达成 SLO 的关键 在当今的技术环境中，对于云原生架构下的软件工程方法存在显著争论。无论是 SRE、DevOps 还是平台工程，研讨会专家成员都认为部门分类远不如实际工作重要。团队应专注于有效和高效地达成 SLO，而不是纠结于职位头衔。要打破 DevOps、SRE 和平台工程是对立的思维定式，是缓解孤岛效应和确保 SLO 满足的关键一步。\n“SRE 是关于设计、构建和大规模运营可靠服务，” Townshend 说道。“只要我在做这些事情，我认为我就是成功的。”\n❤️ Photo by Pavel Danilyuk from Pexels: https://www.pexels.com/photo/a-person-using-a-laptop-outside-at-night-9143840/\n","date":"2024-06-10T09:29:28+08:00","image":"https://martinliu.cn/blog/state-of-sre-in-2023/pexels-pavel-danilyuk-9143840_hu_4627479e8fc10034.jpg","permalink":"https://martinliu.cn/blog/state-of-sre-in-2023/","title":"Dynatrace 出品 2023 年 SRE 状态报告"},{"content":" 本文来源 Gartner ：《How Platform Engineering Teams Can Augment DevOps With AI》\n概述 主要发现 许多组织已经在使用 AI 编码助手、AI 测试工具和 AIOps 平台来优化 DevOps 的特定活动。然而，要缩短整体交付时间，必须识别并克服软件交付各阶段的瓶颈。 生成式 AI 为在软件开发生命周期 (SDLC) 的多个阶段中，减少开发者摩擦，并提升开发者体验方面，带来了新机遇。这些摩擦包括：对代码库的理解不足，以及调试、代码审查和根本原因分析中花费的大量时间。 提升软件交付流程的效率需要优化和协调 SDLC 的所有阶段。常见的低效表现包括：长时间的构建过程、分析构建流水线错误、变更影响分析和缓慢的事件响应。 AI 提供了传统自动化无法比拟的优势，帮助产品团队以更可靠、可持续和成本效益高的方式，来管理其软件交付基础设施。 建议 推动平台工程计划的软件工程领导者应：\n通过识别和优先解决软件交付流程中的瓶颈，确定适合的 AI 应用场景，从而系统地改进 SDLC。注意供应商的“AI 洗涤”现象，避免在传统自动化手段已经足够的情况下，还要使用 AI 技术进行过度设计。 通过支持 AI 增强的工作流来改善开发者体验，减少认知负担，帮助开发者在开发、交付和运营阶段实现流畅的工作状态。 通过将 AI 优化集成到 DevOps 流程中，提高各个 SDLC 活动的反馈效率。 在内部开发平台中，提供自助式 AI 基础设施管理能力，以优化软件交付基础设施。 战略规划假设 预计到2027年，使用 AI 增强 SDLC 每个阶段的平台工程团队的比例将从 5% 增至 40%。\n介绍 随着 AI 编码助手和 ChatGPT 的推出，软件开发成为生成式 AI 的主要应用领域之一。在 2023 年 Gartner 关于生成式 AI 的 IT 领导者调查中，52% 的 IT 领导者表示：他们期望团队在软件开发中使用生成式 AI。Gartner 同行社区成员的调查显示，61% 的软件工程领导者对生成式 AI 在代码生成中的潜力感到兴奋。\n然而，开发人员并不总是花大部分时间在编写代码上。他们平均只有 10% 到 25% 的时间用于编写代码。其余的时间则用在阅读规范、写文档、做代码审查、参加会议、帮助同事、调试代码、与其他团队协作、配置环境、处理生产故障、学习技术及业务知识等方面。因此，若只关注代码编写，而忽略了 DevOps 流程的其他环节，可能就不会暴露出开发周期中的其他低效问题，而无法提升整体性能。\n因此，我们的客户开始从更广泛的角度看待 AI 在 DevOps 中的应用，并提出诸如：“在未来三年内，AI 将如何影响 DevOps/DevSecOps？”，以及“我们如何在敏捷和 DevOps 流程中全面应用 AI？”等问题。\n集中化平台的快速发展，以及在软件开发生命周期各阶段（从构思和规划到生产部署管理）整合 AI/ML，将彻底改变软件工程。 ——JPMorgan Chase 工程师平台和体验负责人 Sandhya Sridharan\n平台工程团队将在解决这些问题中起到关键作用，因为他们的职责是：帮助开发团队提升交付速度、软件质量和大规模的开发者体验。他们需要了解现有和潜在平台用户的需求，从多个产品开发团队的挑战中获取独特的洞见。\n平台工程团队应采取三管齐下的方法，通过 AI 工具和技术来增强 DevOps 工作流（见图 1）：\n改善开发者体验：在 SDLC 各阶段，AI 增强的用例包括：代码建议和代码解释、总结拉取请求的变更，解释流水线错误，以及使用自然语言查询操作数据和服务健康状态。 提升软件交付工作流的效率：AI 优化的例子包括：测试影响分析（缩短构建时间）、自动化代码审查和变更影响分析（辅助人工监督）、以及事件关联（缩短事故解决时间）。 优化软件交付基础设施：AI 技术的例子包括：自主工作负载优化和增强的 FinOps，从而优化可靠性、成本和环境可持续性。 分析 识别并优先解决 SDLC 中的瓶颈 想要通过 AI 增强 DevOps 工作流的平台工程团队，应该先识别并优先解决阻碍 SDLC 工作流的瓶颈。\n这些瓶颈主要有两种：\n跨越 SDLC 各阶段的工作流障碍 SDLC 每个阶段内部的工作流障碍 第一类瓶颈可以在系统性审视整个软件交付价值流时得到显现。系统性视角让我们能够识别到，哪些存在于 SDLC 各角色和团队“交接工作”过程中的瓶颈。\n涉及多个阶段或多个团队的瓶颈示例如下：\n开发人员等待设计师和产品经理的输入 运营团队等待分析变更的影响 安全团队执行部署前检查 某些瓶颈可能被认为是“必要的”，但无论如何，这些延迟对客户来说并没有增加价值（见图 2）。\n第二类限制更容易发现，因为它们出现在“单一工作线程”中。这些逻辑上的工作线程的例子如下：\n开发流程内部（编码、构建、测试、调试、重构、提交） 代码检入过程（拉取请求、代码审查、安全检查） 持续集成（构建代码、运行单元测试、运行 SAST/DAST 测试、运行服务健康检查） 环境管理（创建虚拟机、容器编排、设置基础设施） 事故响应（分类警报、事件关联、分析日志、根本原因分析） 在每个阶段，不同团队可能面临着不同的限制。例如，处理遗留代码库，并进行增量更改的团队发现最大的限制不是编码效率，而是对旧代码库缺乏理解。因此，平台工程团队需要与产品工程团队合作，了解开发者的痛点，确保 AI 功能的实现是基于实际需求的。\n图 3 重点分析了在每个工作线程中的具体活动，并展示了 AI 如何解决这些限制和瓶颈。无法一次解决所有问题—— 因此，应识别并迭代地解决此时此刻的最大的限制约束点（见注释 1）。\n改善开发者体验 改善开发者体验已成为软件工程领导者的关键优先事项，58% 的领导者表示，这对他们的组织高管层非常重要。提升开发者体验或生产力是开发者平台和工具类技术和实践的首要价值因素。因此，平台工程团队在使用 AI 增强 DevOps 工作流的第一步应集中在改善使用平台的人员体验上。\n图 4 展示了在软件开发、交付和运营过程中，通过 AI 增强改善开发者体验的使用案例。\n通过 AI 使能开发者的使用案例改善的开发者体验涵盖整个 SDLC，从开发、交付到运营。以下是 AI 在各阶段提升开发者体验的方式：\n开发 在开发阶段，开发者体验主要受认知负荷和上下文切换次数的影响。AI 编码助手可以在 IDE 内提供相关信息，减少开发者的上下文切换，避免他们需要离开开发环境去网上查找信息。\n帮助开发者减少认知负荷并实现流畅工作的 AI 功能包括：\n代码生成 代码理解 辅助调试 文档生成 漏洞解释 自动修复 有关提供这些功能的代表性工具的详细分析，请参见《AI 编码助手创新指南》和《AI 增强软件测试工具市场指南》。\n交付 在软件交付阶段，改善开发者体验的重点是缩短反馈周期和减少重复的低价值工作。AI 使能的功能示例包括：\n自动建议修复构建错误 预防变更失败（通过变更影响分析和变更风险预测） 缩短构建时间（使用智能测试选择） 这些功能可以为开发者提供更快的反馈。CircleCI、Digital.ai、GitLab 和 Harness 等供应商正将 AI 增强功能集成到 DevOps 平台中（见《DevOps 平台魔力象限》）。\n运营 这一阶段传统上主要依靠 AIOps（预测 AI）功能，通过异常检测、事件关联和基于警报和遥测数据生成见解来加速事故响应（见《AIOps 平台市场指南》）。\n生成式 AI 可以通过以下方式进一步消减常规任务：\n根据事故模式自动生成运行手册-run-book（例如 Shoreline 和 Transposit 等供应商） 在事故响应期间通过总结、解释、翻译、内容生成、预测和建议来减少值班工程师的认知负荷。这在值班工程师不熟悉引发事故的代码时尤为重要（例如 BMC、PagerDuty、ServiceNow、Shoreline 和 Transposit 等供应商）。 在故障排除或自动化 DevOps 工作流时，使用自然语言（例如“描述最近对生产环境的变更有哪些？”）（例如 Cortex、Kubiya、New Relic 和 Dynatrace 等供应商）。 提升软件交付效率 除了改善软件交付工作流中的开发者体验，AI 还具有优化工作流效率的潜力。平台工程团队可以在创建“铺装道路”时集成 AI 功能，以简化从构思到生产的价值流动。在此过程中，他们可以系统地了解从客户承诺到客户看到结果的整个工作过程。系统视图通常是价值流映射的一部分（见《DevOps 流程价值流映射指南》）。\n单靠自动代码生成来提升软件交付性能，在超过一定阈值后会，所产生收益会递减——因为最大的价值交付瓶颈可能在其他地方（见注释 1）。图 5 显示了帮助克服 SDLC 限制（约束点）的 AI 使能案例（如第一部分所述）。\n图 6 展示了用于实现上述使用案例的一些工具，并不限于所展示的示例。供应商正在迅速扩展其功能，因此一个供应商可能支持比这里描述的更多使用案例。\nAI 增强开发的下游影响\nAI 编码助手使开发者的编写代码效率提升，但这也带来一个意外的副作用：代码审查和安全审查的工作量积压增加。缓慢的代码审查会降低整体开发效率。根据 2023 年 DORA 报告，代码审查速度快的团队其软件交付性能提高了 50%。平台工程团队可以看清这些系统性互相关系，适合推动系统性变革，而不仅仅是局部改进。\n因此，平台工程团队在支持 AI 增强开发工具的同时，必须补充卓越的 DevSecOps 实践。否则，我们将面临开发者产生虚假的安全感、重复代码和未经审查的代码推送，进而导致质量和安全问题。\n优化软件交付基础设施 平台工程团队负责管理、治理并向产品团队提供软件交付基础设施。然而，规模化管理软件交付基础设施非常复杂，如下公式所示：\n软件交付基础设施 = （支持所有环境中应用及其组件的完整 SDLC 的基础设施）x（应用数量）\n软件交付基础设施不仅限于生产环境，还包括开发、测试、压力测试和预发布环境。此外，基础设施还必须支持部署和测试应用所需的各个组件。这些组件可能包括源代码管理系统、云开发环境、持续集成服务器、数据库服务器，以及运行时基础设施堆栈（由物理主机、虚拟机容器和应用运行时组成）。\n产品团队越来越期望自助工具能够在成本、可靠性和可持续性之间实现优化（见图 7）。\n通过自助内部开发平台优化云原生软件交付基础设施\n优化公有云基础设施变得尤为困难，但也非常重要。这主要是由于云服务种类繁多、定价模式不一致、云原生应用的分布式特性以及流量模式的季节性变化。为了可靠、经济和可持续地管理基础设施，平台工程团队应为产品团队提供支持 AI 增强的自助平台和工具，以优化成本、可靠性和可持续性。\n新兴技术如自主工作负载优化和增强的 FinOps，可以自动化优化价格和性能，同时实现预定义的业务目标。供应商包括 Akamas、Anodot、Apptio、Avesha、CAST AI、Densify、Google Cloud（Active Assist、Duet AI）、IBM（Turbonomic）、Sedai 和 StormForge。图 8 显示了这些工具支持的 AI 增强使用案例。\n平台工程团队应将这些技术整合到内部开发平台中，以优化计算基础设施。这使开发人员和站点可靠性工程师能够可靠且经济地管理和运行应用程序（见 2023 年 IT 管理智能炒作周期）。\n快速回答 在使用 AI 增强 DevOps 工作流时需要注意哪些陷阱？\n软件工程领导者必须警惕潜在的陷阱和意外的副作用：\n注意供应商的“AI 洗涤”，避免在传统自动化选项足够时，还用 AI 技术过度再造设计。通过组建跨职能团队进行试点，创建和验证相关假设进行前后对比分析。使用结果驱动的 KPI 来定义和衡量成功。 将 AI 应用于 SDLC 的某个部分（局部），可能会导致工作量的转移，而不是节省，从而产生一种虚假的时间节省感。例如，在编码过程中节省了时间，可能会因为代码审查和调试时间的增加，而正负抵消（见评估生成式 AI 如何改善开发者体验）。 尽管 AI 旨在降低认知负荷，但它也可能无意中降低认知技能水平。是人类员工的认知技能在不使用的情况下，而随之退化，这使我们在 AI 工具达到其极限时，反而无法做出正确决策。使用 AI 作为决策引擎的另一个风险是，它会降低人类对系统运行方式的理解，并导致缺乏情境意识。 大多数生成式 AI 工具无法确保输出的一致性、准确性、可重复性和可预测性。“幻觉”使当前的技术难以胜任关键任务。然而，涉及检索增强生成（RAG）和模型微调的技术，可以通过访问最新的知识源和特定上下文数据来减少幻觉。使用基础模型作为控制器来构建执行狭窄任务的智能体也有前景。例如，Adept、AgentGPT、AutoGPT 和 Agents for Amazon Bedrock。Gartner 称这些为“自主智能体”（见 2023 年生成式 AI 炒作周期）。 证据 Gartner IT 领导者对软件工程生成式 AI 的调查：这项调查于 2023 年 5 月 2 日至 8 日在线进行，旨在收集生成式 AI 在软件工程中的当前和预期使用情况数据。共有 91 名 IT 领导者参加，他们是 Gartner 研究圈的成员，一个由 Gartner 管理的小组。参与者主要来自北美（n = 44）和 EMEA（n = 33）；其他受访者来自亚太地区（n = 12）和拉丁美洲（n = 2）。免责声明：本次调查结果仅反映受访者和其公司的观点，不代表全球情况或整个市场。 生成式 AI 对软件工程团队的影响 软件开发人员的日常工作：微软 软件开发中 AI 的现状，GitLab 全球代码时间报告，基于 25 万多名开发人员的数据，Software.com 2023 年 DevOps 状态报告，基于 3000 名专业人员的数据，Google Cloud 自动化的讽刺——Lisanne Bainbridge 国家人类系统集成委员会（BOHSI）小组：人类与 AI 团队合作：研究前沿，ResearchGate 注释 1 在《目标》一书中，Eliyahu Goldratt 博士将约束定义为“限制系统实现更高性能的因素”。\n缓解最关键的约束对整体系统性能有着巨大影响。因此，我们必须迭代地识别、优先处理，并解决阻碍团队交付价值的最大约束。\n❤️ Photo by Pavel Danilyuk: https://www.pexels.com/photo/a-robot-holding-a-cup-8439093/\n","date":"2024-06-05T16:36:07+08:00","image":"https://martinliu.cn/blog/pe-team-augment-devops-with-ai/pexels-pavel-danilyuk-8439093_hu_d7ea0c05f7d44a63.jpg","permalink":"https://martinliu.cn/blog/pe-team-augment-devops-with-ai/","title":"平台工程团队如何利用 AI 增强 DevOps"},{"content":" 译者：刘征\n下载中文版 PDF 文件 下载英文版 PDF 文件 从 Oreilly 阅读白皮书 从 Google 下载白皮书 为完善本报告中的观点，我们与来自不同行业的三位 SRE 领导者进行了交谈，他们在过去几年中以各种形式采用了 SRE。每个人都有关于采用 SRE 的独特故事以及他们可能会做出不同选择的见解，此外还有关于在他们的行业或组织中使 SRE 工作的洞见。\n医疗保健 // Joseph Joseph Bironas 自从担任 Google SRE 领导者后，一直在多个医疗保健组织中领导 SRE 的采用。因此，他能够提供一个行业层面的观点，说明在这一领域实施 SRE 如何与其他技术和初创文化不同。由于其生命攸关的工作流程的性质，可靠性通常是首要考虑的问题。然而，医疗保健行业面临着组织模式、文化、预算和监管要求方面的特定挑战。\n在与一家专注于利润空间极窄的医疗设备制造及 FDA 监管领域的公司合作后，Joseph 观察到，虽然可靠性被视为一种需求，但在该行业中 SRE 的成本效益却未被充分理解。因此，SRE 和基础设施团队可能会发现自己成为“全能工程”，被纳入 IT 成本中心，职责范围大幅增加。\n你可能会问，将 SRE 团队归属在 IT 成本中心下有什么问题？当企业习惯于通过广泛的 IT 框架（如 ITIL）进行管理时，很难对 SRE 做出价值判断，而 SRE 只是 ITIL 的一部分——ITIL 还处理像硬件采购等 SRE 不涉及的事情。更重要的是，管理所有公司和生产 IT 的 CIO 并不是做出软件系统可靠性判断的最佳人选。相反，归属于专注于软件的领导者（例如工程高级副总裁（SVP）或 CTO）更为合理。\n该领域的组织往往面临着希望采用 SRE 而尚未采用 DevOps 实践的陡峭曲线。例如，由于涉及法规和全组织合规控制的复杂性，他们每月只发布一次软件，并且几乎没有 CI/CD 自动化。许多医疗保健组织根本不愿快速部署：对于某些客户来说，快速部署意味着测试不足或安全性不足。\n实施变革（如转向 SRE）的意愿在整个行业中差异很大，可能是由于领导优先事项和风格的不同。Joseph 描述了一个团队能够派遣设计师到现场收集需求，建立新工作流程，通过更好的产品革新护理的场景。在另一个场景中，一个不同的团队只被激励比现任者做得更好，这不需要同样的投资水平。在第三个场景中，一个团队被惯性困扰，在做出任何变革或投资之前等待自上而下的命令。根据 Joseph 的经验，更进步的领导往往对客户对可靠性的需求更敏感。\n与初创文化相比，这些团队的一些变革非常缓慢。一个团队质疑他们是否能在 18 个月内完成“任何事情”（如采用 SRE）——对于初创企业来说，这段时间几乎是永恒的。在考虑这种节奏的组织中的重大变革时，你必须有模型来帮助理解计划的投资回报。了解 J 曲线（见屋顶射击与登月计划（roofshots versus moonshots））在这里很重要，以避免在低谷中放弃努力，错过真正的回报。Joseph 建议每季度与团队进行检查，以保持进展的稳定节奏。他建议在专注于 SLO 之前，从事件响应开始转向 SRE，并通过事件评审（例如，持续六个月）建立持续学习的循环。为了进行“真正的投资”而不是无声地失败，你可能需要寻求高管的赞助，实施顶层 OKR，或专注于使努力在你的组织中“真实”的任何事情。关键不仅是从这个循环中学习，还要将所学付诸实践。\n另一个在医疗保健行业中常见的错误是忽视 SRE 的“软件方面”，当团队习惯于专注于传统运维工作时，认为“通过软件可以大幅减少 IT 支出”这种核心价值通常是领导者所陌生的概念，甚至可能被一些根深蒂固的系统管理员和操作人员故意抵制或破坏。忽视这一方面会使 SRE 显得非常无效。软件工程也很困难且昂贵。即使你购买了商业 SRE 相关工具（尽管有多年的大量贡献者，但这些工具仍不完美），你也无法逃避集成工作，这在很大程度上是一项软件工程工作。\n为可靠性制定预算也可能是一个问题。Joseph 指出，“这个行业没有 [Google 在建立 SRE 时拥有的] 广告收入曲线。” 这影响了他们像 Google 那样专业化和投资的能力，导致他们更多地依赖商业解决方案。业务预算和规划通常仍然采用瀑布模式，这对 SRE 工作来说是一个挑战——探索、理解和设计新解决方案所需的时间不适合瀑布式工作方式。\n从中得到的启示是，这些问题可以适用于所有行业。Joseph 分享了一个故事，说明即使是不完美的尝试也可以是一个有价值的起点。在他曾合作的一家公司中，领导层希望有一个极其简单的错误预算版本。他们没有选择适合其关键用户旅程 (CUJ) 的 SLO，而是为所有内容设定了一个单一的 SLO（99.95% 可用）。这个目标虽然简单易懂，但却削弱了整个工程团队对 SLO 概念的信心。状态和无状态应用程序、批处理和实时应用程序都采用相同的 SLO，这最终是无用的，并削弱了对该技术的信心。这也导致了毫无意义的错误预算，因此这些预算同样被削弱，任何试图使用这些错误预算的过程也被削弱。\n零售业 // Kip 和 Randy The Home Depot（THD）的 Commodore “Kip” Primous 和 Randall Lee 分享了这家大型零售商如何采用 SRE 的经验、成功之处以及面临的一些挑战。THD 是 Google Cloud Platform（GCP）的早期大型零售客户之一，在采用云服务的过程中，他们也遵循最近出版的 SRE 书中的原则采用了 SRE。六年后，他们当初期望构建的与现在存在的截然不同。\nKip 最初是“点商”业务部门的可靠性工程（RE）经理，负责 THD 电子商务网站“浏览堆栈”的工作。Randy 比 Kip 早加入 THD，他们分享了一个共同的 SRE 目标：通过更好的平台提高弹性。他们最初考虑建立自己的云和数据中心，但后来评估了各种云服务提供商，并最终选择了 GCP。在向云迁移的过程中，唯一成功的方法是同时改变他们的工作方式，采用类似 SRE 或“DevOps 2.0”的方法。\n最初，THD 的目标是摆脱庞大的单体商业服务。Aurora 项目由副总裁资助并推动，目的是实现规模经济，减少运营团队的规模，将团队从数百名承包商转变为显著减少的全职员工。还有一个普遍的意图是提高可靠性，减少对组织内部其他可能不完全一致的团队的依赖。点商团队希望能够以“互联网速度”运作。\n对齐非常重要。在迁移到云之前，每次部署都“像发射航天飞机：需要多年努力的协调”。团队觉得目前的 DevOps 模式在 THD/点商内部已经走到了尽头。通过引入 RE，团队能够在新平台和新的职责下采用新的工作模式，并有能力解决任何与可靠性相关的问题。他们雇佣了很多云原生工程师，并尽可能地实现自动化。他们能够突破限制现有 DevOps 团队的边界。\n从 2015 年到 2017 年，SRE 团队能够快速独立地行动，因为他们在新的云基础设施上使用现代工具和硬件工作。然后在 2018 年，企业团队赶上了步伐——SRE 不再是唯一在 GCP 上工作的团队。令人欣慰的是，双方在企业团队更新传统模型时实现了融合——例如，承认在新的短暂虚拟机环境中不应再跟踪单个机器的补丁。通过一系列建设性的对话将团队聚集在一起，点商 RE 团队能够与新成立的集中企业团队合作，帮助建立更符合企业需求的流程和更好的安全准则。此外，他们能够将 GCP 平台的大部分管理工作（如计费、权限、配额等）从 RE 团队转移到企业团队。\n在 THD 进行 SRE 之旅的过程中，Kip 和 Randy 观察到了一些模式和经验，这些经验和模式可能适用于其他行业。让其他团队采用 SRE 概念的过程花了几年时间，并且是循环进行的：推动合规自动化、成本改进、访问控制和网络安全的改进。每次互动都需要大量讨论和教育。在故障或停机很少的平静时期，紧迫感可能来自外部事件。Equifax 故障或 Akamai 或 Facebook 的 DNS 问题可能会引发新一轮的可靠性改进。\n高管的支持对 SRE 在 THD 内部的成功采用至关重要。在点商团队通过使用 SRE 模型成功迁移到云后，SRE 角色在公司内变得与高绩效同义。许多其他团队希望复制这一模型，有些团队即使没有明确的 SLO 要求也被迫实施 SRE。然而，并不是所有团队都像点商团队那样幸运，可以从零开始并采用云原生。这导致一些团队难以认识到 RE 团队所带来的价值，有时会误解角色和责任的期望。当一个团队与组织中的“非官方” RE 互动时，这种模糊性可能会导致问题，因为这些 RE 可能无法在同一水平上工作或使用与原始团队相同的原则。例如，有些人“只是按按钮”，而没有真正的自动化琐事计划。这样的经历会让团队对未来与其他 RE 团队的合作失去兴趣。\nKip 还警告说，如果每隔几年没有新的 SRE 启发的努力，可靠性标准会退化。RE 团队打破了壁垒，但这些壁垒正在重新建立。团队认为，“可靠性不是我的问题，这是 RE 的问题！”这传递了错误的信号。Randy 补充说，一个运行良好的 RE 团队如果没有不断强化和教育 RE 的实践和原则，以及明确的角色和责任定义，就会倒退。\n目前，THD 正在“加倍”投入 RE，但如果变革没有坚持 SRE 的原则，这实际上可能是一种反模式。SRE 不是解决所有问题的万能药，但当一个团队看到 SRE 的成功时，很难不想将 SRE 应用于各个方面。最近，Kip 被要求在分销中心和供应商支持的物理硬件上运行 RE，这并不适合 SRE。虽然总是有机会提高这些系统的可靠性，但在非云原生环境中应用许多 RE 实践更具挑战性。对于某些业务领域，可能更好的前进路径不是 SRE，而是价值流图（Value Stream Mapping）或精益（Lean）等实践。为了避免这些问题，更有意义的是将 SRE 作为“拉动”模型，而不是“推送”模型：不要强迫团队使用 SRE，而是将其作为一种服务提供，让团队自主选择。\nKip 和 Randy 的最大建议是专注于高管教育，并认识到拥护者的价值。如果没有自上而下的支持，很难为任何有意义的变革筹集资金。通过产品开发团队获得资金会导致这些团队“从不想支付这笔税”的现象。每当他们支付这笔税时，只希望 SRE 直接为他们的产品工作并朝着他们的产品目标努力。\n在 THD，最初有一位高级领导倡导创建和发展点商 RE 团队以及其他领域的 RE 团队。THD 现在处于一个尴尬的境地，有许多 RE 团队在不同的项目上工作，应用 SRE 原则的能力各不相同。Randy 和 Kip 认为，拥有一个更高级的领导者可能会改善 THD 的状况。一个负责所有 RE 角色的可靠性副总裁（VP of Reliability）可以提供规模经济。没有中央 RE 组织，SRE 角色可能会演变成不同组织中的 SRE 完全做着不同的事情，并遵循不同的标准和原则。\n结论 我们希望这份报告能够为企业如何采用 SRE 以及可能面临的挑战提供一些见解。我们认为，如果您清晰地定义 SRE 原则，将这些原则映射到具体的实践和能力，并优先培养团队内的成长，成功的机会会更高。我们还展示了一些团队在企业内部启动 SRE 实践的过程中所经历的例子，以及他们所面临和克服的具体挑战。\n我们相信这份报告将有助于您采用 SRE，带来更可靠的技术体验。希望通过这种采用，运营团队可以变得更可持续，服务更具扩展性，开发速度得到提升。\n“愿所有请求顺利，警报永不响起。”\n关于作者 James Brookbank 是 Google 的一名云解决方案架构师。解决方案架构师通过解决复杂的技术问题并提供专业的架构指导，帮助 Google 的客户更轻松地使用云服务。在加入 Google 之前，James 曾在多家大型企业工作，专注于 IT 基础设施和金融服务。\nSteve McGhee 是一位可靠性倡导者，帮助团队了解如何最佳地构建和运营世界级的可靠服务。在此之前，他在 Google 担任了超过 10 年的 SRE，学习如何在搜索、YouTube、Android 和云中扩展全球系统。他曾在加利福尼亚、日本和英国管理多个工程团队。Steve 还曾在一家加利福尼亚的企业工作，帮助他们向云迁移。\nFeature picture ❤️ Anete Lusina: https://www.pexels.com/photo/miniature-toy-car-on-top-of-monopoly-board-game-4792380/\n","date":"2024-05-04T01:01:05+08:00","image":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre-chapter6/pexels-anete-lusina-4792380_hu_d7434be65f18690f.jpg","permalink":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre-chapter6/","title":"《企业 SRE 路线图》第六章：不限于谷歌"},{"content":" 译者：刘征\n下载中文版 PDF 文件 下载英文版 PDF 文件 从 Oreilly 阅读白皮书 从 Google 下载白皮书 一旦你决定 SRE 值得在你的组织中推行并决心投资于它，确保你的投资取得成功至关重要。在系统中引入变革总是困难的，但要让这种变革持续下去则更难。以下是一些关于如何在你的组织中保持 SRE 运作的建议。\n思考要大，行动要小 “如果你不能衡量它，你就不能管理它”这句话经常与 Edwards Deming 联系在一起。然而，完整的引用是“认为你不能衡量它就不能管理它，这是一个代价高昂的谬论。”SRE 的核心是一种以指标驱动的方法。然而，无论有多少 SLO 或 SLI，都无法帮助你理解你的 SRE 实践是否有效并与企业战略一致。你必须通过持续的实验和学习来发现这一点。\n在前面的章节中，我们要求你“思考要大”，但在培养成功方面，你应该“行动要小”。任何形式的大规模变革都需要通过迭代和渐进的方式实现，SRE 也不例外。但有一个明显的警告——如果你的时间线太短，你将无法取得有意义的改变，所以要准备好找到平衡。\nGoogle 内部使用目标和关键结果 (OKR) 来共享目标和对齐团队，即使在实现这些目标的方法不总是明确时。你的组织可能有自己的流程来实现这一点，但必须扩展到包括明确的迭代和定期审查 SRE 团队的各项指标（如琐事、警报、软件工程影响、容量计划等）。由于采用的非线性特性，你的进展总会有挫折，因此这也应该视为过程中的正常部分。\n文化比战略更重要 Google 的一个假设，即 SRE 故事中的一个关键未书写部分，是内在的创新性 Google 文化。Google 还分享了我们进行的研究来描述这些属性。事实证明，团队成员是谁远不如团队成员如何互动、安排工作和看待他们的贡献重要。\n我们了解到，有五个关键动态使成功团队在 Google 中与其他团队区分开来：\n心理安全 : 我们是否能够在团队中冒险而不感到不安全或尴尬？ 可靠性 : 我们是否可以指望彼此按时完成高质量的工作？ 结构和清晰度 : 我们团队的目标、角色和执行计划是否清晰？ 工作的意义 : 我们是否在做对每个人来说都非常重要的事情？ 工作的影响 : 我们是否从根本上相信我们正在做的工作很重要？ 我们看到的许多关于 SRE 采用的典型问题，如成本影响、特定行业关注、技术债务等。然而，这一发现的最好之处在于，像所有好的事物一样，这五个动态基本上是免费的！无论你的行业或情况如何，都可以优先考虑这些因素。Google 的高绩效团队依赖这些文化规范使 SRE 成功，使 SRE 成为这种文化基础上的自然行为。\n忽视文化不会有帮助；等待也无济于事 听我们谈论文化对成功采用 SRE 至关重要，通常令人沮丧，这暗示你应该等到文化达到一定程度后才能采用 SRE。套用一句流行的谚语，最好的改变文化的时间可能是 20 年前，但第二好的时间是现在。除了可靠性问题，不让你的文化对可靠性反馈做出响应还有其他重大后果。\n培养 SRE 的含义是什么？ 要培养和发展 SRE，需要考虑一些关键活动。\n次线性扩展 : 我们之前提到过这一点，但需要澄清，这不是“用更少的资源做更多的事”，而是通过自动化和持续改进的文化来改变我们处理可靠性问题的方式。SRE 明确设计不是通过增加人数来扩展的，因此要抵制在现有软件流水线中增加更多人的诱惑，而是用 SRE 来自动化或省略这些步骤。 建立和保留可持续的、快乐的团队 : 尽管科技行业已经从项目导向转向产品导向，但仍然很常见的是将个体视为可以随意在不同活动之间调动的可替换资源。这直接冲突于我们的文化建议。不要指望这样做还能在 SRE 上取得成功。 承认 SRE 不是静态的——它本质上是一个动态角色，会随着时间成长 : 减少琐事和实施自动化的演变过程的一部分意味着 SRE 会在你的组织中发展。你仍然可以为此预算和计划，但目标是结果而不是具体任务和固定的团队规模。这一开始会感觉很奇怪，因为它与很多自上而下的计划活动相冲突。然而，当 SRE 动态地重新组建团队时，这通常是你正在取得成功的标志。 评估你在组织内的可靠性思维水平和目标 : 达到高水平的 SRE 采用需要比预期更长的时间。在 Google 内部，我们认为达到产品战略级别的可靠性可能需要 3 到 5 年的时间。鉴于保持这一水平需要持续努力，恢复旧习惯也很常见。因此，花时间和精力不断评估和调整这种新的思维方式。 SRE 的关怀与培育 一旦启动 SRE，你需要照顾并培育你新生的组织。随着 SRE 实践的发展，你需要考虑以下几点。\n将一个立足点团队发展成更大的组织\n不要从你最大的难题或每个人都不敢碰触的核心巨型单体应用开始。你需要在一个支持性的环境中通过一些快速的成功来起步，建立你的团队、原则和实践。相反，也不要从一个玩具服务开始。SRE 只有在有重要可靠性需求的地方才有价值。一旦你有了立足点，你需要不断学习，安全地扩展。处理大量不太重要的服务可能看起来很有吸引力，但要抵制这种诱惑。SRE 的价值在于高可靠性服务。其他服务应该遵循“你构建它，你运行它”的模型。\nSRE 组织结构：独立的 SRE 组织与嵌入式团队\n自成立以来，Google 一直有一个专门的 SRE 组织，我们认为这样做有很多好处，例如可靠性文化、发布优先级、招聘等等。我们经常被要求将其与 DevOps 的“打破孤岛”方法进行比较。理解独立的 SRE 管理链不应该成为孤岛是至关重要的。SRE 有多种与开发团队合作的方式，从嵌入个体到轻度咨询。尽管如此，没有专门的组织结构也可能成功地部署 SRE，但需要广泛的高级领导支持。\n晋升、培训和补偿\nSRE 是开发人员，应该期望获得至少与组织中其他开发人员相等的补偿和激励。晋升率也是衡量是否与其他团队平等的一个重要指标。你应该定期比较薪酬和晋升率，以消除任何差距。防止任何认为这种薪酬水平允许你虐待 SRE 的假设（例如，长时间工作）。注意，SRE 对进行有意义和有影响力的工作的期望会更高。\n值班是一项令人恐惧和疲惫的活动，需要仔细的准备和培训。还必须以有意义的方式补偿值班团队。如果你对直接补偿有限制，那么可以通过采用创意的方式（例如调休）来实现。\n沟通和社区建设\nSRE 使能涵盖了各种活动，例如正式培训课程、技术讲座、读书小组等。大部分工作是间接完成的，通过提供时间和资源进行实验（例如 20% 工作时间）。自主权和授权是建设社区的关键，这需要通过积极的领导方式来实现。这意味着设定明确的领导愿景或北极星，并在组织内显著地树立授权的榜样。在任何形式的变革中，沟通的量很容易被低估，而 SRE 也特别擅长检测不真实的信息。\n评估你的 SRE 采用是否有效\n在采用 SRE 的过程中，获得大量的 SRE 工件是很常见的，例如 SLO、SLI、错误预算、仪表板等。这些都是组织的代理指标，但它们不会总是给你一个全面的可靠性变化的图景。为此，你可能需要考虑一些更非常规的视角。如果事情确实进展顺利，良性循环会随着时间的推移显得更加平静。与其仅仅在事故与事故之间救火，不如有一种主动预防火灾的感觉。这可能会让人不安，特别是如果你的组织习惯于通过忙碌来展示其价值。在这一点上，抵制进行战术优化以重新获得忙碌感觉的诱惑。你的 SRE 会在经历失败并提升能力时自然地改进 SLO 和错误预算。\n航向 采用更主动的方法可以让你有更多时间专注于战略愿景。你会开始更清楚地了解组织中不同服务实际需要的可靠性水平。利用这些数据并设定新的预期结果来决定优化的重点。也许你的一些内部系统被标记为业务关键，但你的 SRE 们现在知道它们只需要 99.9% 的服务水平目标（SLO）。其他系统可能现在需要更高的可靠性水平，而判断你是否成功的一个可靠方法是当你开始看到其他团队对获得 SRE 好处的兴趣。\nFeature picture ❤️ Anete Lusina: https://www.pexels.com/photo/miniature-toy-car-on-top-of-monopoly-board-game-4792380/\n","date":"2024-05-03T23:55:05+08:00","image":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre-chapter5/pexels-anete-lusina-4792380_hu_202840cc3611ba78.jpg","permalink":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre-chapter5/","title":"《企业 SRE 路线图》第五章：积极培育成功"},{"content":" 译者：刘征\n下载中文版 PDF 文件 下载英文版 PDF 文件 从 Oreilly 阅读白皮书 从 Google 下载白皮书 一旦你建立了第一个 SRE 团队并掌握了这些原则，就该制定一套实践了。团队的实践由以下组成部分：成员能做什么、他们知道什么、他们拥有的工具，以及他们对这些工具的使用舒适度。\n团队的任务和环境最初决定了他们的工作内容。通常情况下，这意味着那些“开发团队未做的一切”，可能是一些列危险的稳定性缺陷。通过将团队聚焦于部分运维职责，他们可以产生一个能力循环，随着时间的推移相互增强。如果将他们投入到一个未定义范围的复杂环境中，那么结果必然是琐事和沮丧。另一个常见的反模式是将 SRE 工作添加到已经超负荷的团队中。\n团队的知识可以通过教育来扩展，无论是通过自我组织的还是企业集中组织的形式。应该鼓励团队定期举行团的内（间）的交叉培训会议，例如，每周一小时的会议，欢迎研讨任何关于生产环境的问题，无论是新成员还是资深成员都参与其中。如果问题有人能回答，则可以进行经验学习。如果没有人知道答案，可以转变为协作调查。根据我们的经验，这些会议对团队中的每个人都非常有价值。初级团队成员可以学习到新事物，资深成员也有机会传播他们的知识，通常还会发现一些大家都不知道的新事物。类似地，可以开展厄运之轮“Wheel of Misfortunes” 或桌面演练，在非正式的环境中，让团队成员讨论：他们在紧急情况下的角色和响应方式，对于让人们在无压力的环境下，更加舒适地接触生产环境非常有帮助。重现最近的所发生的故障是一个容易开始的起点。如果一个团队成员可以扮演指挥者的角色（会议主持人），并按照现实生产工作中的情况展示证据，其他团队成员就可以讨论：他们会怎么做和/或直接使用什么工具来调查事故发生期间的系统。\n还应该鼓励团队：从开发团队那里获得更多，有关他们正在运维的系统的知识。这不仅是更好地理解现有系统的很好的练习，也是直接引入新监控工具、讨论和规划系统变更（如性能改进）或解决可伸缩性或一致性问题的机会。这些对话在建立团队之间的信任方面通常非常有价值。\n团队的能力也可以通过引入新的第三方工具、开源软件工具或团队编写自己的工具来扩展。\n从哪里开始？ 在为我们的团队赋予新的能力时，应该从哪里入手呢？可靠性和 SRE 的领域非常广泛，并不是所有 SRE 都能适合于一个全新的团队。我们建议从一套能够帮助团队学习成长的，并有具体的下一步工作内容的实践开始。抽象地说，我们推荐使用所谓的“计划－执行－检查－行动（PDCA）”模型。通过根据系统当前的工作状态来决定下一步计划，你的每一步都将需要是能落地的。我们将在本章后面的内容里，解释如何构建这些能力的平台，以及建议从哪里开始。这些初期的能力将形成一个良性循环，团队就不必猜测：接下来应该构建或采用什么，他们将能够根据对系统的观察自然而然地得出下个迭代的工作内容的结论。\n你的目标是什么？ 设定适当的目标非常重要。并不是所有系统都需要达到“五个九”（99.999%）的超高可靠性。我们建议根据你的服务和应用的可靠性需求进行分类，并相应地设定投入水平。如我们之前提到的，记住每提升一个“九”成本可能是前一个“九”的十倍，即99.99%的成本可能是99.9%的十倍。虽然这个说法很难精确证明，但这个原则是成立的。因此，如果在没有深思熟虑的情况下，就盲目或过于广泛地设定目标，可能会让你的投入变得非常昂贵，并在投入中陷入新的困境。过分追求不必要的高可靠性目标也可能导致团队顶尖人才的流失。如果你的目的只是到达近地轨道，那就没有必要设定登月的目标。\n确保你成功的路径是一个可循序渐进实现的目标，而不是期望通过一次性的大型项目或革命性变革来实现。在这里，渐进式改进才是关键。\n当你的团队开始尝试新的实践时，确保记录下所取得的成果，并在团队内部及对外宣传这些成果。同行间的认可非常重要，可以通过在团队站立会议中表扬成员、在会议上让人们分享他们是如何避免灾难的、在内部通讯中发布近失事件，以及向整个组织展示如果没有采取预防措施会发生什么等方式来进行。庆祝这类工作成果非常重要，尤其是在过去没有这样做习惯的环境中。口头表扬和书面表扬可以与奖金或礼物相结合。即使是小礼物，也能产生很大的鼓励作用。\n如何到达目标 不要制定一个长期且过于详细的计划，例如三年的详细规划。相反，你应该专注于确定前进的大方向。了解你的长期目标，但根据当前完成的任务来决定下一步。确立了方向之后，不必急于全面改变现有的团队和流程来适应新模式。相反，应该逐步引导团队步入正确的方向发展。\n我们将这种方法称为“战争迷雾”策略，意味着你清楚最终的目的地，但也为途中可能遇到的任何小问题做好了准备。在这个过程中，短期规划和灵活性至关重要，尤其是在初期，迅速取得成效，并立即展示其影响力，对于一个刚刚起步的项目和团队的士气有着极大的积极作用。设定可达成的短期目标来解决当下问题，同时开始构建可通用、可复用的长期能力，让多个团队都能受益。通过构建一个能够提供这些能力的基础设施，你可以放大投资的影响力。我们将在本章后面进一步详细阐述这个平台和能力的概念。\n组织内不同的产品开发团队在需求和现有能力方面都有所不同。在引入 SRE 时，你应当在参与模式（engamement model）上保持灵活，以适应各个团队的具体情况。通过理解产品团队的现状，你可以解决当前的问题，同时引入全组织范围的标准和最佳实践。当 SRE 团队刚开始运作时，如果有很多团队都想寻求他们的帮助，他们可能会感到负担过重。通过制定明确的参与“菜单”，你可以避免一次性的合作，或其他不可持续的合作模式。参与模式有几种类型，包括嵌入式、咨询式、基础设施支持等，这些在谷歌客户可靠性工程（CRE）团队的博客文章以及《Googel SRE 运维解密》的第32章中有很好的描述。\n对于 SRE 的采用，明确的汇报结构在早期就很关键。我们建议建立一个独立的组织，并且 SRE 领导应在管理团队中拥有一席之地。通过将 SRE 的领导层与产品开发部门分开，SRE 团队将更容易专注于可靠性这个核心目标，而不会受到那些更关注速度和功能交付的团队的直接压力。然而，在这样做时，要避免形成一个孤立的“运维”部门，因为 SRE 与企业其他部分的紧密合作至关重要。开发团队应该与这些共享的 SRE 团队开展紧密合作的投入，从而确保从 SRE 团队获得的价值大于自行构建 SRE 功能。\nSRE 成功的关键 SRE 的成功不仅仅取决于实践方法，如服务水平目标（SLO）和事故回顾（postmortem）。这些实际上是创造 SRE 工作文化起步阶段的产物。因此，成功地采用 SRE 不仅需要模仿这些实践，还必须采纳一种兼容的文化才能取得成功。\n这种文化建立在团队自身的信任和安全感之上。当团队负责控制重要系统时，他们必须感到在心理上是安全的。他们必须能够在不担心惩罚的情况下对同事和领导说“不”。他们必须感到自己的时间被重视，他们的意见受到倾听，他们的贡献得到认可。最重要的是，SRE 不应该感到自己比开发部门的同事更为“另类”或“次等”。基于历史上的原因 Dev 与 Ops 对立模型是一种常见陷阱。\n无责事故回顾就是一个著名的例子。通过记录“出了什么问题”，团队可以协作地确定导致故障的各种因素，无论是技术问题还是程序问题。经常，当人为错误发生时，将错误归咎于“人的因素”可能很有诱惑力，但这已被证明是没有意义的，也不是改进系统的有效方式。相反，SRE 倡导无责文化。可以这样理解：系统应该让人很难犯错。应当有自动化和检查措施来验证操作者的输入，并且鼓励用同行审查（peer review）来促进双方的共识和协作。当人们在报告中自由地提及自己的名字，并且知道不会因为可能发生在任何人身上的简单错误而受到羞辱、降级或负面绩效评估时，这表明你已经实现了无责事故回顾。如果你看到事故回顾中使用了“工程师”或用“人员1”这样的表述，你可能认为这是一种良好的无责实践，但这实际上可能反映了潜在的文化问题，必须直接解决。如果文件中的名字被隐去并替换为“工程师”或“人员1”，但在事故回顾之外仍然对工程师进行指责，那么责任文化问题就没有得到解决。你绝对不应该自动化地从记录或文件中删除任何人的名字——由于这并不能解决根本的文化问题，只会使文件更加难以阅读和理解。与其表面上删除名字，不如直接解决潜在的文化问题，从而实现真正的无责文化。\n一个不良文化的标志是西瓜指标：外表看似绿油油，实则内部问题重重。这类指标反映了团队的努力，它们被精心设计，看上去很美好，但实际上隐藏了真正的缺陷。这与古德哈特法则类似，即任何成为目标的指标就不再是好的衡量指标。例如，过分关注支持工单数量，或整体平均解决时间（MTTR）往往会被滥用，不管是故意的还是出于好意，但都不主动认知自己的错误。通过度量团队的活动，我们把这些活动变成了目标，而不是客户的成果。相反，团队应该定义自己的成功指标，这些指标直接反映了客户满意度、系统稳定性和开发速度等因素。\nSRE 不应仅仅被视为“20%的时间”角色，而应该是组织内一个明确的职位和头衔。应该有一个公开的职业晋升路径，包括转岗要求和晋升期望。团队间的级别和薪酬应该公平对等。转岗不应该有任何显著的影响。\n判断一个成熟的 SRE 团队是否成功的好方法是：观察人员转入和转出SRE的情况。确保人员转移是常规的且没有任何官僚主义或限制，这样你可以快速了解人们是否感到在 SRE 团队中“被困”，或者它是否是一个理想的角色。通过观察从开发转移到 SRE 的自愿转移率，你可以判断这一角色是否吸引人。\nSRE 必须知道他们的时间是被重视的，尤其是当他们的工作需求超出了“正常工作时间”。例如，在谷歌，当 SRE 需要在正常工作时间以外值班时（即“on-call”），他们应该获得加班费补偿。谷歌的一些团队允许值班工程师在金钱补偿和休假之间二选一，按值班时间的一定比例看，通常设置一个值班时间的上限。不应该对一个团队提出超出其交付能力的需求，因此，确保值班池足够大是很重要的。常见的错误是：仅将值班池限定为 SRE 人员，这是不必要的限制。值班池也应该是基于自愿加入的。一旦团队感觉他们的时间被滥用，就会导致士气的迅速下降。\n另一个文化抓手是规划和目标设定。由于 SRE 最接近生产问题，他们通常很清楚最重要的是什么，哪些问题最紧急，哪些问题造成了最大的痛苦。允许 SR E团队设定自己的优先级和路线图，你就赋予了团队权力，他们将会更加有效率和愉快的工作。管理层应遵循共同制定，并达成对预期成果的共识的做法。业务需要加速开发吗？用户需要更快获得发布结果（新版本）吗？一个常见的反模式是泰勒主义，即领导者专权设定和优先考虑详细的计划和任务，然后将它们分配给下属。\n构建能力平台 SRE 团队可以构建一个平台，向合作团队提供能力，理想情况下，随着时间的推移，他们的贡献将扩展到整个组织。通过在共享服务、实践、规范和代码中引入弹性机制，这些团队可以开发出由：自动化、代码、共享库、管道、流程、规范、文档、手册组成的共享平台，甚至包括那些只存在于人们头脑中的特殊未记录知识。与其让每个团队都试图创建自己的最佳实践，不如将这些实践融入到平台中。产品可以从头在平台上构建（所谓的“数字原住民”），也可以移植到平台上。随着平台能力的增长，团队对其操作特性越来越有信心和体感舒适，逐渐将更加关键的工作负载都可以迁移过来。通过采纳这种将能力编码到平台中的模型，SRE 团队可以通过将能力同时应用到多个服务中来放大他们的影响力。平台是一个内部产品，应该像产品一样进行管理，将服务团队视为客户，接受功能请求，并跟踪缺陷（见图4-1）。\n当一个 SRE 团队开始来构建这个平台时，他们会面临一个问题：“首先应该构建什么能力？”通过分析前期采用 SRE 的低风险服务，你就可以将需求列表最小化为一个最小可行产品（MVP）。随着时间的推移，你会添加更多的能力。但下一步是什么呢？有两个来源：你的开发人员和你的环境。也就是说，根据他们的需求来构建，例如，“我们需要一个消息总线！”以及根据你所知道他们将需要的来构建，例如，“必须有一个可扩展的服务发现系统，否则这将无法工作。”\n对于环境所需的能力，这些通常包括：\n对 DevOps 进行优化改进，例如：增强软件开发生命周期（SDLC），更快、更安全地发布更多代码； 可靠性工程的改进：最小化那些已经潜伏于系统中的错误带来的风险。 为了增强可靠性工程，我们推荐在团队中培养一种持续改进的机制。如果你不确定应该从哪里开始，可以从分析已经发生的系统中断事故入手，采取以下措施：\n制定服务水平目标（SLO），明确可接受的系统性能标准。 建立一套正式的事故响应流程，确保在发生故障时迅速有效地响应。 开展无责任的事故回顾和审查，鼓励团队成员坦诚地分析问题，而不担心受到指责。 利用风险建模来确定改进的优先顺序，确保优先处理最关键的风险点。 使用错误预算或其他风险管理方法，来消化待解决的可靠性问题，以保持系统的整体稳定性。 让这种持续改进成为推动团队不断创新的动力。例如，如果有一次的部署导致了整个服务器群的宕机，你可能需要探索减少此类风险的方法，比如通过限制影响范围、实施金丝雀发布，或使用其他灰度（渐进式）部署策略。如果发现了内存泄露问题，你可以在部署的前置流程中加入新的压力测试方法。这些新能力将被集成到你的基础设施平台中，为平台上的每项服务提供额外的保护和收益。随着这些通用的缓解策略逐步的证明了它们的价值，单次修复的情况将会大幅降低。\n领导力 想要构建一个这样的技术平台，你就需要投入宝贵的工程资源，这些资源本可以用于开发新的业务功能。这就要求从基层到高层都需要施必要的加影响力。在功能开发和系统稳定性之间进行权衡时，决策者必须具有全局视野并得到适当的激励。我们越来越多地看到“首席可靠性官”这一职位，他们在组织内应当占有一席之地，参与制定战略性的可靠性决策（这一概念在马克·施瓦茨的《在桌边》一书中有所讨论）。虽然这是 SRE 成功实施的关键角色，但并不是一个常见的职位名称，通常是现有高管的额外职责。\n了解效果\n一个运作良好、重视可靠性的组织会展现出几个明显的特征。首先是面对可靠性问题时，能够及时缓解或暂停新功能的发布。如果唯一目标是快速发布，可靠性和其他非功能性需求就会被牺牲。你的组织是否总是将可靠性工作位居新功能开发之后？是否有因“时间不足”而永远无法完成的项目？重要的是，这并不意味着：你应该放慢代码交付流程的速度，而是保持持续的推进。\n另一个成功的迹象是，个体英雄主义不再受到赞扬，反而积极的劝阻。当系统的成功依赖于少数人的担当时，团队就会形成一种不可持续的英雄主义文化，这种文化终将崩塌。英雄们会被鼓励独占特定领域知识，而不愿意去系统地预防问题的发生。这与《凤凰项目》一书中的布伦特角色类似。依赖个体英雄不仅效率低下，而且可能非常危险。团队必须积极阻止个体英雄行为的发生，同时保持团队责任感，因为英雄主义在短期内看似合理，但实际上不可取。\n一个表现良好的团队还会在出现中断前就对可靠性工作进行投资，并作为主动规划的一部分。在表现不佳的团队中，我们看到仅在发生一系列中断之后，才开始对可靠性进行投资。虽然这可能是必要的增加，但这种投资需要长期维持，而不是被视为一次性的应对措施或在情况好转后就被撤销。\n进一步说明，设想你的组织对于可靠性有两种不同的态度：和平时期和战时。它们分别对应于“一切正常”和“所有人都知道问题即将爆发”。通过区分这两种状态，你可以做出关于投资的决策。在战时，你会在平台的隐性特性、基础设施、流程和培训上投入更多的时间和金钱。而在和平时期，你也不会放弃这些工作，但你肯定会减少投资。\n然而，谁决定公司何时进入战时？这个决定是如何做出的？它如何在整个公司传达，而不造成恐慌或人才流失？一种方式是使用优先级代码，比如黄色警报或红色警报。这些是帮助团队确定工作优先级的组织实践。黄色警报意味着在一个季度内，当前的技术问题可能会变成一定的业务紧迫性。红色警报则表示问题可能在几天内发生，或者是已经存在的稳定性威胁。这些警报应该有明确的标准，所有领导团队成员都必须理解并同意这些标准。宣布这些警报必须得到领导层的批准才能产生预期效果。这些警报的结果应该是改变团队当前的工作优先级，可能会暂停现有的工作（如红色警报的情况），批准大批量投入，并能够直接协调其他团队来提供帮助。优先级警报对企业来说是一项代价昂贵的操作，因此你应该确保它们有明确的预期结果。这些结果应该在一开始就定义好退出标准，并在完成时清晰地传达出结束的信号。否则，团队会经历信号疲劳，而不再进行适当的响应。\n选择投资于可靠性\n那么，作为一个可靠性领导者可能会做出哪些较不戏剧性的改变呢？这将涉及政策和投入。当政策是从基层向上的推动时，那么设置的全组织范围政策往往会是不一致的。如果存在一个领导的角色，由他来进行审核、消除重复、批准和传播这些政策，那将更为有效。同样，公司的资金支出，包括人员、硬件、软件、差旅和服务，通常是以分层的方式进行的。\n在构建前面提到的结构之前，必须考虑组织内可靠性的价值。为了使其有意义，组织必须将可靠性视为一项投资，甚至是业务产品差异化的竞争因素，而不是成本中心。应该明确可靠性是最重要的隐性产品特性。一个不可用、卡顿或充满 bug 的产品，无论具有多么丰富的功能，对客户的价值都会大打折扣。想要设定这个方向，你必须在高层进行操作，以确保持一致性，特别是：如果这是一个新的方向。\n一个简单的论点是，可靠性还可以作为更容易理解的概念的代名词，例如代码质量。如果系统出现了用户可见的问题，那么诸如灰度变更等可靠性实践的应用，就可以使系统在直接解决代码质量问题之前，让最终用户感觉更加稳定。例如，通过只对1%的用户发布带有缺陷的版本，那么99%的用户就不会发现问题。这使得系统看起来比实际上好100倍，并显著的降低了支持成本和声誉的损害。\n做出决策\n在你将可靠性设定为对更强大产品的投资后，你就可以制定更长远的计划了，并会产生更大的影响。传统模式将 IT 视为成本中心，完全倾向于随着时间的推移逐渐降低成本投入。但最终，如果服务不可用了，无论它的后续运维成本是多么的廉价都将失去意义。你仍然可以实施成本的削减，但应该是在实现了可靠性目标之后再予以考虑。如果你发现维持所设定的可靠性目标的成本过高，你可以明确重新定义这些目标——比如，降低一个“9”的标准——并评估由此产生的权衡。\n要实现这些目标，你可能需要说服某个管理委员会、决策者群体或高层管理。你需要他们的支持，以便随着时间推移为供给和维护团队，提供必要的资源，并培训及进一步发展团队成员。这应该被视为长期投资，并明确得到相应的资金支持，而不是隐藏在其他预算项里。\n反模式：忽略奥德修斯 在涉及可靠性时，一个常见的反模式是让停机或其他“坏消息”影响你的计划周期，即使这些情况是预期的。领导层在面对坏消息时，往往会感到需要“做点什么”，而“坚持计划”通常看起来没有影响力。然而，如果计划已经考虑到了停机，除非对系统的理解发生重大变化，否则“坚持计划”正是正确的做法。“奥德修斯契约 (Ulysses pact)”这个术语在这里是一个有用的例子。领导者奥德修斯告诉他的团队在他被绑在桅杆上时，坚持计划，驶过塞壬。当他的团队坚持计划（尽管他在挣扎和乞求停下），他表扬了他们。他们没有被短期思维所诱惑。他们的计划考虑了长期影响，并在混乱开始前制定了一个清晰的计划。 如果允许团队在当下做出决定，你往往会选择忽略一个好的计划，而做出情绪化或以自我为中心的选择。一个经典的例子是领导者介入故障处理中，而没有全面了解情况，尽管一个有能力的团队已经在控制局势。这通常是公司文化的结果。一种高薪人员的意见 (HiPPO) 文化可能对事件管理和整体可靠性产生极其不利的影响。相反，听从奥德修斯，坚持计划，不要弃船。这不仅适用于事件响应，还适用于错误预算耗尽或在面对“非常糟糕”的事件时跟踪 SLO。如果你的计划是在错误预算耗尽时停止功能发布，但你每次都为“这个重要功能”做例外，你的领导力将受到严重削弱。一个有效的改善措施是引入“银弹”，即领导者被授予三颗银弹，用于在必要时覆盖预期计划。通过引入这种人为的稀缺性，领导者必须做出明确的权衡。同样，如果单一的坏事件消耗了一个 SLO，不要忽略它。召集团队分析这如何改变你们对系统的共同理解。这种类型的故障以前从未被考虑过吗？对故障的响应是否不足？\n反模式：同时采用 另一个反模式是尝试在不进行修改的情况下混合旧模型和新模型。这会使团队偏离正确的方向，应避免这种情况。例如，在 ITIL 问题管理中，通常期望一个中心团队通过问题经理来减少问题的原因并缩短解决时间。相比之下，SRE 期望嵌入的工程师通过事后总结和评审来推动他们自己的问题解决。虽然结果仍然一致（更少且更短的停机时间），但方法和角色大不相同。尝试同时做这两件事，你最终会陷入混乱，并且这两种方法的预期结果相互冲突，效果不佳。 我们称这些 SRE 和非 SRE 原则的糟糕混合为“有毒组合”，类似于医学术语中指的不良药物混合。单独使用时每种原则可能是有益的，但两者结合在一起会导致意外的坏结果。我们经常发现使用两者的初衷是好的，通常是为了让现有员工参与进来，或者为了报告的连续性。然而，这种做法的吸引力远不及其带来的更糟的结果：更长的停机时间，更多的琐事和更低的可靠性。\n人员配置和留任 在人员配置和角色定义上也可能出现反模式。在建立 SRE 团队时，很容易会选择从外部聘请 SRE 来对现有团队进行整顿。但这实际上可能导致精力的浪费，通常新聘请的 SRE 无法理解团队或现有技术的细微差别，回归到应用以前使用的方法，而不知道这些方法在新工作中是否合理。\n我们建议将现有团队发展成 SRE 团队。仅仅重新命名是不够的，但提供一个结构化的学习路径和一个成长和发展的环境肯定是有效的。当然，有些情况下过渡可能会失败。如果个人没有被设置在一个成功的环境中，而是被期望仅通过“阅读书籍”立即成为高级 SRE，他们可能会感到沮丧并寻找其他工作。同样，一些工程师看不到变革的理由，没有激励机制，或者非常抵制接受新角色。通过提供带薪教育、时间和学习的空间，并提供背景信息帮助团队理解变革的必要性，你可以成功地将团队过渡到 SRE 角色。这需要时间、精力和耐心。在过渡不成功的情况下，进行离职面谈是很重要的，特别是要解决过渡的问题，个人的感受和效果。你可能会发现你的计划中的缺陷，或发现它没有按你预期的方式执行。最后，当你要求团队做更复杂且影响更大的工作时，请注意这确实是更高价值的工作，团队应该为此获得相应的报酬。也就是说，当你的团队开始像 SRE 那样运作时，你应该支付他们 SRE 的薪酬，否则他们会转到能这样做的地方去。如果你提供团队学习高价值技能的机会，而他们离开去别处使用这些技能，你只能责怪自己。\n技能提升 在培养和过渡现有员工成为 SRE 时，制定一个技能提升计划至关重要。这包括“需要哪些技能”和“如何获得这些技能”——即角色需要的技能以及如何使员工掌握这些技能。技能差距分析和调查等工具在这方面非常有用，用来核实对工作所需基础技能的假设。这些技能在 SRE 文献中往往没有具体提及，但它们对于 SRE 在全组织范围内扩大贡献至关重要。例如，传统运维团队对软件工程基础（如版本控制、单元测试和软件设计模式）不熟悉并不罕见。确保这些基本技能包含在你的技能提升计划中，并针对每个学习者的特点进行调整至关重要，这不仅是为了在团队中建立足够的技能基础，还为了为个人提供一个顺利过渡到新角色预期的路径（从而减少团队成员的流失）。\nFeature picture ❤️ Anete Lusina: https://www.pexels.com/photo/miniature-toy-car-on-top-of-monopoly-board-game-4792380/\n","date":"2024-05-02T21:41:05+08:00","image":"https://martinliu.cn/blog/google-sre-ent-roadmap-chapter4/pexels-anete-lusina-4792380_hu_ce72a86d35a3b574.jpg","permalink":"https://martinliu.cn/blog/google-sre-ent-roadmap-chapter4/","title":"《企业 SRE 路线图》第四章： SRE 实践"},{"content":" 译者：刘征\n下载中文版 PDF 文件 下载英文版 PDF 文件 从 Oreilly 阅读白皮书 从 Google 下载白皮书 在我们探讨具体的实践方法之前，首先要明白的是原则的重要性，这就像法律中遵守法律的字面含义和精神含义。单单实践方法本身并不足够；SRE 的核心精神在于它的原则中。实践方法也面面俱到————它们只是原则的外在体现，也会随着时间和组织的不同而随机应变。\n原则是你转型基础的基本真理，它们在你的决策过程中提供帮助和指导。实现业务目标通常有多种方式，因此鼓励人们充分理解和执行核心原则，要优于：设定一套面子工程的详尽的规则，那只让人按照字面意义去机械的执行，而忽视了核心精神。以 Google 的原则为例，虽然我们有多种：关于如何设计和构建新服务的内部政策，但我们始终坚持的核心原则是：“以用户为中心，其他一切都会随之而来”。\n你的重点应该是：激发每个层次的人，使其都展示领导力，而不是从各种方面剥夺他们的个人意识，不是用指令束缚他们。特别是，业务部门和经理需要认可转型的原因和动机，并必须愿意在他们的专业领域的范围内调整和进行详细的指导。一旦说服了这些有影响力的人，他们就会成为你最大的资产（资源），如果没有被说服，他们就会成为你最大的障碍。\n与原则类似，良好的政策关注的是产出，而不是任务的完成；然而，它们更像观察视角方面的指导。它们是你用于牵引业务的抓手，而不是对抗业务流程的工具。政策和政策框架应该让人们在明确的界限内安全地运行。同时，它们也应该包含合理的默认设置，以便引导行为朝着正确的方向发展。\n反模式：关于如何实施SRE，预先规划一个大而全的计划或设计。\n本质上，你需要花费大量的时间来学习，我们建议：你构建一个由一致的原则指导的反馈循环（也就是说，通过反馈改进，形成一个良性的循环）。\n我们将简要介绍 SRE 书中的每一个原则，以及如何在你的组织中应用它们。若想要获得更多细节，我们建议你阅读《Google SRE运维解密》一书中的相关章节。\n拥抱风险 详见：《GOOGLE SRE运维解密》第三章\n这是在初始阶段最难迈出的一步。我们通常把这个问题描述为：可靠性与速度之间的权衡；然而，这并不一定是真的。对企业来说，对于理解可靠性，最有帮助的方式，是将其与指数级的运维成本联系起来。大约每提高一个\u0026quot;9\u0026quot;（例如，从 99.9% 提高到 99.99%）都会导致成本增加一个数量级，无论是软件、硬件还是人力资源。考虑是否能从这种投资中获得良好的回报，有助于根据业务需求进行调整。故障的类型也非常重要。例如，需要全天候运行的服务会更适合实施 SRE（相比那些公司内部的一周只运行 8 小时，每周 5 天的系统）。另外，对于那些没有得到积极维护的服务，SRE 的作用将会大打折扣，因为这些服务在持续改进方面的机会本来就会很少。尤其是在你故意不进行太频繁的版本发布，或不在编写新的代码时，这点尤为明显。\n反模式：服务 100% 可靠性目标。 对于几乎所有事情来说，100% 都不是正确的目标。\n反模式：在“常规”的运维中实现了 99.999% 的可靠性\n月度指标或维护窗口可能会掩盖灾难带来的巨大影响。\n服务质量目标 详见：《GOOGLE SRE运维解密》第四章\n在你开始考虑实施 SLO 和 SLA 之前，先从服务质量指标（SLI）开始，并根据你系统的实际观测数据，来制定和校准的 SLI，然后用来支持 SLO/SLA 协商（利益干系人间的对齐）。不要让你现有的业务承诺影响你对 SLO/SLI 准确性和相关性的判断————你可以选择使用指标来驱动工作的变化，或者反之亦然。总之，不能进行粉饰，或者挑选优点展示。而要，花时间理解你的客户想要的是什么，而不能，为了支持\u0026amp;证明你理论，使用方便的数据点。简单来说，让事实证据（SLI/SLO）来驱动你的结论（SLA）。尝试关注那些 \u0026gt;99.9% 的服务，对于 \u0026lt;99.9% 的服务而言，SRE 可以先不参与相关维护工作（直到它们产生了需求）。我们反复强调：如果一个服务不从 SLO/SLI 中受益，那么它可能也不会从 SRE 中受益。最后，如果在 SLO 不违规的情况下，你就不能对软件或流程做任何变更了，那么 SRE 对你的收益也会甚微。\n反模式：SLO = SLA 你应该总是将 SLO 设置得比 SLA（例如，SLO：99.95%，SLA：99.9%）更严格。\n反模式：SLI = OKR（目标和关键结果）/KPI（关键绩效指标）\nGoodhart 的法则在这里适用：当一个度量成为了目标，它就不再是一个好的度量。\n消除琐事 详见：《GOOGLE SRE运维解密》第五章\n这可能是最重要的原则之一，因为它与 SRE 成功所需的创新文化密切相关。大多数时候，企业领导层希望加快进度，并通过确保将所有资源都 100% 的利用来实现这一点。如果你真的希望能确保：你的团队正在做正确的事情，而不是快速地做错误的事情，那么你的目标应该是少于 50% 的繁琐工作（或者我们所说的琐事）。这是可靠性（和速度）在大规模下的秘密。不要将其等同于技术债务，即可以把它们都攒起来，以后一起偿还，或者以“琐事周”的形式，每个季度解决一次这个问题。一旦琐事压制住了你的团队，那么所有 SRE 的所有其他活动都会停滞不前。你必须为组织来定义：什么是琐事，并且这必须由 SRE 实践者来决定，而不是自上而下的指令。琐事的定义也会随着时间的推移而改变（定义再次由实践者更新）。\n反模式：将琐事作为一个可有可无的原则\n忽视消减琐事会对应用 SRE 产生很大的影响。如果你没有时间减少琐事，那么你就没有时间实施 SRE。\n反模式：琐事是某个人/某个团队的工作，而不是每个人的工作\n最接近工作的人需要是修复它的人。如果你试图把这个工作转嫁出去，它会驱动错误的行为。\n反模式：琐事清除周\n每季度举行一次“琐事清除周”是常见的诱人的做法，但这是这样是行不通的。你需要采取更系统、更持续的消除琐事的方法。\n监控分布式系统 详见《GOOGLE SRE运维解密》第六章\n可观测性是一门独立的专门学科，它需要像其他开发实践一样受到同等的重视和思考。实际上，大多数企业应当预期投资于多种系统，这些系统将帮助团队更高效地工作。单一的监控平台（大而全的统一控制台）并不能很好地运作；同样，使用数百种功能叠加在一起的工具也不可行。通过理解你独特的 SRE 用户路径，以及他们需要使用多种工具来诊断和解决系统间的逻辑关系，找到适合你的平衡点。将可观测性系统视为：需要投资和精心设计的内部产品，强调工具的实用性，而不是“完美”的仪表板，因为系统总是在变化。记住，告警过度和告警不足同样的糟糕：告警不应直接发送给人类，除非需要他们采取行动。构建这种告警学习循环是加速学习的常见方法；弄的不合理，会迅速使 SRE 精疲力竭。\n反模式：告警信息过载 告警的电子邮件充斥了你的收件箱，我们会忽略所有信息，这意味着高优先级的告警也无法得到必要的响应，因为告警噪音太多。\n反模式：“NoOps”工具会替代 SRE 工具可以增强 SRE 的能力，但还不能替代他们。完全消除运维是不可能的，这样会迅速的让你的 SRE 团队渐行渐远。\n反模式：告警即是原因 你可以记录很多事情，但告警总是针对症状而不是原因发出。\nGoogle 自动化的演变 详见《GOOGLE SRE运维解密》第七章\n当涉及到极高的可靠性水平 (99.99% 或更高) 时，自动化是最重要的，因为在这个时候，如果需要人工介入，你几乎总是会经历的的是：服务水平目标 (SLO) 违约。随着系统错误预算的逐渐缩减，干预的平衡点也随之变化，最终转变为主动维护，会采用的技术手段包括优雅降级、重试等。自动化本身也会成为一个常见的问题，花时间修复不良流程是非常重要的，但很难融入团队文化。自动化也需要和系统其他部分一样的容易维护。\n反模式：不管流程的质量或适用性，默认一切自动化 最好的代码是并不写的代码！对于不很频繁的流程，操作手册（Playbook）是一个很好的中间解决方案。\n反模式：对于“非常重要”的部分也不要人工介入 只有当你真正需要又人来做决定，并且他们有权这样做时，才让人工介入。\n发布工程 详见《GOOGLE SRE运维解密》第八章\n发布工程与你的 DevOps 团队可能已经在进行的持续集成/持续交付 (CI/CD) 实践有广泛重叠。要充分利用这些现有工作，而不试图自上而下的强加另一套实践。强调结果和流程指标以对齐团队，并确保你在一个平台团队 (或根据规模的不同而有多个团队) 上有足够的投资。\n尽可能提前发布相关的工作，即尽早让测试团队也参与进来，并在所有阶段考虑测试。\n不要让开发人员负担过重，但确保发布周期的每个部分都被视为有价值的，并与其他部分保持一致。对于 SRE 来说，发布流水线是导致大多数问题的原因 (因此也是解决问题的关键)。与值班和维护人员也需要紧密的配合。\n反模式：DevOps/SRE 团队负责所有的发布 那是让不同职位的人都来干运维的活。\n反模式：发布工程必须引入 CI/CD 持续交付本身就是一门学科，你的平台和开发团队需要在这方面打好基础 (SRE 可以提供帮助)。\n简单性 详见《GOOGLE SRE运维解密》第九章\n团队的认知负荷很重要，并且会随着团队职责的扩展或缩减而变化。确保允许团队合并或拆分，从而让认知负荷匹配。基本上，复杂性意味着很多事情都会很难理解；因此，要尽可能的激励：减少不必要的复杂性，并将复杂的事情拆分成更小、更易管理的部分，例如领域驱动设计 (DDD)。另一个从 DevOps 中重用的重要概念是：高上下文 (High Context) 与低上下文 (Low Context)，以及 SRE 的一些概念如操作手册（Playbook）、文档、灾难恢复测试 (DiRT) 演习等，这些都是使事情变成低上下文的重要部分。拥有更少的代码和更少的产品特性，可能会与大多数产品的激励相悖，因此：要考虑其可靠性影响时，请确保对此进行控制。\n反模式：简单意味着我能理解它 用一个高管专用的仪表盘，并不可能有意义地显示所有内容。更不要试图强行的实现它。\n反模式：基于年度评估的静态团队 动态团队的形成需要一年多次。\n如何引入这些原则？ 如何将这些原则映射到你组织？将这些原则完全与您的组织对齐的可能性很小，但这没关系！你的 SRE 版本并不需要完全和 Google 的相同，只需要原则一致。但是，请确保你特意地选择将要追求的目标，检查与现存原则之间的差异，并利用这段时间仔细检查面子指标 (参见 Eric Ries 在《精益创业》中解释的“成功剧场”)。在不稳定的基础上进行变革可能很难，因此如果你没有信心，请假设你需要检查和改变。尽量不要在原则上犹豫不决，如果你认为某事无法完成，那么推迟它的实施，要比假装工作更好。\n防止组织破坏性错误 变更可能会潜在的产生非常不同影响。采纳新原则时，进行的一些变更不一定总是有效。变更所带来影响，通常比能否恢复原样更不重要，这意味着最难逆转的变更，通常也会造成最大的痛苦。专注于更容易逆转的改变，即使这些变更是错误的，它们仍然会带来经验教训。例如，如果第一次重组不成功，你可以随时进行另一场重组，但你不能让解雇的人重新回到公司。\n反模式：解雇所有不会编程的运维人员 除了显而易见的道德或法律影响，你根本无法逆转这个决定。\n反模式：给所有开发人员生产的 root 访问权限 良好的安全和运维实践包括：与过往的任何时候相比，最小可用权限最适用于自动化。\n反模式：选择业务中最关键的系统作为起点 你不会在马拉松训练计划的第一天就跑 26 英里。\n建立安全失败的环境 为你的采纳之旅创建一个安全失败的环境，期望失败会发生，但确保你从中学习并长进。在做复杂的事情时，请确保有主题专家（SME）的参与，但在做复杂的事情时，请确保你要么奖励失败，要么有失败预算。在大多数组织中，真正奖励失败很难，因此有时失败预算更合适。这意味着：你根据成功的前 n% 进行衡量，而不是平均/中位数。领导团队中这些行为的榜样作用至关重要，否则他们将无法在整个组织中融入这些行为。\n反模式：我们会支持你的任何冒险，只要结果成功就行 真正的风险预算意味着接受一系列的失败。\n当心优先级分歧 整个领导团队完全支持你的可能性很小。更可能的是，人们想要可靠性，但对变更和成本有合理的担忧。我们建议承认变更的 J 型曲线，如图 3-1 所示，这意味着在一开始的几个相对容易的胜利之后，实现有影响的变更的曲线变得困难。例如，采用自己的新自动化可能感觉像是一个倒退，然后才会实现显著的收益。通过进行屋顶射击而不是月球发射来确保成功。你仍然可以追求显著的改进，但一开始要保守一些。\n反模式：过早放弃。例如，尝试 SRE 六个月，然后在没有立即胜利的情况下停止 这并不意味着你需要立即完成所有事情，但在几个季度之后，必须有一个明确的方向感，表明在朝着正确的方向前进。\n如何取得支持 如何获得这些原则的支持，获得你需要的关键批准和支持？通过考虑 John Kotter 或 BJ Fogg 提到的一般企业变革原则，确保你为 SRE 成功做好准备。即使你的领导团队不完全相信你正在尝试的事情，也没关系，但你需要确保至少有足够的紧迫感来进行变革，并有动机去实施它。\n在技术领域，我们经常奖励解决问题，而不是防止问题的发生，SRE 原则和实践的采用，可能会成为这种操作模式的牺牲品。通过找到适合你组织的指标来确保 SRE 采纳的持续价值是显而易见的。例如，在零售业，你可能专注于在黑色星期五期间最大化销售额，而在医疗保健领域，你可能专注于持续合规性和可用性，在金融领域，可能是关于交易系统的吞吐量或完成分析流水线处理的速度。\n反模式：如果你构建 SRE，他们就会来 实践不能孤立存在。你必须开始实际的工作，才能做出真正的改进。\n反模式：稳步上升的进展 现实世界的变革有起有落。如果你没有失败，那么你就没有在学习。\nFeature picture ❤️ Anete Lusina: https://www.pexels.com/photo/miniature-toy-car-on-top-of-monopoly-board-game-4792380/\n","date":"2024-05-01T21:41:05+08:00","image":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre-chapter3/pexels-anete-lusina-4792380_hu_630865833e3912a4.jpg","permalink":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre-chapter3/","title":"《企业 SRE 路线图》第三章：SRE 原则"},{"content":" 译者：刘征\n下载中文版 PDF 文件 下载英文版 PDF 文件 从 Oreilly 阅读白皮书 从 Google 下载白皮书 可靠性并非新鲜事物。企业一直将其视为业务系统需要不断提升的重要品质，无论是在服务质量、可靠性还是系统正常运行时间方面。那么，SRE方法又有何独特之处呢？为何当下引起如此关注？它与传统方法有何异同？对企业来说，又意味着什么？\n将可靠性作为产品的关键差异化因素 为什么企业要建立 SRE 团队或者追求可靠性呢？他们希望实现什么样的结果？行业技术的流行趋势总是在不断的变化（技术、流程），但它们需要有实质性的商业价值才能被企业留存下来。考虑到可靠性和安全性，它们起初都不是产品明显的差异化因素，而是被视为必备的需求而已。只有在出现问题，并且期望产品具有高可靠性，或其依赖性时，它们才会变得更加突出。例如，多年前，安全漏洞和黑客攻击相对较少见，因此安全性是存在的，但并不会出现在面向消费者，或企业的产品营销材料中。现在，随着漏洞越来越普遍，并成为人们关注的焦点，我们将安全性视为产品的差异化因素之一。\n可靠性（更常见的是可用性或正常运行时间）往往主要会在服务级别协议（SLA）和类似协议或期望设定的详细条款中提及。然而，我们在客户满意度（CSAT）评分、像 Downdetector 这样的第三方网站，以及将更多的生活和业务转移到互联网的整体趋势中，才会感受到可靠性的存在。在 COVID-19 疫情期间，许多软件即服务（SaaS）产品经历了业务的高速增长，并且不得不大幅提高对 SaaS 产品可靠性的期望。\n除了“可用性”之外，作为可靠性特性常见的代名词，我们还可以想到：耐久性、数据持久性、在负载下的速度或性能、一致性和返回结果的质量等各种特性描述，与作为消费者级和互联网服务客户隐性的可靠性诉求相似的特性。\n一旦我们理解到了：可靠性实际上是产品的高期待特性，我们甚至可以大胆地说，它是产品最需要必备的特性。因为，如果产品一旦不可用了，那么它的任何功能（增删改查\u0026hellip;）也都无法发挥作用。如果产品在性能或质量方面的糟糕使用体验导致用户感到沮丧，那么产品服务将不会令用户满意。如果产品服务在高峰时段、关键业务时刻无法使用了，那么产品服务就会让用户感到不值得拥有，而离你而去。\n谷歌搜索以“始终可用”的特点而闻名，以至于认为它是无处不在的服务（甚至用于测试网络是否通畅）。谷歌搜索的可用性是它与竞争对手进行对比时的关键差异化因素，与速度、质量、易用性和用户体验并列。这并非偶然，而是谷歌十多年来的一个刻意选择和投资的成果。\n应该何时关注可靠性？ 当初创公司考虑是否要在可靠性方面进行投资时，可能会认为可靠性还是为时尚早。特别是当他们考虑到像谷歌这样的大型组织所采取的全面措施时。这是可以理解的，因为：初创公司首要的工作是构建一个最小可行产品（MVP），而不是一个耐用的、有韧性的服务。然而，一旦产品的可行性确定了，那就应尽快将可靠性纳入产品路线图，与安全性和其他“横向”工作（国际化、可访问性等）一起开展起来。\n在这些初创公司或早期企业中，关于可靠性的高成本定制化开发投资可能尚早，但与安全管理类似，在可靠性管理领域中，也有许多产品通过开源软件，以及通过第三方提供的服务和工具变得更加通用化。可以尽早的开始利用这些通用的工具和服务，从而避免在后期，不得不在已经发展壮大的复杂系统中进行痛苦的集成工作，或是被动响应可靠性问题。积极的前瞻性考虑是可靠性，及其相关准备工作的关键。另外，值得注意的是，尽管像谷歌这样的公司在内部构建了许多可靠性管理系统，但这绝不是最具成本效益的方法。利用外部的服务和工具是很早就经过验证的最佳实践。外部采购胜过内部自研是值得推荐的做法，特别是在诸如安全性（“永远不要自己编写加密算法”）和可靠性等领域，因为，自研可能会产生大量边缘场景和副作用。虽然，目前可靠性管理供应商领域的成熟程度和规模尚不如安全性，但它正在增长中，并且会对不断发展的公司产生重大影响。\n在规划稳定性投资时，麦肯锡的“增长的三个阶段”模型（见图 2-1）可能会对你有所帮助。它描述了公司未来发展的三种思考方式：\n阶段 1 是当前已经很重要的工作领域。 阶段 2 是预期中新的增长领域。 阶段 3 是未来潜在的长期增长领域，目前处于研发阶段。 通过考虑对每个阶段的不同投资水平，各个团队就可以拆解可靠性领域中不断涌现的工作内容。\n首先，让我们从阶段 1 模型的产品开始，我们应该专注于确保：让可靠性工作能够为公司当前的业务模式保驾护航，同时助力短期需求的持续创新。这相关的工作包括：对于传统的运维工作，可以通过 SRE 实践进行自动化。其他工作内容还包括：服务监控（服务质量目标 [SLO]）、事故响应和持续集成/持续交付（CI/CD）等等。\n阶段 2 模型产品考虑的是：将核心业务扩展到新的市场和面向新客户。将现有的可靠性功能进行扩展，从而支持到更广泛的消费者，并可能在必要的情况下在全球范围内扩展基础设施。这些情况都将带来新的可靠性挑战，例如：分布式团队（7x24覆盖）、针对多个客户群体的容量规划、多区域部署，以及传统的维护窗口应用就不太现实了，这类工作事项本质上仅适用于本地化产品，而不适用于全球化产品（不是“所有用户都在深夜中”）。\n最后，与阶段 3 模型产品相关的可靠性工作包括：公司可能扩展其业务提供的方式。为了应对未来颠覆性机遇或应对竞争威胁，公司应该用新的能力和新的商业模式来实现。投资于阶段 3 的公司将确保其平台和架构不会被绑定在单一的商业模式上，而是允许各种形态的系统的生成和演变，同时保持控制和质量标准。在这里，系统需要是可靠的，但不能僵化。诸如集中式批准委员会和自上而下的架构标准等工作会扼杀阶段 3 模型产品所需的创新。\n因此，将 SRE 应用于阶段 1 可以对您当前重要的业务产生立竿见影的影响。将 SRE 作为阶段 2 的核心基础可以保障未来的成功。然而，阶段 3 并不是开展 SRE 的最佳领域，因为在那里做投资的可行性还不明朗。\n为什么 SRE（站点可靠性工程）在现在才开始流行? 为什么 SRE 不是在 20 世纪 70 年代或者 2010 年被发明并流行起来？显然，基于互联网的服务的复杂性近年来已经明显增长，尤其值得注意的是伴随着云计算的崛起。从商业上讲，我们将云视为分布式系统的后浪，而分布式系统是计算机科学中的一个深入研究的领域。只有在过去的十多年里，这个计算机科学的分支才对个人消费者（例如，Google，Facebook，Apple）和企业（如 Salesforce）产生了重要影响，或者说，它的原则早已经被服务提供商（如 Akamai，Stripe）广泛有效地用于提供可扩展的互联网系统，更不用说云服务提供商了。\n“数据仓库级计算”（这是 Google 的一个概念，将数据中心比喻为一个超级的数据仓库计算机的模式）的引入改变了企业构建、交付、运营和扩展服务的方式。这些新模式明显改变了企业对待成本（CapEx）的方式，从租赁或建造空间和购买计算机系统的资本支出模型转向了按需租赁计算服务片段的运营支出模型（OpEx）。然而，这还涉及到系统设计、架构和应对不断变化的故障模式的问题。\n传统的基础设施遵循类似建筑行业或金字塔的模型：从底部向上构建的大而坚固的基座。如果基座出现了问题，对其上面的所有东西都会是灾难。我们将这种模型称为基于组件的可靠性模型，或者联合模型，即需要使系统中的所有组件都可用，系统才能正常运行；如图 2-2所示，\n在云计算中使用的新模型是概率可靠性或交集模型，由于架构选择是期待故障的，所以只要系统的一部分子集可用，系统就可以正常工作。\n虽然这个概念并不新颖或难以理解，但对于云服务的使用者来说，特别是当我们提出“迁移上云”的建议时，这并不显而易见，因为他们认为旧模型和新模型之间存在这等同性。虽然在新平台上运行旧模型是完全可能的，但必须考虑许多其他因素，这经常会让那些没有做好准备的人感到困惑。例如，传统的 IT 部门可能会为任何特定的虚拟机（VM）的正常运行时间而感到自豪，而对云 VM 则预期其实生命更为短暂：它们会被任意地创建和销毁，而且这个过程通常会非常快。\n企业在像 Google，Facebook 和 Apple 这样的现代公司中看到了成功的案例，发现了两个主要的优势：（1）大规模创新，以及（2）大规模可靠系统。这些公司不仅可以构建新系统，而且可以保持它们的可用性，敏捷性和正确性。这个组合对于企业来说非常有吸引力，因为这使企业也能够快速响应市场需求，并向整个市场提供广泛的解决方案。\n超越 Google 的光环 当然，Google 并不总是如此庞大。实际上，在早期，Google 以更传统的方式管理服务器群。使 Google 与众不同的是，它早期从垂直扩展转向了水平扩展其服务器群，也就是说，从购买更大更强大的计算机转向了购买更多更便宜的计算机。\n你可以通过走过早期托管设施的走道看到这种变化。虽然在第一次互联网热潮期间，许多租户的机架里都有看起来很酷、昂贵的硬件，但 Google 却使用的是大量标准商用硬件，预期任何时候某个机器都可能会发生故障，并在软件设计中也考虑到这种故障。\n引发这个转变的一个重要因素是，这是一个有意为之的选择：在进行水平扩展的过程中，避免相关的运营成也线性增长。也就是说，从财务的角度看，当水平扩展时，也持续雇佣更多人来维护新增的机器是没不合理的。\n在这种技术和财务选择的双重推动下，Google做出了自己的选择——这就是 SRE 部门的诞生。Google 只是在大多数其他公司之前做出了这个选择，因为它是一个非常早期的互联网规模化公司。\n我们相信，许多公司现在面临的扩展挑战与 Google 当时面临的挑战相似。只不过现在这些公司有公共云的优势，而不必在自己的数据中心中填充大量的标准商用硬件。我们相信，Google 能够通过发展 SRE 职能部门来克服这种方法的变化，这意味着 SRE 也可以帮助在其他公司克服同样的难关。\n我们在 Google 学到的一个关于 SRE 与传统 IT 运维人员配备水平的重要观点是，那就是亚线性扩展。我们的意思是，运维一个系统的团队的规模不应该与系统本身的增长速率相同。如果你的系统的使用量翻倍了，那么你也不应该需要两倍的运维团队。Google 选择不按机器数量进行扩展，而是按其他更高级的指标进行扩展：集群、服务或平台。通过关注更高的抽象层级，团队可以做更多的事情，而开销更小。 这些抽象层级往往是由那些以前运维过这些系统的人来构建和扩展的。\n复杂性可以增加对 SRE 的需求，但你的SRE人员配备应该比服务的接入增长得更慢，这个概念被称为亚线性扩展。这实际上直接与减少团队中的重复劳动琐事的原则有关。随着系统的增长和衍生，团队需要做更多的重复的任务来保持系统的健康。SRE 管理必须积极防止并跟踪这一点。如果团队允许过多的重复劳动琐事发生，不主动察觉，这可能会是一个下滑的开始，会导致团队无法维持，同时宕机时间也会增加。\n为什么不选择更传统的运维方式？ 你的组织可以通过利用 Google 从垂直扩展转向水平扩展的经验，以及通过发展 SRE 而产生的相关变化，更早地享受到规模的优势，同时也可以节省资金。想一下另一种方式：为了降低扩展团队的成本，而随着复杂性的增加，团队的责任也在增加，人们也可能会从外部寻找更便宜的劳动力（例如，“外派员工”或“正确的离岸外包”）。这是处理规模和复杂性时一个太常见的方法。这通常会导致系统增长受阻，导致发生停机事故，实际上随着时间的推移，增加的成本会更高。这些意外的成本可能不仅来自停机或对品牌的损害，还可能来自于执行或扩展速度降低、新产品的上市时间延长，甚至最终被竞争对手超越等其他形式的业务收入损失。在选择如何优化运营和可靠性投资的成本时，组织需要考虑全局。\n因此，配备合适的 SRE 团队是很重要的。其实你不需要都去雇佣博士学历，但你也不能吝啬。尽量不要只关注运维人员的单位成本，而是要关注整个系统的综合成本。做个类比，工业食品包装使用着价值百万的机器设备，将桃子装入罐头盒中。你可能会想，“为什么不雇佣非熟练工人？那会比百万美元的机器便宜得多。”乍一看，这听起来更便宜。然而，当你考虑到雇佣非熟练工人的整个系统成本时，实际上更贵。因此，使用价值百万的机器的整个系统最终比雇佣非熟练工人更好、更便宜。如果你让他们，SRE 和平台工程师来为你建造你的罐头机器人。不要因为你过去常做的事情，就强迫他们手动填装桃罐头。\n如果没有高效能的员工，采用像 SRE 这样的高性能实践会更困难。那么现有的团队是不是就没有希望了？一点也不。完全有可能，并且强烈建议开发现有的人才。团队可能会试图雇佣一个外部专家，甚至是一个拥有 SRE 经验的外部团队，但这可能是一个错误。同样，期望通过外派员工或离岸外包获得（长期的）SRE 能力，也不太可能得到你期望的结果。SRE 人员的单位成本往往比传统的运维团队高，试图削减人员预算，或者想在在配备 SRE 团队时，以低成本获得高价值的方式往往都会失败。如果你的组织重视可靠性，你应该能够合理化这个成本，我们将在后面的部分探讨如何做到这一点。\n将运维只看做成本中心是一个常见的错误。你应该考虑收入和总拥有成本的全局，避免局部优化成本，并认识到，只关注短期削减成本最终可能会让你的公司付出更大的代价。例如，通过评估发生事故的情况，估计事故将对收入或品牌的影响，投资一个 SRE 团队的定位，就可以视为一种长期的保险，包括一系列的事故缓解和预防策略。理想情况下，这个团队不仅仅是“保险”，实际上还是驱动改善（可靠性！）向客户交付创新的驱动力。考虑以你的阶段 2 模型产品为目标，并统筹规划你的平台。不要只解决今天的问题；还要为将来做计划。\n考虑转型现有员工的好处。只要给予正确的激励、机会和足够的时间，一个组织就可以改变其常态，并优雅地接受其人员的现代化角色和责任，同时也尽可能地减少了不必要的人员流动。因为，毫无疑问，一个组织最宝贵的资产永远是它的人员。在评估员工的技能集时，不应低估了他们对公司核心业务的真正理解。\nFeature picture ❤️ Anete Lusina: https://www.pexels.com/photo/miniature-toy-car-on-top-of-monopoly-board-game-4792380/\n","date":"2024-04-30T21:41:05+08:00","image":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre-chapter2/pexels-anete-lusina-4792380_hu_b2deac1d7687b106.jpg","permalink":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre-chapter2/","title":"《企业 SRE 路线图》第二章：SRE 方法对可靠性的意义何在？"},{"content":" 译者：刘征\n下载中文版 PDF 文件 下载英文版 PDF 文件 从 Oreilly 阅读白皮书 从 Google 下载白皮书 将 SRE 导入当前的各种传统企业，是一项看似可能艰巨的工作，因此 Google SRE 整理了一些建议，希望能帮助到更多企业。通过评估企业现有的环境、设定合理的预期，并确保企业朝着正确的方向迈出正确的步伐，企业可以从评估 SRE的原则和实践，从评估SRE在组织中的运作方式开始。\n演进优于革命 企业的一个显著特点是：会始终拥有以前的 IT/管理信息系统（MIS）方法和原则的历史，Google SRE将详细讨论一些常见的方法。无论当前状态如何，Google SRE发现在采用 SRE 时，选择通过演进和补充现有框架的方式，而不是直接与其对抗会取得最大成功。此外，SRE 与其他任何技术的采用过程类似，都会受到历史遗留的影响（参见维基百科关于路径依赖的页面）。简而言之，这意味着：在像企业这样的复杂系统中，在不同地方应用相同的改变，也将产生出不一致而非收敛的结果。Google SRE将从一些成功的采用了不同的流行框架的示例开始讨论。\nSRE 实践可与 ITSM 框架共存 信息技术基础架构库（ITIL）是一组详细的 IT 活动实践，如 IT 服务管理（ITSM）。并非每个企业都使用 ITIL，但如果企业的相关组织在一定程度上采用过 ITIL，则应准备好 SRE 和 ITIL 实践之间会存在着重叠。此外，由于 ITIL 是一个框架，企业的定制化实施可能与库中的内容有很大差异。\n关键点：ITIL 有五本核心书籍，用数千页的篇幅涵盖了：关于如何构建和运行 IT 服务的内容，其中的很多主题与可靠性无关，也有很多内容故意未被 SRE 涵盖。ITIL 是一个框架，而 SRE 是一组实践，因此它们肯定是兼容的，但是在翻译术语（例如，“warranty”，“utility” 等）时可能会遇到挑战。此外，SRE 在变更管理和服务的拥有权等领域有着明确的观点，因此即使结果是一致的，也要做好调整的准备。\n对于调和现存的一些常见 SRE 的反模式，可能也会比较有挑战。变更咨询委员会（CAB）是变更控制的常见模式。SRE 所秉持的持续交付的方式，意味着要让这个机构简化和战略化：企业可以在 Google 的 DevOps 研究和评估（DORA）的文章中，了解到更多有关简化变更审批的内容。类似地，对于网络运维中心（NOC，或者中国的 ECC）而言，则应该将其从事件驱动模型转变为更具前瞻性的方式，重点是对其进行自动化和赋能。在这两种情况下，重点是演进当前的运作模式，而非立即替换它们。\nDevOps/敏捷/精益 DevOps 有多种定义。为了简单起见，Google SRE 假定它包括其他方法的相关部分，如敏捷（SAFe、DAD 和 LeSS）和精益（Six Sigma、看板）。Google 的 DORA 研究表明，SRE 和 DevOps 是互补的，因此如果企业的组织在一定程度上采用了 DevOps，则通常会有所裨益。与 ITIL 一样，我们要预见到 SRE 和 DevOps 实践存在着一些重叠，并且企业的定制化实施可能与《DevOps Handbook - DevOps 实践指南》存在着广泛的差异。Google SRE将在后面更详细地介绍特定的 SRE 实践，但 SRE 与 DevOps 相关最大的许多能力（例如版本控制、同行评审等）也通常被视为采用 SRE 的先决条件。无论企业选择通过 DevOps 还是 SRE 倡议来构建这些能力，这些都由企业来决定，但为了确保采用 SRE 的成功，那些重要的 DevOps 能力仍然需要提前准备继续。\n关键点：当企业在调和 DevOps 和 SRE 的差异时，倡议务实的原则；想要完成大规模演进变革的成功，还是要通过迭代和循序渐进的方式来实现。重要的是：需要把特定的工作活动拆解出来，并专注于对人员的赋能，而不是花费不必要的时间和精力来获取一个完美的“空架子”。\n尽管 DevOps 和 SRE 是互补的，但它们在一些领域还可能会令人难以调和。例如，企业可能已经决定将开发和运维报告层次结构替换为跨职能的 DevOps 团队。在这种情况下，重新引入像 SRE 这样的专门职能则需要进行认真的考虑。\n千里之行，始于足下 无论您的企业正在使用着什么方法和框架，了解并诚实地对待企业今天的现状都很重要。正如《Google SRE 运维解密》 一书所言，“希望不是一种策略！” 如果企业认为：当前的企业环境中即没有任何缺失，也不存在任何改进的机会，那么企业应该问自己：为什么要采用 SRE。同样，企业现有的一些技术或员工的想法，在刚开始的时候，看起来也可能与企业的 SRE 愿景并不一致。在做出任何改变以前，花时间来了解这些也很重要。\n明确企业的期望和愿景 接下来，企业了解自己期望的结果很重要。SRE 会包含许多技术和文化的组成部分，但它们都指向一个相同的目标，即：实现可靠性的目标。企业应该提前预计到：企业需要花费大量的时间和精力，来定义SRE 的技术和文化与现有框架的交互方式。只是简单地说“提高可靠性”是行不通的。同样，如果企业期望的结果与可靠性无关（例如：成本、速度），那么就需要准备额外的工作成本，来让SRE 实践与企业的整体愿景进行适配。\nSRE 开始与人 随着时间的推移，流程和技术会潮起潮落，而人员和实践则能够接受和适应它们。如果，企业是从培训和招聘开始的，那么企业可以不断的添加或删除技术和流程。而建立 SRE 能力则是一个渐进的过程；所以，不要试图通过简单的招聘来取得成功。将招聘看做是培训方式的一种加强版，而不是取代培训。记住，SRE 需要一种 “生机文化”（与病态和官僚的企业文化并列） 才能取得成功，所以确保这一点至关重要。\n拥抱自身的特殊性 在企业的某个特定组织内采用 SRE，其实并没有一个标准化的最佳实践的做法。企业能成功的方式才是它唯一正确的方式。Google SRE 现在已经对很多组织的工作成果进行了大量的研究，知道了一些行之有效的方式，还有一些无效的做法；然而，企业必然还是会犯一些新颖的错误。将这些组织的经验视为真正的学习工具，将各种有效的改进循环融入你当前的企业的组织中。\nFeature picture ❤️ Anete Lusina: https://www.pexels.com/photo/miniature-toy-car-on-top-of-monopoly-board-game-4792380/\n","date":"2024-04-30T21:41:05+08:00","image":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre-chapter1/pexels-anete-lusina-4792380_hu_b31ecd472dea13f2.jpg","permalink":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre-chapter1/","title":"《企业 SRE 路线图》第一章：初探企业 SRE "},{"content":"\n下载中文版 PDF 文件 下载英文版 PDF 文件 从 Oreilly 阅读白皮书 从 Google 下载白皮书 这份文档是一本关于如何构建和维持一个站点可靠性工程（SRE）职能部门的书籍，名为《企业 SRE 路线图》（Enterprise Roadmap to SRE），由 James Brookbank 和 Steve McGhee 撰写。这本书由O\u0026rsquo;Reilly Media, Inc.在 2022 年出版，旨在帮助大型和复杂的组织（即企业）采用SRE。\n下面是对本白皮书的简要概述。\n前言\nSRE 的实施与挑战\nGoogle 的两本 O\u0026rsquo;Reilly 书籍——《站点可靠性工程》和《站点可靠性工作手册》——展示了为什么承诺整个服务生命周期可以使组织成功地构建、部署、监控和维护软件系统。前者由 Betsy Beyer、Chris Jones、Niall Richard Murphy 和 Jennifer Petoff 编辑，后者由 Betsy Beyer、Niall Richard Murphy、David K. Rensin、Kent Kawahara 和 Stephen Thorne 编辑。\n本报告旨在在这些书籍的基础上，深入探讨在大型复杂组织（即企业）中采用 SRE 的挑战。尽管 SRE 在过去几年中非常流行，但我们从许多企业获得的反馈表明，SRE 的热情与实际采用之间存在差距。\n我们认为这是一个需要弥合的重要差距，因为可靠性正日益成为企业的重要区分点。云采用和 COVID-19 大流行引发的技术变革速度和规模，通常需要不同的技术来应对增加的复杂性。\n如果您参与生产系统的可靠性，或者依赖其可靠性，并且需要了解更多关于 SRE 采用的信息，这些主题将引起您的兴趣。这包括执行和领导角色，也包括个体贡献者（如云架构师、站点可靠性工程师 [SRE]、平台开发人员等）。无论您的角色是什么，如果您设计、实施或维护技术系统，这里都有适合您的内容。\n第1章：企业 SRE 入门 介绍如何将 SRE 引入现有企业，建议首先评估现有环境，设定期望，并确保在评估 SRE 及其在组织内可能的工作方式时，朝着正确的方向迈出合理的步伐。\n第2章：为什么要采用 SRE 提高可靠性？ 讨论了为什么企业希望建立 SRE 团队或追求可靠性，以及他们希望实现的结果。作者指出，可靠性是产品最需要具备的特性，因为如果产品不可用了，那么它的任何特性都无法被利用到。\n第3章：SRE 原则 在讨论具体实践之前，作者强调了原则的重要性。SRE 的原则包括 拥抱风险、服务质量目标（SLOs）、消除琐事（Toil）、分布式系统的监控等。\n第4章：SRE 实践 一旦建立了 SRE 团队并对原则有了一定了解，就可以在组织中，开始实施一套 SRE 实践。团队的实践取决于成员能做什么、他们知道什么、他们拥有什么工具，以及他们对所有这些的舒适度。\n第5章：积极培育成功 讨论了如何确保 SRE 在组织中成功的实施，包括采取小规模行动、建立和保持可持续的快乐团队、承认 SRE 是一个动态的角色，并随着时间的推移而发展。\n第6章：不仅Google可以，企业亦可行 作者与三位不同行业的 SRE 领导者进行了交谈，他们在过去几年中以各种形式采用了 SRE ，分享了他们独特的故事，包括采用 SRE 的工作方式、他们可能会采取的不同方法，以及对 SRE 在他们的行业或组织中有效运作的洞察。\n结论 作者希望本白皮书能帮助企业采用 SRE，并为每个人带来更可靠的技术体验。他们认为，通过明确定义 SRE 原则，将这些原则映射到实践和能力上，并优先发展和培养团队内部的这些能力，可以提高成功的机会。\n关于作者 James Brookbank 是 Google 的云解决方案架构师，专注于为 Google 客户解决复杂的技术问题并提供专业的架构指导。Steve McGhee 是可靠性倡导者，帮助团队了解如何构建和运营世界级的可靠服务。在担任此职位之前，他曾任职 Google 的 SRE 超过10年，学习如何扩展全球系统。\nFeature picture ❤️ Anete Lusina: https://www.pexels.com/photo/miniature-toy-car-on-top-of-monopoly-board-game-4792380/\n","date":"2024-04-30T11:23:43+08:00","image":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre/pexels-anete-lusina-4792380_hu_19a16ba1141d00d2.jpg","permalink":"https://martinliu.cn/blog/google-enterprise-roadmap-to-sre/","title":"《企业 SRE 路线图》Google SRE 企业路线图白皮书"},{"content":" 通过GitHub认证释放您的全部潜力！获得GitHub认证将让您在展示为GitHub专家方面具有竞争优势。\n认证是打开职业机会之门的黄金钥匙，可以为您的职业生涯提供强大动力，提升工作效率，增加薪资。对雇主而言，认证是增加生产力的秘密武器，它在招聘过程中为您的技能提供不可辩驳的证明，并在组织内激发创新。\n之前GitHub的认证计划，仅供员工和合作伙伴使用，现在已经向全球所有客户开放！现在每个人都可以访问注册站点，开始学习并准备考试。\n4 门认证课程 获得GitHub认证将让您在展示为GitHub专家方面具有竞争优势。让我们来看看每个路径。\nGitHub基础认证 GitHub基础认证计划：旨在向初学者介绍GitHub平台的基本概念和产品。您将学习如何使用git，并探索GitHub的核心功能，如存储库管理、提交、分支、合并和项目管理。您还将了解如何为GitHub上的开源项目做贡献，并有效地使用markdown。您可以在此查看完整课程表（https://learn.microsoft.com/en-us/collections/o1njfe825p602p），以了解此路径中涵盖的更多主题。\nGitHub Actions认证 GitHub Actions证书:向您介绍GitHub Actions，以便您可以学会自动化软件开发工作流程。您将学习如何构建CI/CD管道，管理GitHub Actions，以及许多其他内容。到最后，您将准备好成为团队中处理所有与操作有关事务的人。在此查看完整课程表（https://learn.microsoft.com/en-us/collections/n5p4a5z7keznp5）。\nGitHub高级安全认证 GitHub高级安全（GHAS）证书：旨在教您如何在开发生命周期的每个阶段使用高级安全功能保护您的代码。GHAS专门针对GitHub企业版，因此该证书旨在供企业开发人员评估和配置私有存储库上的秘密扫描、使用CodeQL进行代码扫描、依赖关系管理等等。在此查看完整课程表（https://learn.microsoft.com/en-us/collections/rqymc6yw8q5rey）。\nGitHub管理认证 GitHub管理认证:将教您如何维护一个健康、强大和安全的GitHub环境，以满足组织的需求。您可以在此查看完整课程表（https://learn.microsoft.com/en-us/collections/mom7u1gzjdxw03）。\n学习备考指南 GitHub认证官网为每个认证计划创建了详细的学习指南。您可以从此存储库【https://github.com/LadyKerr/github-certification-guide】获取每个证书的学习指南，以及帮助您准备考试的资源。\n每一门课程的学习资料都可以在微软学习网站上免费访问并学习。\n建议的学习路径是：\nGitHub Foundations ：【推荐】这虽然是一门基础的课程，但是可以说它为你提供了非常丰富的学习内容，包括：GitHub Copilot、Codespaces。还涵盖了项目管理、如何参与开源项目、安全防护代码仓库、处理 PR 等高级内容。即使不一定参加考试，也建议完成的学习一遍。适合人群：想更多了解 GitHub 的人群。 GitHub Actions：【推荐】这门课程主要是讲解 GitHub Actions 的使用，包括：如何使用 GitHub Actions、如何创建流水线进行 CI、如何管理软件包、如何开发和发布 GitHub Actions 等。适合人群：长期在工作在 GitHub 项目上的人群，你想在项目上使用自动化的 DevOps 流水线和 CI、CD 实践。 GitHub Advanced Security：【可选】这门课程主要是讲解 GitHub 的安全防护，在 GitHub 上如何做 DevSecOps，需要的产品功能是GitHub企业版的附加功能，如果你的公司没有购买 GitHub企业版，那么这门课程并不适合学习。 GitHub Administration：【可选】这门课程主要是讲解：如果你是你们公司的一名 GitHub 管理员，你如何维护一个健康、强大、安全的 GitHub 环境，以满足组织的需求。如果你不是你们公司的 GitHub 管理员，或者没有这个想法，那么这门课程可以不用学习。 在学习完之后，如果你想报名考试，请访问：https://examregistration.github.com/overview\n每一门认证考试的费用是 $99，；由于这个培训认证是刚刚 GA 不久，目前 “GitHub基础认证” 认证考试是打折促销，折后只需要 $49 。\n我目测了一下考试的范围和难度：感觉广度是一个挑战，毕竟不是每个人都会参与项目管理、协作、安全、开源/内源这些相关的工作内容。深度上应该不太难，毕竟假如你是天天在 GitHub 上工作的人，都会有一定最基础的经验。建议可以先学习了在说，毕竟学习的内容是免费的。如果想报名考试，报名和考试都是线上进行的，还是比较方便的，特别是 GAF 的折后价格还不错。\n在考试通过之后，就可以获取Credly验证的凭证：您将收到Credly徽章和证书，以验证您的资格。就像其他的电子徽章一样，你可以发朋友圈或者在 LinkedIn 上展示你的徽章。\n下面是四种GitHub认证考试的徽章：GitHub基础、GitHub Actions、GitHub高级安全和GitHub管理。\nGitHub 的官网和微软的学习网站所提供的学习资料和备考指南手册文档都是丰富且详尽的。如果您对认证计划有任何疑问，请务必查看官方的FAQ页面「https://examregistration.github.com/faq」和备考人手册『https://examregistration.github.com/handbook』。\n","date":"2024-01-25T09:38:21+08:00","image":"https://martinliu.cn/blog/github-certifications-ga/Collaboration-DarkMode-2_hu_39f62de56cea88cc.webp","permalink":"https://martinliu.cn/blog/github-certifications-ga/","title":"推荐尝试 Github 系列认证考试"},{"content":"本文原作者：Santiago González\n事先声明一下：本文并非另一篇黑HashiCorp更改Terraform许可的文章。我还有很多不再使用Terraform的考虑。在这篇文章中，我们将回顾Pulumi相对于Terraform的一些优势。这并不意味着要成为Pulumi的追捧者。它只是Terraform的替代解决方案之一，使开发人员能够直观地使用基础设施配置工具。\n为什么讨厌Terraform？ 显然，我在这里写的一切都是主观的，也可能是错的。但这里总结的一切表明了，与我类似的其他许多尝试拥抱Terraform的人，希望用它作为IcA工具所遭受的挫折。\n学习曲线：Terraform拥有自己专用的领域特定语言（HCL），作为一种定义基础设施的独特方式，与传统编程语言迥然不同。这种语言遵循着对其他语言而言比较陌生的逻辑。因此，对团队来说，学习它是需要：付出极大努力，并且遵循这种\u0026hellip; 魔鬼般逻辑的语言更是需要额外的努力。 违背DevOps原则的DevOps工具：如果你在Terraform中编写代码的已经很复杂了，想象一下去编写测试，有可能是什么样子。在这里，您可以了解一下要如何才能做到这一点。这绝对是疯狂的。实际上，这意味着：并非在Terraform的代码上直接实施测试。至少我从来没见过这样的。 秘钥管理：Terraform需要与第三方解决方案集成来实现秘钥的管理。或者，您大可以使用环境变量。 团队生产力：其实很难找到一个开发人员的简历上，就写着他已经熟悉了 Terraform。因此，这意味着：你必须使用一种与项目上所使用的语言相异的语言来实现基础设施的配置，由于使用和学习其他新语言的额外工作量，会导致生产力的下降。 Pulumi能做什么？ 以下是使Pulumi相对于Terraform更好的功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 import com.pulumi.pulumi; import com.pulumi.pulumi.aws.ec2; import com.pulumi.pulumi.aws.rds; import com.pulumi.pulumi.aws.vpc; public class Main { public static void main(String[] args) { // Crear una VPC Vpc myVpc = new Vpc(\u0026#34;myVpc\u0026#34;, VpcArgs.builder() .cidrBlock(\u0026#34;10.0.0.0/16\u0026#34;) .build()); // Crear un grupo de subredes SubnetGroup dbSubnetGroup = new SubnetGroup(\u0026#34;myDbSubnetGroup\u0026#34;, SubnetGroupArgs.builder() .subnetIds(myVpc.getPrivateSubnetIds()) .build()); // Crear una instancia de AWS DocumentDB Cluster documentDbCluster = new Cluster(\u0026#34;myDocumentDBCluster\u0026#34;, ClusterArgs.builder() .clusterIdentifier(\u0026#34;my-docdb-cluster\u0026#34;) .availabilityZones(\u0026#34;us-east-1a\u0026#34;, \u0026#34;us-east-1b\u0026#34;) .dbSubnetGroupName(dbSubnetGroup.getId()) .masterUsername(\u0026#34;admin\u0026#34;) .masterPassword(\u0026#34;mysecretpassword\u0026#34;) .skipFinalSnapshot(true) .storageEncrypted(true) .applyImmediately(true) .engine(\u0026#34;docdb\u0026#34;) .engineVersion(\u0026#34;4.0\u0026#34;) .instanceType(\u0026#34;db.r5.large\u0026#34;) .build()); pulumi.export(\u0026#34;clusterEndpoint\u0026#34;, documentDbCluster.getEndpoint()); } } 语言支持 多语言和多云支持：使其具有很大的灵活性。这使您能够使用与软件项目相同的编程语言，让它对开发人员而言更加友好。此外，它实现了对所需架构的更好抽象，并且还能实现“在产生云账单之前就进行代码测试”。\nPulumi具有秘钥存储 它使用集成的秘钥存储来保护所有敏感数据。这个秘钥存储解决方案在各种部署场景中无缝运行，无论您是使用我们托管的Pulumi服务、自托管的Pulumi服务、还是自我管理的后端。当您使用\u0026rsquo;pulumi new\u0026rsquo;或\u0026rsquo;pulumi stack init\u0026rsquo;创建堆栈时，Pulumi服务会自动保护好秘钥信息。如果你选择使用AWS S3或Google Cloud Storage等自我管理的云存储后端，也是在使用\u0026rsquo;pulumi new\u0026rsquo;初始化新堆栈时定义的口令来保护秘钥。无论场景如何，每个Pulumi堆栈都会收到唯一的加密密钥。\n团队生产力 如果团队使用了与其项目相关联（相同）的程序开发语言，那么，他们就将更容易的对所需使用的组件负责和提供支持。这样，使用和理解具有HCL结构的项目的工作量就被消除了，团队可以继续专注于开发功能，而减少了开发成本和时间。\n使用Terraform状态 Pulumi提供了访问和利用本地和远程Terraform状态的能力。在过渡到Pulumi或您组织内的各个团队具有不同的工具偏好时，这可能非常有价值。通过诸如状态引用支持之类的功能，您基于Terraform的构建的基础架构之上，构建Pulumi中的项目，例如利用Terraform所创建的关键VPC详细信息，如VPC ID和子网ID等信息。这简化了Pulumi和Terraform之间的集成，使其从 Terraform 的迁移变成了一个无缝的过程。\n测试 您可以选择所喜欢的测试框架，并开发进行对基础设施进行必要验证的单元和集成测试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import spock.lang.Specification import io.pulumi.pulumi import io.pulumi.pulumi.aws.s3.Bucket import io.pulumi.pulumi.runtime.Mocks import org.mockito.Mockito class PulumiIntegrationTest extends Specification { def setup() { // Set up AWS and Pulumi configurations for testing pulumi.runtime.setMocks(new Mocks()) // Configure Pulumi mocks } def cleanup() { // Clean up configurations after tests pulumi.runtime.setMocks(null) // Restore Pulumi mocks } def \u0026#34;test AWS S3 bucket creation\u0026#34;() { given: // Set up the environment for the Pulumi program def program = new pulumi.Stack(\u0026#34;mystack\u0026#34;) when: // Execute the Pulumi program that creates the S3 bucket program.apply() then: // Verify that the S3 bucket was created successfully def bucketName = program.getOutput(Bucket.BucketName) assert bucketName != null \u0026amp;\u0026amp; bucketName != \u0026#34;\u0026#34; cleanup: // Perform additional cleanup tasks if necessary } } TL;DR; 太长不读 尽管Terraform拥有着强大的社区支持，但实际上，对于开发团队来说，通常大家还是觉得太复杂，难以用它实现 IaC 基础设施即代码的管理。这主要是由于学习曲线及其HCL语言，它与命令性语言的逻辑不一致。由于替代解决方案如Pulumi的出现，我们可以使用软件项目中的程序语言配置基础设施资源。实际上，与Terraform相比，Pulumi会提高效率和生产力。如果您尚未决定使用哪种IaC工具，值得 先考虑Terraform可能对您的组织产生的潜在影响。\n来源：https://medium.com/aws-tip/say-goodbye-to-terraform-infrastructure-as-code-for-humans-with-pulumi-76e72de1c3d9\nFeature picture ❤️ : kike vega on Unsplash\n","date":"2024-01-08T11:01:38+08:00","image":"https://martinliu.cn/blog/infrastructure-as-code-for-humans-with-pulumi/0_94eq9GcVBbFH3TeR_hu_25307bdc028f3194.webp","permalink":"https://martinliu.cn/blog/infrastructure-as-code-for-humans-with-pulumi/","title":"告别Terraform：使用为人类设计的基础设施即代码Pulumi"},{"content":"DORA Core 模型 下载 PDF 版\n关于这个模型：DORA Core是DORA研究计划的成果，它是从历史和广度上发现到的，一系列最坚实存在的能力、指标和成果的集合。核心是从DORA的持续研究中得出的，包括我们年度《加速DevOps状态报告》中提出的分析。核心旨在在从业者的背景中作为指南使用：它有意追随研究，更保守地发展。核心模型中显示的概念和关系已经在我们的研究中反复证明，并已成功被软件工程团队用于优先考虑持续改进。常见问题解答见下文。\nDORA Core 是什么？ DORA的研究项目是持续而不断的；每年都带来新的调查方向，每次分析都带来新的见解。在前沿领域，新概念经常被引入，而文献（尤其是DevOps状态加速报告）的不断发布，揭示新的见解和动态。随着每项研究，一些先前的发现得到强化，而其他一些可能受到质疑。这是良好科学的标志：任何新发现都应该被视为可疑的——引人入胜，但可疑——直到通过复制和应用得到验证。与此同时，鼓励从业者将研究应用于自己的专业背景中。在这种背景下，跟上DORA的最新发展可能是具有挑战性的：在大型组织中进行文化转型需要稳健的手段，要在跨越多年的时间段内持续进行。试图更新实践以匹配研究的速度可能导致逆生产的变动。在这些情境中，更实际的做法是依赖于“常青”文献。DORA Core代表了DORA最基础的发现的精髓：研究一再展现的指标、能力和结果。它使团队能够更精确地将改进努力集中在可能为其组织目标和生活质量产生有形利益的方面。\n核心包含哪些概念？ DORA Core涵盖了DORA长期研究并得到良好支持的概念集。这些概念包括连续交付和生成性组织文化等能力，以及“四个关键”指标等指标，以及组织绩效等结果。这些已建立的思想与研究中表现出有希望但（尚未）得到DORA预测模型支持的领域或不同的预测路径形成对比。如果一个概念符合以下条件之一，则可以考虑纳入核心：\na)已研究至少两次； b)从业者发现它有价值； c)继续探索是有必要的。 这个标准是有意主观的：它在很大程度上依赖于数据和分析，但最终是由直觉引导的。因此，请贡献出你的观点！您的直觉是宝贵的；如果您觉得某事没有准确反映研究，请告诉我们。\n核心会变吗？ 会！研究的应用比研究本身更稳定。但它并非静止不动。核心会随着时间的推移而发展，我们目前正在调查的事物将来一旦确立，就会“毕业”进入核心。纳入核心需要一定的支持阈值；同样，如果收集到足够的证据来支持核心中的某个部分的移除或修改，它将被弃用。核心是由研究启发并随研究演变的——但速度较慢。\n什么是核心模型？ DORA核心模型是DORA自成立以来一直在开发的预测框架的视觉总结。它借鉴了多年来开发的所有结构方程模型（SEMs），以突出最受支持的实体和预测路径。鼓励从业者研究模型并将其用于指导他们的持续改进之旅。\n所有研究年份都被平等对待吗？ 不是。一些发现被证明非常耐久，年复一年地复制。但是，当研究动态背景时，其他发现已经发生了变化。此外，每年我们都会增加或减少研究领域。我们的目标是在多年内创造出一些持久的东西，同时在我们继续学习的过程中发展。为此，比起较旧的研究，最近的研究权重更大。这就是为什么，例如，“安全向左移”与技术能力分开的原因，它反映了从2021年和2022年的研究中显示出安全实践对软件交付性能的独特影响的发现。\n扩展阅读：感兴趣下载中文版本的研究报告，可以在这里下载https://www.devopschina.org/sdm_downloads/\n","date":"2024-01-04T09:12:31+08:00","image":"https://martinliu.cn/blog/dora-core/1_j4QaVlm5rlBlSsyluXH2Dg_hu_2a6900f78b4d386f.webp","permalink":"https://martinliu.cn/blog/dora-core/","title":"DevOps 从业者需要理解的 DORA Core 模型"},{"content":"2024年DevOps 的采用统计 DevOps 市场庞大，相应的，它离停滞不前还差得远，仍在不断演变，最重要的是，DevOps已经证明了自己的重要性，以往任何时候都更为重要。您将惊讶地了解，在DevOps中发生了一些非凡的事情。您想知道这些事情是什么吗？继续阅读以了解它们。\n根据Gartner的研究，到2025年，超过85%的组织将采纳云为先的原则。这不是很有趣吗？当然，是的，对吧？现在让我们带您了解一下2024年的DevOps采用统计数据。\nDevOps有助于企业将处理支持工单所花费的时间减少60% - 对于寻求在2024年采用DevOps的组织而言，这是一个很好的前景。 组织通过DevOps能够将33%的时间投资于基础设施改进。 94%的组织认为平台工程有助于他们充分实现DevOps的好处 - 这对于那些想在2024年在企业中取得规模化成功的人来说是一个很好的统计数据。 这些统计数据令人兴奋，不是吗？这些统计数据描绘了：DevOps已经改变了企业的工作方式，并产生了成果。\nDevOps 的增长统计 全球DevOps市场规模预计将从2023年的104亿美元增至2028年的255亿美元，增长率为18.95%。根据Global Newswire的研究，到2026年，预计将达到12215.54百万美元，复合年增长率为18.95%。\n86%的企业表示，他们的公司必须迅速开发和投产新软件，因此他们认为DevOps具有价值。不容忽视的是，能够迅速向消费者交付数字产品的企业具有竞争优势。 Google收集的数据和研究也表明，77%的组织目前依赖DevOps部署软件，或计划不久将会这样做。 2024年DevOps的容器化统计 灵活性和快速发布是孕育容器理念的最重要基石，它已经成为当今IT世界的主流。现在让我们介绍一下DevOps容器化服务的一些统计数据，这些数据最终会让您感到惊讶。\n根据Gartner的新预测，全球容器管理收入预计将从2020年的465.8百万美元小幅增长到2024年的944百万美元。 Gartner还预测，到2024年，15%的企业应用将在容器生态系统中运行。这一估计较2020年的不到5%有所增加，受技术债务、应用积压和预算约束的限制。 46%的软件开发人员的首要任务是容器化，43%是质量和安全性，32%是CI/CD实施。 应用容器市场规模在2021年估值为27.6亿美元，预计将在2030年达到338.6亿美元，复合年增长率为32.12%。 DevOps CI/CD 的统计 CI/CD流水线是一组在公司技术引入变更时运行的自动化流程。现在让我们看一下DevOps CI/CD的统计数据。\n全球CI工具市场规模在2022年估值为970.52百万美元，预计在2031年达到4377.77百万美元，在预测期间（2023-2031年）以18.22%的复合年增长率增长。 随着企业对DevOps团队提出更高效率的需求，CI工具市场继续扩大，2021年估值为802.2百万美元。预计到2030年将达到37.6亿美元，代表18.74%的复合年增长率。 AWS DevOps 的统计 首要的事情是，AWS DevOps有着令人印象深刻的声誉。2010年从物理服务器过渡到Amazon Web Services（AWS）云使应用程序和服务能够以更高的速度交付。\n它开始使用由内部Apollo系统管理的持续部署过程。该系统允许开发人员随时在任何服务器上开发代码，在任何需要的地方部署。 截至2011年5月底，亚马逊平均每11.6秒向生产服务器部署新软件。在最繁忙的时候，每小时向生产环境发送1000多个新的版本。 2024年Azure DevOps 的统计 截至2023年，全球超过10695家公司已经开始使用Microsoft Azure DevOps Server作为版本控制工具。使用Azure DevOps服务器进行版本控制的企业主要来自美国，约5073家客户，占Microsoft Azure DevOps服务器客户总数的60.76%。\nAzure DevOps的市场份额为8.81%。它在版本控制类别中与三个竞争工具竞争。 Azure DevOps用户数量接近10亿。根据Azure Active Directory的数据，Azure用户有7.222亿。 在2023财年第一季度，Microsoft Azure的收入增长率为31%。 2024年DevOps工程师统计分析 DevOps已经进入了多个组织，引发了对多个DevOps人才的竞价战。因此，让我们看看一些揭示或描绘DevOps工作蓬勃发展的统计数据。\nDevOps工程师的平均薪水是133,133美元，美国的DevOps工程师的额外现金补偿为16,860美元。 美国目前有超过6,881名DevOps工程师。 所有DevOps工程师中，13.8%是女性，86.2%是男性。 就业DevOps工程师的平均年龄为39岁。 2024年DevOps市场统计 DevOps市场规模在2023年超过104亿美元，并预计从2024年到2028年将以19.7%的复合年增长率增长。此外，它受到缩短软件开发周期和加速交付的需求的推动。\n来自本地部分的DevOps市场规模预计将在2032年达到450亿美元，原因是人们对云环境中数据隐私的担忧增强。 全球DevOps市场规模预计将在预测期间以19.7%的复合年增长率增长，从2023年的估计值104亿美元增至2028年的255亿美元。 DevOps使用统计 Atlassian调查了一些激动人心的DevOps趋势，揭示了一些有趣的统计数据；大多数人可能想知道结果描绘了什么，对吧？\n99%的受访者表示DevOps对他们的组织产生了积极影响。此外，78%的人说，由于DevOps，他们不得不学习新的技能，而48%的人说，这帮助他们得到了加薪。 61%的受访者表示，DevOps有助于生产更高质量的可交付成果。 49%的受访者表示，DevOps改善了他们的发布实验。 99%的受访者表示，DevOps对他们的组织产生了积极影响。 2024年DevSecOps统计 DevSecOps确保在整个开发过程中都有安全控制。它通过将安全性集成到CI/CD管道中所需的地方来实现这一目标。现在让我们带您了解DevSecOps的统计数据。\n34%的组织拥有经验丰富的DevSecOps文化，对于那些寻求在2024年采用DevSecOps的人来说，这是一个好兆头。 到2024年，组织在DevSecOps自动化方面的年度投资将约增加35%。 将DevSecOps文化扩展到组织中的更多团队和应用程序是数字转型和更快、更安全软件发布的关键驱动因素，占94%的CIO。 根据90%的IT领导者的说法，通过在DevOps和安全项目中增加AIOps的使用，可以在2024年及以后扩大DevSecOps。 96%的受访者表示，自动化安全和合规性操作，这是DevOps的核心原则，对他们的业务产生了好处。 60%的工程师能够以两倍的速度发布代码，这归功于DevSecOps的原则。 2024年DevOps收益统计 在实施DevOps之后，组织必须了解，这需要组织变革和转变。这不仅仅是关于实施新技术，更是关于以人和流程为重心的方法。让我们看一些DevOps收益的统计数据。\n操作在最高安全级别运行的22%的企业已经达到了DevOps的高级阶段，根据Puppet的报告。 根据Forrester收集的数据，51%的DevOps用户将DevOps应用于新的和现有的应用程序，其中只有13%表示他们的DevOps方法仅限于概念验证实施。 Forrester的另一项研究表明，71%的DevOps采用者使用微服务和容器。 这是关于2024年DevOps采用和增长的一些统计数据，让我们深入了解了DevOps的影响和趋势。\n来源：https://radixweb.com/blog/devops-statistics\n","date":"2024-01-02T10:32:21+08:00","image":"https://martinliu.cn/blog/devops-statistics/download_hu_3e2478d1b083483e.jpg","permalink":"https://martinliu.cn/blog/devops-statistics/","title":"通过统计数据看 2024 年的 DevOps 趋势"},{"content":"我们迎接2024年的到来，很明显，DevOps正在迅速发展。这一领域正在经历重大变革，开发人员和组织需要及时了解新兴趋势，以保持竞争力和效率。在本文中，我们将探讨正在塑造DevOps未来的十大趋势。\nAI和ML在DevOps中的应用：AI和自动化在DevOps中的使用并非新鲜事物。然而，我们预计在未来一年内这些技术的采用将显著增加。AI和ML正在增强智能自动化，实现预测性分析，并改善DevOps过程中的异常检测。\nDevSecOps和安全集成：网络威胁的频率和复杂性不断增加，这促使安全性集成到DevOps管道的每个阶段，从而催生了DevSecOps的崛起。这一趋势强调在软件开发生命周期的每个步骤都纳入安全措施，培养一种安全责任由所有团队成员共享的文化。\nNoOps和高级自动化：NoOps的概念正在迅速获得推动力，操作流程被自动化到了很高的程度，甚至于感觉保持专门的运维团队都变得多余了。NoOps设想未来的系统将变得自我管理和自我修复，由AI自动化驱动。\n无服务器计算：在2024年，无服务器计算的采用是显著影响了DevOps的趋势。无服务器计算，其中云提供商动态分配机器资源，使开发人员更专注于编写代码而不是管理基础设施。这一趋势受到了对可伸缩性、成本效益以及简化部署过程需求的推动。\n增强的可观测性和监控：全面的可观测性和监控正在成为DevOps的关键优先事项。随着系统变得越来越复杂，对先进监控、日志记录和追踪解决方案的需求变得至关重要，以获得对应用程序性能的深入洞察。增强的可观测性使DevOps团队能够预先解决问题，提高应用程序的可靠性和性能。\n强调多云和边缘计算策略：多云和边缘计算策略的不断普及是2024年影响DevOps的另一趋势。多云方法通过在多个云提供商之间优化工作流程来提供灵活性。这一趋势受到了组织避免供应商锁定，并确保资源高效利用的需求推动。边缘计算也因其能够在数据生成的地方附近处理数据的能力而受到青睐，这对于需要低延迟的应用程序至关重要。\nGitOps和基础架构即代码（IaC）：GitOps和基础架构即代码（IaC）是2024年改变DevOps的两个重要趋势。这些趋势是：对管理日益复杂的基础架构，和更高效的基础设施供应方法的挑战的回应。\nDevOps中的ChatOps：ChatOps，将聊天平台与运维工具集成在一起，是2024年影响DevOps的另一个趋势。与传统通信工具不同，ChatOps允许在聊天应用程序内直接与软件开发工具进行交互，实现即时响应和操作。通信和操作工具的直接集成表明了减少响应时间和增强团队灵活性的实际方法。\n低代码和无代码开发：在2024年，低代码/无代码开发正因组织寻求加速开发流程和降低成本而获得动力。低代码/无代码平台正在通过实现更快速的应用程序开发和部署改变DevOps的格局。\n不断增长的DevOps市场和云采用：根据MarketsandMarkets™的报告，DevOps市场预计将在2023年从104亿美元增长到2028年的255亿美元，年复合增长率（CAGR）为19.7%。这些趋势突显了DevOps在现代软件开发中日益重要的地位，强调了其不断增长的市场潜力和影响。\n结论 当我们审视2024年的DevOps格局时，很明显，这一领域正在经历重大变革。采用AI和ML，将安全性整合到DevOps中，以及不断增加的自动化使用是塑造DevOps未来的一些趋势。\n本文转自：https://blog.codegiant.io/the-next-wave-of-devops-top-trends-for-2024/\n","date":"2024-01-02T10:03:49+08:00","image":"https://martinliu.cn/blog/devops-top-trends-for-2024/devops-trends-thumbnail_hu_d8b373bfa881921f.png","permalink":"https://martinliu.cn/blog/devops-top-trends-for-2024/","title":"2024年 DevOps 的10大趋势"},{"content":"\u0026ldquo;Elastic RUM\u0026rdquo; 是指 Elastic Observability 中的实时用户体验监控（Real User Monitoring，RUM）功能，是 Elastic Stack 中的一部分。Elastic Stack 是一个开源的数据存储和分析平台，包括 Elasticsearch、Logstash、Kibana 和 Beats 等组件，用于处理和分析各种类型的数据。\nReal User Monitoring（RUM）是一种用于监控网站或应用程序性能的技术。它通过追踪和分析实际用户与网站或应用程序交互的数据，从而提供有关用户体验的实时信息。RUM 的关键目标是了解用户在访问网站时经历的性能和交互情况，以便开发人员和运维团队可以识别并解决潜在的性能问题，从而提高用户满意度。\nElastic RUM 的优势包括：\n实时性能监控： Elastic RUM 提供实时性能监控，使你能够迅速发现并解决用户可能遇到的性能问题。\n端到端可观测性： 与 Elastic Stack 的其他组件集成，Elastic RUM 可以与日志、指标和其他数据源一起使用，为你提供端到端的可观测性，帮助你全面了解应用程序的运行状况。\n用户行为分析： Elastic RUM 能够捕获用户与应用程序的交互信息，使你能够分析用户行为、浏览模式和访问路径，从而优化用户体验。\n可定制性： 你可以根据特定的需求和业务场景定制 Elastic RUM 的配置，以满足不同应用程序和网站的监控需求。\n集成弹性搜索： Elastic RUM 与 Elasticsearch 弹性搜索紧密集成，允许你使用 Elasticsearch 强大的搜索和分析功能来查询和可视化实时用户体验数据。\nElastic RUM 通过提供实时性能监控和与 Elastic Stack 的集成，帮助开发人员和运维团队更好地理解和优化用户体验，提高应用程序的性能和可用性。\nElastic RUM 概述 Elastic APM实时用户体验监控（RUM）JavaScript代理提供了对你的Web应用程序的详细性能指标和错误跟踪。它内置了对流行平台和框架的支持，并提供了用于自定义仪表化的API。\n该代理还支持所有出站请求的分布式跟踪。这使你能够分析整个微服务架构的性能——一切尽在一个视图中。\n特性：\n代理使用浏览器定时API（如导航定时、资源定时、绘制定时、用户定时等），并捕获以下信息： 页面加载指标 静态资产的加载时间（JS、CSS、图像、字体等） API请求（XMLHttpRequest和Fetch） 单页面应用程序导航 用户交互（触发网络活动的点击事件） 用户中心指标（长任务、FCP、LCP、FID等） 页面信息（访问的URL和引荐者） 网络连接信息 JavaScript错误 分布式跟踪 拆分指标 准备 JS Agent 代码 本文以 Hugo 网站为例，介绍如何为 Hugo 网站添加 Elastic RUM 监控。我使用 Elastic Cloud 的 SaaS 服务作为数据存储和分析平台，你也可以使用自己搭建的 Elastic Stack 集群。\n本博客所使用的主题是 hugo-theme-stack 由 Jimmy 设计。为其他主题添加 Elastic RUM 的过程类似，只是配置文件的位置和内容可能有所不同。\n根据 Elastic Cloud 的页面上的配置向导，我们可以找到 Elastic RUM 的 JavaScript 代码，如下所示：\n1 2 3 4 5 6 7 \u0026lt;script src=\u0026#34;https://your-cdn-host.com/path/to/elastic-apm-rum.umd.min.js\u0026#34; crossorigin\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; elasticApm.init({ serviceName: \u0026#39;my-service-name\u0026#39;, serverUrl: \u0026#39;https://d4c649267e404779a895b41199d5db98.apm.ap-east-1.aws.elastic-cloud.com:443\u0026#39;, }) \u0026lt;/script\u0026gt; 以上代码片段，你需要根据你的前端部署的实际情况，进行调整后，才能正常工作。\n如下图所示：\n在 APM 的配置向导里，我们先点击 RUM（JS）这个标签，然后页面中会出现为前端项目添加 Elastic RUM 的 JavaScript 代码的两种方式。\n可以使用 npm install @elastic/apm-rum --save 将代理作为依赖项安装到您的应用程序。然后可以在您的应用程序中初始化和配置代理。适用于与大多数的前端项目。而 Hugo 是一个静态网站生成器，不需要使用 npm 安装 Elastic RUM。 本文直接使用的是选项二。将 Elastic RUM 的 JavaScript 代码复制到 Hugo 网站的 layouts/partials/footer/custom.html 文件中。 下面是我在 Hugo 网站的 layouts/partials/footer/custom.html 文件中添加的 Elastic RUM 的 JavaScript 代码：\n1 2 3 4 5 6 7 8 9 \u0026lt;script src=\u0026#34;/js/elastic-apm-rum.umd.min-5.15.0.js\u0026#34; crossorigin\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; elasticApm.init({ serviceName: \u0026#39;martin-blog\u0026#39;, environment: \u0026#39;production\u0026#39;, serviceVersion: \u0026#39;1.5.0\u0026#39;, serverUrl: \u0026#39;https://d4c649267e404779a895b41199d5db98.apm.ap-east-1.aws.elastic-cloud.com:443\u0026#39;, }) \u0026lt;/script\u0026gt; 相关参数的说明如下：\nserviceName：服务名称，这里我使用的是 Hugo 网站的名称。 environment：环境名称，这里我使用的是 production。 serviceVersion：服务版本，这里我使用的是 Hugo 网站的版本号。 serverUrl：Elastic Cloud 的 APM 服务地址。 src=\u0026quot;/js/elastic-apm-rum.umd.min-5.15.0.js\u0026quot; 这里我将 Elastic RUM 的 JavaScript 代码下载到了 Hugo 网站的 static/js 目录下，然后在 layouts/partials/footer/custom.html 文件中引用。你也可以将其放在一个可用于你的多个网站共享参考的 CDN 上，然后使用 CDN 的地址。 对 Elastic RUM JS Agent 的其他详细参数的使用参考文档见：https://www.elastic.co/guide/en/apm/agent/rum-js/current/configuration.html\nHugo 站点的改造 根据你所使用的 theme 的不同，你需要找到在 footer 中添加 Elastic RUM 的 JavaScript 代码的位置。根据我的Hugo主题用户文档的介绍：https://stack.jimmycai.com/config/header-footer。\n我在 Hugo 网站的根目录下创建了目录：layouts/partials/footer，然后创建了文件：custom.html，并将 Elastic RUM 的 JavaScript 代码添加到了这个文件中。\n我的具体实现结果，可以参考我的网站的代码：https://github.com/martinliu/martinliu.github.io.git\nElastic RUM 的效果 在完成了以上的步骤后，我们可以在 Elastic Cloud 的 RUM 和 APM 页面上看到 Hugo 网站的用户体验监控数据了。\n点击Kibana界面左侧导航栏里的 User Experience 仪表板 就可以看到下图。\n页面加载持续时间 这个高层次的概述是你分析的起点，回答了诸如：“我的服务器响应请求需要多长时间？”、“解析和绘制内容花费了多少时间？”、“我的网站接收了多少页面浏览？”等问题。\n仅从这些指标中观察，你可能无法解决任何问题，但当你深入挖掘数据时，你将对整体情况有所了解。\n用户体验指标 用户体验指标帮助你了解你的网站的感知性能。例如，首次内容绘制是浏览器开始呈现内容的时间戳。换句话说，用户在这个时候首次得到页面正在加载的反馈。\n指标参考如下：\n首次内容绘制：侧重于初始呈现，测量从页面开始加载到页面的任何部分显示在屏幕上的时间。代理使用浏览器中可用的Paint定时API来捕获时间信息。 总阻塞时间：在首次内容绘制和事务完成之间发生的每个长任务的阻塞时间之和（持续时间超过50毫秒）。总阻塞时间是时间到交互（TTI）的极好伴侣，后者是实验室指标，不能通过浏览器API在领域中获取。代理根据页面加载生命周期中发生的长任务数量捕获TBT。 长任务：长任务是任何占用UI线程较长时间（大于50毫秒）并阻止执行其他关键任务（帧速率或输入延迟）的用户活动或浏览器任务。 长任务数量：长任务的数量。 最长长任务持续时间：页面上最长长任务的持续时间。 所有长任务的总持续时间：所有长任务的总持续时间 这些指标讲述了关于用户如何体验你的网站的重要故事。但开发人员不应该成为解释和采取这些信号的专家；他们应该花时间对这些指标提供的机会做出反应。因此（以及许多其他原因），Elastic已经采纳了Google核心Web Vitals。\n核心Web Vitals是Google最近推出的一项倡议，旨在引入一组新的度量标准，通过量化真实用户体验更好地分类良好和糟糕的网站。这是通过查看三个关键指标来实现的：加载性能、视觉稳定性和互动性：\n（图片来源：https://web.dev/vitals）\n最大内容绘制（LCP）: 加载性能。LCP是页面的主要内容可能已加载的时间戳。对于用户来说，这是您网站的感知加载速度。为了提供良好的用户体验，Google建议将LCP控制在2.5秒以下。 首次输入延迟（FID）: 加载响应性。FID测量用户首次与页面互动（如点击）之间的时间，以及页面能够响应这些互动的时间。为了提供良好的用户体验，Google建议将FID控制在100毫秒以下。 累积布局偏移（CLS）: 视觉稳定性。由于异步资源加载或动态内容添加而导致内容移动了吗？CLS测量这些令人沮丧的意外布局变化。为了提供良好的用户体验，Google建议将CLS得分控制在0.1以下。 加载/查看分布 操作系统、浏览器家族和地理位置都可能对访问者体验你的网站产生巨大影响。这些数据可以帮助你了解用户何时、从哪里访问你的网站，并帮助你优化的优先级——例如，为访问你的站点最多的浏览器优先进行改进。\n不要忘记，这些数据还会影响搜索引擎页面排名和内容站点在热门故事中的位置——而无需使用AMP。\n错误细分 JavaScript错误可能对用户在你的网站上的体验产生负面影响。但是，用户软件和硬件的差异使得几乎不可能测试每种组合。而且，随着JavaScript变得越来越复杂，对用户体验监控和错误报告的需求也在不断增加。错误监控通过在生产环境中显示发生在你的网站上的JavaScript错误，使这些错误可见。\n点击Kibana界面左侧导航栏里的 APM 服务 ，选择我的 blog 的服务名称，就可以看到下图。\n由于 Elastic RUM 和 Elastic APM 实现的是全链路的追踪，如果我的 Blog 会访问到其他后台服务，而且那些后台服务也接入了 APM 监控，那么在 APM 的界面里，就可以看到端到端的追踪监控视图。\n虽然，我的这个 Blog 网站是一个无后台的静态网站，但是在 APM 中也能看到很多数据分析，包括：\n延迟 吞吐量 事务 错误 当然，我们还可以根据这些数据，使用 Elastic 的机器学习进行异常检查分析，从而并不需要为任何一个指标的数值做阀值告警管理；当然如果某个指标恰好是我们所需要的 SLI，那么我们可以在 SLO 管理功能中，其设置 SLO 的数值，并增加告警策略。\n在完成了以上配置之后，Elastic RUM 帮助我发现了一个问题：Blog 网站的部分图片使用了腾讯云的对象存储，我的腾讯云账户由于欠费，对象存储服务应该是已经停止服务一段时间了，因此部分图片已经无法正常加载，影响到很多篇文章上图片的正常显示。我会根据 Elastic RUM 的错误告警，尽快将那些无法加载图片的文章页面进行修复。\n总结 本文介绍了如何为 Hugo 网站添加 Elastic RUM 监控。Elastic RUM 是 Elastic Observability 中的实时用户体验监控（Real User Monitoring，RUM）功能，是 Elastic Stack 中的一部分。\n如果读者也运行着 Hugo 的网站，可以参考本文，完成 Elastic RUM 的接入。当然其他的静态网站生成器构建的网站也可以参考这个过程，只是具体的实现方式可能有所不同。这里所介绍的知识和配置方式，也同样适用于你正在工作的前端项目。\n参考资料 Elastic RUM 产品文档 Real User Monitoring JavaScript Agent 配置参考 Elastic RUM 概述 Elastic Cloud Elastic Cloud APM 解决方案 Elastic Cloud APM RUM 概述 Feature picture ❤️ Amina Filkins: https://www.pexels.com/photo/crop-man-with-documents-and-laptop-at-table-5424636/\n","date":"2023-12-08T09:44:13+08:00","image":"https://martinliu.cn/blog/add-elastic-rum-to-hugo-site/pexels-amina-filkins-5424636_hu_addd3ef2235ef5a2.jpg","permalink":"https://martinliu.cn/blog/add-elastic-rum-to-hugo-site/","title":"为 Hugo 网站添加 Elastic RUM 用户体验监控"},{"content":"在最近的 ElasticON 大会上，Elastic 可观测性的 AI Assistant 得到了充分曝光。在 Keynote 中，还专门做了一个演示，展示了 AI Assistant 的功能，以及如何使用 AI Assistant 来解决问题。\n我最近好在学习微软的 Azure OpenAI 服务，在我的 Azure 环境中，已经创建了一个 OpenAI 服务，可以用于AI Assistant 的测试。因此，我就想看看 Elastic 的 AI Assistant 和 Azure 的 OpenAI 服务结合起来的效果如何。\nElastic 可观测性的 AI Assistant 它有两个使用方式：\nContextual insights ： 在可观测性 APP 的界面中，在很多特定的位置，都可以点击右上角的 AI Assistant 链接，然后进入当前界面的上下文分析，在日志和 APM 中都已经做了集成。此功能的目标是：帮你理解错误日志和指标信息，并尽可能的给你一定的解释和建议。 Universal Profiling - 解释了运行的应用里最昂贵的库和函数，并提供优化建议。 应用性能监控（APM） - 解释了APM错误并提供纠正建议。 基础设施可观测性 （Infrastructure observability）- 解释了在主机上运行的进程。 日志 （log）- 解释了日志消息并生成搜索模式以查找类似问题。 告警 （alerting） - 为日志速率变化提供可能的原因和纠正建议。 Chat 聊天会话 ： 以可观测性数据为基础，你可以请求机器人为你汇总、分析、和可视化数据。从而得到你想要的结果，可能是为了制作某个报表，也可以能是开始探索分析某个性能问题。 运行这个功能的前提条件：\nElastic Stack version 8.9 或者更高 拥有 Elastic Enterprise 订阅 一个 AI 服务方的账号，比如 Azure OpenAI gpt-4(0613) 或 gpt-4-32k(0613) 服务， 或者 OpenAI gpt-4 服务 为了使用私域文档作为知识库，还需要一个至少 4GB 的机器学习节点。 准备 Azure OpenAI 服务 首先，你需要在 Azure 的 Portal 中创建一个 OpenAI 服务，这个服务提供 OpenAI GPT-4 模型，我创建的服务名称是 ai4elasticstack。\n这里确保选择 Azure OpenAI 的服务所在区域里能提供 gpt-4 模型，比如我选择的是瑞士中部。\n然后，是在这个区域中部署所需要的模型。\n这里我部署了 gpt-4-32k 模型，需要注意的是：token 的限速需要调整到最大，这样才能保证 AI Assistant 的正常使用。\n创建 AI Assistant 的连接器 在 Elastic Cloud 中，创建一个 AI Assistant 所需要使用到的连接器，这个连接器的类型是 Azure OpenAI，然后，填写 Azure OpenAI 服务的相关信息，如下图所示。\nURL 是一个重要的参数，它的格式如下：\n1 https://{your-resource-name}.openai.azure.com/openai/deployments/{deployment-id}/completions?api-version={api-version} 其中，{your-resource-name} 是你创建的 Azure OpenAI 服务的名称，{deployment-id} 是你创建的 Azure OpenAI 服务的部署 ID（即名称），{api-version} 是你创建的 Azure OpenAI 服务的 API 版本。这里的 {deployment-id} 与 {api-version} 有一定的排列组合，某些组合是不工作的，我当前的选择是可以工作：gpt4（32k 0613 版本） 和 2023-07-01-preview\n1 https://ai4elasticstack.openai.azure.com/openai/deployments/gpt432k0613/chat/completions?api-version=2023-07-01-preview 这里配置完 URL 和 API 秘钥之后，点击“测试”页面，如果一切正常，你会看到一个绿色的正常调用 OpenAI 的返回。这样你的 AI Assistant 就可以正常工作了。\n理解日志中的错误 进入可观测性 app，点击 Stream，在这里选中一条报错的日志，内容如下：\n1 2 3 16:23:13.729 elastic_agent.metricbeat [elastic_agent.metricbeat][error] Error fetching data for metricset docker.memory: No memory stats data available 点击 view detail，查看这条日志的详细信息。\nAI Assistant 会自动分析这条日志，然后给出两个选项。\n点击“What\u0026rsquo;s this message?”, AI Assistant 会给出这条日志的解释，以及可能的原因。这个 host 上由于 Docker 服务没有启动，导致 Metricbeat 无法获取到 Docker 的内存信息。AI Assistant 首先对这条日志，做了解释，解释内容里包含了你可能会关注的元数据信息，包括：版本号、操作系统、日志级别等。然后推测出是 Docker 服务没有启动的原因。最后，说明这是不正常的情况，应该尽快排查 Docker 服务。同一条错误信息，也可能会出现不同的解释。下面是整个 AI Assistant 的解释内容： The log entry you provided is from an Elastic Agent running on a host named \u0026ldquo;linux-dev-02\u0026rdquo; with the IP address \u0026ldquo;10.1.0.4\u0026rdquo;. The host is running Ubuntu 22.04.3 LTS (Jammy Jellyfish) with kernel version 6.2.0-1017-azure. The Elastic Agent version is 8.10.4 and it\u0026rsquo;s not a snapshot version. The agent is running on a cloud instance in the \u0026ldquo;eastasia\u0026rdquo; region of Azure.\nThe component that generated this log entry is Metricbeat, which is a lightweight shipper that you can install on your servers to periodically collect metrics from the operating system and from services running on the server. The specific Metricbeat module in use here is the Docker module, which collects metrics and logs from Docker containers.\nThe log level of the message is \u0026ldquo;error\u0026rdquo;, which indicates that an error or problem has occurred. The specific error message is \u0026ldquo;Error fetching data for metricset docker.memory: No memory stats data available\u0026rdquo;. This suggests that Metricbeat was unable to fetch memory statistics for a Docker container. This could be due to a number of reasons, such as the Docker container not being active, the Docker daemon not being accessible, or the Docker API not returning memory statistics.\nWhether this is expected or an issue depends on your specific setup and expectations. If you expect to be collecting memory statistics from Docker containers and this error is preventing that, then it would be an issue. If you\u0026rsquo;re not using Docker or not interested in collecting memory statistics from Docker containers, then it might not be an issue. However, it\u0026rsquo;s generally not expected for errors to be occurring, so it might be worth investigating further to understand why this error is happening.\n如果点击“How do i find similar log messages?” , AI Assistant 会给出一个 KQL 查询语句，使用这个查询语句会返回与这条日志相似的日志。这个查询语句的结果，可以帮助你更好的理解这条日志的上下文。 链接器选择：你可以在 Elastic Stack 中，配置多个 AI Assistant 的连接器，可能对应到不同的 OpenAI 服务+版本的组合。 这个功能的好处：\n通过 AI Assistant 的解释，它可以帮助你更全面的理解日志的内容本身，由于每个人并不是熟悉所有的技术领域，AI 在这里可以很好的补充你的知识短板。 在高压力的排错环境中，从模糊的日志事件内容中，很快的得出下一步排查的方向是比较有意义的。人脑很有可能在疲惫状态下，很难准确地得出下一个排查的动作。 AI 对错误原因的推理，看着并不一定高明，但是作为排错的起点，还是比较有用的。你可以在这个基础上，点击界面上的 “Start Chat” 按钮，进入到 Chat 聊天会话功能模式，然后，继续与 AI 机器人对话，追问：“其他潜在的故障原因是那些？”；这样 AI 给我了另外不同的 4 种故障可能，涉及 Docker 服务器、配置、Metricbeat 的配置等等。可见 AI 在细分领域里的知识的深度还是一些的。 下面是我的追问和 AI 的回答，这里是支持中文：\n“ You：还有什么可能的原因会导致这个问题？\nElastic Assistant ：这个错误信息表示 Metricbeat 无法获取 Docker 容器的内存统计信息。可能的原因包括：\nDocker 容器未运行：如果你试图获取一个未运行或不存在的 Docker 容器的内存统计信息，将会出现这个错误。\nDocker 守护进程无法访问：Metricbeat 需要能够访问 Docker 守护进程来获取容器的统计信息。如果由于某种原因（例如权限问题或网络问题）无法访问 Docker 守护进程，将会出现这个错误。\nDocker API 未返回内存统计信息：Metricbeat 通过 Docker API 获取容器的统计信息。如果 Docker API 未返回内存统计信息，将会出现这个错误。这可能是因为 Docker API 的问题，或者是因为容器本身没有生成内存统计信息。\nMetricbeat 配置问题：如果 Metricbeat 的 Docker 模块没有正确配置，可能也会导致这个问题。例如，如果 Metricbeat 没有正确配置 Docker 守护进程的地址，或者没有提供正确的证书来访问需要 TLS 的 Docker 守护进程，将会出现这个错误。\n你可以根据这些可能的原因进行排查，看看哪一项可能是问题所在。 ”\n这个功能还在可观测性的其它功能模块中也做了深度的集成，例如在 APM 等模块中，也可以调用到 AI Assistant 的 “上下文洞见”；基本上，就是 Elastic Stack 在多个场景中，人类可用将自己分析错误信息的工作一定程度的交给 AI 去做；这样，我们就可以更加专注于问题的解决，而不是在监控数据、时序信息的分析上浪费更多的时间。从长远来看，这个上下文洞见的辅助排查功能，确实是有辅助驾驶和导航的意义，还是比较有用的。\nChat 聊天会话功能 我测试了一个开放式的问题，希望 AI 能帮我分析出：我的服务器是否即将有磁盘空间用尽的情况发生。如下图所示：\n下面解释一下 AI Assistant 的回答：\n我使用英语提问，其实你可以用任何语言提问，OpenAI 都可以正确理解。 点击这里折叠隐藏的 7 个步骤，这些步骤是 AI Assistant 为了回答我的问题，所做的推理思考和处理过程。这里使用了多个方法调用，包括在 Elasticsearch 数据库中查找任何它想要的信息。 AI Assistant 的知识库【你可以将知识库配置在 Elasticsearch 中，AI 的分析流水线，读取并理解知识条目内容，并调用这些知识】，以及我的问题的上下文信息，AI Assistant 会根据这些信息，做出推理，然后给出回答。 最终 AI 用绘图的方式给出主机的磁盘空间利用率的汇总情况，很可惜的是，它几乎就做对了；这个图形没有显示出来的原因是：在最后还应该调用一个 max 或者 avg 的运算函数。 最后一句话，再次解释并总结了我的提问。 我并没有继续这个会话，如果继续问答下去的话，如果 AI Assistant 的聊天内容总是我所期望的正确的结果内容；那么，很可能我们就不需要去各种界面里到处点击、查看和分析各种数据图表和原始数据了。假如以后接入了自然语音的输入界面，那么，未来这种排错和分析场景还确实是一种比较科幻的感觉。\nAI助手使用函数通过文本、数据和可视化组件在聊天对话中包含相关上下文。您和AI助手都可以提出函数建议。您还可以编辑AI助手的函数建议并检查函数响应。\n以下表格列出了可用的函数：\nsummarize ：总结对话的部分。\nrecall ：回顾先前的学习。\nlens ：使用Lens创建自定义可视化，可以添加到仪表板中。\nelasticsearch ：代表您调用Elasticsearch API。\nkibana ：代表您调用Kibana API。\nalerts ：获取可观测性的警报。\nget_apm_timeseries ：显示任何服务或所有服务及其任何或所有依赖项的不同APM指标（如吞吐量、故障率或延迟）。既显示为时间序列，也显示为单一统计数据。此外，该函数返回任何更改，如峰值、步进和趋势更改或下降。您还可以使用它通过请求两个不同的时间范围，或者例如两个不同的服务版本来比较数据。\nget_apm_error_document ：根据分组名称获取示例错误文档。这还包括错误的堆栈跟踪，这可能提示错误的原因。\nget_apm_correlations ：获取在前景集中比背景集更突出的字段值。这对于确定哪些属性（例如error.message、service.node.name或transaction.name）对高延迟的贡献是有用的。另一个选项是基于时间的比较，您可以在更改点之前和之后进行比较。\nget_apm_downstream_dependencies ：获取服务的下游依赖项（服务或未被检测的后端）。通过返回span.destination.service.resource和service.name两者将下游依赖项名称映射到服务。如果需要，可以使用此功能进一步深入挖掘。\nget_apm_service_summary ： 获取单个服务的摘要，包括语言、服务版本、部署、环境以及它运行的基础设施。例如，pod的数量和它们的下游依赖项列表。它还返回活动警报和异常。\nget_apm_services_list ：获取受监控服务的列表，它们的健康状态和警报。\n总结 由于时间有限，我并没有做知识库的导入，从文档中看到，知识库私域信息的注入基本上是这样的过程：首先将知识库文档整理后导入到 Elasticsearch 的一个索引中，然后使用结合 Elasticsearch 本身的 ELSER 自然语音处理能力和 OpenAI 的理解推理能力，来支撑 AI 辅助分析排查问题的过程。\n以上功能测试的配置非常简单，在 Elastic Cloud 的环境中，参考本文，你应该在 10 分钟内就可以完成所有配置。从上下文分析和聊天的两个场景中，我们可以很快的找到 AI 辅助运维的感觉。\n参考文章 ：\nhttps://www.elastic.co/guide/en/observability/current/obs-ai-assistant.html https://www.youtube.com/watch?v=AQ4sPC_O2Ck\u0026ab_channel=Elastic https://www.elastic.co/blog/context-aware-insights-elastic-ai-assistant-observability https://www.elastic.co/blog/whats-new-elastic-observability-8-9-0 https://www.elastic.co/blog/whats-new-elastic-observability-8-10-0 Feature picture ❤️ cottonbro studio : https://www.pexels.com/zh-cn/photo/6153354/\n","date":"2023-12-05T13:10:43+08:00","image":"https://martinliu.cn/blog/elastic-elastic-obs-ai-assistant-aoai/pexels-cottonbro-studio-6153354_hu_21f6d40d3f4192e9.jpg","permalink":"https://martinliu.cn/blog/elastic-elastic-obs-ai-assistant-aoai/","title":"先睹为快 Azure OpenAI 驱动的 Elastic 可观测性 ‘AI 助理’"},{"content":"DevOps的工作流程中所需要到各种各样的命令行工具，在 Azure 的环境中，不同的 DevOps 工具在运行之前，都必须先完成 Azuore 账号的登录认证。而且，最好是在非用户干预和交互的方式下，完成登录认证。在这种情况下就可以使用 Service Principal 的方式，来完成 Azure 账号的登录认证。本文介绍如何创建一个用于在命令行登录认证 Azure 的 Service Principal。\n创建 Service Principal 首先你需要安装或者准备好 Azure CLI，然后使用 Azure CLI 命令行工具，创建一个 Service Principal 的命令如下：\n1 2 3 az ad sp create-for-rbac --name azure-sp-4-devops \\ --role Contributor \\ --scopes /subscriptions/${SUBSCRIPTION}/resourceGroups/${RESOURCE_GROUP} 参数说明：\n--name：Service Principal 的名称，这个名称可以随意指定，但是最好是有意义的名称，方便后续的管理。 --role：Service Principal 的角色，这里指定为 Contributor，表示这个 Service Principal 在 Azure 中的权限是 Contributor。 --scopes：Service Principal 的作用域，这里指定为 /subscriptions/${SUBSCRIPTION}/resourceGroups/${RESOURCE_GROUP}，表示这个 Service Principal 的作用域是 ${RESOURCE_GROUP} 资源组。 ${SUBSCRIPTION}：是一个环境变量，用于指定 Azure 订阅 ID。 ${RESOURCE_GROUP}：是一个环境变量，用于指定 Azure 资源组名称。 在上面的命令中，应该注意的是 --role 需要是权限合理的值。应该保持最小可用权限的原则，不要使用 Owner 这样的权限。如果你不知道应该使用什么权限，可以先使用 Contributor 权限，然后在后续的使用中，逐步降低权限。\n在我最近的测试中，由于我需要在多个教程项目间切换不同的资源组，而且资源组都是短期的，用完了就用删除的资源组，删除整个资源组是彻底清除已用资源的一个好方法。因此我在 --scopes 这个参数中，最经常使用的 SP 作用范围是 \u0026ndash;scopes /subscriptions/${SUBSCRIPTION} ，这样就可以在任何一个资源组中使用这个 SP 了。假如你需要在多个不同订阅之间工作，可以灵活的使用 ${SUBSCRIPTION} 这个环境变量，来指定不同的订阅 ID。\n以上命令行的输出结果类似如下：\n1 2 3 4 5 6 { \u0026#34;appId\u0026#34;: \u0026#34;3930xxxx-xxxx-xxxx-xxxx-xxxxd0e2xxxx\u0026#34;, \u0026#34;displayName\u0026#34;: \u0026#34;azure-sp-4-devops\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;eKxxxxxxxxxxxxxxxxxxxxxxxxxxxxX\u0026#34;, \u0026#34;tenant\u0026#34;: \u0026#34;21d7xx-xxxxxx-xxxxxxx-xxxxxxx-xxxxxx55\u0026#34; } 将 SP 的细节信息用于命令行变量 以上输出结果默认是 JSON 格式的，如果你需要将它直接用于命令行变量，可以使用 --query 参数，来指定输出的格式。例如，如果你需要将 appId 等的值，用于命令行变量，参考使用如下的命令：\n1 2 3 4 SERVICE_PRINCIPAL_JSON=$(az ad sp create-for-rbac --name aks-getting-started-sp --role Contributor --scopes /subscriptions/${SUBSCRIPTION} -o json) SERVICE_PRINCIPAL=$(echo $SERVICE_PRINCIPAL_JSON | jq -r \u0026#39;.appId\u0026#39;) SERVICE_PRINCIPAL_SECRET=$(echo $SERVICE_PRINCIPAL_JSON | jq -r \u0026#39;.password\u0026#39;) TENANT_ID=$(echo $SERVICE_PRINCIPAL_JSON | jq -r \u0026#39;.tenant\u0026#39;) 以上命令中，使用了 jq 命令，来从 JSON 格式的输出中，提取出 appId 和 password 的值，并且分别用于命令行变量 SERVICE_PRINCIPAL 和 SERVICE_PRINCIPAL_SECRET。这样的好处是，避免了手工的复制和粘贴，也避免了数据在命令行的泄露。但是，如果是用于测试目的的 SP，也可以将这三个变量的值，直接复制保持到一个安全的地方，方便后续的反复使用。\n登录 Azure 使用以上准备好的 Service Principal 登录 Azure 的命令如下：\n1 2 3 4 5 6 az login \\ --service-principal \\ --tenant $TENANT_ID \\ --username $SERVICE_PRINCIPAL \\ --password $SERVICE_PRINCIPAL_SECRET \\ --output table 在以上三个变量都正确的情况下，运行完以上命令后，会输出当前登录的 Azure 账号的相关信息，类似如下：\n1 2 3 Environment Name Tenant Id Subscription Id State Is Default ------------- ------------------- ------------------------------------ ------------------------------------ ------- ----------- AzureCloud azure-sp-4-devops 21d7xx-xxxxxx-xxxxxxx-xxxxxxx-xxxxxx55 3930xxxx-xxxx-xxxx-xxxx-xxxxd0e2xxxx Enabled True 这样，就完成了 Azure 账号的登录认证。\n查看当前登录的 Azure 账号 如果不确定，当前是否已经登录，或者不确定在什么 Azure 的账号下，可使用以下命令，可以查看当前登录的 Azure 账号：\n1 az account show 参考 az ad sp create-for-rbac az login az account show ❤️ Feature Photo by Miguel Á. Padriñán: https://www.pexels.com/photo/close-up-shot-of-keyboard-buttons-2882566/\n","date":"2023-11-14T11:03:55+08:00","image":"https://martinliu.cn/blog/create-azure-sp-for-cli/pexels-miguel-2882566_hu_d76995433a28518a.jpg","permalink":"https://martinliu.cn/blog/create-azure-sp-for-cli/","title":"创建用于命令行登录认证 Azure 的 Service Principal 必读"},{"content":"本文介绍如何使用 Terraform 创建一个基础配置的 Azure Kubernetes Service (AKS) 集群，可以用于快速的启动一个开发测试环境，基础特性如下。\n使用尽可能多的默认值 node pool 使用了自动扩展，最小节点数为 1，最大节点数为 10 AKS将使用由Azure自动创建和管理的托管身份 登录 Azure 参考这篇文章《创建用于命令行登录认证 Azure 的 Service Principal 必读》，创建一个用于在命令行登录认证 Azure 的 Service Principal。\n为了将创建的 Service Principal 的细节信息，用于命令行变量，方便 Azure CLI 命令的参数化，还为了将所有必要的变量带入 .tf 文件的变量中。可以参考下面的命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 export TF_VAR_subscription_id=XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXXXX SERVICE_PRINCIPAL_JSON=$(az ad sp create-for-rbac --name aks-getting-started-sp --role Contributor --scopes /subscriptions/${TF_VAR_subscription_id} -o json) TF_VAR_client_id=$(echo $SERVICE_PRINCIPAL_JSON | jq -r \u0026#39;.appId\u0026#39;) TF_VAR_client_secret=$(echo $SERVICE_PRINCIPAL_JSON | jq -r \u0026#39;.password\u0026#39;) TF_VAR_tenant_id=$(echo $SERVICE_PRINCIPAL_JSON | jq -r \u0026#39;.tenant\u0026#39;) az login \\ --service-principal \\ --tenant $TF_VAR_tenant_id \\ --username $TF_VAR_client_id \\ --password $TF_VAR_client_secret \\ --output table 以上在创建 Service Principal 的时候，使用了 --scopes /subscriptions/${TF_VAR_subscription_id}，这样就可以在任何一个资源组中使用这个 SP 了。假如你需要在多个不同订阅之间工作，可以灵活的使用 ${TF_VAR_subscription_id} 这个环境变量，来指定不同的订阅 ID。\n这段命令中一共设置了四个命令行的环境变量，由于需要在 .tf 文件中作为变量使用，因此需要使用 TF_VAR_ 前缀，这样 Terraform 才能识别到这些变量。\n登录 Terraform Cloud Terrafrom 命令行工具的安装本文忽略，详见官方文档 Terraform CLI 。\nTerraform Cloud 是 Terraform 官方提供的一种 SaaS 服务，可以用于管理 Terraform 的状态文件，以及执行 Terraform 的计划和应用。本文中使用 Terraform Cloud 来管理状态文件，以及执行计划和应用。\n首先，你需要在 Terraform Cloud 中创建一个组织，然后创建一个工作区，用于存放状态文件。然后，你需要在本地安装 Terraform CLI 命令行工具，然后使用 Terraform CLI 命令行工具，登录 Terraform Cloud。\n1 terraform login 创建 AKS 集群 本文使用的样例代码在 GitHub 上，你可以直接使用这个样例代码，也可以参考这个样例代码，自己创建一个 AKS 集群。\n下面是样例代码中的 main.tf 文件，这个文件中包含了创建 AKS 集群的所有必要的配置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 terraform { # 使用远程 Cloud 后端 cloud { organization = \u0026#34;DevOpsCoach\u0026#34; workspaces { name = \u0026#34;aks-labs\u0026#34; } } } provider \u0026#34;azurerm\u0026#34; { features {} # 下面的配置允许 Terraform 以您的身份与 Azure API 进行交互，从而管理您的资源。 # 从 CLI 的环境变量中取得这些实际的数值 tenant_id = var.tenant_id subscription_id = var.subscription_id client_id = var.client_id client_secret = var.client_secret } resource \u0026#34;azurerm_resource_group\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;${local.prefix}-rg\u0026#34; location = local.location } 以上文件中引用了两种变量，一种是从 locals.tf 文件中引用的本地变量，另一种是从命令行的环境变量中读取到的TF_VAR 开头的变量。这样从 Terraform 命令行执行之前，就可以将这些变量设置好，然后 Terraform 就可以使用这些变量了。\n下面是样例代码中的 locals.tf 文件，这个文件中包含了创建 AKS 集群的所有必要的本地变量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 locals { prefix = \u0026#34;aks4devops\u0026#34; location = \u0026#34;eastasia\u0026#34; } variable \u0026#34;client_id\u0026#34; { description = \u0026#34;Client ID for the Azure provider\u0026#34; type = string } variable \u0026#34;client_secret\u0026#34; { description = \u0026#34;Client Secret for the Azure provider\u0026#34; type = string } variable \u0026#34;subscription_id\u0026#34; { description = \u0026#34;Subscription ID for the Azure provider\u0026#34; type = string } variable \u0026#34;tenant_id\u0026#34; { description = \u0026#34;Tenant ID for the Azure provider\u0026#34; type = string } 这里文件中设定了两个变量参数，另外还声明了四个命令带入的变量，它们是从命令行的环境变量中读取到的TF_VAR 开头的变量。\n下面是样例代码中的 aks.tf 文件，这个文件中包含了创建 AKS 集群的所有必要的配置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 resource \u0026#34;azurerm_kubernetes_cluster\u0026#34; \u0026#34;example\u0026#34; { # AKS cluster basic information name = \u0026#34;${local.prefix}-k8s\u0026#34; location = azurerm_resource_group.example.location resource_group_name = azurerm_resource_group.example.name dns_prefix = \u0026#34;${local.prefix}-k8s\u0026#34; # node pool settings default_node_pool { name = \u0026#34;default\u0026#34; node_count = 2 min_count = 1 max_count = 10 vm_size = \u0026#34;Standard_DS2_v2\u0026#34; enable_auto_scaling = true } # AKS use system auto created identity identity { type = \u0026#34;SystemAssigned\u0026#34; } } 以上集群基本上使用了所有的系统默认配置，除了设定了一个 node pool，这个 node pool 使用了自动扩展，最小节点数为 1，最大节点数为 10。\n在阅读了这些文件之后，就可以在本地执行 Terraform 的计划和应用了。\n1 2 3 terraform init terraform plan terraform apply 在执行以上命令的过程中，我们可以在 Terraform Cloud 的 Web 界面中，看到 Terraform 的执行过程。\n在测试完成了之后，可以使用下面的命令，删除 AKS 集群。\n1 terraform destroy 参考 Terraform Cloud Terraform Cloud - CLI Terraform Cloud - CLI - Login Azure CLI Login Azure AKS documentation Azure AKS Terraform documentation ","date":"2023-11-13T09:49:03+08:00","image":"https://martinliu.cn/blog/terraform-create-aks-cluster/154_hu_161fd2d1d4c1301b.png","permalink":"https://martinliu.cn/blog/terraform-create-aks-cluster/","title":"使用 Terraform 创建 Aks 集群"},{"content":"使用 Azure CLI 创建 K8S 集群是一种非常简单易用的方式。你可以在任何操作系统中安装 Azure CLI 命令行工具； 或者启动含有 Azure CLI 的容器，然后在容器内使用 Azure CLI 。\n准备 Azure CLI 本文的演示命令都是在 macOS 上操作的，Azure CLI 在任何 OS 上安装的文档见 Install Azure CLI 。\n如果你不想在本机安装 Azure CLI 命令行工具，可以使用 Docker 容器的方式，启动一个含有 Azure CLI 的容器，然后在容器内使用 Azure CLI 命令行工具。下面这个参考命令，是在此容器中带入当前路径做为容器内工作目录，并且指定运行特定 Azure CLI 版本的例子：\n1 docker run -it --rm -v $(pwd):/work -w /work mcr.microsoft.com/azure-cli:2.0.80 登录 Azure 参考命令如下：\n1 az login 假设你是使用本机安装的 Azure CLI 做 Azure CLI 的命令行登录认证，那么在运行了以上命令后，会弹出一个浏览器窗口，让你输入 Azure 的账号和密码，然后完成登录认证。\n然后，你可以查看当前账号中的订阅；确保随后使用中一个正确的订阅，用于创建 K8S 集群。\n1 az account list -o table 为了确保后续的命令行操作使用正确的订阅，可以用下面的命令设定订阅 ID；并且使用命令行变量的方式，设置当前使用的订阅。\n1 2 az account set --subscription \u0026lt;subscription-id\u0026gt; export SUBSCRIPTION=XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXXXX 创建资源组 为了让本次操作的过程产物，都放在一个资源组中，我们先创建一个资源组。这样方便在测试完的时候，可以一次性删除所有曾经用到过的资源。\n使用命令行变量设定资源组的名称和所在的区域，以及其他的参数：\n1 2 3 4 5 6 7 export RESOURCE_GROUP_NAME=aks-getting-started export LOCATION=eastasia export AKS_CLUSTER_NAME=aks-4-devops export AKS_CLUSTER_VERSION=1.28.3 export AKS_NODE_COUNT=2 export AKS_NODE_VM_SIZE=Standard_B2s export AKS_NODE_DISK_SIZE=50 创建资源组：\n1 az group create --name $RESOURCE_GROUP_NAME --location $LOCATION 创建 Service Principal 为了让 K8S 可以使用到 Azure 账号中的各种必要的资源服务（disk，负载均衡，存储等等），需要创建一个 Service Principal，用于 K8S 访问 Azure 资源。下面用新的命令行变量携带 Service Principal 的相关信息：\n1 2 3 4 5 6 7 SERVICE_PRINCIPAL_JSON=$(az ad sp create-for-rbac --skip-assignment --name aks-getting-started-sp -o json) SERVICE_PRINCIPAL=$(echo $SERVICE_PRINCIPAL_JSON | jq -r \u0026#39;.appId\u0026#39;) SERVICE_PRINCIPAL_SECRET=$(echo $SERVICE_PRINCIPAL_JSON | jq -r \u0026#39;.password\u0026#39;) az role assignment create --assignee $SERVICE_PRINCIPAL \\ --scope \u0026#34;/subscriptions/$SUBSCRIPTION/resourceGroups/$RESOURCE_GROUP_NAME\u0026#34; \\ --role Contributor 关于 Service Principal 的更多信息，可以参考 Azure AD Service Principal 。\n创建 K8S 集群 可以先使用下面的命令获取创建 aks 集群详细的帮助信息，以及丰富的可用选项；\n1 az aks create -h 查看当前可用区中的 AKS 服务中的 Kubernetes 版本：\n1 az aks get-versions --location $LOCATION -o table 运行创建 AKS 集群的命令：\n1 2 3 4 5 6 7 8 9 10 11 12 az aks create -n $AKS_CLUSTER_NAME \\ --resource-group $RESOURCE_GROUP_NAME \\ --location $LOCATION \\ --kubernetes-version $AKS_CLUSTER_VERSION \\ --load-balancer-sku standard \\ --nodepool-name default \\ --node-count $AKS_NODE_COUNT \\ --node-vm-size $AKS_NODE_VM_SIZE \\ --node-osdisk-size $AKS_NODE_DISK_SIZE \\ --network-plugin kubenet \\ --service-principal $SERVICE_PRINCIPAL \\ --client-secret \u0026#34;$SERVICE_PRINCIPAL_SECRET\u0026#34; 连接到 K8S 集群 使用下面的命令，获取 AKS 集群的连接信息：\n1 az aks get-credentials --resource-group $RESOURCE_GROUP_NAME --name $AKS_CLUSTER_NAME 这条命令会将 AKS 集群的连接信息，写入到 ~/.kube/config 文件中，然后你就可以使用 kubectl 命令行工具，连接到 AKS 集群了。\n1 kubectl get nodes 以上忽略命令行 kubectl 的安装方式，详见 Install and Set Up kubectl 。\n部署应用 下面参考 https://learn.microsoft.com/zh-cn/azure/aks/learn/quick-kubernetes-deploy-cli 文档中的操作步骤，部署 AKS 应用商店应用程序 。该应用系统的示意图如下：\n创建名为 aks-store-quickstart.yaml ，清单文件点此下载 ，并将以下清单复制到其中：\n使用 kubectl apply 命令部署上面的应用：\n1 kubectl apply -f aks-store-quickstart.yaml 使用 kubectl get pods 命令，查看应用程序的所有 Pod 都处于 Running 状态：\n1 kubectl get pods 使用下面的命令获取 store-front 服务的外网 IP 地址：\n1 kubectl get service store-front --watch 最后，打开 Web 浏览器并转到服务的外网 IP 地址，以查看 Azure 应用商店应用的实际效果。\n清理资源 使用下面的命令，删除整个测试的资源组、Service Principal 和 AKS 集群，以及当前命令行中 kubctl 的配置文件中的 K8S 集群的上下文。\n1 2 3 az aks delete --resource-group $RESOURCE_GROUP_NAME --name $RESOURCE_GROUP_NAME --yes az ad sp delete --id aks-getting-started-sp kubectl config delete-content $AKS_CLUSTER_NAME 总结 本文主要讲解了使用 Azure CLI 创建 K8S 集群所使用到的一般性流程和选项，目标是为你更复杂的使用场景打下基础。\nAzure CLI、Terraform 和 Pulumi 都是创建和管理云资源的工具，但它们各有优势：\nAzure CLI：\n简单易用：Azure CLI 的命令结构简洁明了，易于理解和使用。 Azure 专用：Azure CLI 是专为 Azure 设计的，对 Azure 的各种服务和资源有深度集成。 Terraform：\n提供声明式语法：Terraform 使用声明式语法，用户只需描述他们希望达到的最终状态，Terraform 将处理如何达到这个状态。 提供状态管理：Terraform 能够跟踪和管理每个部署的状态，这对于管理复杂的系统非常有用。 跨平台：Terraform 支持多个云服务提供商，不仅限于 Azure。 Pulumi：\n使用常规编程语言：Pulumi 允许使用常规编程语言（如 Python、JavaScript、TypeScript、Go 等）来描述和管理云资源，这使得开发者可以利用他们已有的编程知识和技能。 提供状态管理：与 Terraform 类似，Pulumi 也提供状态管理功能。 跨平台：Pulumi 同样支持多个云服务提供商。 选择哪种工具取决于你的具体需求和偏好。后续我们演示使用 Terraform 和 Pulumi 创建 K8S 集群的方式。\n参考 Quickstart: Deploy an Azure Kubernetes Service (AKS) cluster using the Azure CLI https://github.com/marcel-dempers/docker-development-youtube-series ","date":"2023-11-10T22:52:40+08:00","image":"https://martinliu.cn/blog/az-cli-create-aks-cluster/hb9riivbne1jpgrnh77w_hu_9b564d0f18895c0e.png","permalink":"https://martinliu.cn/blog/az-cli-create-aks-cluster/","title":"使用 Azure CLI 创建 K8S 集群"},{"content":"“可观测性”英文 observability ，缩写 o11y 。\n常见定义 最常见的引用来自机械工程领域中关于“控制论”的研究，1960 年鲁道夫·E.卡尔曼首次提出了“可观测性”这个词。\n在控制论中，这个概念涉及：物理机械系统和与之对偶关系的数学模型。然而，这个机械工程师用来研究物理系统的术语，并一定能完全的适用于我们所研究软件应用系统。\n大多数人将“可以根据系统的外部输出信息推断出系统内部状态的好坏（源自于《控制论》）”全盘接受，并套用在了软件行业相关讨论的上下文中。\n常见误解 降维误读：“可观测性”就是“遥测-telemetry”和“监控-monitor”的同义词。它与监控并没啥区别。就是通常所说的三大支柱（日志、指标和 Trace）。\n厂商的市场宣传：由于市场宣传的需要，目前几乎所有传统做指标、日志和 APM - Trace 的厂商都直接宣称他们都是做可观测性的厂商，提供可观测性产品、解决方案或者 SaaS 服务。常见做法：可观测性是他们扩展出来的，用旧产品改名。\n有些公司会直接的进行概念替换：“我们就是可观测性”。\n以上现实情况，给所有人对可观测性的理解带来了一定的障碍。\n应有的定义 在我们排除以上学术上的认祖归宗，以及市场宣传的张冠李戴以后。\n我们应该可以给出一个关于可观测性更加严谨的定义：\n可观测性是应用系统的一种内在属性，我们可以通过可观测性管理工具将其显性的展现出来，用于探索分析。 度量能力：无论系统中发生着多么费解的现象，它的度量数据能帮助你更好地理解和解释系统当前的状态。可以解答：系统处于什么状态？ 探索能力：我们能够在各类系统状态数据的所有维度和组合之间进行关联分析，并无需遵循某种预定的调试\u0026amp;排查模式和路径，用于解答：系统中发生了什么变化？为什么会发生这样的变化？ 可按需调整能力：最好是不需要改变原有软件系统的代码，如有需要，也能随心所欲的按需埋点覆盖新的洞察认知。 以上是关于可观测性定义应该具备的描述信息。适用于我们在对软件系统进行运行和维护的上下文中，这个概念应该具有的含义和外延还有很多。\n为何现在o11y很重要？ 特别是在云原生的运维场景中，传统监控并非唯一的最佳方法；而且，传统的指标和日志监控已经捉襟见肘；产品团队和运维人员始终处于很被动的状态，传统监控数据仅限于让我们了解有限的历史状态，很难推理和预测未知故障。在创建了大量告警规则后，告警事件的数量和信噪比都居高不下，运维值守人员终日忙于关闭噪音事件，很难聚焦在有意义的事件上。\n调试\u0026amp;排查应用系统 在生产环境中，调试和排查应用系统的故障和性能问题充满着各种挑战。任意一个人是无法完全的理解复杂的软件系统，大部分人都是习惯于使用分解法思考系统故障；先脑补系统的整体架构，然后怀疑某个系统组件，再考虑组件之间的关联关系。在云原生系统中，我们很难准确的在大脑中勾勒出系统架构的全貌，甚至都不能准确的定位出某个组件（子服务）是运行在什么地方（AZ，Host，Pods）。而且，现代分布式系统所发生的故障，是一系列持续的不同的新问题，发生故障的代码有可能是自己开发的，也很可能是第三方依赖组件\u0026amp;外部服务。人的诊断故障的直觉和经验只能对已知的错误模式有效，传统监控就是面向已知问题的，先假设每一个监控点都是确定的未来的故障点。而使用可观测性进行故障诊断，是面向未知问题的，是用来解释未知问题是如何发生的。\n用可观测数据度量和感知应用系统的状态，以及状态的变化，就需要认识到数据的两个维度“基数”和“维度”。\n基数 基数的定义：关注于一条可观测性数据的某个字段，如果每个字段都是一个 Key - value 对，维度指的是这个组合中 value 的唯一性，也就是值的唯一数量。\n高基数字段的例子：用户 ID、UUID、购物车 ID、请求 ID、容器 ID、主机名（弹性、不可变架构）、Pod ID等等。 低基数字段的例子：性别、种族、国家、婚姻状态等等 基数对于可观测性的作用是：通过聚合采集到的高基数数据集合，得到低基数的分析结果；可观测性管理拥抱高基数数据，也就拥抱更多未知的可能性，因此它具备感知未知故障模式的先天优势。\n而传统监控（日志、指标）数据的基数一般处于一个合理的规模，默认规避高基数，希望用尽可能少的指标分析定位问题，从工具上反映出来的是枚举法；在日常实践中：监控工具的使用者，倾向于关闭大量的认为没什么用的，或者不会出问题的故障采集点。即使是指标全开，日志尽采，而后续的数据分析和洞察手段往往是低效且滞后的，数据后期处理的高价值工作不是没有能力做，就是没有人力和成本做。\n工具厂商（指标、日志、APM）可能会按照所能覆盖到的监控指标的数量，而增加工具使用的费用。\n维度 维度的定义：关注于一条可观测性数据的所有字段的数量，如果每个字段都是一个 Key - value 对，维度指的是这个组合中 key 的数量，也就各种 key 键的多寡。\n高维度可观测性数据是一条结构化数据，代表这一次事件，亦或是一个状态，它的“宽度”可以高达上千个键值对（字段），事件越宽所携带的上线文信息就越丰富。高维度数据的作用是用来回答：到底发生了什么？\n用一组可观测性数据，在多个维度上进行排列组合分析，就是剖析现代软件系统中的所有故障模式的可能性。\n最常见维度组合包括：\n用户 代码 系统-运行环境 使用可观测性调试 基于充足的应用系统的可观测性数据，进行开放式的探索数据分析，你就能理解系统所进入的任何状态，而且通过多维度的关联分析，还能知道为什么会形成这个状态。\n可观测性管理工具是鼓励开发人员主动的收集应用运行时可能发生的任何事件，包括携带丰富的上下文，充足的遥测数据是日后探索分析的基础。\n可观测性管理工具平台应该是专门为高基数、高维度的遥测数据而设计的，它鼓励应用系统的所有参与方都参与：主动建立有利于故障调试的可观测性数据的活动中来。包括分工完成下面的各种工作：\n开发者在可观测性驱动开发思想的指导下，有意识的在代码中引用埋点框架（如 OpenTelemetry），对代码进行必要\u0026amp;足够的埋点。 运维人员确保不同语言的应用程序在运行前都携带了自动化埋点的探针（Agent）程序，如果是容器化程序，还可以在打镜像的时候设置这个检查点。确保在任何运行环境（开发、测试、准生产、生产）里APM 或者 RUM 的埋点数据都可以在正确的配置下发送回后台的可观测性管理平台，完成数据的采集。操作系统及以下系统环境的指标和日志是基础工作，是参考数据，这里不赘述。 测试人员和其他，都有使用可观测性数据的习惯，利用可观测性数据回答：bug 修复了么？性能回顾解决了么？错误率和延迟是否都很低了？ 产品经理和服务交付经理通过可观测性数据整理出每一套应用系统的 SLO 管理报告，指导下个迭代的工作方向，安排 bug 修复和特性交付的优先级，评估生产的运行风险。 分析调试现代化应用系统的难度包括两个层面：\n相对简单：系统的硬件和基础设施、云平台等方面，也就是代码以下的所有。 相对困难：代码、真实用户的问题，也就是代码本身及以上的所有。 适用于现代应用系统 现代化应用系统指的是运行在云上的，并经过适配改造的，与云平台的各种服务有很多集成的应用系统。它也可能是一个单体的运行在云主机中的应用，但更多的是容器化、微服务化、分布式的应用系统。前者用传统的监控方法也可以有效管理；后者使用可观测性管理方式更加适合。\n具备可观测性的软件的各种运行状态天然能被理解，我们无须猜测其内部状态，无须提前预判可能的故障模式，无须更新程序代码来暴露盲区。\n现代应用系统的故障模式的特点是：以新的、罕见、没发生过的故障模式为主；通常不可预测；需要使用支持高基数、高维度、可自由探索分析的可观测性管理平台进行配套管理。\n点击以上图片查看或者下载高清大图。\n本文参考《可观测性工程》第一章内容。\n❤️ Feature Photo by Joshua Woroniecki: https://www.pexels.com/photo/person-holding-a-compass-3832684/\n","date":"2023-08-29T15:04:00+08:00","image":"https://martinliu.cn/blog/what-is-o11y/pexels-joshua-woroniecki-3832684_hu_8f654a5bd957a67.jpg","permalink":"https://martinliu.cn/blog/what-is-o11y/","title":"可观测性的定义和真实含义是什么？"},{"content":" 作者：dragondrop.cloud 来源：https://medium.com/@hello_9187/\n背景 2021年8月10日，HashiCorp 将其之前的“开源”项目的许可证更改为商业源代码许可证（BSL），从而使它们成为未来所有版本的“源代码可用”。我们在这里详细讨论了此变更的原因和动机。\n2021年8月15日，OpenTF 宣言发布。其主要观点是，他们希望HashiCorp将 Terraform 的许可证恢复为真正的开源许可证，否则承诺者联盟将支持由基金会管理的 Terraform 分支。\n我们的看法 我们认为 OpenTF 宣言对新许可证的描述方式有失偏颇，有利于那些受到许可证变更影响最大的盈利公司，而如果发生分支，Terraform 生态系统的潜在成本太高。此外，作为受影响方，我们不介意将 Terraform 许可给嵌入到我们自己的解决方案中，因为 HashiCorp 建立和维护的庞大支持生态系统。\n让我们详细分析这个说法*。\n*以下内容不构成法律建议，请咨询熟悉您特定情况的律师。\n许可证偏颇和扭曲的陈述 1） 在宣言的开头部分“我们的关切：BUSL 许可证是 Terraform 的毒丸”，他们声称： “\u0026hellip;现在，使用 Terraform 的每家公司、供应商和开发人员都必须考虑他们的行为是否可能被视为与 HashiCorp 的产品竞争。”\n这个说法似乎相当不准确。唯一需要担心许可证变更的公司是那些将“在托管或嵌入的基础上为第三方提供 Licensed Work”的公司，这些行为与 HashiCorp 的产品竞争。\n最初确实有一些关于某些具体问题的合理疑问，即如果 HashiCorp 发布与您先前发布的工具重叠的功能，会发生什么情况？然而，在 HashiCorp 的首席技术官回答了其中一些常见问题后，似乎很明显，这只会影响那些向其他公司销售软件，并且该软件与 HashiCorp 的 Terraform Cloud 和 Terraform Enterprise 产品竞争，或者将 Terraform（源代码或 CLI 二进制文件）托管或嵌入的公司。\n值得注意的是，与 HashiCorp 管理的 Terraform 产品直接竞争的三家最大公司，Spacelift、Env0 和 Scalr，在支持一个 Terraform 分支的多年里，已经做出了数百万美元的承诺（这三家公司之间共有13个全职员工，为期五年）。他们的员工和创始人一直是 OpenTF 宣言的最积极的贡献者和传播者。\n2） 对于一个分支可能带来的好处的引用，这些好处在 2021 年和现在一样成立。 OpenTF 宣言列出了分支的关键原因，包括创建一个“真正的开源”、“社区驱动”、“公正”和“分层和模块化”的 Terraform。这些都是 Terraform 核心的有效关切，实际上是任何拥有的开源项目公司的问题，但是这些与 Terraform 核心仓库的问题并不是新问题。多年来，HashiCorp 社区接受社区提交的速度一直很慢，他们从未在核心中添加某些企业风格的功能（像任何拥有开源工具的公司一样）。\n在过去的大约14天里，唯一的实质性变化是一些公司的利润状况发生了变化。\n分支生态系统潜在的成本非常高 如果发生了分支，Terraform的主干版本可能不会闲置。HashiCorp可能会感到迫切，加强其地位，并在新版本的Terraform和主干云供应商中引入不兼容的差异。在最好的情况下，这可能会导致社区为了采用新的Terraform主要版本而做很多额外的工作，在最坏的情况下，导致主干版本和分支之间的兼容性裂痕。\n这样的裂痕对于工具的应用将是毁灭性的（我应该使用哪个版本的Terraform？有什么区别？算了，我只是去选择一个替代品）以及纯粹支持Terraform的开源项目（我为哪个分支编写？我是否支持两者并增加维护工具所需的工作？）。这还可能导致巨大的重复工作量，需要永久地并行维护镜像库、provider（提供者）和Terraform核心。\n即使在发生分支的情况下，HashiCorp继续照常运营，对整个社区来说，这也像是一个巨大的重复劳动，因为分支的主要受益者只是不同的营利实体及其用户。\n总之，分支对Terraform社区可能非常、非常代价高昂。\nHashiCorp支持Terraform社区的投入巨大 Terraform社区主要是由HashiCorp维护的，与之相关的成本非常高。\n他们每年支持数十亿的提供者下载，免费的模块托管（我们的组织将其作为一个关键的分发机制）以及数十亿的Terraform二进制下载。\n上述成本投入不包括主干云Terraform提供者和Terraform核心本身的维护。不用说，HashiCorp会持续的在社区大量投入，并将继续这样做。\n反论：BSL的改变不就是遏制竞争吗？ 许多Terraform Cloud替代品，特别是Spacelift、Env0、Scalr和Digger，都为Terraform管理开发了创新的工具和功能。与此同时，他们已经从HashiCorp所做的大型生态系统投资中取得了利益。明确地说，这种方法没有错，只要能继续以接近零成本的方式进行，这是一个聪明的商业策略。\n许可证更改至少提高了所有Terraform Cloud/Enterprise竞争对手的运营成本。这些成本很可能以某种形式转嫁给他们自己的客户。这可能是通过更高的定价结构，因为许可费冲击了他们的利润率，或者是某些企业完全放弃了Terraform管理，从而选择较少（这种后续响应当然最能遏制竞争）。\n还有一件事需要记住，那就是HashiCorp也是一家企业，因此期望它们继续亏损，而与此同时，不受维护和运营Terraform社区资产所需的固定成本的约束的竞争对手直接针对它们，是不现实的。虽然这个领域的产品价格几乎肯定会因为生态系统成本更加均匀地被承担而变得更加昂贵，但如果HashiCorp变成一个不存在的实体，那也不是理想情况。\n结论 从我们的角度看，Terraform社区主干分叉的潜在成本可能非常高昂，并可能对Terraform的未来造成严重破坏。HashiCorp继续使用BSL对\u0026gt;99%的Terraform用户没有影响；但主要的OpenTF宣言作者有明确的利润动机，并已经从不同的角度呈现了这种情况。\n我们认为Terraform的分支对社区的维护成本，远远超过了少数那几家被改变了营利模式企业的商业价值，并因此我们不支持OpenTF项目。\n背景 本文作者所在的公司：如果对我们自己的偏见感到好奇，我们的公司构建了一个嵌入了Terraform CLI的产品，并具有与Terraform Cloud重叠的一些功能，特别是漂移检测，因此受到了BSL更改对Terraform 1.5.5之后版本的影响。dragondrop.cloud的使命是在使用基础设施作为代码时自动化开发者的最佳实践。我们的旗舰开源产品cloud-concierge允许开发者将他们的云计算进行编码，检测漂移，估计云计算成本和安全风险等，更多地通过拉取请求提供结果。对于大规模运行cloud-concierge的企业，我们提供了一个自托管的管理平台。\n","date":"2023-08-29T09:46:45+08:00","image":"https://martinliu.cn/blog/why-we-are-not-supporting-opentf/0_djNEkw3EPJvERiqT_hu_e15bdf390d1d1935.webp","permalink":"https://martinliu.cn/blog/why-we-are-not-supporting-opentf/","title":"为什么我们不支持 OpenTF？"},{"content":"“可观测性工程”(Observability Engineering) 是一个近年来在软件工程和系统管理领域中逐渐受到关注的概念。它主要关注的是：如何更好地理解、监控和调试复杂的分布式系统。\nDevOps浪潮已经给“软件工程”相关的实践带来了极大的影响。首先表现在各个职能团队已经越来越更加紧密的协作和沟通，部门墙正在逐渐消失，有更多的产品团队转型为“Two pizza team”风格的全功能团队，开发、测试、运维、数据库专家、云计算专家都融合在一起，自给自足的独立发布产品。其次软件流水线的工艺也更加的自动化，有朋友曾这样告诉我：他们的 CI/CD 已经可以实现每日多次自动化发布，产品团队每周持续交付到了手发麻的程度。\n然而，不管我们如何娴熟的使用云平台、容器平台和微服务所带来的高可靠性、自愈能力和稳定性等等优势。当我们在生产环境中 debug 故障的时候，我们依然是云里雾里的凭经和灵感验猜测，还是不得不在多种监控工具之间解读着七长八段的数据， MTTR 故障修复时间仍然长的忍无可忍。我们应该能逐渐意识能到：应用系统的现代化所带来的也不都是好处，还有更多的是“复杂度”。软件应用系统本身和其运行环境的复杂度都在逐渐攀升，四分五裂的运维管理的工具集正在迅速蔓延。\n在最近的三年多以来，我逐渐开始对曾经经典的“可观测性 == 三根支柱”的理解有所动摇；简单的信号量数据的叠加和关联就足够了么？监控工具手段的更新换代是否就可以实现可观测性。在持续没有找到答案的时候，《observability engineering》这本书出版了。\n作者： Charity Majors, Liz Fong-Jones, George Miranda 出版日期： 2022 年 5 月 出版社： O\u0026rsquo;Reilly Media, Inc. URL：https://www.oreilly.com/library/view/observability-engineering/ Liz Fong-Jones 曾经是 Google 资深的 SRE 工程师和布道师。我几乎看过她的所有相关视频，也转发了一些在我的 B 站里。她离开了 Google 之后，与 Charity 一起创立了 Honeycomb 公司。 George Miranda 是后加入 Honeycomb 公司的员工，他加入这本书的写作时，这本书已经基本是个半成品。\n本书是第一本只讨论“可观测性”这一主题的书籍，围绕这个主题做了相当深度和广度的讨论。这本书的完整目录在网上都可以找到，下面是关于核心内的脑图。\n“可观测性” - 应该成为软件在交付生命周期中的不容忽视的一个重要属性。不只是一个技术问题，在软件系统中实现和提升可观测性同样需要 DevOps 风格的多团队协作。\n\u0026ldquo;可观测性工程\u0026quot;的价值 - 增强可观测性的主要好处是提高系统的可靠性、性能和安全性。当系统出现问题时，拥有良好的可观测性意味着可以更快地发现、定位和解决问题。\n“可观测性工程”的文化和实践：可观测性不仅仅是一组工具或技术，它也是一种文化和实践。这意味着，开发者和运维人员需要紧密合作，共同关心系统的健康和性能。\n随着现代软件系统变得越来越复杂，可观测性工程成为了确保高可用性、性能和用户满意度的关键要素。\n《可观测性工程》这本书分为五个部分，从历史到未来，从理论到落地，从团队到组织，从商业到文化，内容非常全面。对不同角色和职位的人都有不同的意义：\n运维：学习掌握本书的内容，可以提升你的眼界和实践能力；你会更好的识别和反思当前所处的困局，你会从分门别类的监控工具集应用，转向“聚焦生产环境问题的快速识别和解决”。 SRE：使你对基于 SLO 的监控更加有信心，特别是升级你对遥测数据采集、数据结构、后台存储和在团队中推广等方面的认知。你将会更有效的和产品团队合作。 开发：希望这是你学习可观测性的第一本书，本书的前三个部分就是你需要学习掌握的部分。掌握了可观测性驱动开发的概念，你以后就会对应用系统的运行状态了如指掌，它是你 DevOps 和 SRE 技能组合中不可缺少的一个部分。 经理和管理者：建议完整的阅读本书的所有内容，重点理解第一、四和五这三个部分。如果您已经熟知可观测性这个概念，可以直接重点阅读第四和第五部分。这是你在产品团队中，在整个组织里大范围落地可观测性左移的必备常识。分布在各个章节里的真实案例分析是不可错过的内容。 CxO：建议至少阅读中的案例研究，然后重点了掌握第四和第五部分。从这些内容中，你可以轻易的了解到投资可管的测性的技术要点，用于前期的投资和收益的评判，用于中后期管理的成熟度模型（PS：适用于产品团队自身的成长和进度评估，不建议用于产品团队间/部门间的横向比较和绩效考核）。 《可观测性工程》书籍中的亮点和创新之处在于：将可观测性的基础知识部分，用开发一种全新的可观测性程序的方式进行描述。首先解释：这个程序最底层的构建要素的角度是什么？分析可观测性的最底层数据结构是什么？然后，我们可以很容易的将这些数据应用到用它们来描述：应用系统在生产环境中的状态的变化过程。同时还提到了如何对接开源的 OpenTelemetry 数据；希望开发的同学能对此种描述方法倍感亲切，同时让运维和 SRE 同学也能拥有一个全新的视角。\n《可观测性工程》一书的另外一个独特之处，是在第八章中引入的“用第一性原理调试应用故障”。虽然可观测性管理的基本流程也是收集、存储和分析使用数据的过程，这看起来和其它单点的监控功能相似。但是，有没有一个统一的思路可以贯穿这个过程始终，并且推动这个过程不断的循环起来。我总是听说马斯克怎样运用第一性原理指导他在造车和火箭过程中的各种创新，并没有想到和监控运维管理会有什么关系。但是本书中所描述的“核心分析循环”还是令我耳目一新。在生产环境排错的过程中，所有人都将关注点和焦虑点都放在“谁？什么时候？可以在系统中定位到哪个最准确的唯一（假想中的）的根因（root cause）”。这种过分关注的结果想法，让我们已经忽略了，在 Debug 过程中，我们应该使用什么思路，去探索未知现象中隐藏的未知的应用运行的多重故障原因。\n“核心分析循环”并不是系统宕机后的救命稻草，而是一种理性冷静的思考方法，你可以在事故的前中后的任何时刻想到它。它能指导我们进行更加深度的分析思考，在一个理智的探索过程中，你会更加有条理的得出一连串假设，并逐个求证，在评判各种已知数据的时候，你同样需要不停的怀疑一切，推翻一切结论的勇气。切勿让单点工具的片面观察角度、对历史经验数据的依懒性，限制了我们 debug 生产系统的想象力，限制了人脑更适合做网状的复杂关联分析的能力。\n下面是本书中的一些精彩片段。\n【序言 - Cindy Sridharan】：本书没有关注协议或标准，甚至各种遥测信号的低级表示，而是将可观测性的三大支柱 设想为结构化事件、假设的迭代验证以及“核心分析循环”的三位一体。根据第一性原理对可观测性的构建要素进行整体重构，有助于强调仅通过遥测信号（或简单使用获取这些信号的工具）并不能最大限度地践行观测系统的所有行为。\n【11.6 章 \u0026ndash; 可观测性左移】：可观测性驱动开发允许工程团队将他们的玻璃城堡变成可以互动的游乐场。生产环境不是一成不变的，而是充满了活力。工程师应该有能力和自信来应对任何异常并且取得胜利。\n【14.4 章 - Slack 案例研究结论】：我分享了Slack 如何探测CI 流水线以及如何调试分布式系统的示例。开发人员了解生产环境中的代码情况，首先要考虑的应该是调试分布式系统的复杂性。但是，在发布到生产环境之前，如何正确理解和调试分布式系统同样具有挑战性。\n我个人认为：本书完整的回答了大量的问题，可观测性是什么？如何构建？如何左移？实现可观测性管理平台中的重要技术要点？如何在团队和组织中落地和规模化可观测性？怎样构建可观测性文化？等等。即使作者在序言和文中郑重提出，作者团队尽量避免持有任何立场，避免推广其公司产品和技术的意图。但是从文章中所引用的工具界面上看，从对核心数据结构“事件”的论述过程中看，从所引用的他们与 Slack 公司的合作案例上看；都难免脱离所在公司产品的身影。而公正的看，我们无法称之为瑕疵和片面。读者需要在理解此背景的前提下，批判性吸收书里的内容，从而避免在理解上以偏概全的可能性。本书的行文内容上看，那些高调的、上得了厅堂的内容可以用来与 CxO 对话；那些深入的、下得了厨房的代码可以用来与开发工程师沟通。本书使用了大量的篇幅在讨论“可观测性”的来龙去脉，讨论与传统监控的区别和关系，论述落地实现的细节；总的来说：这是一本在“可观测性”主题上用心良苦的作品。意在苦口婆心的引导大家走上构建应用系统可观测性的正确道路。\n下面是在 Amazon 上关于本书的评论总结：\n本书深入介绍了可观测性的实际含义，强调它能够解决新问题，构建可观测系统不一定需要添加新遥测数据。 书中讨论了可观测性的基本概念，指出它是社会技术系统，能够促进开发人员和业务人员之间的沟通。 可观测性在大型公司内部的推广是社会问题，需要说服管理层，书中提供了这方面的指导。 书籍中有关构建可观测性堆栈的高级方法的简要说明。 可观测性不仅仅是监控，它强调了从\u0026quot;为什么\u0026quot;出发，涉及实现细节和相关技术。 评论者强调可观测性是在分布式系统中获取有用信息的关键，提到了跟踪数据流和高基数跟踪的重要性。 书中包含了一些行业领导者的案例研究，介绍了他们如何应用可观测性方法监控生产环境。 书中涉及了日志、度量、span、追踪、警报等概念，强调了原则胜过具体代码。 评论者强烈推荐本书，认为它适用于任何希望为客户构建系统的人，并具有实际应用价值。 评论者认为本书是向可观测性转变的人的必读之作，介绍了关键概念和工具的应用。 中文版书籍在各大电商平台有出售。感兴趣的朋友可以入手学习。\n最后，我认为一个软件系统应该拥有三只眼：\n👁 稳定之眼：从 SRE 站点稳定性工程的角度讲，系统的稳定性是最重要的feature，没有之一。我深度认同这个观点。稳定性包含了服务必须具备的可用性和足够的性能。只有运行在生产环境中，被用户能正常访问和使用的代码才能发挥出它应有的价值。在运行的过程中，应用系统会宕机，运行环境可能会出问题，这都会导致应用系统的无法访问和使用；或者系统的 Bug 导致的高错误率，让系统处于半死不活的状态，用户也能从界面上看到千奇百怪的错误。系统是否进入了非正常的不可用状态？系统是否正在经历着性能抖动的过程？错误率是否高涨到即将溃坝？这些现象本质是产品的稳定性不足导致的，而这些现象是否可见，故障根源是否能快速定位？我们就需要用到第三只眼。 👁 混沌之眼：这是一只作死之眼，它是混沌工程。混沌工程旨在对生产环境中注入人为的故障，在云环境中可以使用的手段很多：随机的关闭虚拟机、随机的杀死正在运行的进程、在网络中注入导致网络拥塞的数据包等等。在错误注入的过程中，我们关注于应用系统还是否能正常使用？应用系统如果宕机了的话，它的故障模式是怎样的？然而，可视化这个过程，可视化应用宕机现场的细节，都需要用到第三只眼。对于混沌工程的复盘和数据分析能帮助应用系统提高稳定性，消除单点故障，提升故障容忍度和自动化迁移等等。 👁 可观测之眼：可观测性是应用系统本身的一种属性，可观测性的呈现不仅需要在应用程序代码中进行埋点增强（充分条件），还需要方便的采集遥测数据，这些都需要用到可观测性管理平台：可观测信号量的收集、上报、存储和展现分析等功能。可观测性管理平台是‘可观测性’显现（外显）/表现出来的必要条件。 以上是我对《可观测性工程》这本书的简介，希望对大家学习可观测性知识有所帮助。在结尾我用比喻的方式引出了应用系统应该拥有的三只眼的观点，它们是相辅相成且相互成就的关系。\n❤️ Feature Photo by RealToughCandy.com: https://www.pexels.com/photo/person-holding-a-sticker-11035393/\n","date":"2023-08-22T11:10:46+08:00","image":"https://martinliu.cn/blog/observability-engineering-book/pexels-skitterphoto-63901_hu_de8c5e18e2645589.jpg","permalink":"https://martinliu.cn/blog/observability-engineering-book/","title":"《可观测性工程》为软件系统开启第三只眼👁"},{"content":"可观测性并不是空穴来风，也非关键词炒作。大家不妨回顾一下我们所熟知的运维管理的演化历程，抛开运维管理中关于流程和人的那些繁文缛节。让我们只关注于：基础设施和应用架构的变迁，关注于这些层出不穷的技术工具侧面。\n兼容全域信号量 从遥测方式的角度看来：任何类型的信号都有各自的用途和道理。武断地选取其一作为可观测性的代名词是一种比较偏激的想法，在Debug生产环境的道路上，我们难以依靠单一方法，一招鲜吃遍天的情况是不可能存在的。我们要根据不同应用系统的特点和服务类型，选择合理的SLI组合，用恰当的信号量来覆盖目标应用系统，目标是打造应用系统本身的可观测性“属性”。这样，你就必须要明智地选择、添加或变化信号类型，要能做到按需求，对症下药。这里不是监控数据源越多越好，盲目的全面覆盖亦是事倍功半的做法；在应对高维度、高基数的运维大数据的场景中，我们很容易走向存储成本飙升的局面，无效杂音数据还能严重稀释有价值的信息点。\n所谓全域信号量究竟都有那些：\n日志 Log：文本记录系统和应用的活动、事件和错误，提供详细上下文。 指标 Metric：定量的性能度量，如CPU使用率、请求速率，帮助监控系统状态。 分布式追踪 Trace：跟踪请求在分布式系统中的路径和性能瓶颈。 流数据 Stream：实时产生的数据，如用户行为，用于即时监测和分析。 用户体验数据 RUM：记录用户在应用中的交互、操作和反应，评估体验质量。 eBPF：扩展 Berkeley Packet Filter，收集内核级别的数据，用于分析和监控。 网络性能管理 NPM：监测网络带宽、延迟和连接状况，优化网络性能。 Profiling：分析代码运行时的性能特征，帮助优化应用程序。 云服务 Cloud：从云提供商获取的监测数据，跟踪资源使用和性能。 拨测数据 Uptime/synthetics：定期对系统进行外部测试，监测系统在不同地点和条件下的可用性和性能。 未来新技术：未知类型数据。 “可观测性管理平台”应当以兼容并蓄全方位的信号量为初始设计目标。这意味着：在观测数据的采集、上传、存储、展示以及关联分析的整个过程中，各类数据都需要能被正确的处理，要能更能合理、有效地进行跨类型的数据关联；在数据下钻的过程中，可以自由地在各种时间线之间跳转和探索。\n当然，监控已知的“未知”是一项基本的管理需求，你应当能使用某一种信号量即可实现。而可观测性更多的是要讨论：对“未知”对象，在“未知”状态间进行变化的管理；这就需要“可观测性平台”能处理多层级、高依赖、多云环境、分布式系统下的高“复杂度”，信号量的全面准备和按需取用往往也只是一个必要条件。\n目前市场上已经有许多运维管理平台都自称为“可观测性”管理平台。但他们中的大多数都是从某个特定监控类型开始，并逐渐扩展覆盖其他更多信号类型的。通常，只有能够涵盖3种以上信号类型的平台，才可能具有出色的实用效果；对于那些已经是有3至5年历史的‘可观测性’产品而言，他们不太可能在短期内实现华丽的转身，也不可能会从头重构一遍自己的产品。\n统一采集和上传工具 在物理机大行其道的时代中，对于一台主机（虚拟机或者物理机）而言，由于它很可能承担着多重角色。而且根据不同团队的管理需求，在其操作系统中会安装多种管理监控代理程序Agent，例如：操作系统指标、日志、数据库、中间件、安全巡检等等；这种叠罗汉的形式不仅给操作系统的资源带来了严重的消耗，甚至还给服务器的管理带来了大量的琐事，例如：数据库监控 Agent 还需要创建专用的用户账号等。为了解决这个问题，很多公司希望使用尽可能少的单一采集代理的模式，例如：BMC 公司的 Patrol 监控产品，拥有多种采集模块 KM（数据库、中间、web 服务器等等），用户可以按需要进行配置，而不需要部署多个采集代理程序。然而，BMC 公司会逐渐收购很多新产品，后来的产品有动态性能基线管理、自动化配置管理等等。从工具厂商的角度看， 他们无法进行快速的产品整合，很难维持单一采集代理的局面。\n在甲方企业的环境中，不同部门会根据自己的需求采购不同的管理工具，部门间的差异导致了工具的重复建设，数据的重复采集，而且数据并不会很轻易的在部门间共享。这样不仅带来了采集工具在同一个主机上的叠加部署，还会导致：独立的运行着大量具有重复数据的孤岛运维数据数据库。这种局面进一步导致了其他问题，例如：同一个主机的同一个故障会在各种工具中都触发多条告警事件；事件风暴来临了。这种混沌的局面，给 AIOps 的工具带来了生存的空间，即使可以产生一些事件收敛和压缩的收益，但这里存在着一个很明显的“治标不治本”的错误。\n时光穿梭到了虚拟化\u0026amp;云原生时代，以上局面并没有发生根本性的改变。反而带来了套娃式深层依赖关系的困境。我们不会把 web、中间件、数据库、消息队列等功能跑在一个 POD 中，但是将其各自独立部署在可横向扩容的子服务（容器服务）中后，这就带来了管理对象的数量呈现指数级飙升的现状。\n容器时代带来了新鲜的监控工具，包括：Prometheus、Grafana、FluntD、Graphite、cAdvisor、Loki、EFK等等。我们可以观察到，新生的工具并不会完全改变：多种采集功能代理并存\u0026amp;叠加的局面。Elastic 看到了部署多种相似代理程序的问题后，最近几年很快的将之前的多种 Beats 程序（多次收购的项目）整合成到了一个统一代理 Elastic Agent中，而这个程序目前还只是多个 Beats 程序的马甲（包装壳）程序。Zabbix 是一个依然长期存在的常见采集代理，我个人推测：在当今容器环境居多的情况下，容器内用云原生监控工具集，容器外依然使用老牌监控工具的组合做法，依然是一个普遍存在的现状。\n多种采集工具集不仅在端点上会造成大量部署和配置的琐事，而且，它们的后台都对应着各自的独立的数据库部署。同一个管理对象在不同的数据库中的字段描述基本上都不同，这导致了：工具集的使用者很难在各类数据库中实现关联分析，用人脑携带着排错的上下文，在一堆控制台之间跳转是相当消耗体力的工作，对齐时间线和监控对象会很快耗尽人的认知上限。CMDB 可能是一个解决方法，而 CMDB 的设计和建设的难度并不亚于构建任何一个监控系统项目本身， 用CMDB解决这个问题的实现难度大，成本高。数据治理也会是一个常见做法，而在这些运维数据库集合之间做 ELT，做数据治理工作，最终实现异类运维信息的归一化的解决方式，也只是一个顺坡下驴的无奈之举，相关实施人员在项目中必将饱尝：将计就计的辛酸。\n貌似最早由 Elastic 推出的统一数据模型（ECS）https://www.elastic.co/cn/elasticsearch/common-schema 是一个让数据走向标准化定义的可行之道。我们也看到了：OpenTelemetry 项目很快就采纳了 Elastic ECS。CNCF 在随后也推出了相似的观测数据定义模型。我相信 CNCF 一定是看到了，在它的技术蓝图中，可观测性和分析分类中相似\u0026amp;同类工具的快速繁荣。而这些标准也只能让我们望梅止渴，由于目前还没有看到多数厂商、大量开源项目都快速跟随实现和兼容落地的局面。\n观测云的 DataKit 是一款多功能的采集代理程序，它具备解决上述问题的设计，它已经在兼容和对接更广泛的技术生态系统。任何采集代理程序在采集或者对接到了目标数据之后，它其实还需要处理一些列的细节，否则就仍然无法实现“源头治理”，无法避免“garbage in gargage out”的窘境。首先，DataKit 在组织封装数据的时候，所有字段的定义都遵从着一个观测云定义的数据字典（等同于 Elastic ECS ）；其次，上报数据包在封包前，还能做数据的 Pipline 处理，实现了数据字段的丢弃、质量控制、治理和脱敏等问题。最后，DataKit 的采集还可实现对接开源\u0026amp;闭源生态系统，例如接收 DataDog 的 APM 探针数据，对接 OpenTelemetry 的数据等等。它还能实现观测数据在网际、网络间的转发等。\n统一的存储后台 在构建可观测性平台的过程中，每种类型的信号量都理应得到它最佳的容身之处：\nElasticsearch ：在 Elastic 的 ECS 的加持之下，貌似它是一个很恰当的一库存所有的方案，但前提是你需要能 hold 住性价比。 时序数据库：不一一列举，适合指标类时序数据。 列数据库：以 ClickHouse 为代表的实时数据分析的列数据库，可兼容多种信号。 关系型数据库：WHY NOT。 从数据入库的角度看，给每种信号量配置其最佳的数据库类型，貌似是一个皆大欢喜的局面。这也不辜负，目前各种开源数据库百花齐放的形势。\n略过上面已经提到的数据孤岛和治理问题不谈。从查询的角度看，用户将不得不学会多种查询语言，前方有 n 种 SQL 语法需要你学习，否则你不得不开发维护一个一对多的查询界面。这里我们暂且不论述：你会如何实现可观测性数据的跨库数据关联分析。\n问题：是否存在一种多模态的统一数据库，将多种类型的信号量数据融入一个统一的数据仓库中？\n实际上，目前的可观测性 SaaS 提供商们，已经给他们的用户提供了这样一种统一融合的数据后端，起码从查询探索可观测性数据的使用体感的角度上，确实是已经做到了。而观测云也正在推出这样一款解决以上统一融合多态并存管理需求的数据库。观测云用户很快将在 SaaS服务中，在私有部署的产品上使用到这种技术。\n自由探索和综合使用数据 可观测性数据的价值体现在使用上，能自由的探索和综合的使用各种数据，才能放大数据的价值。在考虑到可观测性数据使用场景的时候，我强烈建议大家运用“第一性原理”来进行思考。这样才能避免对经验的依赖，排除对新可观测性技术能平替所有旧技术的单纯幻想，才能回到可观测性技术的概念本源。\n此处省略 n 百字，仅以上图与读者们一起随时随刻的校准自己对“可观测性”定义的理解。\n总结 本文从四个层面对可观测性平台实现的技术要点，做出了一定深度和时间跨度上的探讨。希望：在您的工作环境中，统一融合的可观测性平台可以很快的落地。穿上两只靴子的你，可以脱离以前赤足上阵，光脚救火的困境。希望可观测性平台能够帮助到软件交付流水线中的所有人，运用可观测性来补Ops的锅，助SRE的威，壮Dev胆。\n","date":"2023-08-15T16:17:43+08:00","image":"https://martinliu.cn/blog/what-observability-give-us/pexels-pixabay-237258_hu_b2ed21c3136c11a9.jpg","permalink":"https://martinliu.cn/blog/what-observability-give-us/","title":"究竟可观测性能给我们带来什么？"},{"content":"如果你是红帽开源软件的个人开发者（用户），你可以通过“红帽开发者计划”实现访问、下载和使用红帽全系列产品的福利。\n红帽开发者会员的好处是可以免费获得广泛的资料库，包括：\n所有红帽软件 （含所有产品及时的更新） 开发者资源 (technical articles, e-books, cheat sheets, and more) Interactive tutorials on the latest technology and Red Hat products Free in-person and virtual events with Developer experts Free Developer Sandbox to build your apps 会员资格包括访问：\nRed Hat 所有和刹那品，包括 Red Hat Enterprise Linux, OpenShift 和 Ansible 等等 Red Hat Customer Portal 客户门户的访问权限 重要资源：\n开发者计划介绍：https://developers.redhat.com/about 无费用的 Red Hat Enterprise Linux 个人开发者订阅的常见问题：https://developers.redhat.com/articles/faqs-no-cost-red-hat-enterprise-linux# Red Hat 提供开发者订阅 Red Hat Enterprise Linux 个人开发者订阅的数量为16个RHEL操作系统实例。 需要在使用开发者订阅的操作系统上联网激活订阅 激活的账号和密码与开发者门户的账号相同。 在 Red Hat 客户门户网站上，你可以管理和续订开发者订阅。 下图是在客户门户网站上查看当前订阅使用状况的界面。\n如果你所使用的公有云里有Red Hat官方支持的 RHEL 镜像，你可以将你的开发者订阅使用在公有云的虚拟机上。在Cloud Access这个页面上，可以看到我将微软的Azure账户和红帽开发者订阅做了关联。\n这样就可以实现：有限数量的 Azure 虚拟机可以运行最新版的 RHEL 操作系统，这些操作系统的 License 计费到了 Red Hat 开发者订阅上；而开发者订阅又是有限免费的，因此实现了这些虚拟机的免费使用 RHEL 订阅。由于我在 Azure 中的长运行虚拟机并不多，因此这些虚拟机目前都是使用的 Red Hat Enterprise Linux。\nAzure 支持 AHB 的混合权益 参考这篇 Azure 的官方文档《Red Hat Enterprise Linux (RHEL) 和 SUSE Linux Enterprise Server (SLES) 虚拟机的Azure 混合权益》\nAzure 提供的 AHB（Azure Hybrid Benefit）使用中携带你自己的订阅到公有云里使用的方式。如下图所示。\n右侧的这个框的说明了 Azure 虚拟机的成本结构。除了计算资源这部分需要计费意外。如果你在 Azure 中开启了 RHEL 虚拟机实例，默认情况下 RHEL 的许可证费用是有 Azure 代收的，Azure 的账单里包含了这部分。\n对于我在 Azrue 中的长运行虚拟机来说，经过我的配置之后，Azure 的账号和 RedHat 开发者订阅关联在了一起。所以这些 RHEL 虚拟机实例上的 RHEL 许可证费用就是在 RedHat 客户门户账号（来自于红帽开发者计划福利）中计费，最多支持 16 个虚拟机的免费使用。\n如何在 Azure 中配置个人（公司）的 RHEL 订阅 如下图所示，在创建 Azure 的虚拟机的时候，选择 Red Hat Enterprise Linux 模板。\n在授权这个部分，点击第二个“了解更多信息”链接。这时候，浏览器会跳转到红帽客户门户中，在输入了用户名和密码登录了以后，你就完成了红帽开发者订阅和当前 Azure 账户的关联。\n在虚拟机创建完成以后，你可以用 RHEL 的订阅管理命令将当前的 RHEL Linux 操作系统注册到红帽客户门户的订阅上。参考命令如下：\n1 subscription-manager register --org=1234567 --activationkey=DevOps \u0026mdash;org ：是你在红帽门户中的组织 ID。 \u0026ndash;activationkey ： 是自己定义的激活秘钥；一个组织可以定义多个激活秘钥，用户部门和用途的区分。 这条命令中虽然 ID 是不适合明文暴露的；但是，这样避免了将红帽客户门户账户的用户名和密码都以明文的形式写入配置文件，或者在命令中出现：subscription-manager register --username \u0026lt;username\u0026gt; --password \u0026lt;password\u0026gt; --auto-attach\n在当前操作系统注册成功以后，你可以在/etc/yum.repos.d下能找到一个redhat.repo文件。这个文件里包含了当前操作系统所有能使用的红帽产品的订阅。\n1 2 3 4 5 6 [root@mysql yum.repos.d]# dnf repolist Updating Subscription Management repositories. repo id repo name packages-microsoft-com-prod packages-microsoft-com-prod rhel-8-for-x86_64-appstream-rpms Red Hat Enterprise Linux 8 for x86_64 - AppStream (RPMs) rhel-8-for-x86_64-baseos-rpms Red Hat Enterprise Linux 8 for x86_64 - BaseOS (RPMs) 参考这篇文章《https://access.redhat.com/solutions/253273》》；就可以启用或者禁用所需要的产品。\n在其他环境中的使用 红帽开发者订阅可以让你在客户门户中下载 RHEL 安装 DVD。可以用 DVD 在私有云或者个人电脑（Home Lab）中安装 RHEL 操作系统。\n使用上面相同的方法，既可以实现 RHEL Linux 操作系统的注册，然后完全合理合法的使用全套红帽产品线。\n红帽开发者订阅的有效期是一年；在到期之后，在还需要在客户门户中免费续签。如果当前的开发者订阅过期了，所有 RHEL 操作系统实例就都不能正常更新和安装新的软件包了。在网站上完成了开发者订阅的免费续签之后，所有系统就可以恢复正常使用，无需做其他任何操作。\n开发者订阅的数量是 16 个，更具我最近一年的使用体验看来，这个数量是足够用的。假如你的虚拟机模板激活了订阅，根据这个虚拟机克隆出来的虚拟机是不需要使用注册命令就可以正常更新和安装软件包的。如果订阅数量真的被用完了，可以暂时从红帽客户门户中暂时删除几个不常用的系统，这样就释放出来几个可用的 RHEL 订阅。\n排错 新创建的 RHEL 8 的虚拟机，在激活红帽 RHEL 订阅之后，在更新系统软件安装包的时候，报 SSL 证书过期错误，可以参考下面的命令进行解决。\n1 2 3 4 5 yum --disablerepo=\u0026#39;*\u0026#39; remove \u0026#39;rhui-azure-rhel8\u0026#39; wget https://rhelimage.blob.core.windows.net/repositories/rhui-microsoft-azure-rhel8.config yum --config=rhui-microsoft-azure-rhel8.config install rhui-azure-rhel8 yum update ca-certificates yum clean all ","date":"2023-05-21T10:21:15+08:00","image":"https://martinliu.cn/blog/use-rhel-dev-sub-in-azure/virtual-machine_hu_cc77b277739714e5.png","permalink":"https://martinliu.cn/blog/use-rhel-dev-sub-in-azure/","title":"如何在 Azure 中使用 Red Hat 的开发者订阅"},{"content":"随着技术的发展，与之相关的趋势也在不断变化。DevOps也不例外。现在，企业比以往任何时候，都更加认识到DevOps的价值，及其优化开发和运营的能力。随着我们走过2022年，进入2023年，重要的是要保持领先，了解未来几年推动DevOps的趋势。\n2022年对于DevOps技术来说是令人兴奋的一年，因为企业越来越认识到自动化和协作对于实现业务成功的重要性。采取敏捷的DevOps方法的公司在效率和生产力方面有了相当大的改善。这是由云计算的持续采用和容器化的崛起所做出的支撑。此外，随着 DevOps-as-a-Service（DaaS）解决方案的日益普及，意味着所有规模的组织都能够从DevOps实践中受益，而不需要专门的DevOps团队。\n云原生架构、无服务器计算和容器被广泛的采用，更多的组织将它们作为未来的方向。这使团队能够以敏捷和高效的方式快速部署、扩展和管理应用程序。人工智能/ML工具成为DevOps工具箱中的一部分，使团队能够更快速、高效地提供软件更新和功能，并检测代码中的异常情况，从而更容易在潜在问题变成严重问题之前发现它们。安全性仍然是一个重要的优先事项，企业在最新的技术和最佳实践方面进行了大量投资，以确保他们的系统是安全可靠的。\n同时，DevOps团队也开始专注于改善他们的协作和沟通，使团队能够更快地行动，并对客户的需求和反馈做出更多响应。\n在过去的一年里，我们在DevOps领域看到了很多令人兴奋的发展，但2023年的趋势是什么？让我们来看看今年我们在DevOps领域可以看到的主要趋势。\nKubernetes 的采用和部署的增加 2022年，Kubernetes的采用显著增加，使其成为事实上的容器编排平台。这是由于它的灵活性和可扩展性，使企业能够在云中快速旋转和拆解应用程序。此外，DevOps的兴起使该平台成为云基础设施的一个关键组成部分。\nKubernetes的流行因其与云原生堆栈的整合而得到进一步支持。它支持各种应用，包括微服务、无服务器和数据库，使其成为希望利用云的组织的首选。因此，Kubernetes的部署数量在2022年急剧增加。这一趋势预计将持续到2023年，更多的公司将采用Kubernetes作为其云原生解决方案。\n预计Kubernetes将很快主导市场，每个组织都会转向这个平台进行部署。社区的支持水平和该平台令人印象深刻的增长速度没有放缓的迹象，使Kubernetes仍然是满足部署需求的首选。\n无服务器计算将得到广泛的应用 无服务器计算已经成为科技行业的一个主要趋势，预计在2023年将变得更加流行。这种计算方法允许企业在不需要管理服务器的情况下，开发和运行服务和应用程序，使其成为一种高度创新和高效的软件部署方法。据Gartner称，到2025年，超过85%的组织将使用云计算策略，95%的新数字工作负载将在云平台上进行。这意味着，任何不采用无服务器计算的组织都可能难以跟上竞争的脚步。\n预计到2030年，无服务器市场将达到300亿美元。目前，已经有超过50%的基于云计算进程的企业将无服务器计算整合到他们的系统中。DevOps流程尤其受益于这一趋势，因为它有助于缩小开发和运营之间的隔阂，简化DevOps流水线的代码。成功实施无服务器计算的一个例子是 Autodesk，一家专门为建筑、工程、施工和制造设计软件的公司。通过扩大其在AWS的业务范围并实施AWS Dynamodb和AWS Lambda，Autodesk能够将创建账户所需的时间从两周大幅减少到十分钟。\n无服务器计算为工程师提供了许多好处，包括通过消除服务器管理来减少工作量，通过只在需要时支付服务器空间来降低成本，以及在减少延迟的同时轻松扩展和部署。因此，这是一个值得在2023年关注的趋势。\n微服务架构的采用将继续增长 微服务架构是一种越来越流行的设计、构建和管理应用程序的结构。这种方法有助于DevOps专业人员开发出更加模块化、与其他组件解耦、更易于维护和扩展的应用程序。通过将一个复杂的应用程序分离成更小、更容易管理的服务，DevOps专业人士对应用程序的各个部分有更多的控制。这使得更新和排除错误更加容易。此外，微服务允许DevOps专业人员通过创建新的服务或更新现有服务来快速响应客户需求。\n以提供可扩展性、灵活性和敏捷性的方式开发和部署服务的能力是DevOps专业人士开始接受微服务的主要原因。在一个不断发展的IT环境中，公司需要能够快速、轻松地适应行业的变化。微服务是实现这一目标的好方法，因为它们允许在小的、易于管理的部分中开发和部署服务。因此，DevOps专业人员应该关注微服务在未来几年的持续发展。\n安全自动化将获得发展势头 安全自动化涉及自动化安全流程和任务，以确保应用程序和系统的安全和保护，使其免受潜在威胁。在2023年，DevOps专业人士应密切关注安全自动化的增长和安全即代码方法的采用。\n企业实施安全自动化的一种方式是使用Harness安全测试自动化（STO）等工具，该工具允许在CI/CD管道内进行单元、集成和负载测试的自动化。这可以节省宝贵的工程时间，并降低整体云计算成本。集成到CI/CD流水线中的安全自动化保证了代码在部署到生产之前接受严格的安全测试。这确保了只有被验证为安全的代码才被允许进行。此外，在软件开发生命周期（SDLC）中使用人工智能和机器学习正变得越来越普遍，因为这些技术可以被训练来识别代码中的违规行为并提供改进建议。\n另一方面，安全即代码解决方案将安全测试整合到CI/CD流水线中，使企业能够在整个开发过程中执行安全策略。这有助于确保安全在开发过程的每个阶段都得到考虑，而不是事后才想到。安全自动化和安全即代码解决方案都可以节省宝贵的工程时间，降低整体云计算成本，同时保持高水平的安全性。\n2023年，随着企业寻求简化和自动化其安全流程，安全自动化将获得更大的发展势头。安全自动化工具将变得越来越复杂，具有自动安全测试、漏洞扫描和持续安全监控等功能。这将使企业能够在安全风险成为重大问题之前快速有效地识别和解决这些风险。\n混沌工程实验的增加 混沌工程是一个相对较新的领域，近年来得到了普及，预计在未来几年将继续增长。\n混沌工程是一种战略方法，涉及到通过将产品、服务和系统置于极端条件下测试其复原力和可靠性。这有助于组织了解其系统和应用在这种条件下的行为，并确保它们能够承受这些条件。混沌工程的目标是识别部署过程中的 \u0026ldquo;不完美\u0026rdquo;，如漫长的周期时间，并防止故障发生。混沌工程师的目标不是要消除故障，而是要减轻故障，具体方法是找出不完善的地方并自动修复。\n我们相信，随着企业认识到确保其产品和服务的高可用性和弹性的重要性，混沌工程和混沌原则的使用将在2023年变得更加广泛。随着混沌工程的采用越来越多，也可能会开发出新的工具和最佳实践，以帮助组织更好地理解和管理其系统的复杂性。\nDocker将继续提升开发者的体验 Docker是一个深受开发者欢迎的工具，它通过允许开发者在云中快速构建、打包和部署应用程序，简化了开发生命周期。Docker的吸引力在于它的简单性，以及它将容器化应用快速带入生产环境的方式。\nDocker是一个深受开发者欢迎的工具，它通过允许开发者在云中快速构建、打包和部署应用程序，简化了开发生命周期。Docker的吸引力在于它的简单性，以及它将容器化应用快速带入生产环境的方式。\n尽管最初的假设是，当Kubernetes取消支持时，Docker将被淘汰，但事实并非如此。值得注意的是，Docker的设计从一开始就没有考虑到Kubernetes。Docker之所以能够保持其受欢迎程度，是因为有大量的开发者社区在使用它，而且它提供了易用性。\n围绕Docker的社区令人印象深刻，无与伦比，它的广泛采用和强大的社区支持使它成为寻求简化工作流程和提高生产力的开发者的可靠选择。因此，Docker预计在未来几年仍将是DevOps领域的一个关键角色，为更多协作开发工作流程的趋势推波助澜。\n2023年值得关注的一个DevOps趋势是Docker继续增强开发者的体验。该公司已经在开发新的工具和功能，使部署过程更简单、更快、更有效。它的重点是简化操作，同时也提供直观的用户体验。因此，采用Docker的公司可望体验到更大程度的灵活性和可扩展性。\nGitOps将获得更多的信任 在GitOps中，开发人员将他们的代码存储在Git仓库中，然后将其部署到Kubernetes集群中。这种方法的好处是，开发人员可以将他们的代码保存在源码控制中，而不必担心管理Kubernetes集群的问题。\n在过去的几年里，GitOps作为一种提高软件交付速度、可靠性和安全性的方法，在DevOps专业人士中获得了巨大的吸引力。在2023年，我们希望看到GitOps在希望改善其软件交付流程的组织中获得更多的信任和采用。\n我们相信GitOps在2023年将继续流行，有几个原因。首先，GitOps使企业能够采用更加声明性的方法来管理其应用程序和基础设施。这意味着，开发人员不必手动配置和部署资源，只需将他们想要的状态提交给Git，剩下的就交给自动化工具处理。这可以帮助减少错误的风险，提高软件交付的速度和可靠性。\nGitOps促进了开发团队内部的协作和透明度。通过使用Git作为真理的中心来源，团队中的每个人都可以看到正在进行的更改和系统的当前状态。这可以帮助减少冲突，改善团队成员之间的沟通。\nGitOps可以帮助企业提高其软件交付过程的安全性。通过使用Git作为唯一的真理源，并使部署过程自动化，企业可以减少未经授权的更改的风险，并确保只有经过批准的更改被部署到生产中。\n随着GitOps继续在DevOps领域获得关注，预计它在未来几年只会继续增长。这是因为它能够简化DevOps流程，使开发者更容易部署他们的代码。因此，GitOps肯定会成为2023年值得关注的领先DevOps趋势之一。具体来说，随着开发者越来越了解GitOps的好处，对GitOps的信任将继续增加。随着越来越多的组织采用GitOps，并成为DevOps流程的标准部分，GitOps将获得更多信任。\nAIOps将变得突出 MLOps和AIOps是两个最突出的DevOps工具，预计将成为该行业的主要参与者，到2026年预计价值为409.1亿美元。这些工具对于优化DevOps操作和实现高质量的快速发布至关重要。MLOps有助于加强机器学习的开发系统，而AIOps则使IT流程和操作自动化。\nAIOps是一个强大的工具，可以使复杂的DevOps流程自动化，使团队能够快速检测和解决任何潜在的问题。它还可以提供对DevOps流程性能的洞察力，并在造成任何破坏之前确定任何潜在的问题。AIOps通常被用作DevOps工具链的一部分，实时监控和管理这些系统，为集成工具和DevOps工程师提供自动反馈。AIOps也可用于自动化某些任务，如应用测试和部署，这可以大大减少完成DevOps任务所需的时间和精力。\n2023年，随着企业寻求提高IT效能，减少管理复杂数字系统的人工劳动，预计AIOps将继续流行。\n内部开发者平台将变得更加重要 到2022年，颠覆公司构建软件方式的DevOps趋势已经发展成为一种软件交付方式，通过打破孤岛将开发和运营联系起来。\n内部开发者平台是一套专门为企业的开发者设计的工具和服务，通常托管在企业自己的基础设施内。\n内部开发者平台为工程团队提供了一个集中的中心，以进行合作和共享资源。这可以帮助内部开发人员的学习和发展，使他们能够增加技术知识，并使他们能够轻松地与其他工程团队一起进行项目工作。这种平台还可以帮助减少错误，提高代码质量，因为资源共享和审查更容易。在2023年，我们预计会看到企业内部越来越多地采用内部开发者平台的趋势。\nDevOps协作将成为主流 DevOps的理念包括打破软件开发人员和开发运营团队之间的围墙，允许他们在构建、测试和部署软件方面进行协作。随着越来越多的组织追求敏捷开发，他们也在提高开发人员和系统之间的障碍。亚马逊、谷歌和Stripe等组织都依靠DevOps协作来促进速度和创新。\n协作工作正在改变，高管们正在使用新的软件工具来帮助他们监控工作流程。使用Slack、Microsoft Teams、GitHub和Atlassian的工具的DevOps团队对他们的工作流程有更大的可见性。在未来两年，DevOps领导层将继续看到DevOps协作成为主流，新的管理方式将出现。\n低代码平台 低代码平台的确是扩展敏捷和DevOps优势的有用工具。它们允许开发人员快速、轻松地构建和部署应用程序，而不需要编写大量的代码。这对于需要快速开发和部署应用程序的组织来说特别有利，因为这可以让他们更有效地应对不断变化的业务需求和市场条件。\n低代码平台也可以很好地适用于想要采用DevOps方法的组织，因为它们可以促进开发人员和IT运营团队之间的合作。通过使用低代码平台，开发人员可以专注于构建和测试应用程序，而IT运营团队可以专注于部署和监控。这些平台通常与所有主要的DevOps工具集成，从而有助于成为管理CI/CD的单一界面。\n总的来说，对于希望采用敏捷和DevOps实践的组织来说，低代码平台可以成为一个有价值的工具，因为它们可以帮助加速开发过程，提高应用程序的质量和可靠性。\n向标准化部署和真正的自动化转变 现在出现了许多端到端的DevOps平台，它们都是以低代码的方式构建的。此外，他们专注于为部署引入标准化；这一直是阻碍团队扩展和控制其部署的主要障碍。使用标准化的CI/CD管道使团队能够重新使用特定的管道来部署性质相似的微服务，只需在需要时调整一些参数。这有助于解决管道臃肿的问题，简化管道管理。\n这些低代码平台还有助于实现真正意义上的自动化，这一直是DevOps的一个关键原则，但由于各团队的工具和工作流程分散，其实施一直是孤立和不统一的。这种趋势在未来可能会继续，重点是通过DevOps平台实现真正的端到端自动化。自动化可以帮助减少构建、测试和部署软件所需的时间和精力，这可以提高效率并加快开发过程。部署后的自动化在帮助检测故障和启动即时回滚以确保更高的应用可用性方面也有很大的作用。\n混合云环境的兴起 许多组织正朝着混合云模式发展，其中一些工作负载在企业内部运行，另一些在云中运行。要求也决定了需要让应用程序在多个云区域运行，并有许多共享资源。这种趋势在未来几年可能会继续下去，DevOps实践将需要适应，不仅要支持混合云的部署，还要支持简化的跨集群监控、备份等。\n基础设施即代码 基础设施即代码（IAC）将成为DevOps的领先趋势之一。这一趋势有利于通过自动化而不是人工的方式来管理和配置基础设施。这是一个基本的DevOps最佳实践，将持续监控、虚拟化测试和版本控制应用于指导基础设施开发和管理的基础代码。\n基础设施即代码使采用DevOps技术以及基础设施团队和软件开发团队之间更紧密的合作成为可能。当基础设施是代码并被纳入你公司的软件生命周期时，有一个共同的词汇和一套共同的标准，利益相关者已经理解。团队之间的沟通因这种共享的知识而得到促进，这对DevOps至关重要。\nDevSecOps DevSecOps是指开发、安全和运营。它是一种软件开发实践，在每个阶段都集成了安全元素，直到开发的解决方案不能成功交付。DevSecOps是从DevOps演变而来的，因此，实施DevSecOps而不是DevOps将在未来获得更大的发展。DevSecOps将安全整合到CI/CD管道中，使开发团队能够以DevOps的速度解决目前最紧迫的一些安全问题。\nSRE (网站可靠性工程) DevOps部署的下一个层次是站点可靠性工程。在DevOps的未来趋势中，似乎采用SRE作为战略，以实现高可用性、可靠性和增强的数字消费者体验。SRE技术对于完成内部服务水平目标和服务水平协议（SLA）（SLO）也是必要的。\n可观测性 可观察性将是DevOps的关键趋势之一。它提到了协助开发和运营团队记录、收集、关联和分析来自分布式应用的大量性能数据的方法和软件工具，以获得当下的洞察力。\n多云环境 DevOps和多云环境相辅相成，具有同义关系。他们的结合提供了好处，在提高生产力的同时，也为彼此增加了价值数。尽管如此，DevOps和多云在一起仍然是不寻常的。大多数拥有完善的DevOps管道的企业离将多云安排到位还有一段距离。\n结论 随着IT组织实施DevOps计划，他们无疑将面临一些挑战，这些挑战将考验他们在不断的压力下管理变化、跨团队协作和有效工作的能力。大多数IT组织将意识到，有必要让所有利益相关者参与到DevOps中来，包括业务部门，这样他们都能理解正在实施的方法背后的原因。\n2023年，DevOps团队将继续推进他们的采用率，因为他们从企业高管那里得到的支持越来越多。DevOps团队将继续关注自动化，将应用程序迁移到云平台，推出Docker容器，建立容器协调工具，以及将他们的关注点扩展到安全方面。更多的公司将把DevOps嵌入到他们的运营结构中。这一发展将使企业开发、部署和运行应用程序的方式以及支持其团队的方式发生重大变化。除了采用DevOps实践外，企业还将调整数字化实践，从他们开发和部署的软件中获得更大的价值和质量，并管理企业的数字化转型。\n参考 本文参考的文章资料如下：\nhttps://alltechmagazine.com/devops-trends-to-watch-for-in-2023/ https://ozone.one/top-6-devops-trends-to-look-for-in-2023/ https://www.solutionanalysts.com/blog/top-10-trends-of-devops-in-2023/ https://www.analyticsinsight.net/top-10-devops-trends-and-predictions-to-follow-up-in-2023/ ","date":"2023-01-04T10:19:53+08:00","image":"https://martinliu.cn/blog/deveops-trands-in-2023/pexels-samar-mourya-13378403_hu_faa8508d07c88532.jpg","permalink":"https://martinliu.cn/blog/deveops-trands-in-2023/","title":"DevOps 在 2023 年的趋势和预测"},{"content":"《CloudBees全球CxO安全调查》对美国、英国、法国、德国、西班牙和澳大利亚的600名CxO高管进行了调查，发现安全和合规性挑战是大多数组织的创新战略的一个重要障碍。四分之三的企业高管表示，合规性挑战（76%）和安全挑战（75%）限制了他们公司的创新能力。这部分是由于在合规性审计、风险和缺陷上花费了大量时间。调查还显示，高管们绝大多数赞成左移的方法，即把软件测试和评估转移到开发生命周期的早期，把安全和合规的负担放在开发团队身上。尽管如此，58%的人也同意左移的安全策略对开发团队来说是一种负担。总的来说，调查结果显示，全球的公司将从改善和精简安全和合规性流程中大大受益，以确保他们的软件供应链，改善开发人员的经验，并增加创新的时间。\n本报告解读的视频如下：\n感谢和我一起晚上直播的三位朋友：[大鲲、南方、悟空]\nQ1 你对软件供应链的攻击有多担心（如果有的话）？\n十分之九的企业高管表示，他们对软件供应链攻击感到担忧，其中一半表示非常担忧。 来自澳大利亚、法国、西班牙、英国和美国的C-suite高管比德国的C-suite高管更有可能说他们担心软件供应链的攻击。 Q2 与两年前相比，您认为您对软件供应链攻击的担忧是多还是少？\n超过五分之四的C-suite高管表示，与两年前相比，他们对软件供应链攻击更加担忧。 在所有六个国家中，至少有四分之三的C-Suite高管表示，与两年前相比，他们更担心软件供应链的攻击。 Q3 你认为你的软件供应链的安全性如何？\n去年，超过九成（95%）的C-suite高管表示他们的软件供应链是安全的，超过一半表示非常安全。在2022年，这一比例下降到88%，认为它是安全的，只有三分之一（32%）的人认为它是非 常安全的。 德国的首席执行官比其他国家的执行官更有可能说他们的软件供应链不安全。 Q4 您认为您的软件供应链的合规性如何？\n超过四分之三的C-Suite高管（78%）表示他们的软件供应链完全或几乎完全合规，低于去年十分之九（90%）的说法。 澳大利亚、法国、英国和美国的首席执行官比德国和西班牙的首席执行官更有可能说他们的软件供应链完全或几乎完全合规。 Q5 虽然两者都很重要，但哪个对你的组织最重要？\n四分之三的C-suite高管表示，安全和合规是最重要的，而四分之一的人表示快速和合规是最重要的。 每个国家至少有三分之二的C-Suite高管表示安全和合规比快速和合规更重要。 Q6 您认为，贵公司的团队每年平均花多少时间在合规性审核上？如果您不确定，请使用您最好的估计。如果您真的不知道，请选择不确定。\n虽然超过五分之一的C-suite高管表示他们完全不确定，但平均而言，C-suite高管表示他们的团队每年花在合规性审计上的时间超过37天。 来自西班牙、英国和美国的C-Suite比其他三个国家的C-Suite更有可能说他们的团队每年平均花更多时间在合规性审计上，而德国的C-Suite更有可能说他们完全不确定。 Q7 在平均一周内，您认为您的团队在以下各项上花费的时间是多少？如果您不确定，请使用您最好的估计。\n尽管首席执行官们说他们的团队在创新上花费了更多的时间，但他们在风险和缺陷上花费的时间也相差不远。 innovation 创新 risks 风险管理 Defacts 缺陷管理 Technical Debt 技术债务 虽然所有国家的比例都差不多，但在澳大利亚和西班牙，花在风险上的时间比花在创新上的时间多。 Q8 在平均一周内，您认为您的团队应该在以下各项上花费多少时间？如果您不确定，请使用您的最佳估计。\n毫不奇怪，C-suites说他们的团队应该把最大的时间花在创新上。 德国和英国的C-suites高管比其他国家的高管更有可能说更多的时间应该花在创新上，而美国和西班牙的C-suites更有可能说更多的时间应该花在风险上。 Q8-A 是什么阻碍了你的开发团队将更多的时间花在你认为他们应该花时间的活动上？请选择所有适用的。\n超过一半的C-suite高管表示，合规性和/或流程占用时间是阻止他们的开发团队花更多时间在他们认为应该花时间的活动上的原因。 合规和/或流程所需要的时间 合规和/或安全方面的知识 过多的技术债务 糟糕的产品测试 其他的东西 没有什么能阻止他们 澳大利亚和美国的C-suite高管比其他国家的C-suite高管更有可能说合规和/或安全知识是阻止他们的开发团队花更多时间在他们希望他们花时间的活动上。 Q9 你有多大程度上同意或不同意以下说法？\n几乎十分之九的C-suite高管表示，与两年前相比，他们现在更多地考虑保障软件供应链的安全和合规问题。 我现在比两年前更多地考虑保障供应链的安全。 我现在比两年前更多地考虑合规问题 合规挑战限制了我们的创新能力 安全挑战限制了我们的创新能力 我宁愿处理自然灾害，也不愿处理我们软件供应链中的安全问题 在我们公司，安全问题可能是一个缓慢的部门。 如果我们的软件供应链受到攻击，我不确定我们会首先向谁求助 几乎三分之二的C-suite高管表示，在他们的公司中，安全可能是最慢的部门。 人口统计学上的差异。按C-suite高管的类型 :CEO比CTO/CIO/CISO和其他C-suites更有可能说。\n他们现在比两年前更多地考虑合规问题（93% vs. 85%和79%）。 合规挑战限制了他们的创新能力（82%对73%和73%）。 安全挑战限制了他们的创新能力（84% vs. 72% \u0026amp; 64%）。 他们宁愿处理自然灾害，也不愿处理软件供应链中的安全问题（80% vs. 62% \u0026amp; 52%）。 在他们的公司里，安全可能是最慢的部门（79% vs. 58% \u0026amp; 50%）。 如果我们的软件供应链受到攻击，我不确定我们会首先向谁求助（70%对45%和51%）。 人口统计学上的差异。按年龄划分 :40岁以下和40至54岁之间的人比55岁以上的人更有可能说。\n安全挑战限制了他们的创新能力（82% \u0026amp; 74% vs. 55%）。 他们宁愿处理自然灾害也不愿处理软件供应链中的安全问题。 供应链的安全问题（69% \u0026amp; 69% 对 48%）。 在他们的公司里，安全可能是最慢的部门（71% \u0026amp; 65% vs. 39%）。 他们不确定如果他们的软件供应链受到攻击，他们会首先求助于谁（62% \u0026amp; 55% vs. 34%）。 人口统计学上的差异。按公司规模划分：员工人数少于1000人的公司比员工人数在1000人以上的公司更可能说。\n他们更愿意处理自然灾害而不是软件供应链中的安全问题（70%对62%）。 人口统计学上的差异。按在C-suite的时间划分 ：在C-Suite工作10年以下的人比10年以上的人更有可能说。\n在他们的公司里，安全可以成为缓慢的部门（67%对52%）。 澳大利亚的C-Suite高管比其他国家的高管更有可能说，如果他们的软件供应链受到攻击，他们不确定会首先求助于谁。 所有这些与去年相比都有所下降，但这可能与西班牙和澳大利亚的加入有更大关系，而不是条件的变化。 Q10 每项的自动化程度如何？\n五分之三的C-suites（59%）说他们的软件供应链几乎或完全自动化；比去年的四分之三（75%）有所下降。 澳大利亚、英国和美国的首席执行官比法国、德国和西班牙的首席执行官更可能说他们的软件供应链是自动化的。 近五分之三的企业高管表示他们的合规流程完全或几乎全部自动化，而四分之一的企业高管表示他们的合规流程大约有一半自动化。 澳大利亚和美国的C-suites比其他国家的C-suites更可能说他们的合规流程是自动化的。 Q11 当谈到你拥有的安全和/或合规性问题的工具时，哪种工具与你正在使用的工具最接近？\n五分之三的C-suite高管（59%）表示，他们拥有的安全和/或合规性工具全部或大部分都来自外部，而十分之三的人拥有混合的工具，十分之一的人（11%）拥有大部分或全部自己创建的工具。 与法国、德国和西班牙相比，澳大利亚、英国和美国的首席执行官们表示，他们在安全和/或合规问题上使用了所有或大部分的外部工具。 Q12 你目前是否在你的组织中实施了向左转的安全和合规方法？\n超过四分之三的C-suite高管表示，他们正在其组织中实施 \u0026ldquo;左移 \u0026ldquo;的安全和合规方法，其中三分之一表示他们肯定在实施。 澳大利亚、西班牙、英国和美国的首席执行官比法国和德国的首席执行官更有可能说他们正在其组织中实施 \u0026ldquo;左移 \u0026ldquo;的安全和合规方法，而德国人更有可能说他们没有实施这种方法。 Q13 哪一个最接近左移方法对你的开发者的影响？\n近五分之三的C-suite高管说 \u0026ldquo;左移 \u0026ldquo;方法对他们的开发人员是一种负担，而超过三分之一的人说它是一种帮助。 澳大利亚的C-suites比其他国家的C-suites更有可能说 \u0026ldquo;左移 \u0026ldquo;方法对他们的开发人员是一种负担，而德国和西班牙的C-suites更有可能说这是对他们的帮助。 Q14 你有多同意或不同意以下说法？\n十分之九的C-suite高管表示他们的风险管理团队拥有建立和/或确保安全的软件供应链的知识和专长，而几乎十分之九的人表示他们的架构师和/或开发人员拥有。 我们的风险管理团队拥有建立和/或确保安全的软件供应链的知识和专长。 我对我们的软件在生产中的安全性非常有信心 我们的架构师和/或开发人员拥有构建和/或确保软件供应链安全的知识和专业技能 我们的风险管理团队拥有他们需要的所有工具 我们的开发人员拥有他们需要的所有工具 左移对我们的组织来说是很重要的 超过五分之四的C-suite高管表示 \u0026ldquo;左移 \u0026ldquo;对他们的组织很重要。 西班牙、英国和美国的C-suite高管比澳大利亚、法国和德国的C-suite高管更有可能说他们对自己的软件在生产中的安全性非常有信心。 S4 目前有多少开发人员在贵公司工作？如果您不确定，请使用您最好的估计。\n五分之二的C-suite高管（41%）说他们公司目前有100个或更少的开发人员，而超过三分之一（35%）的人超过200个。 Q2 与两年前相比，您认为您对软件供应链攻击的担忧是多还是少？\n法国、德国、西班牙和英国的C-suite高管比澳大利亚和美国的C-suite高管更有可能说他们的公司目前有1-50名开发人员，而澳大利亚的高管则更有可能说他们有201-300名。 方法论\nCloudBees与Regina Corso Consulting合作，对澳大利亚、法国、德国、西班牙、英国和美国的C-suite高管进行了调查，以收集关于软件供应链和围绕它的安全问题的见解。 本次调查的对象是来自至少有250名员工的公司的600名C-suite高管，澳大利亚、法国、德国、西班牙、英国和美国各有100名受访者。 本次调查于2022年6月27日至7月8日在网上进行。 阅读图表时注意。由于四舍五入，或由于问题允许多次回答，百分比的总和可能不是100%。此外，\u0026rdquo;*\u0026ldquo;表示回答少于0.5%。除非另有说明，所有幻灯片的基数代表600名C-suite管理人员的总数。如果问题与前一年的调查重复，则显示趋势数据。 关于逐年数据的说明。2021年只有四个国家（法国、德国、美国和英国），而2022年增加了两个国家。 人口统计学\n年龄：18-39岁=45%，40-54岁=40%；和55岁以上=16%。 性别特征。男性=70%；女性=29%；非二进制=*。 公司规模。250-999名员工=53%，1000名或以上员工=48%。 C-suite高管的类型。CEO=34%；CIO=21%；CTO=19%；首席审计官=6%；CISO=6%；首席风险官=2%；以及其他C-suite=12%。 担任C-suite高管的时间：5年或以下=29%；6-10年=48%；11-20年=16%，20年以上=7%。 点此处，下载本报告的 PDF 文件 📃\n","date":"2022-12-18T12:17:39+08:00","image":"https://martinliu.cn/blog/cloudbees-global-c-suite-security-survey-report-2022/cover_hu_33384f5671d07209.png","permalink":"https://martinliu.cn/blog/cloudbees-global-c-suite-security-survey-report-2022/","title":"CloudBees 全球企业高管安全管理调查报告-2022年"},{"content":"从欣赏和磨练耐心性的角度看，养护鱼缸里的生态系统也值得推敲的，是一件很有意思，而且可以是非常技术流的事情。\n大概是去年的冬天，在鱼缸里生长了 10+年的那一条金鱼寿终正寝了。它是一条从租住屋里搬进家的普通红白金鱼，它是其它几个同伴中唯一的幸存者；到最后，我也没有想到它能独自生长这么多年。它的生存环境应该说是极其简陋的，每两周会给它换掉鱼缸里的一半的水，偶尔用增氧泵给它开几个小时，它快死的那几个月，增氧泵用的多一些。想想这条鱼的一生也是挺艰难的，偶尔还会遇到我们全家出游一个多月的时候。然而，它却和我们不离不弃的，坚强的活到了最后。最后应该是得了什么病了，肚子肿大，身体无法保持平衡，最后静静的离去。\n最近由于弹窗 3 的缘故，从十一前开始，就没有好好在北京呆过几天，应该有一个多月的时间都在燕郊，好处是可以安心的陪着妈妈天天做饭吃饭；然而，这有家不能回的烦恼也是显而易见的。\n说回到下面这个鱼缸的故事。\n这是一个 35 cm 宽的白玻璃鱼缸。由于疫情的缘故，在家里呆着的时间会比较多。几乎所有社交也都减免了，天天过着几乎是隐居一般的生活。养几条鱼，让屋子里多一些生机，能看着小鱼儿们在水草间游弋，也是一种非常减压的举动。\n养鱼先养水，我用很多 5 升的矿泉水桶装满自来水晒在阳台，一周后这些水就都困好了，水里的有害物质也几乎挥发殆尽。为了更加贴近大自然，我去河里采集了两桶河水，然后混入了困好的自来水。去河边还采集了一些免费的水草和石头，这样在继续养水的过程中，还能让缸里的景观不至于单调。河里的石头上还有，免费附赠的一些田螺，它们是鱼缸里最初的原住民。\n混合河水的鱼缸在稳定了一周以后，我去买了一些小鱼，鱼缸里一下子充满了生机。随后又添加了一个小型的瀑布式过滤器。还加入了一个方形的水培绿萝的小盒子，固定在鱼缸的一个角落，里面放了几颗滤材。\n鱼缸生态系统浅谈：\n水质是根本。鱼会在水中排出粪便等污染水质的物质，污染物的来源是鱼食，显然喂鱼是整个这件事情最有意思的部分。净化水质的手段不仅依靠水泵的循环，还依靠看不见的硝化细菌。 硝化细菌的培养依赖于，水利的底纱、过滤器里的滤材和水中的石头等因素，这些环境物质给硝化细菌提供了条件。 鱼的生存还依赖于氧气，氧气的获取来自水泵和水草。在中午日光最强的时候，冬天的低角度日光可以直接照射水草三四十分钟，日光的光合作用是最明显的，可以看到水草上成串的放出光合作用的产物氧气。 水草的生长依赖阳光和二氧化碳，鱼能产生少量的二氧化碳，但是缸里能自己产生的二氧化碳的量也不至于让水草疯长，但足够水草维持生命。 在鱼缸里的生态系统非常健康的情况下，水会非常干净，鱼的排泄物会被很快的分解的无影无踪。甚至于鱼缸的内壁上的沉积物也没有，鱼缸从外部看起来清澈透明。\n为了保持这个生态系统的持续性，我从不给鱼缸大换水；只加水不换水。鱼缸自然蒸发导致水位下降了两厘米左右的时候，我就会加相应容量的困好的氺。喂鱼也尽量忍住不频繁投喂，目前这是最大的水质污染来源。目前的硝化细菌还比较弱势，缸内壁的附着物两周不管，就会比较影响缸壁的透明度，这是最亟待改善的部分。所有的鱼都是小型鱼，它们的耗氧量本来就比较少，因此都非常活跃。河里的田螺不知道为什么，死亡了几只。买过一些黑壳虾，它们能躲在水草上，吃水藻，观赏性也不错，但是由于一次新水泵的测试，一夜之间都几乎被水泵吸入后阵亡了。\n总之，维持鱼缸里合理的生态系统并不难。从观赏性和嗜好的角度都算是高投入产出比的事情。养鱼这件事还是很好玩，后期会注重与水草和造景，尝试更多种类的小型鱼。\n","date":"2022-11-07T14:27:37+08:00","image":"https://martinliu.cn/blog/aquarium-eco-systems/small-tank_hu_cc25aca9dd9bfdd8.jpg","permalink":"https://martinliu.cn/blog/aquarium-eco-systems/","title":"鱼缸里的生态系统"},{"content":"从 homelab 的规模上来说，我的这个并不算什么，可是从设备的种类和目标上来说，就稍微有点复杂了，和我多年积累电子设备有关，和我的好奇心有关。\ncisco ccna lab: router = 2x2800 + 1x2600, sw = 2 x 3560; firewall = 1x pix 515; 希望有机会用他们恢复一下我生锈的网络知识。 4 x raspberry pi ，没有玩多久就放一边吃灰了。 2 x MacBook Pro，之中一台 2011 年的老款，外壳上亮灯型号。1 x MacBook 1 x Hp Z420 当时想用来做 TrueNAS 的，后来运行 esxi 了。 1 x Dell R220，身材精干，莫却虽小五脏俱全的企业级服务器。 1 x Lenovo P710 是 Homelab 从 Intel NUC 升级上来的败笔，从买了这个机器以后，后续各种想法和需求就决堤了。 2 x 华南金牌组装服务器，搭配 P710 成功搭建了 Nutanix CE 集群。 1 x SuperMicro 服务器，配合外置的硬盘支架，用 6 个 4TB 西数红盘组成了 TrueNAS 服务器，说真话，对于 homeLab 而言，其实这一个服务器就够了。真的不需要上面所有设备 交换机 - core switch 我用了一台 48 口的 Cisco 3560-x 作为核心交换机，对于我这个 32U 高的机架而言，它提供了足够的网口空间，再用了将近一年后，觉得选择稍微高于当前想法的交换机是非常正确的选择。建议采购 1.3 ~ 1.5 计划需求的交换机。\nVLAN ：必用功能，特别是在虚拟化场景和多个子网隔离的需求下。 Trunk / Access mode 端口：VLAN+Access port 的模式是最多用的；在 esxi 虚拟化服务器上会用到 VLAN+Trunk port 的需求。 Routing / DHCP ： 可以开启 VLAN 之间的路由功能，由于我用 pfSense 服务器做的防火墙，因此 DHCP 和各个子网的网关都用 pfSense 服务器做了；因此这个功能在我这里就测试了一下，据说这个功能开启了以后也会比较消耗资源。 我还配备了一台 Cisco 3560 PoE-24，最初是为了试一下我的两个 PoE 供电的设备，它们是 piHat 和 海康威视监控头。不过这个设备以后主要会用于 NetDevOps 的研究，Ansible 的 Cisco 模块一直没有研究过。 配线架 - patch panel 如果你准备入手机架，或者正在规划中，都一定不要忘了这个重要的组件。它最终帮我实现了一次性网线布线，轻松在机架前调整网络配置的便利性。特别是在后续经常调整设备网络配置的时候，越用越能感受到这个神器的价值。\n我在配线架跳线（patch cable）上所走的弯路：\n我买了一卷网线用于配线架后所有设备的连接，配合网线钳和水晶头，我将24 口配线架的后面都布满了长度和是的网线；这个用法和做法是没有问题的。 然后，我用相同的方法开始做长短不一的短跳线，等我做完了十几根跳线以后，意识到：网线的线径太粗，中间的芯太硬，他们横七竖八的排列着非常难看。 让误以为是鸡肋的理线器上岗，在交换机和理线架中间挪动出 1U 的空间后，理线架将张牙舞爪的跳线都收纳起来后，视觉上感觉好多了。可是跳线太粗，与从 pfSense 上走下来的 6 根网线混居到一起后，居然就已经把配线架的狭小空间塞满了，这意味着，我发在塞入以后新增的跳线需求了，还有七八个口没有跳线。 买了 24 根超细的 0.5m 的跳线，不忍彻底更换下来辛辛苦苦做的我十指发麻的 n 多根跳线。 下面是更换细跳线的过程。\n这个视觉效果应该是可以了，而且从功能上来说，理线器中宽松的空间，让我以后给不同的配线架端口变更网络配置的时候，就轻松自如多了。\n网线 - cables 除了专门买的那一卷 25m 的网线，我手头还是有不少长短各异的网线。\n超五类：外皮较柔软 六类/超六类：都是长短不同的成品网线，有些被我掐掉一端的水晶头后，利旧部署在配线架上了，虽然都是8 芯的双绞线，不同的中间塑料芯和双绞线的粗细和硬度都是不同的。 扁网线：收纳方便，柔软，用于临时飞一根网线出来。 纤细的跳线：适合在高密度配线的地方使用。 通过使用这套工具，可以让你充分理解什么是物理层。在制作水晶头的过程中，也会屡屡失手。\n最后值得一提的是这个细跳线，并不是为了美观，主要是为后期更改跳线操作。留下更多的操作空间。\n在过几天，我当前的网络配置就会固定下来，起码所有网口都就位，后续网线布线方面的待办事项：\n打印 1 ~ 24 的网线标签纸，贴到配线架后面的网线上。 更新配线架上网口上面的标签纸，标明后面接的是什么设备的那块网卡。 用尼龙绷带，将位置基本上固定不变的设备的网线固定在机架的立柱上。 优化核心交换机的 VLAN 配置，调整VLAN 中的端口数量。调整 esxi 服务器管理网和虚拟机网的端口配置（Trunk 配置） 优化 10GB 光纤交换机上 1GB 以太网口的配置，将其作为 Trunk 模式，接入存储网 VLAN 意外的其他 VLAN。让后续 Nutanix CE 重构后，虚拟机和存储网可以都在这个万兆交换机上，但是流量是隔离开的。 ","date":"2022-10-26T20:08:21+08:00","image":"https://martinliu.cn/blog/home-lab-network-cable/cover_hu_9e141613b6064779.jpg","permalink":"https://martinliu.cn/blog/home-lab-network-cable/","title":"Homelab 里剪不断理还乱的莫过于网线"},{"content":"测试过程和环境概述：\n用一个 RHEL 9 虚拟机安装 Elasticsearch 和 Kibana；然后部署 Fleet 服务器。 在另外一个虚拟机安装 Elastic Agent，初始化注册到 Fleet 服务器，然后更新对它的管理策略。 在 Kibana 的可观测性和安全解决方案中观察采集到的数据。 安装 Elasticsearch 下载 Elasticsearch 的 rpm 安装包，用 rpm 的方式安装 Elasticssearch 服务器。 dnf install elasticsearch-8.4.3-x86_64.rpm 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 [root@elk8 ~]# dnf install elasticsearch-8.4.3-x86_64.rpm Updating Subscription Management repositories. Red Hat Enterprise Linux 9 for x86_64 - BaseOS (RPMs) 3.9 kB/s | 4.1 kB 00:01 Red Hat Enterprise Linux 9 for x86_64 - AppStream (RPMs) 3.9 kB/s | 4.1 kB 00:01 Dependencies resolved. ============================================================================================================================= Package Architecture Version Repository Size ============================================================================================================================= Installing: elasticsearch x86_64 8.4.3-1 @commandline 540 M Transaction Summary ============================================================================================================================= Install 1 Package Total size: 540 M Installed size: 1.1 G Is this ok [y/N]: y Downloading Packages: Running transaction check Transaction check succeeded. Running transaction test Transaction test succeeded. Running transaction Preparing : 1/1 Running scriptlet: elasticsearch-8.4.3-1.x86_64 1/1 Creating elasticsearch group... OK Creating elasticsearch user... OK Installing : elasticsearch-8.4.3-1.x86_64 1/1 Running scriptlet: elasticsearch-8.4.3-1.x86_64 1/1 --------------------------- Security autoconfiguration information ------------------------------ Authentication and authorization are enabled. TLS for the transport and HTTP layers is enabled and configured. The generated password for the elastic built-in superuser is : guJrLagKN5bsmUh72bha If this node should join an existing cluster, you can reconfigure this with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reconfigure-node --enrollment-token \u0026lt;token-here\u0026gt;\u0026#39; after creating an enrollment token on your existing cluster. You can complete the following actions at any time: Reset the password of the elastic built-in superuser with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic\u0026#39;. Generate an enrollment token for Kibana instances with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana\u0026#39;. Generate an enrollment token for Elasticsearch nodes with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s node\u0026#39;. ------------------------------------------------------------------------------------------------- ### NOT starting on installation, please execute the following statements to configure elasticsearch service to start automatically using systemd sudo systemctl daemon-reload sudo systemctl enable elasticsearch.service ### You can start elasticsearch service by executing sudo systemctl start elasticsearch.service /usr/lib/tmpfiles.d/elasticsearch.conf:1: Line references path below legacy directory /var/run/, updating /var/run/elasticsearch → /run/elasticsearch; please update the tmpfiles.d/ drop-in file accordingly. Verifying : elasticsearch-8.4.3-1.x86_64 1/1 Installed products updated. Installed: elasticsearch-8.4.3-1.x86_64 Complete! [root@elk8 ~]# 安装完毕之后，用 vi 编辑器打开 /etc/elasticsearch/elasticsearch.yml 配置文件 ； 在这个默认配置文件中寻找类似这样的一行 cluster.initial_master_nodes: [\u0026quot;elk8\u0026quot;] ；将这一行注释掉。\n然后在此配置文件的最下面增加下面这几行。\n1 2 3 4 cluster.name: homelab-elk8 discovery.type: single-node network.host: 0.0.0.0 xpack.security.authc.api_key.enabled: true 启动 Elasticsearch 服务，并查看服务的状态。\n1 2 3 4 sudo systemctl daemon-reload sudo systemctl enable elasticsearch.service sudo systemctl start elasticsearch.service sudo systemctl status elasticsearch 在使用 ES 前，可以先修改ES服务初始化的内建用户密码，改成自己好记的安全可控密码。否则需要到 ES 的启动日志里寻找系统自动生产的管理员密码。\n运行 /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic -i 命令修改 ES 的管理员账号 elastic 的密码。\n1 2 3 4 5 6 7 8 9 [root@elk8 ~]# /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic -i This tool will reset the password of the [elastic] user. You will be prompted to enter the password. Please confirm that you would like to continue [y/N]y Enter password for [elastic]: Re-enter password for [elastic]: Password for the [elastic] user successfully reset. 在启动 ES 服务前，打开后续测试所需要的防火墙端口。\n1 2 3 4 firewall-cmd --permanent --add-port=9200/tcp firewall-cmd --permanent --add-port=5601/tcp firewall-cmd --permanent --add-port=8220/tcp firewall-cmd --reload 在浏览器里访问 es 的访问网址 https://10.0.30.105:9200/ ，忽略关于证书的安全提示，输入上面所修改的 elastic 账户信息，测试是否可以正常登录。\n安装 Kibana 下载 Kibana 的 rpm 安装包到服务器，然后执行下面的安装命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 [root@elk8 ~]# dnf install kibana-8.4.3-x86_64.rpm Updating Subscription Management repositories. Last metadata expiration check: 0:22:56 ago on Sun 16 Oct 2022 02:20:20 PM CST. Dependencies resolved. ======================================================================================================================================= Package Architecture Version Repository Size ======================================================================================================================================= Installing: kibana x86_64 8.4.3-1 @commandline 274 M Transaction Summary ======================================================================================================================================= Install 1 Package Total size: 274 M Installed size: 649 M Is this ok [y/N]: y Downloading Packages: Running transaction check Transaction check succeeded. Running transaction test Transaction test succeeded. Running transaction Preparing : 1/1 Running scriptlet: kibana-8.4.3-1.x86_64 1/1 Installing : kibana-8.4.3-1.x86_64 1/1 Running scriptlet: kibana-8.4.3-1.x86_64 1/1 Creating kibana group... OK Creating kibana user... OK Created Kibana keystore in /etc/kibana/kibana.keystore /usr/lib/tmpfiles.d/elasticsearch.conf:1: Line references path below legacy directory /var/run/, updating /var/run/elasticsearch → /run/elasticsearch; please update the tmpfiles.d/ drop-in file accordingly. Verifying : kibana-8.4.3-1.x86_64 1/1 Installed products updated. Installed: kibana-8.4.3-1.x86_64 Complete! 在启动 Kiban 服务器之前，先需要创建 Kibana 需要的各种加密 key ，执行下面的命令。\n1 2 3 4 5 /usr/share/kibana/bin/kibana-encryption-keys generate xpack.encryptedSavedObjects.encryptionKey: 2e71f1b16031c2b111b76276268dbf9e xpack.reporting.encryptionKey: 84cb58b5e944fa9f65f73382384612a5 xpack.security.encryptionKey: c5ac5b306ee011838a67e2eaf4154dd0 记录以上三行配置参数，并增加2行新参数，将它们全部添加到 Kibana 默认的配置文件中。\n1 2 3 4 5 server.host: 0.0.0.0 server.publicBaseUrl: \u0026#34;http://10.0.30.105:5601\u0026#34; xpack.encryptedSavedObjects.encryptionKey: 2e71f1b16031c2b111b76276268dbf9e xpack.reporting.encryptionKey: 84cb58b5e944fa9f65f73382384612a5 xpack.security.encryptionKey: c5ac5b306ee011838a67e2eaf4154dd0 用 vi 打开 Kibana 的默认配置文件 /etc/kibana/kibana.yml ，将上面的 5 行配置参数添加到文件中。\n在命令行执行 systemctl enable --now kibana 命令启动 Kibana 服务器.\n然后执行命令 tail -f /var/log/messages ， 在日志中寻找 Kibana 服务启动的信息，等待出现 Kibana 配置的访问 URL。在日志中寻找类似这样的信息：\n1 2 Oct 18 10:36:48 elk8 kibana[2163]: i Kibana has not been configured. Oct 18 10:36:48 elk8 kibana[2163]: Go to http://0.0.0.0:5601/?code=732948 to get started. 将 0.0.0.0 替换为这台虚拟机的 IP 地址，然后在浏览器中打开这个类似这个 http://10.0.30.105:5601/?code=732948 网址。网页中会出现一个大输入框，等待输入Kibana 注册秘钥。\n在命令行执行 /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana 命令，从而获取 Kibana 的注册令牌。\n1 2 [root@elk8 ~]# /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana eyJ2ZXIiOiI4LjQuMyIsImFkciI6WyIxOTIuMTY4LjEwLjEwOjkyMDAiXSwiZmdyIjoiZTdlOTdlZWU2YWVlYjVmYTczZWM1YTVkNzBiNDJkZGUzZjlkZmNjMDJhNTVmZDcwZjAxOTQwZmExNzE5YWM2MSIsImtleSI6IjNHLVEzNE1CYnA4c3p4TEZEZXpCOk0wUDMzRC1VVFAyT0ZxQVFBekNKSWcifQ== 将这个 Token 复制到网页里，完成Kibana 的初始化配置，最后用 es 的管理员账号登录 Kibana。\n从 kiban 目录中找到 es 的根 ca 证书，将其安装在系统的默认根证书目录中。查看 Kibana 的配置文件找到类似这样的一行配置信息。\n1 elasticsearch.ssl.certificateAuthorities: [/var/lib/kibana/ca_1666060779947.crt] 运行下面的命令安装这个根证书。\n1 2 3 update-ca-trust enable cp /var/lib/kibana/ca_1666060779947.crt /etc/pki/ca-trust/source/anchors/ update-ca-trust extract 建议将这个根证书也用这个方法复制到其他需要用 Elastic Agent 采集监控数据的操作系统中，并安装备用。也可以在 Elastic Agent 安装的时候指定忽略 ES 证书校验的参数。\n安装 Fleet 服务器 在 Kibana 的菜单中找到， Fleet 选项，点击 Settings，然后点击 Edit Hosts ，选择增加 Fleet server 配置信息，输入 https://10.0.30.105:8220 ，注意这里必须是 https协议。\n回到 Fleet 主页，找到 agent 管理的地方，按照流程做，点击创建 Fleet Server 配置。然后就会在页面上生成 Fleet 服务器的安装配置命令。\n按着提示的命令参数安装 Fleet 服务器。\n1 2 3 4 5 6 7 8 curl -L -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.4.3-linux-x86_64.tar.gz tar xzvf elastic-agent-8.4.3-linux-x86_64.tar.gz cd elastic-agent-8.4.3-linux-x86_64 sudo ./elastic-agent install \\ --fleet-server-es=https://192.168.10.10:9200 \\ --fleet-server-service-token=AAEAAWVsYXN0aWMvZmxlZXQtc2VydmVyL3Rva2VuLTE2NjU5MTM3ODg1NTA6aWdrR1pvNk9SWmk5N09tV3pUQktTUQ \\ --fleet-server-policy=fleet-server-policy --insecure 上面是连续四条安装命令，需要在最后一条命中，增加一个参数 --insecure ；这样可以确保 Fleet 服务器的正常配置。\n在 Fleet 服务器正常启动以后，上面创建 Fleet 服务器配置的网页上的最后一步就会显示：Fleet 服务器已经连接正常，等待注册 Elastic Agent 。这样表明 Fleet 服务器已经安装正常，并且运行在默认的代理配置采集策略下。\n可以在 Kibana 的界面里查看 Fleet 服务器的监控信息。点击 Kibana 左上角的菜单：Observability -\u0026gt; Infrastructure -\u0026gt; Inventory ，即可看到 Fleet 服务器的监控数据。\n安装 Elastic Agent 监控代理 在 Fleet 的管理界面中新增一个名为 my-policy1 的管理策略，避免和 Fleet 服务器使用相同的策略。点击 Add agent 连接，获取如下代理注册命令。\n1 2 3 4 curl -L -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.4.3-linux-x86_64.tar.gz tar xzvf elastic-agent-8.4.3-linux-x86_64.tar.gz cd elastic-agent-8.4.3-linux-x86_64 sudo ./elastic-agent install --url=https://10.0.30.105:8220 --enrollment-token=NW9ZTjZZTUJtUENhc0ZFTDI5SV86MkZQT1hlc2dUOEdWZnRrWWhNbXVjdw== 将上面的命令复制到一个写字板中，修改最后一条命令，在最后增加--insecure 参数\n1 ./elastic-agent install --url=https://10.0.30.105:8220 --enrollment-token=NW9ZTjZZTUJtUENhc0ZFTDI5SV86MkZQT1hlc2dUOEdWZnRrWWhNbXVjdw== --insecure 通过执行上面的命令，我们就在被管理服务器上，一键式的安装了用于数据采集功能的 Elastic Agent ，并将其注册到 Fleet 服务器上。你也可以手工下载好 elastic-agent-8.4.3-linux-x86_64.tar.gz 文件，但是反复在多个被管理服务器上复制也很麻烦。\n搭建本地安装包下载服务器 为了让局域网中的操作系统能就近下载 Elastic Stack 技术栈中，所有可以通过 Fleet 服务器管理（安装、配置、升级、删除等）的组件，我们可以参考文档的方法：https://www.elastic.co/guide/en/fleet/8.4/air-gapped.html#host-artifact-registry 在本地部署一个安装包下载服务器。\n首先，安装一个 Nginx 服务器，在根目录下创建目录 downloads ，并且运行下面的下载脚本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 curl -O https://artifacts.elastic.co/downloads/apm-server/apm-server-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/apm-server/apm-server-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/apm-server/apm-server-8.4.3-linux-x86_64.tar.gz.asc curl -O https://artifacts.elastic.co/downloads/beats/auditbeat/auditbeat-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/beats/auditbeat/auditbeat-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/beats/auditbeat/auditbeat-8.4.3-linux-x86_64.tar.gz.asc curl -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.4.3-linux-x86_64.tar.gz.asc curl -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.4.3-linux-x86_64.tar.gz.asc curl -O https://artifacts.elastic.co/downloads/beats/heartbeat/heartbeat-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/beats/heartbeat/heartbeat-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/beats/heartbeat/heartbeat-8.4.3-linux-x86_64.tar.gz.asc curl -O https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-8.4.3-linux-x86_64.tar.gz.asc curl -O https://artifacts.elastic.co/downloads/beats/osquerybeat/osquerybeat-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/beats/osquerybeat/osquerybeat-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/beats/osquerybeat/osquerybeat-8.4.3-linux-x86_64.tar.gz.asc curl -O https://artifacts.elastic.co/downloads/beats/packetbeat/packetbeat-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/beats/packetbeat/packetbeat-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/beats/packetbeat/packetbeat-8.4.3-linux-x86_64.tar.gz.asc curl -O https://artifacts.elastic.co/downloads/cloudbeat/cloudbeat-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/cloudbeat/cloudbeat-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/cloudbeat/cloudbeat-8.4.3-linux-x86_64.tar.gz.asc curl -O https://artifacts.elastic.co/downloads/endpoint-dev/endpoint-security-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/endpoint-dev/endpoint-security-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/endpoint-dev/endpoint-security-8.4.3-linux-x86_64.tar.gz.asc curl -O https://artifacts.elastic.co/downloads/fleet-server/fleet-server-8.4.3-linux-x86_64.tar.gz curl -O https://artifacts.elastic.co/downloads/fleet-server/fleet-server-8.4.3-linux-x86_64.tar.gz.sha512 curl -O https://artifacts.elastic.co/downloads/fleet-server/fleet-server-8.4.3-linux-x86_64.tar.gz.asc 将下载后的目录结构整理的和下载路径一致，目录结构如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 [root@elk8 html]# tree downloads/ downloads/ ├── apm-server │ ├── apm-server-8.4.3-linux-x86_64.tar.gz │ ├── apm-server-8.4.3-linux-x86_64.tar.gz.asc │ └── apm-server-8.4.3-linux-x86_64.tar.gz.sha512 ├── beats │ ├── auditbeat │ │ ├── auditbeat-8.4.3-linux-x86_64.tar.gz │ │ ├── auditbeat-8.4.3-linux-x86_64.tar.gz.asc │ │ └── auditbeat-8.4.3-linux-x86_64.tar.gz.sha512 │ ├── elastic-agent │ │ ├── elastic-agent-8.4.3-linux-x86_64.tar.gz │ │ ├── elastic-agent-8.4.3-linux-x86_64.tar.gz.asc │ │ └── elastic-agent-8.4.3-linux-x86_64.tar.gz.sha512 │ ├── filebeat │ │ ├── filebeat-8.4.3-linux-x86_64.tar.gz │ │ ├── filebeat-8.4.3-linux-x86_64.tar.gz.asc │ │ └── filebeat-8.4.3-linux-x86_64.tar.gz.sha512 │ ├── heartbeat │ │ ├── heartbeat-8.4.3-linux-x86_64.tar.gz │ │ ├── heartbeat-8.4.3-linux-x86_64.tar.gz.asc │ │ └── heartbeat-8.4.3-linux-x86_64.tar.gz.sha512 │ ├── metricbeat │ │ ├── metricbeat-8.4.3-linux-x86_64.tar.gz │ │ ├── metricbeat-8.4.3-linux-x86_64.tar.gz.asc │ │ └── metricbeat-8.4.3-linux-x86_64.tar.gz.sha512 │ ├── osquerybeat │ │ ├── osquerybeat-8.4.3-linux-x86_64.tar.gz │ │ ├── osquerybeat-8.4.3-linux-x86_64.tar.gz.asc │ │ └── osquerybeat-8.4.3-linux-x86_64.tar.gz.sha512 │ └── packetbeat │ ├── packetbeat-8.4.3-linux-x86_64.tar.gz │ ├── packetbeat-8.4.3-linux-x86_64.tar.gz.asc │ └── packetbeat-8.4.3-linux-x86_64.tar.gz.sha512 ├── cloudbeat │ ├── cloudbeat-8.4.3-linux-x86_64.tar.gz │ ├── cloudbeat-8.4.3-linux-x86_64.tar.gz.asc │ └── cloudbeat-8.4.3-linux-x86_64.tar.gz.sha512 ├── endpoint-dev │ ├── endpoint-security-8.4.3-linux-x86_64.tar.gz │ ├── endpoint-security-8.4.3-linux-x86_64.tar.gz.asc │ └── endpoint-security-8.4.3-linux-x86_64.tar.gz.sha512 ├── fleet-server │ ├── fleet-server-8.4.3-linux-x86_64.tar.gz │ ├── fleet-server-8.4.3-linux-x86_64.tar.gz.asc │ └── fleet-server-8.4.3-linux-x86_64.tar.gz.sha512 └── pull-bin.sh 12 directories, 34 files [root@elk8 html]# 为了方便查看这个目录的内容，修改 nginx 的默认配置文件，在 http 这个部分增加下面三个参数：\n1 2 3 autoindex on; autoindex_exact_size off; autoindex_localtime on; 重启 Nginix 服务器后，在浏览器中可以访问： http://192.168.10.10/downloads/ ，确保可以看到正确的目录结构和文件。\n进入 Fleet 的配置页面，在 Agent Binary Download 下面点击 “Add agent binary source” ，新建一个新的代理安装包下载来源网站。\n在 Agent Policies 页面新建一个新的测试用 Agent 管理策略，名为 “my-policy2”；进入这个策略的配置界面，修改 Agent Binary Download 为刚才创建的下载源。保存并测试这个策略。\n点击 “Add agent” 连接，获取下面的新注册代理注册命令。\n1 curl -L -O https://artifacts.elastic.co/downloads/beats/elastic-agent/elastic-agent-8.4.3-linux-x86_64.tar.gz tar xzvf elastic-agent-8.4.3-linux-x86_64.tar.gz cd elastic-agent-8.4.3-linux-x86_64 sudo ./elastic-agent install --url=https://10.0.30.105:8220 --enrollment-token=R29qRDZZTUJtUENhc0ZFTFNDSW06bVFOeW5vcUpTQmFmZDBwLUgyTDBYZw== 修改这些命令参数，如下：\n1 2 3 4 curl -L -O http://192.168.10.10/downloads/beats/elastic-agent/elastic-agent-8.4.3-linux-x86_64.tar.gz tar xzvf elastic-agent-8.4.3-linux-x86_64.tar.gz cd elastic-agent-8.4.3-linux-x86_64 sudo ./elastic-agent install --url=https://10.0.30.105:8220 --enrollment-token=R29qRDZZTUJtUENhc0ZFTFNDSW06bVFOeW5vcUpTQmFmZDBwLUgyTDBYZw== --insecure SSH 登录到另外一个虚拟机，用新创建的 Agent 管理策略，一键式安装 Elastic Agent 并注册到 Fleet 服务器。由于这个策略使用了本地的安装包（默认会使用到 Filebeat 和 Metricbeat），所以它的部署速度应该会比较快。\n在 Elastic Agent 的日志文件中应该可以看到类似这样的信息。\n1 2 3 4 cat /opt/Elastic/Agent/elastic-agent-20221018.ndjson ```json {\u0026#34;log.level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;@timestamp\u0026#34;:\u0026#34;2022-10-18T14:37:26.697+0800\u0026#34;,\u0026#34;log.origin\u0026#34;:{\u0026#34;file.name\u0026#34;:\u0026#34;artifact/config.go\u0026#34;,\u0026#34;file.line\u0026#34;:138},\u0026#34;message\u0026#34;:\u0026#34;Source URI changed from \\\u0026#34;https://artifacts.elastic.co/downloads/\\\u0026#34; to \\\u0026#34;http://192.168.10.10/downloads/\\\u0026#34;\u0026#34;,\u0026#34;ecs.version\u0026#34;:\u0026#34;1.6.0\u0026#34;} 这个信息表示：当前的 Agent 会使用上面自建的安装包下载源服务器。\n用这个命令 elastic-agent inspect 也可以确认这个配置。\n万用采集端的好处 在上一篇文章中已经说过了这个问题，这里不赘述。\n为了验证这个功能，可以尝试更新当前的一个 policy，增加 Packetbeat 数据采集能力。操作步骤如下：\n打开当前的一个正在使用中 policy 点击 Add intergation 按钮，在众多选项中选择 Network Packet Capture 模块。 增加新的采集模块后，保存这个策略。 它更新了版本，观察 Fleet 界面上所有使用这个策略的节点的状态变化。 这些节点会自动的，很快的更新到新的管理策略中，Elastic Agent 会自动化安装 Packetbeat 采集模块。 返回 Kiban ，进入安全管理解决方案，我们可以看到 Filebeat 和 Packetbeat 的采集结果。 在策略更新了以后，我们没有在 Elastic Agent 端做任何操作，它就已经自动化的下载新的策略，并更新了自身。\n常见问题 Elastic Agent 在采集数据的服务上安装正常，在 Fleet 服务器的管理界面中也可以看到其状态正常。但是在可观测性的页面中看不到它的任何数据。\n可能的原因：Elastic Agent 采集端程序和 ES 后台服务器的通讯不正常，检查 9200 端口，用 curl + ES 服务器端的数字证书，用户名和密码，尝试访问 ES 的服务地址 https://192.168.10.10:9200。\n也可以尝试在 Fleet 的管理页面上删除这个 Agent；然后在被管理服务器上，用命令 elastic-agent uninstall 删除服务，然后重新安装注册这个被管理服务器，注意在注册命令的最后面可以尝试增加这两个参数： --insecure --fleet-server-es-insecure 第一个参数是忽略 Fleet 服务器的 ssl 证书校验，第二个参数是忽略 es 服务器的 ssl 证书校验。或者尝试重新手工安装一遍 es 服务器上的 ca 根证书。\nFeature picture ❤️ Brett Sayles图片: https://www.pexels.com/zh-cn/photo/2881224/\n","date":"2022-10-18T21:32:14+08:00","image":"https://martinliu.cn/blog/elastic-agent-fleet-update-8-4/observability_hu_6354775269d8fc1d.png","permalink":"https://martinliu.cn/blog/elastic-agent-fleet-update-8-4/","title":"Elastic Agent 和 Fleet 服务器 安装手册 v8.4"},{"content":"数据摄入的痛点 安装、升级和维护各种数据采集工具，包括 Filebeat、Metricbeat、APM 埋点、Logstash数据重整转发、端点安全控制，还有很多很多其它功能选项，貌似每增加一丁点功能，以前的数据采集项目又要重新再来一遍。\n采集管理的配置文件不光只是 YAML 文件，越写越长的 YAML 文件渐渐将你带入了十八层地狱。\n在每个端点上启用和配置不同采集模块行为参数，很多情况下，你不得不在大量采集点的命令行里执行配置命令。\n不同采集模块在采集节点上都需要创建新的用户，不仅复杂化了操作系统用户的管理，还可能引入更多的风险。\n自动化配置管理工具可以批量分发和部署这些数据摄入配置文件，但是你又不得不为此学习另外一种新的武功。\n优化的方向 简化采集端部署 下面是 Elastic Agent 所实现的效果。减少采集不同类型数据的采集代理程序的种类，最好能只使用一个全功能的采集代理程序；有可能的话用一种万能的采集代理程序替代所有单点采集程序，诸如：Filebeat， Metricbeat， APM Agent， Heartbeat， Winlogbeat 等等各种 Elastic Stack 的采集程序。其他的这种类型的各个厂商和各种开源工具你可以自己联想。\n尽量发挥万能型采集代理程序的特性，最好它能够一键式的安装，能支持上百种流行的开源软件、商业软件和云服务。\n在采集代理程序开始正常工作以后，避免在端点的命令做任何配置工作。\n以上的数据采集端点程序部署在大多数情况下，都是覆盖可观测性解决方案的需求；如果可能的话，能够兼顾信息安全管理需求是一种更高效的做法；如果能一石二鸟，那又何乐而不为呢。\n直观的集中统一管理 使用一个统一的采集代理管理中间层 Fleet 掌控全局。在这里一站式的实现采集代理的配置分发、更新等变更；实现采集代理程序的持续版本升级；随着采集端点数量的蔓延，横向扩展 Fleet 层，用一个 Fleet 服务器对接分布在各地的数千个 Elastic Agent。\nELK 数据摄入架构变迁 7.13 的 ELK 架构是持续了很久的传统模式，是社区里存在着大量描述文章，本文忽略对其的解释。\n渐进式的架构变化是从 7.13 开始初具雏形的，Fleet 功能组件作为 Kibana 的内置功能，正式登场。\nKiban 的定位是作为 Elastic Stack 的数据探索窗口，和管理控制平面。统一管理 Elastic Agent 需要增加两个功能：策略管理器和配置包管理器。需要引入新的 Fleet 服务器实现下面的需求：\n对 n 多采集点的更小暴露平面。 降低了 Kibana 服务器本身资源消耗和部署工作量。 更容易管理并发模式。 从 7.14 以后的架构图如下。这是以后的发展方向。\nFleet 服务器的代码和 Elastic Agent 是一套程序。它就像是一个万能工具一样。\n它在对底层的采集端点上，实现的是全能型代理程序的管理。他在 Fleet 这个模式的主要功能是：从 Elasticsearch 后端或许最新版的 Agent 管理策略；相应采集端点上采集代理的管理策略拉取请求。管理策略的单向下发，采集数据的单向上传可以有几个选项，或者集中目标：\n自己部署管理的 Elasticsearch 集群 自己部署管理的 Logstash 服务器 Elastic Cloud SaaS 服务里的 Elasticsearch 服务端点 Elastic Cloud SaaS 服务里的 Logstash 服务端点 Elastic Agent 采集端进程管理所有其他 Beats 进程，使用 GRPC 通讯协议发送数据，和下拉管理策略更新。\nElastic Agent 可以工作在被 Fleet 服务器统一管理的模式；也还可以运行在独立自管理状态，从而满足极端少量的特殊需求。\n其他周边的重要组件：\nElastic Package Registry - 包含了 Elastic Stack 技术栈中所有组件的配置细节，包括安装、升级、更新和删除等等。用 zip 压缩包文件的方式分发。 Policy Builder - 在 Kibana 的界面里展现所有可以让用户掌控/修改定制的配置细节，用简单的开关按钮和输入框完成不容易出错的采集配置细节的定制，这样就消除了对 YAML 配置文件的管理。 参考信息：\nFleet and Elastic Agent Guide Review testing methods for Elastic integrations using the elastic-package tool Feature picture ❤️ analogicus图片: https://www.pexels.com/zh-cn/photo/5516029/\n","date":"2022-10-17T21:09:52+08:00","image":"https://martinliu.cn/blog/fleet-and-elastic-agent/pexels-analogicus-5516029_hu_2e77f64d6a2b7183.jpg","permalink":"https://martinliu.cn/blog/fleet-and-elastic-agent/","title":"面向未来的 Elastic Stack 数据摄入架构"},{"content":" 直播预告。在 10 月 19 日晚上，我会在社区里再次为大家梳理一下 SRE 的知识体系模型，还是用脑图的方式，向大家讲解 SRE 都有相关部分组成。\n本次直播活动的录播视频。\n下面这幅脑图是在我翻译完了《SRE Workbook》之后编写的，用了我好几天的时间，并且前后改了好几版。\n编制这个脑图的出发点在于：SRE 从来源到 5 大基础模块，到推广实施的方法论都看似比较完整，比较成体系。这种脉络明晰的知识体系（knowledge body）本来就有画出脑图的可能性；而且脑图应该是一种比较便于吸收和学习的形式。\n脑图的第一个版本是从 《SRE Workbook》的目录开始的，我尝试用最精简的方式，梳理每一章节中的知识点。可是在编制了前两章以后，就发现这个工作量其实非常的大。然后，我果断的放弃了“完美”的目标，然后将目标定位为：先完成一版。下图就是这样一个版本。后续我们讨论还有那些改进和与社区协作的想法。\n后续的未尽事项：\n细化现有版本，将《SRE Workbook》中的知识点尽量都涵盖尽量。 将 SRE 的第一本出版物《Google SRE 运维解密》也梳理进来，由于它已经被 Workbook 彻底包含，并且多次引用。 将 SRE 安全那本书也梳理进来，由于安全的特殊性，独立做一个节点梳理比较现实；如果能融入的更好，则更加。 需要找到一种方便人们协作的线上脑图协作软件，应该至少具备一下功能： 多人协作 评论知识点 支持导入导出标准格式的脑图文件 支持导入导出 pdf，png，jpg ，html 等方便人们引用的文档 欢迎范围和参考 Google 官方 SRE 独立站点。https://sre.google/\n网站中的相关出版书籍如下。\nSite Reliability Engineering 中文版书名：SRE：Google运维解密 英文版线上阅读 The Site Reliability Workbook 中文版书名：Google SRE 工作手册 英文版线上阅读 Building Secure \u0026amp; Reliable Systems 中文书名：《Google系统架构解密》 英文版 PDF 版 官方免费下载 ","date":"2022-10-10T23:13:43+08:00","image":"https://martinliu.cn/blog/sre-knowedge-body-mind-map-live-show/1_er5uoPoOmLkfuxjTAy2zwQ_hu_ef368128145a3c1.jpeg","permalink":"https://martinliu.cn/blog/sre-knowedge-body-mind-map-live-show/","title":"SRE 实践的知识体系梳理"},{"content":"下面是标准的 IDC 机架结构示意图，结构比较复杂，发挥其所有功能还需要依赖于专业机房所提供的风火水电环境的各种配套支持。\n下面这个标准规格【42u x 19 英寸】机架架结构图，这是最常见的服务器机柜，在普通的办公室里，或者公司专门的 server room 服务器机房中很常见。高低、深浅、能否墙挂都可以选择。\n对我来说，显然以上两种的功能过于复杂，并不适合我在家庭使用；我个人比较偏爱 StarTech 公司的开放式机架。\n但是，我发现 StarTech 公司的机架产品在国内没有代理商，在淘宝里也没有卖家。就算是有，价格也比较贵。不过它确实是国外 HomeLab 玩家评测的最多的。\n总结一下我们置办家庭机架的几个所谓合理的动机：\n整理收纳一定数量的电脑和网络产品，包括家用 NAS，wifi 和其他可能存在的新旧电脑（包括家用 PC、笔记本、服务器、网络设备等）。 给这些电子产品更好的运行环境，确保供电、散热、网络连接和安全性等需求。 让使用更加方便，需要开机的开机，用不到的关机省电。 目前真在，或者已经走向 HomeLab 的人，请自觉跳这个坑。 希望在本地组网，并自给自足一定数量本地虚拟机的需求，同时降低或者避免使用云主机的成本。 其他特殊需求：一个炫酷的机架也是不错的网络软件演示环境和直播的装饰背景。 下图是我的 HomeLab 机架的第一个版本。\n设备包括：\nCCNA lab 测试设备一套。 TrueNAS 服务器一台 四个旧树莓派 几个旧 MacBook Pro 电脑 这些版本基本上能满足以上列举的所有需求，成本可以忽略。缺点就是：它的承重能力有限，无法在堆放更多设备。由于疫情的原因，我需要把放在公司的四台PC服务器拿回家，方便使用。\n由于比较了很久国内的品牌服务器机柜，他们的规格很齐全，很多人也都是买的这些成品机柜，到货开箱就可以使用，很方便。但是，成品并没有 DIY 的乐趣可言，我真的是不喜欢有全封闭式机柜，不想虑散机柜内的散热\u0026amp;热制冷问题（以及次生噪音），而且不方便触达设备的各个侧面。\n因此我只能求助与万能的淘宝，在研究了一段时间自行搭建开放式机柜产品的可能性之后，我出手了。\n这是第一次下单的产品，包括：\n四根 32U 高的立柱：机架高度的选择是 DIY 搭建机架的最重要决策，考虑到一定的扩展性，应该至少规划 130% 的高度。 其次考虑深度，我铁定不想买全尺寸深度（600+mm）的设备，因此实际上就想搭建了一个：32U x 19 寸 x 19 寸的立方体，这就是成品机柜的瓤子，就是柜体里装的金属框架的部分。 四个服务器托盘 ：如果设备可以上下堆叠的话，其实也不用这么多，但是考虑到分层分区，设备取出和放入的方便性，需要计算好使用的个数。 四块盲板：是前后上下，将四根立柱连接起来的主要部件。 两幅服务器导轨：安装在了顶部和底部框架的侧面，将机架的前后链接起来，安装好这四根导轨，机架就可以站立起来了。居然前后左右都不怎么摇晃，整体框架还比较的支棱的 😄 一个理线架：其实不需要，由于你不可能有大量线需要整理，买多了。 销售以上产品的淘宝商家是：军臣机柜 1 店；前后从他们家下了两个单（320+38），第二个单补了四根导轨，起稳定机架，更优化的分层分区，更方便的叠放设备的作用，释放了两个托盘，托盘将主要用于在实现开放平层，起到设备物品的放置功能。安装起来后的效果如下。\n在将设备放进去的过程中，发现了几个问题：\n洗衣机用移动滑轨无法胜任如此重量机架前后左右的快速移动，而且只能前后移动；还需要一个更加稳定，且更方便四向移动的底座。 机柜还需封顶，只有封顶后，上面才能便于放置物品。 解决方法：\n在淘宝里买了一块底座板，规格 2cm 厚 x 53cm x 53cm 的压缩板，到货后发现：其实坚固程度不输于实木板。够用且耐用，全面黑漆，多种颜色可选。 淘宝店家送了我四个万向轮和更多的机架螺丝，轮子安装在了底座板的四个角上，底座比机架大了一圈，既不占地方，也实现了稳定承载机架的目的，还可以四个方向顺滑的移动，其实用不到带锁死功能的万向轮。 用一块大约19 寸 x 22 寸的房间隔音装修剩下的隔音板封顶，大小相当合适。用木螺丝和机架固定在了一起。 下面是将所有设备上架，网络连通后，晚上的效果。\n这么多年来积累下来的所有 HumeLab 设备就都在这里了，堆叠在一起之后意识到，给自己挖的这个坑，是越挖越深了。\n最后从几个方面讲讲当前这个阶段的经验总结。\n电源供给\n机架专用 PDU 的好处多多，能用尽量用。 前置 PDU A ：是一款 1U 高度，前面板 10 位独立开关，后身走电源线的，好处是省空间，后身走电源线更隐蔽、美观。但是需要重新买 10 根美标垂直三叉的电源线（5 根 1 米 + 5 根 1.5 米，这款 PDU 只能插这种电源线），目前还富裕了 2 到 3 根供电源线。 后置 PDU B ：是一款 2U 高度，8 位独立开关。目前有一个空位；电源插头供电位的需求远远比你想的多得多，除非设备不会在增加了，千万别想一个插排就搞定。 需要首选可以安装在机架上的 PDU 优于家用的插排。整合性极佳。 USB 供电，安装一个 10 位的 USB 插排，有了它给树莓派、风扇、灯光设备的供电就方便且统一了，一个电源插头位置就替代了 n 个 usb 变压器插头的需求。 网络拓扑\n入户光纤+光猫+WiFi 给所有无线设备使用，暂时没有无线访问机架内设备的需求，有的话，会首选在 pfSense 上做 NAT 的方式接入，从而最小化 WiFi 部署数量。 通过房间内的走线管，从入户弱电箱的光猫上拉了一根网线到机架的房间，并且接到机架上。实现了机架的外网链接。在手里云主机资源充足的情况下，我完全忽略远程访问机架中设备的鸡肋需求。 核心以太网交换机：一台 Cisco 48 口千兆交换机，可划分 VLAN，属于 CCNA Lab 设备的一部分。 万兆存储网交换机：一台 MikroTik 8 口 SPF+ 交换机，功能很强大，学习曲线陡。用于 TrueNAS 存储服务，和 Nutanix 超融合集群的组网。 山泽 24 口配线架：用了以后才能理解配线架的底层逻辑，将所有设备都统一终结在同一级，然后就可以在机架前面，按标签快捷的给设备分配不同的网络。 买了一卷网线制作跳线：配合打线钳和测线器，一盒 50 个的水晶头，做完了一些跳线后，568B 线序就成了肌肉记忆了。推荐使用，虽然费事，但是可以让网线布线\u0026amp;走线更加简洁。 风冷散热和用电方式\n我坚守不使用大功耗\u0026amp;全尺寸服务器设备的原则。感觉只有这样才能实现通过房间环境的自然散热，注意房间的正常通风即可。 给设备按需增加和升级必要的风冷风扇。 最耗电的是联想 P720 两路工作站，它是 Nutnaix 集群的一部分，升级了 CPU 的散热器，加装了机箱前置风扇，解决旧风扇导致的无法正常开机和运行中过热机器卡死的问题。 最牛的是给 8 口 pfSense 防火墙工控机扇热的 USB 桌面小风扇，它顺便还给树莓派集群风冷了；这是从家里小朋友哪里征用的。风量大，几乎静音，基本上能秒掉各种尺寸和价格的 DIY 机箱用风扇，已经买过几个了，它们的噪音大到不能忍。 常开的设备包括：TrueNAS 服务器和 48 口核心交换机和 MikroTik 万兆交换机。其他的设备按需开机，保持最小的功耗和发热量。 由于家庭 WiFi 和这个机架无关，因此在需要用的时候，或者人不在家的时候整个机架关机断电。 以上就是目前的经验总结分享，欢迎交流讨论。以后可能会以本文为大纲录制一期视频，在讲的细一些。\n","date":"2022-10-10T00:00:39+08:00","image":"https://martinliu.cn/blog/build-your-best-rack/R-C_hu_e45a4528eedbffce.jpg","permalink":"https://martinliu.cn/blog/build-your-best-rack/","title":"亲手为自己打造一个完美的机架"},{"content":"趁着更新 Blog 皮肤的机会，也把我拖延很久的一些优化补一补。\n最新版本的 Hugo 可以使用 Hugo modules 功能加载一个新的 Theme，我是第一次通过这种方式添加新皮肤，犯了几个错误：\n首先不应该用 git clone theme-url theme/ 或者其他手工下载的方式了，应该使用文档中说的 hugo mod get -u github.com/CaiJimmy/hugo-theme-stack/v3 方法。 在本地测试的话，需要确保本地的 Hugo 安装的是 extended 的扩展版本，否则有些短代码用不了。用这条命令检查 hugo version ，应该返回类似这样的信息：hugo v0.104.2+extended darwin/arm64 BuildDate=unknown 更新了 GitHub Action 的工作流，实现了如下的想法：\ndeploy-2-page.yml : 在所有分支的 push 操作上触发构建动作，并且把更新的网站内容发布到 GitHub Pages 的部署分支中，用这个方式实现线上的网站内容预览；当新的分支在本地预览正常后，就可以 push 到远程了，push 之后就可以先在 martinliu.github.io 的域名下实现分支合并前的线上预览，如果线上预览正常的话，在进行合并分支 pr 的操作；如果线上预览有问题，则继续在本地更新，直到线上预览正常之后在合并。 page-deploy.yml : 当 master 分支上收到 pr 时触发这个发布操作，我将 GitHub Pages 的免费空间当做了发布前的预览的空间；而网站的内容是通过 CloudFlare 的 Pages 功能 host 的。通过这种方式，将 GitHub 的所有功能和空间作为开发服务；而 CloudFlare 定位为 DNS 和静态内的生产环境。 目前我的 blog 的工作流程是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # 第一步：在本地创建新的分支，并 push 同步到远程 ➜ martinliu.github.io git:(master) git branch build-your-best-rack ➜ martinliu.github.io git:(master) git checkout build-your-best-rack M themes/hugo-theme-stack Switched to branch \u0026#39;build-your-best-rack\u0026#39; ➜ martinliu.github.io git:(build-your-best-rack) git push origin build-your-best-rack Total 0 (delta 0), reused 0 (delta 0), pack-reused 0 remote: remote: Create a pull request for \u0026#39;build-your-best-rack\u0026#39; on GitHub by visiting: remote: https://github.com/martinliu/martinliu.github.io/pull/new/build-your-best-rack remote: To github.com:martinliu/martinliu.github.io.git * [new branch] build-your-best-rack -\u0026gt; build-your-best-rack # 第二步：用 hugo 命令创建新文章的文件，然后开始编写更新新文章 ➜ martinliu.github.io git:(build-your-best-rack) hugo new content/post/build-your-best-rack/index.md Content \u0026#34;/Users/martinliu/code/martinliu.github.io/content/post/build-your-best-rack/index.md\u0026#34; created # 第三步：本地预览正常后，push 到 GitHub Pages 空间在远程预览 https://martinliu.github.io ➜ martinliu.github.io git:(build-your-best-rack) ✗ git add . ➜ martinliu.github.io git:(build-your-best-rack) ✗ git commit -m \u0026#34;review new post online\u0026#34;[build-your-best-rack e21fffe8f] review new post online 1 file changed, 6 insertions(+) create mode 100644 content/post/build-your-best-rack/index.md ➜ martinliu.github.io git:(build-your-best-rack) git push --set-upstream origin build-your-best-rack Enumerating objects: 9, done. Counting objects: 100% (9/9), done. Delta compression using up to 10 threads Compressing objects: 100% (5/5), done. Writing objects: 100% (6/6), 540 bytes | 540.00 KiB/s, done. Total 6 (delta 3), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (3/3), completed with 3 local objects. To github.com:martinliu/martinliu.github.io.git 49d889b6e..e21fffe8f build-your-best-rack -\u0026gt; build-your-best-rack branch \u0026#39;build-your-best-rack\u0026#39; set up to track \u0026#39;origin/build-your-best-rack\u0026#39;. # 第四步：在 GitHub 上发起并合并 pr # 第五步：删除本地特性分支，删除远程特性分支，更新本地 master 分支。 ➜ martinliu.github.io git:(change-to-new-theme) git checkout master warning: unable to rmdir \u0026#39;themes/hugo-theme-stack\u0026#39;: Directory not empty Switched to branch \u0026#39;master\u0026#39; Your branch is behind \u0026#39;origin/master\u0026#39; by 5 commits, and can be fast-forwarded. (use \u0026#34;git pull\u0026#34; to update your local branch) ➜ martinliu.github.io git:(master) ✗ git push origin --delete origin/change-to-new-theme error: unable to delete \u0026#39;origin/change-to-new-theme\u0026#39;: remote ref does not exist error: failed to push some refs to \u0026#39;github.com:martinliu/martinliu.github.io.git\u0026#39; ➜ martinliu.github.io git:(master) ✗ git push origin --delete change-to-new-theme To github.com:martinliu/martinliu.github.io.git - [deleted] change-to-new-theme ➜ martinliu.github.io git:(master) ✗ git pull 根据这款新皮肤的提示，我查看了最新的 Hugo 的文档，为了发挥这个皮肤的图像 resize 功能，并且遵从新的编写 post 的规范。以后的所有新文章的 md 文件和图片文件都需要放到一个独立的新目录中。\n新创建一篇 post 的时候使用这个命令：\n1 hugo new content/post/new-blog-test/index.md 在站点的根目录下执行这条命令后，会帮你创建新的目录和 index.md 文件；由于我的站点默认使用了中文语言，因此，如果我想写一篇英文的文章的话，我就需要将 md 文件的名字写成 index.en.md ；这个皮肤支持双语的，如果这篇文章也有中英两个版本的话，md 文件就应该有两个：\nindex.zh-cn.md index.en.md 这样就有了中英文的两个独立的页面，而且两种语言各自的页面上，都会有一个语言切换的按钮，所以这个皮肤对于双语，或者多语言写作的人来说，应该是非常顺手的一个选择。我将主导航的那些页面都做出了双语的版本。\n由于，我最后的所有静态文件和图片都发布到了 CloudFlare 的 Pages 服务里，而且它们还提供 CDN 服务，而这个功能在 GitHub Pages 空间中是不提供的。因此，以前我用 GitHub Pages host 这个 blog 的时候，每次编写和发布新文章的时候，还需要手工的将图片上传到其它第三方的图床空间中，然后在更新 md 文章中图片的网址，其实还是比较繁琐和麻烦的。\n这个国庆节期间，我基本上也完成了 home lab 的 Rack 搭建项目，初步效果如下：\n以上这张图片放置在了和 md 文件相同的目录中，插入这张图片的代码就变得异常简单了 ![](new-rack.png) ；而且图片也被拉伸到了和文章页面宽度等宽，大小合适的情况下会充满页面宽度，而且能够自适应浏览器显示器的宽度。\n后续会出一些关于这个 home lab 的文章。\n关于这个皮肤的使用文档，请访问： https://docs.stack.jimmycai.com/\n如果你也喜欢这个风格的皮肤，请查看： hugo-theme-stack-stater\n遗留问题：\n左上角的头像图片无法正常显示 添加一种免费好用的评论互动插件 增加搜索功能 ","date":"2022-10-09T00:00:00Z","image":"https://martinliu.cn/blog/change-to-jimmy-stack-theme/2022-10-1-beijing-guomao_hu_b13beb0466265335.jpg","permalink":"https://martinliu.cn/blog/change-to-jimmy-stack-theme/","title":"更新到 Jimmy Cai 的 Stack Hugo Theme"},{"content":"本文总结了我从单机的 Home Lab 环境，发展到三节点 Nutanix 超融合混合盘集群的经验和教训。\n为什么需要超融合集群 我的 Home lab 的进化史\n长期保持一些特定功能的虚拟机 在本地保持丰富的虚拟机模版和快照 将照片和视频家庭资料放到媒体服务器中【Plex】 探索IoT智能家居，家庭安防等项目 充分利用虚拟话带来的福利，计算和存储资源超量分配 利用高级分布式软件定义存储都高级功能，空间的节省：压缩，去重，纠删码等；性能提升：虚拟机享受全闪存本地磁盘+精简制备；同时享用性能和空间：通过 SSD+HDD的混合容量存储池实现鱼和熊掌兼得。 本地实验室网速提升到万兆以太网，尝试最新的数据中心DPU（智能网卡）、边缘计算和IoT趣味设备。 排除家用 NAS主机（群晖）、ALL in One 主机、云和容器等选项 其他可能选项\nVMware 的 ESXi 平台 + VSAN ；熟悉 VMware 技术栈； 或被人带着追捧者多用。 Citrix 的 XenServer + 家用集中存储；少见家用的人。 其他的开源虚拟化选项 Proxmox ，单机版家用服务区比较常见。 各种系统使用体验 不论是单机的服务器/NAS，总之使用场景的需求是越用越多的，HomeLab 用的时间越久，想要做的事情就会越多。\nIntel NUC 这是一台 Nutanix 售前工程师标配的测试机。我用了好几年，非常皮实耐用。\n硬件平台：\n集成主板，i7 8 Core + 集成 Intel 显卡 32GB 内存，DDR4 - 2133 MHz SSD 500GB x 2 ， M.2 nvme 接口 使用体验：\nCPU和内存资源都比较有限 散热不理想，风扇噪音越用越大 无法扩展 不适合长期开机 安装 Nutanix CE （AHV） 超级轻松，从不会遇到失败，hypervisor 安装在U盘上。安装后，调低 cvm 的资源，剩余可用资源，所剩无几。 Lenovo P720 公有云虽然是完全可用的，但是无法满足我企业数据中心相关技术的本地体验。还是需要搞一台配置高的，资源更多的机器，因此入手了第二台测试机，为了放置空间和电费都更容易接受，折中选择了二手的品牌机工作站。\n硬件平台：\nIntel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz 14 core x 2 64 GB ，还有很多空余插槽 SSD ：120 GB + 256GB ，一共有四个 3.5 寸的标准磁盘位。 安装 VMWare ESXi + vCenter 超分资源+精简存储制备 广泛的开源虚拟机模版下载 大量开源和私有企业技术支持 经过一年多的扩容，截止到现在的配置如下：\n56 logical core： 2 x Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz -14 core 【保持】 128 GB DDR4 2011Mhz 【感谢上海网友】 HDD：西部数据WD 4Tb 5400rpm x 2 【增加了两块 HDD】 SSD：三星750 Evo 120GB，三星870 Evo 250 GB，三星870 Evo 1TB 【新增一块 SSD】 NIC：Boardcom BCM57412 NetXtreme-E 10Gb SPF+双口 【感谢panpan】 使用体验：\n存储空间不足，虚拟机越来越多，需要不断买新磁盘扩容 CPU\u0026amp;内存有限，无法做一些性能基准测试 想扩展为单机版 VSAN ，或者 VSAN 群集，但是它无法支持SSD+HDD的混合容量磁盘组 只有两张千兆网卡（主板集成），无法实现集群情况下高速的网络数据I/O 虚拟机开多了，导致CPU过热，机器会自动关机后，机器暂时无法启动，不得不替换了更好的散热器 单机工作站的 HomeLab 模式无法实现，我对更多集群型软件的部署使用场景，包括：\nElasticsearch 冷热温多层架构 + ELK 全家桶的长期数据本地保留 高可用 K8S 集群搭建和长期持有 *更多 DevOps 开源工具链的搭建，新版本更新，长期随时可用 还有其它，不赘述。 建议平台选型 为了实现三节点的超融合群集，双十一出手购买了一些产品。\n国产主板套装 x 2 国产套版的性价比和评价其实都还是ok的，满心怀疑的开始测试起来。\n华南金牌 x99-AD4 - 单路\n12 CPUs x Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz 64 GB - DDR4 - 2400Mhz 磁盘接口：\nnvme接口：1 x M.2 - AHV 可用，ESXi不可用 NGFF接口: 1 x M.2 - 同上 sSATA x 2：空闲 SATA x 6: SSD1: KINGSTON 60GB x 2 SSD2: Samsung SSD 860 500GB + Samsung MZ7TE 256GB HDD3/4: 西部数据WD 4Tb 5400rpm x 4 主板集成RTL8111/8168/8411 千兆网卡，ESXi 7/6 都不能直接兼容\n显卡：无集成显卡，ATI Radeon HD 2GB x 2 - 买错了，最好是集成显卡。\n万兆网卡： Boardcom BCM57412 NetXtreme-E 10Gb SPF+双口 【感谢panpan】 x 2\n千兆网卡：\nIntel 82576 千兆双口 x 1 （ESX i 6/7 兼容） Intel I340-T2 千兆双口 x 1 （ESX i 7 不兼容） 机箱：开放式亚克力透明双层机箱 x 2\n使用经验：\nBIOS 中的Boot模式一定要设置为Legacy模式 忽略主板集成网卡，除非你非常擅长将驱动注入ESXi 的iso文件，安装前兆或者万兆网卡 Nutanix CE安装的时候需要网卡驱动正常，ESXi 虚拟化必须能从本地web服务器下载iso安装文件 AHV虚拟化安装很正常，连nvme接口的M.2磁盘都可以正常使用 ESXi虚拟化安装的结果是失败的，但是手工可以拯救CVM，步骤可以忍受。 超微豪华高仿Nutanix 新购了一块超微主板，做下对比测试，缓解一下华南主板坑多的低落心情。\n单路：SuperMicro X10SRL-F CPU：E5-2690 v3 @2.60 GHz，12 core SATA3: x 10 SSD 1/2 HDD x2 主板集成双千兆网卡 （ESXi 6/7 兼容） 用这块主板 + 以上华南金牌的全套磁盘+CPU+内存+万兆网卡，安装Nutanix CE，ESXi 6/7都可以顺利安装，连CVM都能够自动创建成功，不需要手工拯救失败的CVM，这个平台安装部署Nutanix CE 应该是毫无压力感。\n超微主板是Nutanix原厂超融合硬件平台的供应商，这任选了一块测试版的兼容性就确实没话说。不用再测，不用在多了，关键是把上面的国产廉价平台能用起来。\n方案汇总 类型 主板 内存 SSD HDD 网络 节点 价格 最小可平台 Intel NUC 32GB 500GB x 2 USB/hypervisor 1G1/2 1 7+千左右 工作站平台 Lenovo P710 128GB 1/2/3+ 1/2/3/4/5+ 1Gx2/10Gx2 1 8+千左右 国产套版 华南x99-AD4 64GB 2 1/2/3/4 1Gx2+10Gx2 1/3/4 7+千左右/2套 超微平台 SuperMicro X10SRL-F / / / / 1/3/4 随意搭配，参考市价 旧服务器 Dell/Lenvov/HP/浪潮 / 2+直通 2+直通 1Gx2+10Gx2 1/3/4 参考市价 其他组件的选择 下面是对于自选平台的DYI的建议：\n机箱：根据主板的选择，开放式主板方便使用水冷系统，热量容易散发，可以借助环境的空气散热，选择封闭机箱则需要注意CPU散热器的选择，确保CPU工作温度正常。 电源：CPU和显卡电耗需要提前计算，确保电源供电攻略足够。 显卡：主板尽量带集成显卡，保持系统最简化可用，后续如果需要GPU了，可以在加显卡，确保主板有两个PCIx16的插槽。 网卡：尽量选择ESXi7可以识别免驱动的，7这个版本兼容的网卡类型比6少很多，安装过程中需要IP地址，免得给自己找麻烦，我的一块千兆网卡不能被7正常驱动，因此ESXi的版本无奈降到6.7u3。 PCI插槽：建议16x至少2个，用于显卡和万兆网卡，其它速率的若干，用于兼容其它可能的网卡或者设备。 集群搭建流程 准备工作 注册Nutanix社区帐号，https://next.nutanix.com/，必须用公司邮箱注册，才能下载最新的Nutanix CE安装镜像，和其它相关组件。在首次登陆Nutanix CE群集的时候，也需要输入这个帐号和密码验证。\n准备安装镜像：\nWindows 10 + Ruft 下载 Nutanix-2020-9016.tar Fedora 35 Live CD 16 GB U 盘 x2 准备网络环境\n千兆 + 万兆 （DAC 铜缆） DHCP + DNS + Internet 网络 Web 服务器 + esxi702a.iso 「不安装 vsphere 虚拟化的不需要 web 服务器」 安装流程 Fedora Live CD 启动，磁盘工具删除分区 插好网线 Nutanix 安装盘启动，观察网卡 IP 地址获取 设置 Hypervisor 类型、磁盘布局、集群信息等，建议不要勾选创建点节点集群的选项，后期手工创建更可控。 5. 同意软件许可 6. 等待 Hypervisor （ahv一般较快，或者vsphere）成功安装\n安装后重启服务器，首次 host 启动，观察 cvm 启动过程和结果，等待 CVM 就绪，确认 CVM 上硬盘的挂载情况 登录后确保集群处于未配置状态 重复以上步骤，安装其他 2 ～ 3 个节点 【CE 最多支持4个节点】 检查和确认集群的状态，每个节点都输出，集群未配置，准备工作就绪。 在其中一个 cvm 上，运行创建 Nutanix 集群的命令， cluster create 首次登陆集群，完成初始化配置 配置并确认网络配置，在存储迟管理的地方，创建过载到所有vsphere 主机的共享 NFS 统一存储空间。存储资源就绪。 安装部署 vcenter，在 Prism 中注册 vcenter 安装虚拟机模版 创建虚拟机测试 运行基本的性能验收测试 正式投产 可选：安装 PC、Fileserver、CALM、K8s 问题解决 【Hypervisor】安装过程中 screen is terminating 【vSphere虚拟化】虚拟化安装成功，但是重启后 cvm 创建失败 【vSphere虚拟化】cvm 创建成功且运行正常，但是不能正常挂载 HDD ESXi 安装后 CVM 创建失败/HDD挂载问题 由于安装程序无法正常初始化所有磁盘，直通的HDD没有正常加载，初始化脚本有小bug导致。手工挂在直通HDD，修复有bug的python代码，重新初始化创建 cvm，确保 CVM 虚拟机最后能正常运行。\n处理方法：\n网页访问 ESXi 的 ip 地址 ，使用默认的用户名【root】和密码【nutanix/4u】登录，查看确认如下：\n存储-设备下面是否所有磁盘都可见 网络：所有uplink，网卡，两个虚拟交换机，五个port group SSH 登陆 ESXi host ，查看错误日志的内容：/bootbank/Nutanix/firstboot/esx_first_boot_launcher.log；查看是否是如下的常见错误：\n1 2 3 4 5 6 7 8 9 10 11 FATAL Fatal exception encountered: Traceback (most recent call last): File \u0026#34;/bootbank/Nutanix/firstboot/esx_first_boot.py\u0026#34;, line 2516, in \u0026lt;module\u0026gt; main() File \u0026#34;/bootbank/Nutanix/firstboot/esx_first_boot.py\u0026#34;, line 2361, in main create_svm_vmx_and_attach_rdm_disks_ce() File \u0026#34;/bootbank/Nutanix/firstboot/esx_first_boot.py\u0026#34;, line 1478, in create_svm_vmx_and_attach_rdm_disks_ce dev_paths = get_disk_locations_ce() File \u0026#34;/bootbank/Nutanix/firstboot/esx_first_boot.py\u0026#34;, line 1019, in get_disk_locations_ce device_identifiers.remove(disk[:-3]) ValueError: list.remove(x): x not in list 使用这篇文章https://next.nutanix.com/discussion-forum-14/esxi-failed-install-on-hpe-dl380-gen9-ce-2020-09-16-38898中的解决方案，查看这个论坛帖子需要注册论坛的账号。\n使用上文的方案，运行修改后的 esx_first_boot.py 程序。等待程序执行完毕，在ESXi web client中观察CVM的创建过程。\nCVM 创建成功运行起来之后，你会发现它可能只挂载了SSD，下面需要手工加载加载系统中的HDD。\nssh 登陆 ESXi host 用命令 ls /vmfs/devices/disks/ 查看系统上的所有磁盘设备，记录未挂载上的HDD的设备路径，例如：/vmfs/devices/disks/t10.ATA_____WDC_WD40EFRX2D68N32N0_________________________WD2DWCC7K0ZN6E93 进入 CVM 虚拟机的配置文件目录 【如：/vmfs/volumes/NTNX-local-ds-4abcf92c-A/】，创建所有HDD的直通磁盘，参考命令：vmkfstools -z /vmfs/devices/disks/t10.ATA_____WDC_WD40EFRX2D68N32N0_________________________WD 2DWCC7K0ZN6E93 ./wd4t-1.vmdk 在ESXi web client中，关机（PowerOff） CVM，修改配置 将上一步创建的直通HDD添加进来 修改虚拟机选项的操作系统，改为CentOS7 查看CVM虚拟机所有磁盘，确保所有SSD和HDD都已经加载，先不要修改其它任何配置，开机，观察虚拟机是否可以正常启动。 ssh登陆CVM虚拟机的操作系统，使用默认用户名【nutanix】和密码【nutanix/4u】。用ping其它集群节点的（host和cvm）ip地址，确保网关和DNS服务器都可达。\nCVM 正常运行后，才可以作为空白节点加入群集，或者用于创建新群集。\n经验教训 在 Nutanix 官方用户论坛的CE板块搜索问题或提问，你不是孤独的。 散热器买专用的，通用的套具安装费劲，适配的并会很好 磁盘至少使用 Fedora live cd 的磁盘工具查看状态，避免坏盘。 cvm 创建失败应该是可以修复的 安装过程需要联网 集成显卡更好， 相同的错误复发时要记得赶紧收工，明天再搞 其他可用资源 HCI超融合技术对于了解它的人来说很火热，但是还有很多不太了解HCI的人；HCI的用户对它也有不同的使用场景和期望。请大家参与这个《中国超融合状态调查》，我们每月为参与本调查的朋友进行抽奖，抽奖结果在下次直播的时候公布。扫码参与调查。\n我们为希望学习HCI技术的朋友们创建了一个qq群，希望可以给大家带来一定帮助。扫码加入我们的QQ群。\n下期预告 HCI系统的搭建还有很多问题值得一起探讨和学习，HCI超融合系统软件还有很多功能可以学习了解。我们为DevOps社区的朋友们新开辟了这个HCI板块，希望以后会每个月为大家输出一期新的内容。下期直播的简介如下：\n日期：2022 年 3 月 22 日， 下午 1点开始 内容：Nutanix CE 的多集群管理 主持人：刘征，吴孔辉 直播平台：B站搜/关注：中国DevOps社区 直播抽奖：未知神秘礼物 🎁 报名：互动吧搜/关注：中国DevOps社区 ","date":"2022-02-20T23:05:40+08:00","image":"https://martinliu.cn/img/cos/2022-02-21-hci-nutanix.jpeg","permalink":"https://martinliu.cn/blog/hci-nutanix-ce-training-camp/","title":"HCI | 超融合平台线上训练营第二期"},{"content":"过年前给自己挖了一个 Drupal 的坑，经过一些时间的研究之后，感觉这个系统和 Remedy 非常神似。说到底它们其实都是表单系统。每个表单表达一种分类的信息而已。Drupal 注重的是表单上的信息点的记录、管理和展示，Remedy 注重的则是每种表单（工作类型）上“工单流程状态”字段变化的记录和管理。\nDevOps China 网站的选型之旅，最初使用的是 hugo，但是由于内容更新人员们对 github 系统掌握程度参差不齐，导致对于参与者不友好的问题，这为所有社区内容创建的朋友们设置了一个不必要的门槛。最初设计的是：以官网的内容为最源头参考点，然后同步到其它平台，包括：微信和互动吧等社区对外到入口。最后，微信公众号后台文案编辑的易用性超越了 GitHub 上 Hugo 站点的更新。社区网站维护志愿者也很难投入足够的精力，手工的从微信上同步回社区官网。就这样社区官网的及时更新问题居然持续了两年。\n2022年是解决这个问题的时候了。在对 Drupal 经过一定的研究之后，希望这次选型的 Drupal 能不负众望，完美的实现这个艰巨的使命。【 why drupal ？ 参考文章】\nDrupal 是个内容管理系统 在 macOS 上搭建 PHP + MySQL 的开发环境的工具有很多。我选择使用的是已经绝版的 Acquia Dev Desktop 2 ，它包括了：php 7.3.15 的 php 语言运行环境， MySQL 5.7.29 数据库， Apache/2.4.29 的网页运行服务器， phpMyAdmin 4.9.0.1 数据库管理工具。\n这种集成的 PHP 运行/开发/管理环境，还有很多其它选择，这里不展开。我的目标是：保持最简化和易用，与其它社区伙伴的协作，紧跟 Drupal 版本发布和补丁更新，用容器化实现云上的按需扩展。\n首先，我使用 Acquia Dev Desktop 2 创建了一个本地的测试站点，用于学习 Drupal 的使用、定制和开发。它不仅是一个友好的 GUI 工具，其实还附带了 php 开发环境的命令行工具：composer 和 drush 。 使用这两个命令行工具可以完成 Drupal 系统的一键式搭建。在开发一个真实的内容管理系统网站以前，最基础的铺垫工作可能差不多了。\n一键安装 Drupal 系统 首先，打开 Acquia Dev Desktop 2 ，在界面上点击进入命令行按钮（more -\u0026gt; Open Console）。macOS 系统默认的 termenal 就会被打开，它会在默认环境中增加如下环境变量参数\n1 2 Last login: Sat Feb 5 10:25:58 on ttys005 export PHP_ID=php7_3; export PATH=\u0026#34;/Applications/DevDesktop/php7_3_x64/bin:/Applications/DevDesktop/mysql/bin:/Applications/DevDesktop/tools:$PATH\u0026#34; \u0026amp;\u0026amp; cd \u0026#34;/Users/martin/learning-drupal\u0026#34; 这样就可以在你的目标目录中，执行下面的一键安装脚本了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 下载Drupal特定版本的代码库 composer create-project drupal/recommended-project:9.3.5 drupal-dev --no-interaction cd drupal-dev # 配置以下可以让我们静默安装 drush 的参数 composer config --no-plugins allow-plugins.composer/installers true composer config --no-plugins allow-plugins.drupal/core-composer-scaffold true composer config --no-plugins allow-plugins.drupal/core-project-message true # 安装 Drupal 站点维护工具 drush composer require drush/drush --no-interaction ln -s vendor/drush/drush/drush ./ ./drush version composer require drush/config-extra --no-interaction # 创建目标 MySQL 数据库和用户名/密码 mysqladmin -u root drop local_devopschina -f mysql -u root -e \u0026#39;create database local_devopschina\u0026#39; mysql -u root -e \u0026#34;grant all privileges on local_devopschina.* to ddoc@localhost identified by \u0026#39;ddoc123\u0026#39;\u0026#34; # 上面的一切都是为了这个命令可以静默安装，它替代了很多 php 开发的系统在网页上用安装程序进行的初始化工作，下面的数据库 root 密码为空 ./drush si standard --locale=zh-hans --db-url=mysql://ddoc:ddoc123@127.0.0.1:33067/local_devopschina --db-su=root --site-name=\u0026#34;DevOps China\u0026#34; --account-name=admin --account-pass=admin -y # 安装和启用 Drupal 系统必要的模块和皮肤 【ToDo】 # 生产环境数据迁移，数据库备份的导入，相关文件下载 【ToDo】 # 启动 Drupal 系统 ./drush runserver localhost:8090 以上是一个写死了的 shell 脚本，还可以对其中的关键参数进行变量替换，使之最终成为一个可以传入参数的可用脚本。\n进入 Drupal 开发流程 下图展示了 Drupal 网站开发的工作流程。\n用下面的表格梳理一下：\n序号 工作内容 概述 所需要技能 备注 1.0 Content Type 既是任何一条内容对象的完整定义，也是任何一个可管理实体。系统默认自带了‘文章’和‘基本页面’两个内容类型，隐含的具备了简单的 ‘用户’ 管理系统。在此基础上还需扩展出‘社区合作伙伴’、‘社区活动’等实地。 数据库ER设计、数据结构 并不需要在 MySQL 中建表，都是在 Drupal 界面完成 2.0 Fields 是组成任何内容和实体数据结构的信息点，包含PHP编程语言的数据类型和Drupal 社区里的各种模块，例如‘电话号码’这样的数据结构的引用就是先启用对应的模块 php开发 Drupal 社区已有模块不满足才做开发 2.1 Taxonomy 就像是一个二位数组，在每一个分类里有一堆确切的词汇表。例如社区网站的文章、活动和论坛里的帖子都可以引用“话题”这样一个字段，用于单选或者多选，“话题”这个字段里包含了很多DevOps术语“ci”、“敏捷”、“SRE”等。 领域知识、数据机构 随着网站内容建设的过程而演进 2.2 Media 文档、音频、图片和视频的统一管理，这样方便任意媒体文件的使用；Drupal 9 自带的 Media Libary 模块能够满足需求 数字媒体管理、CDN加速 所有用户生成媒体都在这个范畴，会严重影响网站速度，依赖与网站 CDN 加速的实施 2.3 Modules Drupal 模块非常丰富，从电话号码这样的数据结构，到文本地址到百度地图的转化，到整个知识库结构的定义；社区参与者积分和排名这样的功能将会使用自开发的模块实现 php开发、数据库 需要懂 php 开发语言，可独立开发 3.0 Path 每一个内容实体在 Drupal 中被称之为 node，它们都有默认的访问路径，例如：/node/12/；需要整体规划网站的访问路径，不但让网站变得更加有条理，而且还会提高人和搜索引擎的友好程度，Drupal 的相关模块可以实现 内容系统梳理 尽量保持简单、清晰和持久 4.0 Permessions 用户权限需要提前设计，Drupal 除了具有内置的权限机制外，它对任何一个功能模块（内容分类）都可以实施给予角色的矩阵式权限设置，需要提前设计好用户角色类型，权限体系 权限设计、信息安全 这是实施文章内容上传、论坛和社区活动管理的基础。 4.1 Workflows 工作流是 Drupal 系统中默认的功能模块，经过定制以后可以实现社区贡献文章的审核功能。例如开放所有注册用户的投稿权限，投稿文章必须经过审核人员确认后才能发不出来。还可以用于知识库或者编辑的多重审核功能 流程定制 需要掌握 Drupal 相关模块的使用，确保流程简单易用 5.0 Layout 网页布局结构设计，manage display of nodes 这是基础工作 -\u0026gt; blocks -\u0026gt; layout builder -\u0026gt; views -\u0026gt; image styles ，不同的 theme 自带一套 block 的布局 5.1 Blocks 实施页面中的每个模块，模块是一个实体可以容纳视频、文字、图片和其他更多，搜索栏，菜单等；他不是内容，是一个 placeholder 5.2 Layout Builder 一个核心模块，拖拽式可视化页面设计实施工具，可以为不同的内容类型、实体和其它创建定制的布局。 5.3 Views 创建数据库查询，过滤和筛选内容，静态的操作或者根据上下文的 。Display【page、block】，format，lields,filter,sort, 6.0 Add Content 在以上工作基本完成之后，就可以进入网站内容的填充阶段 SQL查询 6.1 Menus 菜单包括网站的主导航菜单，页脚导航和各个页面上可能使用到的分类选项 6.2 Site Management 开发、测试和生产环境之间的迁移和更新流程 CI、CD、Cloud、DNS、CDN 用 GitHub 、Docker 和 Azure 等技术实施必要的工作流程 7.0 Theme 网站展示风格的开发贯穿于以上所有工作内容的过程中。需要基于某种Drupal网站皮肤作为底板，开发自己的定制皮肤，在需要改进的时候随时调整和更新 前端开发、CSS 图片等美工设计需要交付给社区的设计同学 为了多人、开放式、实现社区网站开发和内容建设的工作，我们还需要一个项目管理工具。这里可以选用 GitHub ：https://github.com/orgs/DevopsChina/projects/1/ 用它可以实现以下功能。\n任务记录、跟踪和分配 统一管理多个代码仓库的任务 任务可以和代码库工作相关，也可以无关 通过内置的工作流，可以实现代码库 issue \u0026amp; pr 任务的自动关联，状态同步 可以创建自定义字段的视图，用于不同目的的跟踪，支持任务清单，ToDoList 等视图。 下一步邀请社区网站工作组召开项目启动会。\n版本化开发环境 初始化上面所创建的项目文件夹。将其推送到 https://github.com/DevopsChina/drupal-dev.git\n先参考 Drupal 代码库 web 目录下的样例文件，在项目目录中创建 .gitignore 文件。应该在这两个文件中排出以下文件，处于演示目的，本项目并没有将其排除在外。\n.env sites//settings.php sites//services.yml 执行下面的代码推送动作。\n1 2 3 4 5 6 git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin https://github.com/DevopsChina/drupal-dev.git git push -u origin main 在完成了代码库初始化工作后，会设置一下 main 主干保护策略。防止直接对 main 的变更。\n容器化 Drupal 系统 容器化当前的项目需要经过这些操作步骤：\n确认当前 Drupal 系统中的配置和内容，这个状态会打包到容器环境中。用 sqldump 导出数据库。 参数化 web/sites/settings.php 文件，将变量和密码变成参数。 创建 Drupal 主应用镜像的 Dockerfile 。 创建包含数据库服务和开发工具服务的 docker-compose.yml 服务定义文件。 在本机测试和确认容器服务中 Drupal 网站的可用性和内容。 1 - 确认当前系统状态 在经过初始化的配置后，几乎所有系统级别配置信息都保存在了 MySQL 数据库中，用 sqldump 导出 MySQL 数据库，dump 文件会用于 MySQL 容器服务的初始化文件。字段定义、文章编辑、初始化内容的填充也会产生一些数据文件（图片、文件、视频、音频），这些文件就位于 web/sites/default/files/ 目录中。\n1 2 mkdir sql mysqldump -u root local_devopschina \u0026gt; sql/dump.sql 在项目文件夹中，执行以上命令，就可以得到的到一个大约十几兆的 MySQL 数据库备份文件。\n2 - 参数化 Drupal 主配置文件 Drupal 的数据库链接字符串和账号信息都位于 web/sites/settings.php 文件中。为了确保 Drupal 镜像启动后可以链接到正确的 MySQL 数据库服务。需要改此文件。\n原始配置参数：\n1 2 3 4 5 6 7 8 9 10 $databases[\u0026#39;default\u0026#39;][\u0026#39;default\u0026#39;] = array ( \u0026#39;database\u0026#39; =\u0026gt; \u0026#39;local_devopschina\u0026#39;, \u0026#39;username\u0026#39; =\u0026gt; \u0026#39;ddoc\u0026#39;, \u0026#39;password\u0026#39; =\u0026gt; \u0026#39;ddoc123\u0026#39;, \u0026#39;prefix\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;host\u0026#39; =\u0026gt; \u0026#39;127.0.0.1\u0026#39;, \u0026#39;port\u0026#39; =\u0026gt; \u0026#39;33067\u0026#39;, \u0026#39;namespace\u0026#39; =\u0026gt; \u0026#39;Drupal\\\\Core\\\\Database\\\\Driver\\\\mysql\u0026#39;, \u0026#39;driver\u0026#39; =\u0026gt; \u0026#39;mysql\u0026#39;, ); 备份原始配置文件。由于修改以后在本机用 drush 运行的本地测试 Drupal 应用就中断了。后续可以优化一下：保持原始配置文件不变，参数化一个配置文件的副本，在 Drupal 打包过程中加一个参数化配置文件的覆盖替换动作。\n修改为如下内容：\n1 2 3 4 5 6 7 8 9 10 $databases[\u0026#39;default\u0026#39;][\u0026#39;default\u0026#39;] = array ( \u0026#39;database\u0026#39; =\u0026gt; $_ENV[\u0026#39;DBASE\u0026#39;], \u0026#39;username\u0026#39; =\u0026gt; $_ENV[\u0026#39;USER\u0026#39;], \u0026#39;password\u0026#39; =\u0026gt; $_ENV[\u0026#39;PASS\u0026#39;], \u0026#39;prefix\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;host\u0026#39; =\u0026gt; $_ENV[\u0026#39;HOST\u0026#39;], \u0026#39;port\u0026#39; =\u0026gt; $_ENV[\u0026#39;DPORT\u0026#39;], \u0026#39;namespace\u0026#39; =\u0026gt; \u0026#39;Drupal\\\\Core\\\\Database\\\\Driver\\\\mysql\u0026#39;, \u0026#39;driver\u0026#39; =\u0026gt; \u0026#39;mysql\u0026#39;, ); 以上参数化非必要的最佳操作，本文目标在与记录，后续会优化这个步骤。\n3 - 创建 Drupal 主应用镜像 基于 Drupal 官方的镜像文件创建适合自己项目的 Dockerfile。\n1 2 3 4 FROM drupal:9-php7.4-apache RUN set -eux; \\ apt-get update; \\ apt-get install -y --no-install-recommends git 然后运行 docker build 命令，确认本地可以成功构建这个自定义镜像。\n1 2 docker build -t devopschina/drupal-dev . docker image 本测试镜像创建成功后，没有镜像上传的动作，镜像上传到特定的镜像仓库后，就可以实现在云容器服务中的部署。这里省略此 push 步骤。\n4 - 创建服务定义文件 为了简化本地测试，这里使用 docker-compose 工具。创建包含数据库服务和开发工具服务的 docker-compose.yml 服务定义文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 version: \u0026#39;3.1\u0026#39; services: # 使用 mysql 作为后端数据库 db: image: mysql:5.7 container_name: devopschina_db restart: always volumes: # 用本地当前路径 sql 目录中的 sql dump文件初始化 MySQL 数据库 - ./sql:/docker-entrypoint-initdb.d/ environment: # 用这些环境变量初始化 mysql 数据库，创建目标数据库，创建用户和密码，为 root 用户初始化随机密码 MYSQL_DATABASE: \u0026#34;${DB}\u0026#34; MYSQL_USER: \u0026#34;${DBU}\u0026#34; MYSQL_PASSWORD: \u0026#34;${DBP}\u0026#34; MYSQL_RANDOM_ROOT_PASSWORD: \u0026#34;1\u0026#34; # PHPMyAdmin 数据库管理工具，只用于开发或者测试环境 phpmyadmin: image: phpmyadmin/phpmyadmin container_name: devopschina_myphpadmin restart: always environment: PMA_HOST: \u0026#34;${DBH}\u0026#34; PMA_USER: \u0026#34;${DBU}\u0026#34; PMA_PASSWORD: \u0026#34;${DBP}\u0026#34; PMA_ARBITRARY: \u0026#34;1\u0026#34; ports: - 9999:80 # 使用 drupal 官方镜像 v9 ，指定 php 版本为 7.4 drupal: #image: drupal:9-php7.4-apache 这里以后需要优化为私有镜像名称，而不需要在服务启动的时候做任何构建 build: . container_name: devopschina_drupal restart: always ports: - 9998:80 working_dir: /opt volumes: # 将当前项目目录加载到容器中，这里产生了一个和本机的依赖，后续优化：通过 Dockerfile 的复制当前开发目录中的成功到容器中 # The \u0026#39;z\u0026#39; option tells Docker that the volume content will be shared between containers. Docker will label the content with a shared content label. Shared volumes labels allow all containers to read/write content. The \u0026#39;Z\u0026#39; option tells Docker to label the content with a private unshared label. - .:/opt:z environment: HOST: \u0026#34;${DBH}\u0026#34; DBASE: \u0026#34;${DB}\u0026#34; USER: \u0026#34;${DBU}\u0026#34; PASS: \u0026#34;${DBP}\u0026#34; # composer update 操作确保容器中的 Drupal 服务运行与当前的最新状态，这个操作也应该后续移植到Dockerfile 文件中 command: bash -c \u0026#34;composer update \u0026amp;\u0026amp; rm /var/www/html \u0026amp;\u0026amp; ln -s /opt/web /var/www/html \u0026amp;\u0026amp; /usr/local/bin/apache2-foreground\u0026#34; 相关测试命令：\ndocker-compose config 测试所有参数是否被完整且正确的填充，有错误的话，需要修改 .env 文件。 docker-compose build 构建必要的镜像。 5 - 本地集成测试 在本机测试和确认容器服务中 Drupal 网站的可用性和内容。\n在项目目录中，执行 docker-compose up 命令观察整个启动过程，待启动停止后，在浏览器中访问：http://localhost:9998 ，应该能够看到如下的网页。\n在云平台部署社区官网 下面是关于后续工作的一些规划：\n组件新的网站开发团队，召开项目启动会 优化以上代码库 用一台云主机搭建一个公共的测试环境 确认和实施相关基础设施：镜像仓库、用于Drupal迁移的对象存储桶、优化容器化过程、启用一个用于开发评审的容器测试环境、确定生产环境的运行状态【LAMP单机 vs. 容器环境+其它云服务】 ","date":"2022-02-05T11:11:55+08:00","image":"https://martinliu.cn/img/989197bbd274de342caf84c3642d8c6bc7b980ea-1920x700.png","permalink":"https://martinliu.cn/blog/setup-drupal-dev-env-macos/","title":"在本地搭建容器化的 Drupal 开发环境"},{"content":"本期分享的内容是超融合的基础知识，Nutanix CE社区版AHV/KVM单节点集群的搭建。\n在本期线上直播中，我们给大家科普了超融合的基础概念，介绍了Nutanix CE社区版【AHV/Kvm虚拟化】的单机安装和基础配置。本文为大家回顾一下其中的技术要点。\n观看本次直播并且中奖的朋友们是：我是ZCQQQ、盔甲小子、繁硕星辰、壮星豆、flyinghourse110、YS8297和阿尔萨狮123，请联系微信 Jane-happylife 索取你的奖品。本次奖品是Nutanix提供的空气加湿器或者运动背包。备注 12月超融合直播活动 领取礼品。两种礼品（根据库存来决定随机寄出）。\n本期的视频回放链接在这里：https://www.bilibili.com/video/BV1YY411a7w2/\n认识 HCI 超融合 来自网络的定义：超融合基础架构（Hyper Converged Infrastructure，或简称“HCI”）是指在同一套单元设备中不仅仅具备计算、 网络 、存储和服务器虚拟化等资源和技术，而且还包括备份软件、 快照技术 、重复数据删除、在线数据压缩等元素，而多套单元设备可以通过网络聚合起来，实现模块化的无缝横向扩展（scale-out），形成统一的资源池。\n从我个人角度看，我的对基于OpenStack的私有云持有消极的态度。虽然，OpenStack 给企业数据中心基础设施的建设路线带来了不小的影响；但是，它还是无法解决传统数据中心里经典的三层架构基础设施的三大根本痛点。\n三层架构即由x86服务器层、网络层（以太网/SAN）和存储层所搭建的规模不大数量巨多的虚拟化/物理机集群资源池。由于虚拟化技术的成熟和普及，这些虚拟化集群资源池为业务应用提供了所需要的计算、存储和网络资源。在最近十几年的企业数据中心中处于主力架构，但是它有其核心的三大问题：\n性能瓶颈问题比较突出：当突发大量来自于网路的业务请求时，且处理它们需要大量的读写存储操作时，后台存储系统乃至SAN网络都将发生性能耗尽的瓶颈，存储延时剧增，等待时长暴增，还可能伴随大量读写操作失败。 容量无法线性扩展：三层资源中的任何一层的资源容量耗尽后，都需要多个专业运维团队进行大量手工操作，才能进行物理量容量的扩容，扩容过程中很难实现业务服务的持续性，数据量大的时候甚至不得不面临很长的业务停机时间窗口。 复杂性令运维和开发胆寒：虽然在虚拟化系统中，虚拟化技术可以提供资源层的HA/FT等功能，但是当业务出现宕机故障时，从应用到下层的硬件，从上到下排查的时候，所有相关团队都不得不全员上线救火，业务服务故障很难在这个复杂性极其高的系统中快速定位。服务质量水平命悬一线，而且SLA很难挽救。 超融合的理想是全面消除以上三个问题。超融合系统其实为三层架构做了减法，它对传统磁盘阵列的存储设备产生了颠覆性的冲击，它利用优化的网络分布式存储服务消除了传统架构中的存储层。它还利用自动化部署工具，极大的降低了虚拟化集群的搭建、升级和维护过程。HCI超融合系统的本身及其精简，非常好扩容和维护，而且可以实现容量和性能的同步线性按需增长。从云计算的五个基础特征来考察HCI技术栈，我个人觉得它比OpenStack更像是云计算。\n学习超融合技术栈也有很多种学习路径，动手搭建超融合系统无疑时最佳的方式。本期超融合视频中，我们选择的是免费版的Nutanix CE社区版。下面划出本期直播中的重要知识点。希望大家可以在自己的环境中开始超融合刷机之旅，当超融合成为你的一个日常工具的以后，你可能才会对HCI有更深的理解。\n硬件选择 HCI系统是虚拟化、x86计算机、万兆以太网和超融合软件完美的组合。在你的工作环境中就存在着大量可用的机器，经过一定的挑选和准备之后，你就应该可以操练超融合技术了。\n任何可以运行服务器虚拟化【esxi/kvm】软件的x86计算机都可以，最近10年以内采购的机器应该都可以适用。为了让其发挥应有的价值和意义，下面是一些建议选项：\n最低配置：cpu 桌面机 i5/i7级别起步，4个物理核，或更高配置；服务器推荐E3/E5的多核处理器起步，或者更优CPU；内存32 GB，或更多。 建议配置：cpu尽量选择双路E5级别，或更新的CPU；单机内存建议128GB，或更多，或者按需增加。 磁盘选择是超融合系统的重点之一，通常包括SSD和机械磁盘，它是组成分布式存储服务的基础。对于使用RAID卡的服务器，RAID卡上需要删除所有盘的任何RAID配置，确保所有磁盘都直通给主板，SATA接口的主板，请直接按照先后顺序，先连接SSD磁盘，后连结机械盘。\n最低配置：单机配置1块64GB SSD用于运行虚拟化软件（U盘-8/16GB也可以，但不建议），250GB SSD 一块或两块，用于安装和运行超融合软件，这是HCI的核心，它往往是以一个虚拟机的形式存在的，该虚拟机会完全运行在SSD上，SSD上的剩余空间计算在分布式存储池的全局空间中，SSD对虚拟机起到了重要的加速功能。机械磁盘一块或者多块，用于提供廉价大量的存储空间，机械磁盘的存储容量和SSD一起计入存储池的空间中。对于纯软件测试目的机械硬盘可以不要。SSD是必须的。机械盘是可选的。推荐混合使用，从而实现性能和空间的鱼和熊掌兼得。 建议配置：单机配置1块64GB SSD用于运行虚拟化软件，两块1TB的SSD用于运行超融合软件，且为全局存储池提供足够的高速性能SSD存储空间。两块2TB机械硬盘起步，机械盘后续还可以按需添加。集群中所有计算机上的所有SSD和机械磁盘共同组成了统一的混合型存储层。每个虚拟机都可以访问到所有磁盘中的性能和空间。Nutanix CE版文档声称支持总共四块磁盘，但是社区中也有朋友分享6+块盘的正常工作案例。 网络的选择有以下注意事项：\n最低配置：单节点配置至少一个千兆网口，对于单机的超融合系统而言，Nutanix也可以利用到基本上大部分优势功能，包括：运行虚拟机、为虚拟机提供混合盘组成的存储空间、单节点上双副本的数据可靠性等等，我曾长期运行在这个配置上。 建议配置：一块双口万兆网卡，一个万兆网口用于集群内的存储网络流量，另外一个用于虚拟机中应用的相互网络访问，用VLAN隔离两个网段的流量。测试的目的下，可以混合在一个具备Internet访问条件的网段中。 建议优化配置：两块双口万兆网卡，一块双口千兆网卡，用于对网络流量、高可用性和性能的进一步优化，这里先不做展开。 网络交换机的选择，Nutanix CE免费版支持1、3、4节点的搭建模式。单节点没有特殊要求，多节点情况下，现场需要具备至少一台万兆以太网交换机和一台千兆以太网交换机。并且做相应的VLAN准备。\n准备工作 必须在 https://next.nutanix.com 注册社区账号，记录登录邮箱和密码备用。访问 Download Community Edition | Nutanix Community 这个帖子，下载 Installer ISO https://download.nutanix.com/ce/2020.09.16/ce-2020.09.16.iso 。将这个ISO文件刻录在启动U盘中。安装前确保网线已经连结正常，且能访问Internet。\nNutanix CE安装文件也可以在这个网盘中下载：链接：https://pan.baidu.com/s/1DdvvfcPhcpR1jkfrXhCraA 提取码：4dgc\n安装过程 Nutanix CE版的安装可能会持续1小时左右，过程中包含比较多的自动化操作流程，基本需要用户少量的输入操作，其他更多的是等待时间。\n下面是必须要关注的注意事项，相当于checklist：\n在主板BIOS的启动模式选项中，设置为legacy模式，其他模式不支持。 在BIOS中确认能看到所有磁盘。 插入一个桌面版 Linux Live CD U盘（如fedora 35），或者Win PE启动U盘，先设置从这个U盘启动。 用Linux Live CD中的图形化磁盘分区工具，检查所有磁盘的空间，SMART信息，如果磁盘已经可见的老化或者错误，就替换掉在进行后续的装机。删除掉所有磁盘中的分区。重启。 插入Nutanix CE社区版安装U盘。开始正式的刷机流程。 选项介绍：\n选中 AHV - 即Nutnaix版本的KVM的虚拟化软件。 按顺序选中：服务器虚拟化 Hpyervisor 的SSD盘，CVM的SSD盘，和做数据空间用的机械磁盘。 Host ip ： 物理机运行虚拟化所在网段IP CVM ip：超融合软件运行的网段IP，必须通Internet。 不要选则创建单节点集群选项。 阅读完用户许可证全文后，选中接受，并且点击开始。Nutanix CE是一个裁剪版本有限制的软件，本文建议用于开发测试环境。\n开始了物理机的虚拟化的安装，然后自动开始CVM的安装，CVM是一个虚拟机软件，会被自动启动和部分初始化。\n最后，安装成功的话，拔出U盘，重启服务器。如果是多节点安装，每个节点都需重复这个过程，注意提前规划好Host Ip和CVM Ip的网段。\n初始化配置 在安装完第一次重启的过程中，我们需要一些等待时间，逐步确认超融合系统的充分就绪，一下每个步骤必须顺序进行，不可跳跃进行：\nssh 登录 host 的ip 地址，root 的默认密码是 nutanix/4u ；登录后，使用hostname 命令查看并记录主机名，运行 virsh list 命令观察 cvm虚拟机的运行状态。 ssh 登录 cvm 的 ip 地址，默认用户名 nutanix ， 密码 是 nutanix/4u ；登陆后，使用 hostname 命令确认是否变为了 host的主机名+ -cvm 这样的名字，如果看到的是一个 cvm 的ip 地址，什么也不要做。等cvm第一次重启后，在此登录确认主机名。 在cvm 中执行 ping qq.com 命令，确保和internet的互联。 在cvm 中执行 genesis status 命令，如果过输出是持续报错信息，就等待错信息的停止，最后正常的输出应该是若干行服务的名称和端口号。 执行 cluster status 命令，如果过输出是持续报错信息，就等待错信息的停止，知道最后一行显示本系统中还没有被配置，需要创建集群。 执行超融合集群的创建命令， cluster -s 192.168.1.20 create ； 这里是创建单节点集群，ip地址就是当前cvm的ip地址。等待这条命令初始化集群完毕后，可以看到Nutanix超融合系统的所有服务状态清单。 多节点（3/4）节点 AHV 集群的搭建说明:\n重复以上的安装过程三次或者四次 确保每个计算机上的cvm都处于 cluster status 输出信息正确一致的状态 在每个 cvm上ping 其它邻居cvm的ip，确保网络畅通。 在其中一个cvm的命令行执行多节点集群创建命令： cluster -s 192.168.1.20,192.168.1.22,192.168.1.24 create 。该命令的正确结果是，每个cvm上的集群服务状态信息。 最后，在cvm上使用 cluster status 命令，确认所有节点的所有服务都正常运行了以后，继续登录超融合系统的网页图像界面。\n集群使用基础 顺序只需一下基础的配置和功能操作。\n在浏览器中访问任一cvm的ip地址，使用默认用户名 admin 密码 nutanix/4u登录，立刻会让你修改 admin 的默认密码，使用并记录这个新密码备用。 用新密码登录。 在要求输入Next 账号的地方，输入前面注册好的 Nutanix 论坛的邮箱和密码。 成功登录后，你可以看到超融合的初始化界面，观察第一个关键信息点，观察左上方的第二个信息块，这里的显示的是存储池的物理和逻辑容量。如果这个数据没有立刻显示出来，那么表明该节点存在的某种问题，但是这不表明它不能用于多节点集群的创建。我有三个计算机时这种情况，单节点初始化失败的计算机在多节点集群的创建中反而没有问题。 在右上角的配置菜单中，选中镜像访问 image service ，在哪里上传一个准备好的 iso，img 或者 qcow2 文件。等待几分钟后，每个文件应该即处于就绪使用的active 状态。 在网络配置中创建一个用于虚拟机运行的网络。 创建空白的虚拟机，挂在iso文件，并且开始虚拟机的安装。 创建空白虚拟机，创建基于img 或者 qcow2虚拟机模板文件的磁盘，开机后即可使用。 参考成本 我个人喜欢在本地运行很多虚拟机的测试环境，属于 self-host 粉。我的虚拟机数量逐渐增加。从一个Intel NUC的单机微型测试机。 到单机联想工作站（双路E5CPU），到现在新增了两个某宝的组装兼容机，最后组成了三节点的Nutanix 超融合集群【vSphere 虚拟化】。个人实现多节点超融合集群的必要性因人而异，这里只是告诉大家，使用Nutanix CE在这些机器上是可行的。\n下面是网购订单的统计信息，希望对于想自行攒机的朋友，或者对扩容利旧服务器的朋友有些帮助。\n下期预告 HCI系统的搭建还有很多问题值得一起探讨和学习，HCI超融合系统软件还有很多功能可以学习了解。我们为DevOps社区的朋友们新开辟了这个HCI板块，希望以后会每个月为大家输出一期新的内容。下期直播的简介如下：\n日期：2022年1月26日中午1点 内容1：Nutanix CE版AHV安装答疑解惑 内容2：VMware vSphere 集群的搭建 主持人：刘征，吴孔辉 直播平台：B站搜/关注：中国DevOps社区 直播抽奖：未知 报名：互动吧搜/关注：中国DevOps社区 其他 HCI超融合技术对于了解它的人来说很火热，但是还有很多不太了解HCI的人；HCI的用户对它也有不同的使用场景和期望。请大家参与这个《中国超融合状态调查》，我们每月为参与本调查的朋友进行抽奖，抽奖结果在下次直播的时候公布。扫码参与调查。\n我们为希望学习HCI技术的朋友们创建了一个qq群，希望可以给大家带来一定帮助。扫码加入我们的QQ群。\n","date":"2022-01-03T18:19:20+08:00","image":"https://martinliu.cn/img/cos/2022-01-04-th1.jpg","permalink":"https://martinliu.cn/blog/hci-01-nutanix-ce-ahv-setup/","title":"HCI | 超融合平台线上训练营第一期"},{"content":"最近在闲鱼上收了几台网络设备，其中有一台Cisco 3560X作为lab的核心交换机，其它一些都是用于练习网络运维。本文从清除老旧设备上的vlan开始，将会记录我在这些网络设备上的所有重要配置操作。\n网络设备的初始化 Cisco 交换机 Cisco 3560 的初始化是非常容易和方便的，这是一台非常新的设备，拆机后，机箱内部都没有什么积累明显的灰尘。第一次开机的时候通过mini USB口的连线连接，登陆console后发现需要密码才能进入enable模式，然后不得不重置这个设备的所有配置。\n在交换机开机的情况下，先用mini USB连接好电脑和交换机。 拔掉交换机的电源线 按住交换机前面板，左上角的mode按钮不放 插上交换机电源线 保持mode按钮10+秒以上 看着交换机正常启动，并且进入了快速配置模式 选择进入快速配置模式，或者选择no，进入正常无向导的手工配置模式 到此处为止，你就进入了一个无密码，几乎无配置的状态。虽然现在这是一台几乎空白配置的交换机。但是交换机的文件系统里还是有一个名为vlan.dat的数据文件。这个文件是之前这个交换机的管理员留下的。有了他的存在当你当你执行 ‘ show vlan brief ’ 命令的时候，这个数据文件中的vlan数据有近百行，滚动了半天，非常烦人。因此需要想办法将其删除。\n清除VLAN数据文件 参考文章：https://www.networkstraining.com/deleting-the-vlan-database-from-a-cisco-switch/\n首先查看flash上有哪些文件，使用命令 show flash\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 sw-bj-01#show flash: Directory of flash:/ 10 -rwx 4371 Jan 2 2006 23:55:34 +00:00 config.text 2 -rwx 26945536 Aug 31 2018 10:01:56 +00:00 c3560e-universalk9-mz.152-4.E6.bin 3 -rwx 26844160 Feb 28 2019 05:02:21 +00:00 c3560e-universalk9-mz.152-4.E7.bin 4 -rwx 0 Mar 27 2019 18:36:06 +00:00 merge_config.txt 5 -rwx 6168 Jan 2 2006 23:55:34 +00:00 multiple-fs 6 -rwx 2915 Jan 2 2006 00:02:10 +00:00 config.old 8 -rwx 27468 Mar 27 2019 18:36:05 +00:00 candidate_config.txt 9 -rwx 736 Jan 2 2006 00:08:27 +00:00 vlan.dat 11 -rwx 3835 Jan 2 2006 23:55:34 +00:00 private-config.text 57671680 bytes total (3395584 bytes free) 上面的命令结果中的倒数第二行就是用来保存vlan信息的文件。然后我们使用 delete vlan.dat 命令将其删除即可。然后使用 copy running-config startup-config 保存当前的战果。还可以使用 reload 重启一下交换机，再次登陆交换机之后使用 show vlan brief 命令校验当前的交换机上只有默认的6个vlan存在。\n启用 ssh 和 web 登陆 每次都适用console线连接并配置交换机？这样还是有点麻烦的，我们需要启用交换机的管理ip和ssh登陆这样以后就可以从网络配置了。以后就可以用Ansible之类的DevOps工具玩NetOps了。配置过程的主要命令如下：\n配置管理ip， 参考命令如下： 1 2 3 4 # ip default-gateway 192.168.101.1 # interface vlan 101 (config-if)# ip address 192.168.101.2 255.255.255.0 主机名， 参考命令如下： 1 2 3 # config t (config)# hostname myswitch (config)# ip domain-name thegeekstuff.com 创建 RSA 密钥，用于启用ssh登陆，参考命令如下 1 2 3 4 5 6 7 8 myswitch(config)# crypto key generate rsa The name for the keys will be: myswitch.thegeekstuff.com Choose the size of the key modulus in the range of 360 to 2048 for your General Purpose Keys. Choosing a key modulus greater than 512 may take a few minutes. How many bits in the modulus [512]: 1024 % Generating 1024 bit RSA keys, keys will be non-exportable...[OK] 配置一些 Line VTY 和 console 的参数 1 2 3 4 5 6 7 8 9 # line vty 0 4 (config-line)# transport input ssh (config-line)# login local (config-line)# password mypassword (config-line)# exit # line console 0 (config-line)# logging synchronous (config-line)# login local 设置用户名和密码 1 2 3 myswitch# config t Enter configuration commands, one per line. End with CNTL/Z. myswitch(config)# username myusername password mypassword 如果你还没有配置enable的密码可以参考下面的命令。\n1 2 myswitch# enable secret myenablepassword myswitch# service password-encryption 校验 ssh 访问 使用命令如下：\n1 2 3 myswitch# sh ip ssh SSH Enabled - version 1.99 Authentication timeout: 120 secs; Authentication retries: 3 现在你可以用网络上的电脑测试ssh登陆这个交换机的ip了。\nCisco 路由器 待完成\nCisco 防火墙 待完成\n\u0026mdash;- 未完待续 \u0026mdash;-\n","date":"2021-11-09T12:58:16+08:00","image":"https://martinliu.cn/img/cos/2021-11-09-bigstock-network-hub-and-patch-cables-12234593-1.jpeg","permalink":"https://martinliu.cn/blog/delete-all-vlan-from-cisco-switch/","title":"删除Cisco交换机中的所有VLAN数据"},{"content":"国内很多公司比较多认同的是这样一些职位：开发者社区运营、技术品牌运营、开发者市场运营等，这些都是偏运营的职位。在挺多的职位描述中，往往只需要比较少的工作经验。\n在国外也有很多公司正在寻找 DevRel 方面的人才，他们对这个角色的意义和价值也不尽相同，具有明显的差异性。因此这个职位的定位其实和公司的目标是紧密相关的。\nGoogle 的定义 Developer Relations’ role is to create a vibrant ecosystem of 3rd party developers, by being the interface between those developers and your platform’s product, engineering, and design teams. (From)1 中文翻译：开发者关系的作用是为第三方开发者创建一个充满活力生态系统，成为开发者和你们公司平台的产品经理、工程师和设计团队之间的接口。\nTwilio 的定义 Our job is to inspire and equip developers to build the next generation of amazing applications. This means understanding what they are trying to do, pointing them to tools and training and generally helping them be successful. (From)2 中文翻译：我们的工作是激励和装备开发人员建立下一代令人惊叹的应用程序。这意味着理解他们正在努力做什么，为他们指出工具和培训，并普遍地帮助他们取得成功。\n以上两种定义的区别是：这个职位在Google偏重于双向接口，在Twilio偏向于单向对外赋能。\nMichael Mahemoff 曾经写过一篇博客文章《Developer Relations: A Five-Level Maturity Model》\n级别 描述 LEVEL 0: 无 DevRel 没有从公司内部的投入，来推广该公司的平台和技术，支持开发者，或捕捉外部开发者的反馈。「未开放的闭门造车阶段，对外部开发者/用户无感知」 LEVEL 1: 非正式的 没有官方的开发者关系人员或规划，但一些开发者关系由其他职能部门处理。市场PR可能是在推广平台/技术，业务发展「BD」可能是与开发商合作并支持他们。厂商的开发者可能会给社区一些技术讲座。「市场和BD部门潜意识的覆盖开发者」 LEVEL 2: 高度接触/合作伙伴 与宝藏级合作伙伴（即大型、成熟的公司，或那些有足够资源为新功能搭建演示的公司）建立频繁接触，这往往是隐性的关系。这是一种\u0026quot;不用给我们打电话，我们会给主动联系你\u0026quot;的外联活动，可能需要公司的平台提供资金或直接的技术能力来构建整合方案，并经常伴随着尚未宣布的技术合作，可能可以与一组即将发布的应用一起推出。「重点培养合作伙伴」 LEVEL 3: Evangelism 通过会议、合作关系和网络媒体大规模地推广宣传、讲解和支持公司的产品/技术/平台。积极主动地招募大量的开发者使用该平台「批量引流开发者/用户」 LEVEL 4: Advocacy 一种双向的关系，在这种关系中，公司技术/平台自己的员工认为自己不仅仅是为技术/平台做宣传，而且是为使用平台的开发者着想。在这种心态下，开发者关系在反馈真实世界的产品Bug和功能需求方面发挥着积极的作用，并建立支持性工具来改善开发者的体验。「更深入的和开发者/用户产生双向互动，从而获取反馈并提供更好的支持」 LEVEL 5: 可量化的 度量指标驱动的方式，在这种方式中，开发者关系的投资回报被理解，外联工作能够被量化，无论是对高接触的合作伙伴还是对大规模开发者群体。「理性量化的度量工作成果，用于数据指导下一步的工作。」 注：在以上的表格中，每一行最后一句话，在方括号中的内容，是我添加的观点。参考资料：\nDeveloper Advocate versus Technical Evangelist; When names change the tone 3 Developer Relations: A Five-Level Maturity Model 4 在以上的表格中，我们可以清晰的看到 DevRel 不同的风格或者做法，任何公司根据他们当前的现状和目标，而选择了其中的某一种，然后逐渐演变。如果一个公司希望把重点放在推广和宣传上，或者可能通过参与较少的活动来降低成本，那么他们可以决定把重点放在 Evangelism 宣传上。如果一家公司优先考虑从开发者那里收集产品反馈，那么 Advocacy 宣传可能是更好的方法。\n开发者关系有可能帮助到企业的许多领域，所以你在业务拓展（技术/平台）方面确定的战略和目标很重要。因此可以使用 Dave McClure 的 AARRR 指标可以作为一个基础，从而证明开发者关系是怎样帮助到业务拓展的。\nDeveloper Relations 的定义 DevRel, or developer relations, is a process for nurturing mutually beneficial relationships between organisations and software developers. (From)5 中文翻译：‘开发者关系’是一个培养组织和软件开发者之间互利关系的过程。\n换句话说，这是一个战略和战术的集合，帮助公司与软件工程师更好地合作。开发者关系团队到底做什么，为什么要做，取决于他们的组织需要是什么，目标是什么。\n为什么要做开发者关系？ 从不同公司的角度，所追求的 DevRel 的战略动机可能有很大的不同。例如，X公司做DevRel可能是为了推动其API的采用，而Y公司的团队可能是为了提高公司雇用软件工程师的机会。\n这些动机的差异导致了不同DevRel战略、战术的采用，和对DevRel工作成果成功的定义。事实上，理解你的组织为什么需要开发者关系，是你需要知道的关键，而不是其它任何DevRel的工作事项。它可以帮助你理解DevRel该做什么，需要让谁参与，以及如何度量你的投入。\n那么，开发者关系的战略原因是什么？今天，大多数开发者关系计划都集中在鼓励采用产品/技术方面，如API。然而，至少还有其他五个常见的原因。包括采用，大多数公司投资于DevRel是因为他们想影响下面的各个方面：\n采用：该组织希望更多的开发者使用他们的产品。 产品构建：该组织依靠开发者社区来建设他们的（可能是开源的）技术。 产品与市场的契合：了解开发者的需求和愿望对产品的成功是必要的。 开发者支持：提供教育、工具和基础设施，以便开发者在其雇主采用产品后使用该产品。 开发者认知：该组织认为当前的开发者认知是其产品成功的潜在障碍。 招聘：该组织希望改善其雇主品牌，以便对他们需要雇用的开发者更具吸引力。 在实践中，组织的DevRel活动的是为了满足以上这些战略驱动力的某种组合。例如，一个需要推动采用的公司，很可能也想确保其产品具有良好的市场适应性。\n尽管公司在做开发者关系时有各种不同的原因和动机，但不论他们怎样做，都是基于一套类似的技能和策略，我们称之为开发者关系的四个支柱。\n“DevRel的四大支柱”\n就像市场营销不全是广告一样，开发者关系也不只是建立知名度。虽然不是每个人都同意这个命名，但DevRel有四个互补的领域。\n开发者营销｜Developer marketing：理解产品的目标开发者是谁，然后确保他们有信息和工具来做决定（是否使用你们的产品）。 内容创作、投放和分发 活动Event的赞助、演讲、出席、组织 广告和其他付费宣传活动 竞争和市场研究 开发者支持｜Developer enablement：提供开发者成功使用产品所需的一切。 开发者教育：文档、教程、视频、指南 开发者体验：API设计、SDK、参考应用程序、示例代码 支持和帮助开发者取得成功 开发者布道｜Developer advocacy：作为开发者和组织之间的支持者和渠道。 作为技术品牌的公众形象 在社交媒体、论坛和活动中与开发者直接互动 在活动（会议、meetup）中发言/分享 Twitch线上直播、视频制作、播客制作 充当从开发者到公司的反馈回路 创建宣传和教育材料 开发者社区｜Developer community：创建和维护一个可持续的环境，使开发者 提供并主持论坛、聊天和其他渠道，为开发者提供直接交流的平台。 实施冠军计划（类似于微软的MVP，Google的GED，AWS的Hero等）和其他激励/奖励参与者的形式 设定互动的标准和基调（社区行为准则） 创建一个可持续的流程和环境，使人们能够满足他们的需求，为一个共同的目标而努力。 什么是开发者市场营销（developer marketing）？ 开发者营销\u0026ndash;也被称为B2D，或企业对开发者的市场营销，是与软件开发者受众打交道的市场营销方式。开发人员是一种不同的受众，根据2020年的官方统计数据，中国有七百万软件从业人员。对这么多人进行归纳总结是很难的。即便如此，开发构建软件的工作其实也产生了一些共性的特征，这些特征对于任何想向软件开发者推销的人来说都是很重要的。6\n软件开发者们实际上倾向于：\n希望得到事实，而非完美的、用于市场宣传的产品推广信息 在他们选择某一项技术时，会把他们的声誉风险也绑定在了一起 拥有深厚的专业知识，可能比产品/技术/平台的厂商更了解他们的细分市场 从非主流的来源获取信息 重视实践经验，而非豪言壮语的保证 在技术供应商的选择方面，产生直接的影响 这影响到信息传递、渠道、语气、战术组合，以及市场营销人员可能做的几乎所有其他事情。\nB2D 的产品是不同的 这不只是因为开发者是一个不同类型的受众。以开发者为目标产品在这一点上是不同的。\n要了解他们的能力，以及所需要的专业知识 他们的观点可以在相对较短的时间内得到证明 购买者往往是用户 失败到产品可以迅速的升级到影响数百万人 综合来看，根据开发者目标产品的特殊性，根据软件开发者的需求的不同，我们需要专门的开发者市场营销战略和策略。\n但是，开发人员不讨厌市场营销吗？不，开发者并不讨厌营销。像所有人一样，开发者不喜欢很差劲的市场营销。\n有时，当非开发者试图谈论一项针对开发者有好处的技术，或者尝试理解开发者常见的情况时，他们就会暴露，其实对开发者根本缺乏理解。而这并不是不可逾越的。任何人都可以学习，第一步是认知到开发者受众们都有其特定的需求。\n这一点很重要，因为开发者在研究产品时要寻找值得信赖的信息。如果你所传递的信息感觉\u0026quot;不对劲\u0026quot;，也许是因为它掩盖了一些关键的细节，那么就很难相信你所提供的产品。\n构建开发者市场营销策略 构建B2D的市场营销策略与构建任何营销策略都很相似。从目标开始，然后制定如何达到目标的方案。\n更详细地说，建立开发者商营销战略的阶段如下：\n广泛的了解公司的战略，并确定服务于该战略服务的北极星目标。 通过对现状的情景分析来评估你的起点。 对你的开发者受众进行细分，然后决定哪些是目标人群。 开展一些用户调研，来了解这些开发者。 开发针对性的信息，用于和这些开发者对话，表达他们的需求和你的解决方案。 创建战略方案，帮助你的目标开发者经历你所设计的用户漏斗旅程。 定义衡量方案成功的指标，并反馈到你的整体开发者营销目标。 在深入理解 DevRel 前，希望现在大家已经对开发者市场营销有了大概的理解，其实他们是紧密相关的。\n从 AARRR 指标的角度看 DevRel 的工作内容 Phil Leggetter 将 AARRR 【客户生命周期：成功获客的5个步骤】做了两头的扩展，变成了 AAARRRP， 在头尾分别增加了新的\u0026rsquo;A\u0026rsquo;和‘P’。下面用 AAARRRP 7步法来勾勒出 DevRel 可能会影响到的日常工作内容。\nAwareness ｜宣传 \u0026ndash; 对平台/技术/产品和它的功能的认识 Acquisition ｜获取 \u0026ndash; 注册/下载/安装 Activation ｜激活 \u0026ndash; 在自己开发的应用中积极使用该平台/技术/产品 Retention ｜保留 \u0026ndash; 持续使用和跟踪该平台/技术/产品，使用新的/附加的功能，并在新的应用程序中继续使用。 Revenue ｜收入 \u0026ndash; 付费使用该平台/技术/产品，或者从开源软件版本用户提升为付费版客户。 Referral ｜推荐 \u0026ndash; 告诉别人这个平台的情况，分享自己踩过的坑和技术。 Product/platform ｜产品/平台 \u0026ndash; 用户参与上游厂商的产品构建协作，并提供对平台/产品和技术的反馈。 有一系列广泛而多样的活动可以归入开发者关系DevRel的日常工作中。这些活动中的每一项都可能与实现AAARRRP目标的计划的一个或多个属性相关。\n编写文档（获取、激活、产品）。 参考资料 指南（How-to） 库开发（激活，产品） 快速上手的杨例应用程序（激活、产品） 博客文章（认知、获取、激活、保留） 教程 实用技巧 思路指导 网络研讨会 (认知、获取、激活、保留) 活动赞助（认知、获取）。 Meetup 赞助 会议展位 分享演讲（认知、获取） 聚会 会议 社区/社团 支持（激活、保留、产品） 用户支持系统，如：Zendesk StackOverflow 回答问题 公司和第三方论坛，如：Discuss等 售前技术讨论（收入、激活）。 呼叫 Calls 电子邮件 技术支持 专用论坛，如Google Groups或Discourse，如SmartThings社区（激活、保留）。 Alpha/Beta 产品试用计划（保留、产品） 办公时间 Office Hours（激活、保留）。 获取开发者的反馈（保留、产品） 帮助公司招聘（宣传）。 成功地开展这些活动的结果是：对某受众产生积极的影响，并与之建立关系，对公司的形象和公司本身的可信度将提升。这可以增加被推荐的可能性。但这些建立这些关系是需要时间的。\n‘商业收入’在上述活动中被明显的遗漏了。收入可能与开发者使用产品的水平有关。它还依赖于产品的定价结构。所以，还这不能笼统地纳入上述活动清单，但它肯定可以帮助你专注于可能提供更大投资回报的活动或目标中的开发人员。\n那么，根据最常见的工作头衔，这些不同的角色会参加什么活动？\n开发者布道师 Developer advocate ： 可以进行上述所有的活动，作为其开发者关系计划的一部分。特别是那些标有产品或保留的活动。 开发者代言人 Developer evangelist ： 可能会更多地关注引导新用户的活动，如文档、博客文章、活动赞助和分享演讲。请看那些有助于认识和获取的活动。 好了现在你可以使用‘DevRelOMeter’下面这个工具来测试一下，你自己的日常工作中都从事了以上那些工作，包括主动和被动的，看看你的工作性质是偏 Advocate 还是 Evangelist。\n点此进入测试页面\n下面再从Google专家的角度看看DevRel这件事。下面转载 Reto Meier 【Developer Advocate @ Google, software engineer, and author of “Professional Android” series from Wrox. All opinions are my own.】到两篇文章的部分内容：\nWhy Do We Pay These People Anyway? The Core Competencies of Developer Relations Reto Meier是从谷歌的Android的生态系统方向考虑和描述DevRel的，Google擅长通过构建平台的方式在全球的范围规模化推广自己原创产品和技术。这有其特殊性，在阅读下面内容的时候，请注意保持第三方的视角。在后需的文字中，读者需要通过上下文辨别‘开发者’，有时候是厂商原厂开发者，有时候是第三方开发者。\n我们为什么要付给这些人钱？ 在我看来，建立一个平台的决定是基于如何最好地服务你的用户。\n一个健康的生态系统会提升你的平台，通过填补你自己没有准备、不能或不愿意填补的空白，提供比你的产品更丰富的产品。你牺牲了市场上的独占性，但作为交换，你为自己和他人创造了更大的机会。你创造了一个更大的馅饼，以换取将其中切的较小的一片。\n如果一个平台能从与日俱增的用户采用中获益，那么它就需要用产品和服务来吸引这些用户；构建一个第三方开发者的生态系统就是这些产品和服务的发展方式。\n生态系统还为其他僵化的垂直结合到产品提供了灵活性。安卓和iOS都是应用开发者的平台，因此，对于每个设备的使用价值来说，只限于由谷歌或苹果为它们编写软件，倒不如开放给所有开发者能加有意义。安卓则更进一步，构建了一个对于所有设备制造商开放的生态系统。\n在不同的规模上，谷歌地图API创造了一个由数百万个应用程序和网站所组成的生态系统，每一个App都有一个嵌入的谷歌地图。这种开放第三方实施开发方式增加了谷歌地图的使用度，这远远超过了谷歌自己可以构建的规模。\n在实践中，创建开发者生态系统的基本目标是复杂而交织的。对平台拥有者来说，它为他们贡献的第一方App和服务到受众增加了，他们可以通过向开发者收取使用平台的费用，或在生态系统内再次分发来实现盈利。一个平台也可以是对冲对竞争对手的屏障，或刺激创新的尝试。考虑到创建一个平台和生态系统的成本，最有可能的目标是这些因素的组合。\n把一个产品变成一个平台并不总是合理的。这样做有可能使竞争对手从你自己的产品中吸纳用户，或者使你的产品的用户体验下降。\n一个健康的生态系统是可自我持续发展，且获利中立的，第三方开发者的成功会帮助你的用户并支持你的目标，反之亦然。\n开发者关系是什么？ Developer Relations’ role is to create a vibrant ecosystem of 3rd party developers, by being the interface between those developers and your platform’s product, engineering, and design teams. 中文翻译：开发者关系的作用是为第三方开发者创建一个充满活力生态系统，成为开发者和你们公司平台的产品经理、工程师和设计团队之间的接口。\n为了确保界面（接口）的高保真度，开发者关系部必须由工程师组成；这些工程师将同样能够在核心平台或第三方开发者的角色中工作。\n除了建立认知，开发者关系还负责创作，第三方开发者使用你的平台构建伟大产品所需的一切。从收集开发者提出的bug和功能请求、执行早期访问计划（beta和试用）、编写文档、创建样例程序、编写教程和技术视频、在会议上发言、以及在论坛和Stack Overflow上回答问题，等等的一切。\n他们还帮助应用平台的开发者的需求，通过与社区接触\u0026ndash;通过社交媒体在线，以及亲自参与到Meetup和会议中\u0026ndash;并在你的产品和工程团队中充当社区开发者的代言人。这确保了平台的开发与你的生态系统的需求的一致性。\n最终，开发者关系负责你的平台的开发者体验。这将帮助开发者打造更好的产品，从而创造更好的用户体验，从而能构建更成功的应用程序，以及更成功的生态系统\u0026ndash;这反过来又鼓励开发者打造更好的应用程序。\n“开发者关系的良性循环”\n在小公司（或新生产品），开发者关系任务往往是产品和工程团队的责任。最终你的平台会成熟到需要有工程师来全职专注于这些活动，并扩大他们的工作范围，包括更复杂的项目，如培训和社区参与，并通过开发更丰富的场景来支持外部互动，并包括多个平台和API。\n开发人员需要信任你的DevRel团队；要做到这一点，他们必须是正统的。\n开发者关系是你的开发者产品的公众形象\u0026ndash;第三方开发者的主要信息来源，以及与他们的互动。将这些互动转化为一种可信赖的关系至关重要。\n开发者关系团队的可信度将由厂商所产生的代码的质量，以及他们所提供的建议来衡量。最终，平台本身的质量将通过你的开发者关系团队制作的材料的质量、全面性和可用性进行评估。\n第三方开发人员必须能够信任你的DevRel团队，以及所提供的代码、技术答案、最佳实践和培训，将其作为开发者信息的最佳、最准确和最正规的来源。\n你的开发者关系团队也必须得到你的内部工程团队的信任，确信他们可以准确的表达第三方开发者的想法和体验，给予坦率的技术反馈，并面向开发者受众们诚实地代言平台。\n他们会因为是平台提供方原厂公司的代言人而轻易获得一些最初的信任，但为了产生真正的影响，他们还必须用独立于他们所代表的公司的方式，通过其展现的正统性建立与他人的信任。\n开发者关系并不是市场营销、业务发展BD或销售\u0026ndash;这些都不在工程团队。\n开发者市场：与开发者关系DevRel一起工作，帮助提高对市场内容的认知，提供市场研究，支持开发者活动，并创造统一的品牌形象。 业务发展-BD团队与商业决策者合作，他们需要的不仅仅是良好的开发者体验，以说服他们投入资源在你公司的平台上构建应用。BD通常与少数知名的合作伙伴合作，他们各自的成功可以加速你的平台在用户中的采用。一旦做出承诺，开发者关系部经常与相应的工程团队合作，以确保成功的合作。 销售团队通常用于开发那些直接为为平台消费的客户，例如云或广告平台。销售团队有时会与销售工程师配对，他们的技术同行，能够与客户的工程团队进行1对1的合作，以支持销售或基于商业关系。 注：以上是源于Google的组织者结构，一个成熟的大型商业组织，内部团队分工和配合都非常明确。\n一个繁荣的开发者生态系统需要一个由工程师组成的值得信赖的开发者关系团队，他们是第三方开发者和构建底层平台的工程和产品团队之间的接口。\n“开发者关系的持续的接口循环”\n图片翻译（从左到右，从上到下的顺序）：\n平台产品和工程 平台、API和SDK的更新 开发者的反馈 开发者关系 认知和激励 开发者资源 开发者反馈 开发者观点 第三方开发者 开发者关系是真相的官方来源，既适用于寻找文档、最佳实践和培训的第三方开发者，也适用于需要了解第三方开发者的想法和体验的内部工程团队，并获得有关其开发者产品的坦率技术反馈。\n在Reto Meier看来，以下是建立一个能够产生真正积极影响的开发者关系团队所需的最重要的价值和能力。\n他们需要是合格的工程师 ： 工程师们并不信任伪开发者，所以开发者关系团队需要由合格的开发者组成。即使如此，他们也不会轻易相信任何工程师\u0026ndash;我们DevRel需要证明自己。 他们需要成为优秀的沟通者 ： 你的开发者关系团队需要创造出能解决问题的材料，同时也要有启发性、趣味性和娱乐性。 他们需要有多样性 ： 开发者关系的目标是与尽可能多的开发者受众合作，创建一个充满合格工程师的多元化开发者关系团队，使其包容更多的受众。 他们不可能销售任何东西 ： 开发者关系部不能成为销售活动的拉拉队，或是伪装的销售人员。他们应该让马认识到水的存在，展示水对它的帮助，引导它去喝水，并让水尽可能地容易喝。 他们需要感受开发者的痛苦 ： 如果一个好的开发者关系团队不相信他们能够诚实地推广和宣传一个产品，他们就不会成为它的代言人。 他们需要去倾听和响应。 他们需要成为多产的人 ： 开发者关系是你对你的开发者受众说话的声音\u0026ndash;重要的是，他们经常发声，而且声音很大。 他们需要规模化地工作 ： 想想开发者关系团队需要面向全球开发者。 一个有效的开发者关系团队是由一群具有超强沟通能力的合格的工程师所组成的，他们并不会推销任何东西，而会与他们的受众心心相印\u0026ndash;他们不断倾听和回应。他们必须以一种能够规模化到全球千万级万开发者受众的方式来做这一切。\nWhat is Developer Relations? - from Why Do We Pay These People Anyway*? blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDevangelism at Twilio - from Twilio Heroes blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDeveloper Advocate versus Technical Evangelist; When names change the tone blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDeveloper Relations: A Five-Level Maturity Model blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhat is developer relations? blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhat is developer marketing? blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2021-10-05T15:44:13+08:00","image":"https://martinliu.cn/img/cos/2021-10-05-people-g95677a868_1920.jpg","permalink":"https://martinliu.cn/blog/developer-relation-devrel/","title":"开发者关系、Developer Relation、DevRel这是什么职业？"},{"content":"这是一次激动人心的记忆。没有 DevOps 社区志愿者的共同努力，我们肯定无法将峰会办的如此成功。\n我在拖了很长时间之后，我还是一定要总结一下有关这次盛会的点滴记忆和感受。我曾经多次去大连出差，于我而言大连不算是一个陌生的城市。可以由于海滨城市对人吸引力，人们对大连一如既往的美誉，本次峰会让我尤为期待。\n对于美好的事情而言，它们都必然要符合天时地利人和。可是在新冠疫情的影响下，大连这座港口城市的地利，也几乎改写成了劣势。大连峰会本来是计划在 2020年就要举办的，但是去年大连在几乎每次的疫情爆发时，都参与了陪跑的角色；因此小伙伴们准备了一半的大连峰会，不得不往后顺延到了 2021 年。大连峰会在 2020 年无奈跳票，也导致我们不得不将其改到了北京，幸亏 DevOps 社区北京的小伙伴们也是不负众望，20年的北京峰会也在望京庆丰包子疫情事件期间如期举办。今年又在幸运之神的眷顾下，让我们终于得以圆梦大连。\n于 2021 年 9 ⽉ 4 ⽇，中国 DevOps 社区峰会⼤连站，在位于市中心的⽇航酒店隆重举⾏。本次峰会报名⼈数约 500 ⼈，峰会当天近 450 ⼈签到，这也创下 DevOps 社区有史以来，签到⼈数最多的纪录【2020 年 12 月北京，2020 年 9 月成都，2019 年 10 月杭州】。我们有幸邀请到了⼤连软件⾏业协会秘书⻓秦健致开幕辞，邀请到了来自全国各地的讲师和志愿者来到这个浪漫的海滨城市，大家在DevOps社区里欢聚一堂，火热的分享和交流 了一天的DevOps ⽂化、理念、技术和实践。\n每年“DevOps社区峰会的举办权”是 DevOps 社区各个城市的组织者们，通过公开竞投标的流程而产生的。因此，DevOps 社区下一年两次峰会的举办城市和时间具有不确定性。在当年第二次峰会的复盘回顾会议中，我们设置了一个峰会申办和竞标环节。任何有意申办的社区组织者都可以为其所在城市投标和拉票，所有参会的社区志愿者们会公开用投票的方式选举出得票数前两名的申办城市，这两个投标成功的城市会从此开始下次峰会的筹备工作。\n峰会举办城市的组织者会成立峰会筹备小组，本次⼤连峰会的筹备⼩组中有来⾃全国的 56 名志愿者，其中⼤连本地的志愿者占了绝⼤多数。在整个峰会举办的过程中大家用定期周会的方式组织和安排各种峰会的工作事项。大连的 DevOps 社区呈现出了极佳的多样性，志愿者们的背景、职位、公司类型、年龄和性别都非常多元化。在当天大会现场，据目测观测，女性参会者的人数和比例也略高于其他城市的同类会议。\n下⾯是我对⼤连社区环境的概要分析：\n据不完全统计，⼤连的软件从业⼈员是 20 万⼈。【2021 年常住人口 745 万】 软件公司的业态主要为外包业务，给国内外企业提供项目开发、技术⽀持、运营和呼叫中⼼等服务，还有⼀些企业提供国内外电商平台的技术⽀撑服务，线上教育服务等等。通过云计算交付业务系统，全生命周期软件开发业务正在逐渐递增，交付⽔平受整个⾏业的带动，正逐年提⾼。 ⼤连软件企业所服务的客户既包括国内的⾏业⻰头企业【通信和金融等】，还有更多的是⼤量的⽇本企业，并且与很多优质的⽇本企业具有稳定而长期的业务关系。受疫情影响，⽇本等外资客户对⼤连软件企业的依赖性有提⾼的趋势。 ⼤连本地有⽐较丰富的社区存在，敏捷社区、云原⽣社区、项目管理社区都在⼤连举办过线下和线上的技术交流活动。DevOps 社区已经在⼤连持续发展了三年，我们和其他社区直接也有⼀定的⼈员重叠和合作关系。 ⼤连本地的软件从业者，基本上没有加班的习惯，在下班后或者周末里加班并不是常⻅的现象。⼯作之余他们会从事⾮常丰富的户外活动，跑步、滑雪和帆船等活动非常普遍。 历届 DevOps 社区峰会都是一个完整和复杂的项目。当社区组织者在全国社区核心运营团队的配合下，成功的完成了各项大会工作。包括峰会前的宣传⽂案、讲师招募、盲⻦票推广、讲师⽇程推广、赞助商⽂案、赞助商讲师海报推广等。这些工作过程和海报都会在 DevOps 社区全国的所有微信群发布，在其他合作社区的微信群⾥做了联合推荐。这些文案和过程都可以在社区的微信公众号（DevOpsMeetup）上查看到。本次大连峰会的总计注册人数是 492 人，由于大连峰会的举办日期距离这个城市上一次的疫情封闭时间并不遥远，因此这个注册人数确实来之不易，堪称相当完美；我们甚至做了转线上峰会的方案。而且实现了 80+%的签到率，更表现出了在一个解封不久之后的城市里，大家报复性的出门参与社区活动的现实。峰会后的宣传包括峰会总结⽂案（内含演讲者的 ppt 下载）。社区为每个演讲者都做了现场演讲稿的速记，随 PPT 图⽚⼀起发布⼀篇推广⽂案。还为演讲者制作了演讲 PPT 录屏视频（带同步⾳频），会后社区将所有视频都发布到了 DevOp 社区的 B 站【https://space.bilibili.com/370989874】和 YouTube 频道【https://www.youtube.com/channel/UC_gVuu1g05VREvNp2pwJbvw】。\n大连峰会⼀整天的活动内容包括上午半天的集中式主会场学习，下午设置了三个分会场和⼀个⼯作坊。分享演讲总数：21 个。\n为了给本次峰会的与会者提供更多层⾯的交流机会，我们在会前组织了夜跑活动。这又是一项DevOps社区的文化传统，首次峰会也跑是三年前的环杭州西湖夜跑，当时我们喊出了“随风奔跑，DevOps是方向”的口号，这句口号被沿用至今。这次大连峰会的夜跑活动的⼈数是有史以来最多的⼀次。在⼤会的前⼀天晚上参与者们分组完成了在星海湾⼤桥的夜跑活动，参与者最后合影留念，并领取了社区定制款夜跑服装。我完美的完成了首次星海湾大桥往返十公里的首刷，和其他社区的小伙伴们一起在桥上海上欣赏到了完美的大连市夜景。在跑步活动结束以后，又去参加了老同事安排的烧烤酒局，这真的是要感恩大连当地志愿者的完美会前准备工作，峰会前的当晚，社区居然没有任何人需要奋战在会场加班，我也首次实现了峰会前撸串的自由。\n峰会当天的我，应该说是非常兴奋的，虽然我们没有能通过大连在9月开海季节的天时地利拉取到大量到外地参会者，但当天早晨的签到数量也让我们非常激动。也有参展商遇到了所有资料和礼品在上午就很快的全部发放完毕的情况。会场之外我们也能感受到热闹非凡的交流氛围。我的主题分享在下午，晚上我们为所有志愿者和讲师准备了晚宴；席间我们还请到了一桌CxO贵客，大家畅聊DevOps实践相见恨晚。\n在峰会的第⼆天，DevOps 社区组织了志愿者的内部回顾会议和团建活动，在为期⼀天的社区交流活动中，参与者们详细的回顾了本次峰会的整个历程。大家组团游览了当地的部分经典名胜景点，包括：乘坐游艇出海东港投喂海鸥，游览棒槌岛景区和海滩，在渔老人码头的品海楼品尝大连当地特色的海鲜大餐，去老虎滩极地海洋公园畅游，最后大家回到市中心的星海广场观赏海景和星海大桥。在整天的社区团建活动中，我和所有人没完没了的聊天，内容大多还是围绕着大连本地的软件行业发展和现状。通过本次全国志愿者的团结活动，DevOps 社区的文化和凝聚⼒得到了巨大的提升，这进一步确信了全国社区一盘棋的发展方针。\n会后，我们还向所有与会者推送了峰会满意度调查问卷，收到近签到人数20%的有效分析数据。从调查数据中看到：非常满意（67.82%）和满意（26.44%）。对本次活动的净推荐值 NPS 高达 9.01 分，推荐率为 64.37%，这个数据同比预全行业而言，是一个非常不错的成绩。反馈者们也给我们本次峰会提供了很多有价值的改进建议，非常感谢所有参会者对社区活动的参与。本次峰会到场⼈数（450）在此刷新了记录，随着社区影响⼒的扩⼤，参与者满意度调查的⼈数和满意程度均呈现上涨趋势。与会者中，公司项目经理、团队负责⼈、管理者和⾼管的报名⽐例⾼于以往历届峰会。参会者在自于各个本地知名的⼤型软件服务商东软、埃森哲、IBM、日立、IBM、中软等咨询公司，其他⼤型外企和软企业占⽐较多。\n和其它同类峰会不同的是，我们在峰会满意度调查问卷中加入了 Top10 Speaker 的评选环节，选出了本次峰会的民选十佳讲师：\n科创时代下的创新与敏捷 | 王立杰–IDCF 中国DevOps社区 快乐中砥砺前行 | 姚冬 – 华为 数字化转型成就业务价值 | 黄隽（黄岛主）- 腾讯 云原生DevOps与Continuous Everything的实践 | 王宇博-亚马逊科技 用OpenTelemetry通明数字化系统的可观测性 | 刘征– Elastic 基于DevOps的开源治理 | 庄表伟 – 华为 AI智能分析和数字化质量管控应用实践 | 高蕊 – 中信银行 数字化转型趋势下NGINX KIC的高级应用技巧 | 罗剑锋 – F5/Nginx 容器应用交付控制持续集成持续部署最佳实践 | 宋志麒– F5/Nginx 从DevOps发展角度看应用架构的演进 | 张卫滨 – 大连金兰软件 以上就是我本次大连峰会完美体验的一些记录。我非常期待深圳峰会的举办，非常期待明年峰会城市的竞标结果。\n中国 DevOps 社区是⼀个公益、中⽴、开放的专业 DevOps 社区。我们会在社区的建设过程中，努⼒创新，着⼒打造⼀个充满温度的，对所有参与者友好的学习环境，同时实现多赢的局⾯，为全国软件开发行业的相关从业人员作出应有的贡献。社区的发展离不开所有赞助商和合作社区的支持，衷心感谢大连峰会的所有赞助商和合作方。\n基于本次峰会的整体感受，我也确实体会到了大连 DevOps 社区核心组织者黄隽（黄岛主）曾经在举办城市竞标拉票宣言中的那句话“大连是一个浪漫的海滨城市”；本文写在峰会结束了两个月以后，所有难忘瞬间还都历历在目。对我个人而言本次峰会意味着：会前与小伙伴们一起夜跑打卡星海大桥并观赏完美大连夜景；和老同事新朋友们品尝大连小海鲜和烧烤，喝到不醉不归；在峰会现场的主题分享，和会场的与会者们做各个层面的交流；在会后社区峰会团结活动中团体的享受和放松；这样的精彩还有很多很多，言之不尽。可是浪漫本身意味着：冒险、经历和激情；而这次黄岛主带领着大连本地的社区志愿者们，通过一次惊艳的社区峰会为我们完美的诠释了“何谓社区的浪漫❤️”，我们需要再次感谢所有大连本地的社区志愿者们，所有参会者和志愿者们都感受到了浓浓的社区情怀。这不禁给让社区种下了解锁中国所有其它著名网红城市的小愿望。\n","date":"2021-09-12T16:16:29+08:00","image":"https://martinliu.cn/img/cos/2021-11-25-IMG_7942.JPG","permalink":"https://martinliu.cn/blog/devops-summit-dalian-2021-best-ever/","title":"DevOps社区峰会2021大连后记"},{"content":"从开发者画像、技术流行趋势、工作就业和薪酬状态和社区等方面完整的描述了当今开发者的众生相。虽然调查人数有限，只有中国开发者人数的十分之一，但是也基本上反应了欧美发达国家的开发者现状。\n概述 我们在年度调查中提出的问题将帮助我们改善Stack Overflow社区和为他们服务的平台。\n例如，今年，我们观察到开发人员教育自己的方式发生了重大演变。对于年龄在18岁以下的不断增长的编码者来说，像视频和博客这样的在线资源比书本和学校加起来还要受欢迎，这一统计数字在我们其他年龄组中并不成立。总的来说，这个行业充满了新加入者，超过50%的人表示他们从事编码工作不到十年，超过35%的人从事这个行业不到五年。\n快速预览 1） 毫不奇怪，几乎60%的受访者是从网上资源学习如何编码的。年轻的受访者倾向于从在线课程、论坛和其他在线资源中学习。另一方面，年长的受访者则从学校和书本等更传统的媒介中学习。\n2）AWS保持其作为最广泛使用的云平台的领先地位，但谷歌云和微软Azure比去年有了很大的进步。值得注意的是，今年是我们将云平台从一般平台问题中分离出来的第一年。\n3）今年，React.js超过了jQuery，成为最常使用的Web框架。\n4）新来的Svelte占据了最受喜爱的框架的首位。React是最受欢迎的，有四分之一的开发者想要使用。\n5）Perl从去年的最高薪语言变成了今年的第五高薪。Clojure开发者的工资中位数最高，比第二名的F#多出1.4万。\n6）81%的专业开发人员是全职雇员，比2020年的83%有所下降。表示自己是独立承包商、自由职业者或自营职业者的专业开发人员比例从2020年的9.5%增加到2021年的11.2%\u0026ndash;表明潜在的工作不安全或转向更灵活的工作安排。\n我们面临的挑战和机遇是继续扩大和提高我们帮助所有开发人员的能力，并使他们在我们的社区感到受欢迎。\n继续阅读，了解更多关于塑造当今软件技艺和实践的态度、工具和环境的重大洞见。\n开发者画像 我们对全球开发者社区的认知。\n主要地区 Stack Overflow 是服务于国际的社区，我们的调查收到了来自地球上几乎所有国家的回复。\n地域 美国和印度继续提供最高数量的调查回应，其次是德国和UKI（英国和爱尔兰）。前十名的国家几乎占了所有答复者的60%。要查看前十名的国家，请参考方法论部分。当我们放大到美国（我们回应最多的国家）时，我们看到，拥有成熟的科技中心的州拥有最多的回应者。加州、纽约、华盛顿和德克萨斯。\n经验 高级管理人员和经理往往有最多年的编码经验，而从事数据科学和机器学习的人往往有最少的编码经验，平均来说甚至比学术研究人员还少。\n何时写下第一行代码？ 编码者从年轻时就开始了：有超过50%的受访者在11至17岁之间编写了他们人生的第一行代码。\n如何学习编码？ 毫不奇怪，几乎60%的受访者都是通过网上的资源，来学习如何编码的。年轻的受访者倾向于从在线课程、论坛和其他在线资源中学习。另一方面，年长的受访者则从学校和书本等更传统的媒介中学习。\n编码年限？ 50%的受访者从事编码工作的时间在十年以内。来自英国的受访者，平均而言，在我们前十个国家中，拥有的编码经验年数最多。\n专业编码年限？ 大多数受访者以专业开发人员的身份工作的年限为十年或更短，这意味着他们从未在没有Stack Overflow的世界里工作过【译者注：这句话说的 有点感觉StackOverflow的人自我感觉非常好：），难道说非专业人士们离开了 stack overflow 就不会搬砖了么，哈哈：） 】。\n按不同开发者类型划分的专业编码经验年数？ 担任更高级职务的开发人员拥有最多年的专业编码经验。同时，数据科学家和机器学习专家的经验最少，比学术研究人员的年限少。\n开发者角色 担任全栈开发人员角色的人是最普遍的。有趣的是，设计师的角色自去年以来有所下降，与系统管理员的位置互换。\n开发者类型? 全栈、后端、前端和桌面开发人员仍然占所有受访者的大多数。\n教育程度 开发人员是一个受过高等教育的群体，超过65%的人拥有学士学位或更高学历。但是，传统的大学教育并不代表一切，大约四分之一的受访者拥有低于学士学位的学历。\n受教育程度? 70%的受访者和80%的专业开发人员完成了某种形式的高等教育，学士学位是最常见的。\n人员统计 大约有三分之一的受访者回答了我们关于心理健康的问题。这是在2020年提供反馈的比例的两倍，这可能反映了人们对心理健康的重要性和正在进行的大流行病的影响的认识在不断提高。\n年龄？ 48%的专业开发者是25-34岁。65岁或以上的受访者中，几乎有一半不认为自己是专业开发者。\n性别？ 91%的受访者和92%的专业开发人员认为自己是男性。美国的性别少数群体（女性、非二进制、变性人或性别不符者）的比例最高。我们有相当多的工作要做，以确保我们的平台具有包容性，并确保我们的调查能代表各地的开发者。\n变性人？ 只有1%的受访者认为自己是变性人，其中一半是专业开发人员。\n性取向？ 11.5%的受访者认为自己是直男/异性恋以外的人，6.5%的人倾向于不认同任何取向。要确保开发商社区更具包容性，仍有许多工作要做。\n种族和族裔？ 我们继续看到有证据表明，有色人种在专业开发人员中的代表性不足。\n残疾状况？ 2,960名受访者有身体上的差异，这些受访者大多数是盲人或有视力障碍。\n心理健康？ 超过16,000名受访者回答了我们关于心理健康的问题，其中近10%的受访者表示他们有焦虑症。\n技术 每年，我们都会探索开发人员目前正在使用的工具和技术。而且，像往常一样，我们问他们什么技术是最喜欢的、最害怕的和最想要的，包括几个类别。\n今年，我们还引入了一个新的部分，即 \u0026ldquo;使用过的与想要使用的\u0026rdquo;，它向我们准确地展示了开发者在过去一年中使用了什么，以及他们希望在下一年中使用什么。如果你需要复习一下我们是如何构建 \u0026ldquo;喜爱\u0026rdquo;、\u0026ldquo;害怕 \u0026ldquo;和 \u0026ldquo;想要 \u0026ldquo;的，或者你想读一下 \u0026ldquo;用过 \u0026ldquo;与 \u0026ldquo;想要用 \u0026ldquo;背后的直觉，请查看我们这篇元文章。\n最流行的技术 Python超过了SQL，成为我们第三大最受欢迎的技术，而Node.JS则升至第六大最受欢迎的技术。\n编程、脚本和标记语言？ JavaScript连续九年完成了作为最常用的编程语言的任务。对于大多数开发者来说，编程就是网络编程。Python与SQL交换了位置，成为第三种最受欢迎的语言。\n数据库 所有受访者和专业开发者之间最常用的数据库是一致的。我们观察到的唯一区别是，专业开发者使用Microsoft SQL Server的可能性略高于MongoDB。\n在过去的一年中，你在哪些数据库环境中做了大量的开发工作，你想在下一年中在哪些环境中工作？\n(如果你既在数据库中工作，又想继续这样做，请在该行的两个框中都打勾)。\n云平台 AWS保持其作为最广泛使用的云平台的领先地位，但谷歌云和微软Azure比去年有了很大的进步。值得注意的是，今年是我们将云平台从一般平台问题中分离出来的第一年。\n在过去的一年里，你在哪些云平台上做了大量的开发工作，以及在未来一年里你想在哪些云平台上工作？\n(如果你既在该平台上工作过，又想继续这样做，请在该行的两个方框内打勾)。\nWeb 框架 今年，React.js超过了jQuery，成为最常用的网络框架。\n在过去的一年中，你在哪些网络框架和库中做了大量的开发工作，以及你想在下一年中从事哪些工作？ (如果你既使用过该框架，又想继续使用，请在该行的两个方框内打勾)。\n其他框架和库 在其他技术中，.NET框架得到了最多的喜爱，尽管有几个用于Python的数据科学库表现强劲。\n在过去的一年中，你在哪些其他框架和库中做了大量的开发工作，以及你想在下一年中从事哪些工作？ (如果你既在框架中工作过，又想继续这样做，请在该行的两个框中都打勾)。\n其他工具 超过90%的受访者使用Git，这表明它是作为一个开发者的基本工具。\n在过去的一年中，你在哪些工具中做了大量的开发工作，以及在未来一年中你想在哪些工具中工作？ (如果你既使用了该技术，又想继续使用，请在该行的两个框中都打勾)。\n集成开发环境 作为所有开发者的首选IDE，Visual Studio Code具有显著的领先优势。\n在过去的一年中，你经常使用哪些开发环境，以及你希望在未来一年中使用哪些开发环境？ 请勾选所有适用的。\n操作系统 Windows仍然是最受欢迎的操作系统，尽管在专业开发者中略显逊色。今年也是我们第一次将WSL作为一个选项。\n你工作的主要操作系统是什么？\n最爱、最敬畏、最想用的 Rust是最受喜爱的语言。Python和Typescript是开发者最想使用的语言，如果他们还没有这样做的话。\n编程、脚本和标记语言 在第六年中，Rust是最受喜爱的语言，而Python则是其第五年（去年的报告显示）最想要的语言。\n在过去一年中，你用哪些编程、脚本和标记语言做了大量的开发工作，以及你想在未来一年中用哪些语言工作？\n(如果你既用该语言工作，又想继续这样做，请在该行的两个方框内打勾)。\n数据库 Redis成为最受喜爱的数据库已经是第五年了。PostgreSQL以不到1%的比例勉强超过MongoDB成为最受欢迎的数据库。而IBM DB2则连续第二年成为最令人畏惧的数据库。\n在过去的一年中，你在哪些数据库环境中做了大量的开发工作，以及在未来一年中你想在哪些数据库中工作？ (如果你既在数据库中工作过，又想继续这样做，请在该行的两个框中都打勾)。\n云平台 AWS不仅是最受欢迎的云平台，也是最受欢迎的云平台，处于领先地位。\n在过去的一年中，你在哪些云平台上做了大量的开发工作，以及你想在未来一年中在哪些云平台上工作？ (如果你既在该平台工作过，又想继续工作，请在该行的两个方框内打勾)。\nWeb框架 新来的Svelte占据了最受喜爱的框架的首位。React是最受欢迎的，有四分之一的开发者想要。\n在过去的一年里，你在哪些网络框架和库中做了大量的开发工作，以及你想在未来的一年里从事哪些工作？ (如果你既使用了该框架，又想继续使用，请在该行的两个框中都打勾)。\n其他框架和库 虽然Tensorflow是最受欢迎的库，但Pytorch是一个更受欢迎的库。Stack Overflow作为.NET Core的用户，我们很高兴看到它排在首位。\n在过去的一年里，你还在哪些框架和库中做了大量的开发工作，以及你想在未来一年里在哪些框架和库中工作？ (如果你既使用了该框架，又想继续使用，请在该行的两个框中都打勾)。\n其他工具 早些时候，我们看到有93%的受访者使用Git。现在我们看到，其中85%的受访者希望继续使用Git工作。Git、Docker和Kubernetes都是最受喜爱和最想要的工具。\n在过去的一年里，你在哪些工具中做了大量的开发工作，在未来一年里你想在哪些工具中工作？ (如果你既从事过该技术，又想继续从事该技术，请在该行的两个方框内打勾)。\n协作工具 虽然Neovim是最受喜爱的编辑器，但它是第10个最受欢迎的编辑器。\n在过去的一年中，你经常使用哪些开发环境，你希望在未来一年中使用哪些环境？ 请勾选所有适用的。\n用过 vs. 想用 编程、脚本和标记语言 这里有很多东西需要解读，但以下是我们发现的一些最值得注意的趋势。有超过1万名Javascript开发者希望开始或继续使用Go或Rust开发。大多数想要使用Dart的开发者目前都在使用JavaScript。我们还看到，想用PHP工作的开发人员只有SQL开发人员。\n在过去一年中，你用哪些编程、脚本和标记语言做了大量的开发工作，以及你想在未来一年中用哪些语言工作？ (如果你既用该语言工作，又想继续这样做，请在该行的两个方框内打勾)。\n数据库 12,590名MySQL开发人员希望与PostgreSQL一起工作，而6,429名PostgreSQL开发人员希望与MySQL一起工作。\n在过去的一年中，你在哪些数据库环境中做了大量的开发工作，以及你在未来一年中想在哪些数据库环境中工作？ (如果你既在数据库中工作，又想继续这样做，请在该行的两个框中都打勾)。\n云平台 虽然AWS是最受喜爱的平台，但我们看到明年有大量的AWS开发者希望在谷歌云中开发。8,586名AWS开发者希望与谷歌云合作，而只有7,668名谷歌云开发者希望在AWS工作。目前使用Heroku或Digital Ocean的开发者更愿意开始使用或继续使用AWS，然后是谷歌云，最后是Azure。目前使用Azure的开发者中，很少有人想转到Heroku。\n在过去的一年里，你在哪些云平台上做了大量的开发工作，你想在未来一年里在哪些云平台上工作？ (如果你既在该平台上工作过，又想继续工作，请在该行的两个方框内打勾)。\nWeb框架 Django、Flask和Spring的开发者都满足于继续在各自的框架中工作。很少有开发者愿意在ASP.NET中工作。\n在过去的一年中，你在哪些网络框架和库中做了大量的开发工作，在未来的一年中你想在哪些框架中工作？ (如果你既在框架中工作过，又想继续这样做，请在该行的两个框中都打勾)。\n其他框架和库 想在Hadoop工作的开发者目前正在使用Pandas或Numpy。有和3328名Tensorflow开发者希望继续使用PyTorch，但只有2328名Pytorch开发者希望转到Tensorflow。\n在过去的一年中，你还在哪些框架和库中做了大量的开发工作，以及在未来一年中你想在哪些框架中工作？ (如果你既在框架中工作，又想继续这样做，请在该行的两个框中打勾)。\n其他工具 在过去的一年中，你在哪些工具上做了大量的开发工作，以及你想在下一年中从事哪些工作？ (如果你既从事了技术工作，又想继续从事技术工作，请在该行的两个方框内打勾)。\n协作工具 我们看到IPython/Jupyter用户希望在VS Code中工作。这可能是由于VS Code在他们的IDE中加入了Notebook API。\n在过去的一年中，你经常使用哪些开发环境，你希望在下一年中使用哪些环境？ 请勾选所有适用的。\n学习与问题解决 在遇到困难时你会怎么做？受访者在遇到困难时最常使用谷歌或访问Stack Overflow。\n当你遇到问题时，你会怎么做？ 选择所有适用的。\n薪酬最高的技术 Perl从去年的高薪语言变为今年的第五高薪。Clojure开发者的工资中位数最高，比第二名的F#多出1.4万。\n你目前的总薪酬是多少（年工资、奖金和福利，在税收和扣除前）？ 请在下面的方框中输入一个整数，不要有任何标点符号。如果你是按小时计酬的，请估计一下相当于周薪、月薪或年薪。如果您不愿意回答，请在方框内留空。\n工作 工作现状 我们看到更多的受访者从事兼职或在学校工作，而表示全职工作的受访者则减少。这可能反映了非典疫情的影响，所有行业的工人都在后退，并重新评估他们与全职和在职的关系。\n就业状况 81%的专业开发人员是全职雇员，比2020年的83%有所下降。表示自己是独立承包商、自由职业者或自营职业者的专业开发人员比例从2020年的9.5%增加到2021年的11.2%\u0026ndash;表明潜在的工作不安全或转向了更灵活的就业方式。\n以下哪项最能描述你目前的就业状况？\n按地域划分的就业状况 与去年相比，来自印度的全职就业者的百分比下降了15个百分点。相比之下，学生的数量增加了9个百分点。\n以下哪项最能说明您目前的就业状况？\n公司情况 公司规模 与去年相比，今年我们看到从事自由职业的受访者有所增加。\n你目前工作的公司或组织大约雇用了多少人？\n薪资 按开发者类型划分的薪资 从整体上看，工程经理、SRE、DevOps专家和数据工程师往往获得最高的薪水。当专注于美国时，我们看到在工资分布的底部有一些差异。在美国，与全球开发者人口相比，移动开发者和教育工作者的工资相对于其他职业来说往往更高。\n你目前的总报酬（年工资、奖金和福利，在税收和扣除前）是多少？ 请在下面的方框中输入一个整数，不要有任何标点符号。如果你是按小时计酬的，请估计一个相等的周薪、月薪或年薪。如果您不愿意回答，请在方框内留空。\n按开发者类型划分的薪资和体验 尽管工程经理、SRE、DevOps专家的薪酬最高，但我们看到他们平均也有超过10年的专业经验。数据科学家或机器学习专家的薪酬排在第8位，但平均来说，他们的经验最少。设计师的工资最低，尽管他们平均有超过十年的经验。\n您目前的总薪酬（年工资、奖金和福利，在税前和扣除前）是多少？ 请在下面的方框中输入一个整数，不要有任何标点符号。如果你是按小时计酬的，请估计一个相等的周薪、月薪或年薪。如果您不愿意回答，请在方框内留空。\n按语言划分的薪资和体验 与具有相同经验的其他语言相比，PHP开发人员的工资低得不成比例。\n你目前的总报酬是多少（年工资、奖金和福利，在税前和扣减前）？ 请在下面的方框中输入一个整数，不要有任何标点符号。如果你是按小时计酬的，请估计一个相等的周薪、月薪或年薪。如果您不愿意回答，请在方框内留空。\n社区 社区是我们所有工作的核心。\nStack Overflow网站的使用 访问过Stack Exchange网站 不到1%的受访者从未访问过Stack Overflow或Stack Exchange网络。\n您曾访问过以下哪些Stack Overflow网站？ 选择所有适用的。\n访问Stack Overflow 我们知道，开发人员经常访问Stack Overflow，今年早些时候，我们确认他们复制代码的次数也很多。从今年的调查中，我们还知道80%的受访者每周都会访问Stack Overflow，其中55%的人每天都访问。\n你认为你访问Stack Overflow的频率如何？\n有多少参与者拥有Stack Overflow账户？ 10位受访者中，有8位拥有Stack Overflow账户。 你有Stack Overflow账户吗？\n开发者多长时间参与一次Stack Overflow？ 在拥有Stack Overflow账户的人中，46%的人每月参与该网站的次数少于一次或每月。\n您认为您在Stack Overflow上参与问答的频率如何？ 我们所说的参与是指提出、回答、投票或评论问题。\n开发者认为自己是Stack Overflow社区的一员吗？ 只有44%的受访者认为自己 \u0026ldquo;有点 \u0026ldquo;或 \u0026ldquo;肯定 \u0026ldquo;是Stack Overflow社区的成员。在这些受访者中，我们看到性别少数群体认为自己是Stack Overflow社区成员的可能性较小。\n你认为自己是Stack Overflow社区的成员吗？\n现在的Stack Overflow社区 其他在线开发者社区的成员 大多数受访者不属于任何其他在线开发社区。 你是其他在线开发者社区的成员吗？\n其他公共或私有社区 近2.5万名受访者属于其他在线开发者社区。其中85%是对公众开放的，任何人都可以加入。这些其他社区大多属于Reddit、Github或Discord。\n请说出你所属的其他5个在线开发者社区，并说明它们是公开的（任何人都可以加入）还是私人的（需要邀请）。\n方法论 概况 本报告是基于对全球181个国家的83,439名软件开发人员的调查。这是我们根据在完整的、已完成的调查中所花费的时间而认为 \u0026ldquo;合格 \u0026ldquo;的答复数量；另外提交了约172份答复，但没有包括在分析中，因为答复者在调查中花费的时间不到3分钟。\n该调查从2021年5月25日到2021年6月15日进行。\n合格答卷者在调查上花费的时间中位数为10.21分钟。\n应答者主要是通过Stack Overflow拥有的渠道招募的。受访者的主要来源是现场消息、博客帖子、电子邮件列表、横幅广告和社交媒体帖子。由于应答者是通过这种方式招募的，Stack Overflow上的高参与度用户更有可能注意到在征集活动期间进行调查的提示。\n作为一项激励措施，完成调查的受访者如果完成了调查，可以选择获得一个 \u0026ldquo;年度调查 \u0026ldquo;的徽章。\n由于美国的运输/出口制裁，在克里米亚、古巴、伊朗、朝鲜和叙利亚的潜在受访者很遗憾地无法获得我们的调查，因为我们的第三方调查软件封锁了流量。虽然一些受访者使用VPN来绕过封锁，但在解释调查结果时，应牢记这一限制。\n许多问题只根据受访者以前的回答来显示。例如，关于工作和工作的问题只显示给那些说他们在工作的人。\n我们询问了受访者的工资情况。首先，我们问每个受访者通常使用什么货币。然后我们问受访者他们的工资是什么货币，以及该工资是每周、每月还是每年。\n像调查中的大多数问题一样，工资问题是可选的。有46,844名受访者向我们提供了工资数据。\n我们使用2021年6月16日的汇率将用户货币的薪金转换为美元，并假设为12个工作月和50个工作周，转换为年薪。\n美国国内和国外最顶尖的大约2%的工资被修剪掉，用门槛值代替。美国国内和国外的门槛值是不同的。\n为了确定今年的调查应包括哪些技术，我们查看了Stack Overflow上最受欢迎和增长最快的标签（就发布的问题而言）。我们将这些技术与去年包括的技术进行了比较，并查看了有多少人选择了每个选项。我们把所有这些综合起来，策划了一个要包括的技术集合。\n这些问题被组织成几个问题块，它们的顺序是随机的。此外，大多数问题的答案也是随机排列的。\n反馈意见 你对今年的调查长度有什么看法？ 大多数受访者认为今年的调查长度是合适的。\n完成这项调查有多容易或多难？ 不到百分之一的受访者认为今年的调查很困难。\n参与者 谁参与了这次调查 与往年类似，绝大部分受访者的职业是开发人员。\n以下哪个选项最能描述今天的你？这里的 \u0026ldquo;开发者 \u0026ldquo;是指 \u0026ldquo;写代码的人\u0026rdquo;。\n你住在哪里？ 以下国家是我们收到答复的前10个国家。\n","date":"2021-08-13T18:29:57+08:00","image":"https://martinliu.cn/img/cos/2021-08-13-134055.jpg","permalink":"https://martinliu.cn/blog/stackoverflow-survey-2021-cn/","title":"2021 年 Stackoverflow 开发者状态调查报告-中文版"},{"content":"这本以“DevOps”为主题的小说的故事情节很接地气，引人入胜的剧情会让人很难放手，所以我在周末只用了两个长 sprint（迭代）就读完了。\n掩卷后迟迟没有写读后感的原因，主要是没想好在不剧透的情况下，如何向大家介绍这本书。下面先和大家聊聊在 DevOps 社区中耳闻目睹到的那些事。\n谈到 DevOps 这个话题，我们就不得不纵观当下中国 IT 行业的全景，一边是国家积极倡导的信息化创新和产业数字化转型；一边是国产基础实施类开源软件创业公司的风生水起。随着移动互联网和社交媒体的发展达到了顶峰， 5G 、IoT 、芯片和边缘计算等新技术也迎面而来。对于所有 IT 从业人员，特别是软件开发人员而言；我们可能正处在一个有史以来最利好的时代；同时整个 IT 行业正深陷于严重内卷的残酷现实，也在提醒着我们，这同时也是一个最坏的时代。\n《独角兽项目》的精彩故事情节，使我不禁要停下来，稍微总结一下我在最近 4 年多的时间里，见闻的这些鲜活案例和事实。以下所描述的内容，仅代表我的个人观点，还望各位看官指正和海涵。\n国内 DevOps 水平最高的团队应该在这些一线互联网企业的优秀产品团队；请大家注意我的描述，软件研发的工程工艺水平在这些大厂的不同产品团队间也可以是良莠不一的；研发效能卓越者已经达到了 DORA 2019 状态报告中精英级别的能力组合，即业务需求每日持续发布给用户，软件代码变更分钟级上线投产，上线成功率（失败率）几乎不影响客户体验，以及能分钟级别恢复业务事故等。而它们为什么能这样又快、又好、又安全！由于他们所满足的是中国亿级人口日常的网购、社交和娱乐体验，这些业务能创造巨大的社会和经济价值，每个风口浪尖上的产品也同时承受着巨大市场竞争压力和考验，业务危机使然；而危机感的缺乏的非明星产品团队必然也不需要那么高深的 DevOps 的技艺。这些一线大厂强大的技术品牌输出也事实上几乎统治了现在所有顶级技术大会；在最近刚刚结束的 QCon 北京峰会上，我竟然很难在讲师清单中找到非互联网行业公司的讲师。DeOps 做的好的企业必然是能做到无招胜有招。个别头部互联网企业正在向外输出他们自研的 DevOps 产品和服务平台。\n让我们将视线转移到国内传统行业的诸多“马”公司（相对于市值动辄上亿的独角兽企业），在金融服务、通讯和制造行业中，这几年 DevOps 也有了长足的发展。由于国家的各种信息安全、行业合规的要求颇高，我们以为他们或许应该是最不可能实施 DevOps 的企业。而在我最近参与的一次 DevOps 社区线下 Meetup 上，招行的案例分享确实令我折服。在我的其它大量的社区观察中，那些颇有造诣的企业不仅限于 DevOps 流水线和敏捷业务开发方面的卓越技艺；他们还在组织级别的规模化转型，内部精益教练推广，系统 SRE 建设，甚至混沌工程等方面都各有千秋；从这些角度看，他们的成长速度已经超越了，他们所刷的某些评奖定级。我对所有传统企业在 DevOps 社区的输出尤其赞赏，由于他们之间的相互学习交流和传播，可能对整个 IT 行业更加重要，毕竟实体经济才是中国发展的根本所在。希望他们能将各自的实践经验持续的输出到社区，一起来推动整个行业的变迁。其实《独角兽项目》小说中的场景设定，可能更符合他们的实际情况。传统行业企业往往坐拥得天独厚的资源优势，具有数十年积累的大规模信息科技研发组织和基础设施。 他们更多的出现在全球财富百强清单中是毫无悬念的，但是有时候所拥有的优势和劣势是对等的。如何破局企业组织部门间的制约和博弈，怎样意识到和消除深重的技术债务，怎么能持续优化 IT 服务的价值交付链条？这些都是更加复杂的系统性工程，自我颠覆和业务创新可能是他们的终极挑战和危机。希望大家能借鉴《独角兽项目》小说中的剧情，做到转危为安，实现企业的跃迁。\n《独角兽项目》一书的任何情节并没有配图，但是上面这幅图中的寓意相信各位看官们都能够秒懂。其实桥和火车是一体的，火车像是企业持续发展的业务。如果我们将这个场景作为 IT 行业软件开发和运维的隐喻，我们可能甚至都不好意思说“我们是高科技从业者”。还有很多企业的开发和运维团队尚处于“刀耕火种”或“手工作坊”的阶段，版本管理混乱、代码分支合并发布困难、重复繁琐的软件测试工作严重依赖人工、在物理隔离的多套环境中不得不纯手工配置和部署应用系统、监控告警的分类定级基本完全依赖经验，这些尚待 DevOps 解决的反模式不胜枚举。\n最后，我觉得虽然《独角兽项目》中的情节是虚构的，但是它们确实是反映出了软件开发过程中众多反模式的一个子集而已；如果在你阅读这本书的过程中，觉得情节离奇而夸张，那么我要恭喜你，可能你要再等一下，才能到这个阶段，或者你已经超越了这些苦难了（我表示否定）；如果你觉得稀松平常的话，那么我认为，你要么已经躺平接受了，要么就是掉进了更大的坑。反模式的后果包括：996/007的加班、职业透支、各种就发生在工位上的悲剧，这些是人类所不可接受的；反模式在《独角兽项目》中将那些斗志犹存，越战越勇，不甘心失败的人团建和聚集在了一起。希望现实工作生活中的大家都可以参考小说中的相关情节，哪里有压迫，哪里就有反抗，就有不可熄灭的追求理想的动力。\n《独角兽项目》向我们展示了软件开发团队迎难而上，在抗击行业困苦的过程中，需要坚定追求的五大理想。它们就像在社会主义发展的各个阶段中，社会所追求的主旋律都各不相同，但是社会整体上是螺旋上升的一样。这五大理想依次是：\n局部和简单性 专注、流动和快乐 改进日常工作 心理安全 以客户为中心 注：书中的译文是“五大理念”，在本文中我稍微升华了一下；本书的翻译质量上乘。\n虽然本书是献给 Developer 的一本书，但是在 DevOps 的视角中，测试、运维和安全，以及各种角色都应该是 Developer，大家的工作成果都应该是可以被计算机理解和执行的代码；在人机的交互模型中，切莫让人类变成重复执行任务的工具人（各种人肉某某某），人类应该做更高级的智力劳动。希望此书能给各行各业的开发者们带来一些启发和勇气。\n本书的作者Jene Kim 是 DevOps 领域中的大咖，本书是继《凤凰项目》（Phoenix Project）和《DevOps 实践指南》（DevOps Handbook）之后的一本书，也是他的巅峰之作。我是 DevOps Handbook 的译者之一，《凤凰项目》孕育了《DevOps 实践指南》一书，而《独角兽项目》的故事情节不但完美的延续了《凤凰项目》，而且它们向我们用戏剧化的方式，完整的展示了企业从开发到运维的全景，展示从一个技术团队从技术债的谷底背水一战、反败为胜的全过程。如果你对以上三本书都感兴趣的话，建议可以一次性购入，推荐的阅读顺序如下：\n《凤凰项目》 《独角兽项目》 《DevOps 实践指南》 这套书可以是团队读书会的必读书目，也是你劝说领导支持你做 DevOps 的铺垫。相信读过以上三本书的领导，可以与 DevOps 团队有更多的共同语言。\n在中国 DevOps 社区中（微信号 DevOpsMeetup），应该说我们汇聚了来自各个公司的 ，属于像是《独角兽项目》中所描述的反抗军的朋友们。社区中的很多朋友也曾经是孤独无助的 DevOps 践行者，通过一己之力很难推动团队瓶颈的解决。大家在DevOps社区的交流互动中能够收获到很多的顿悟时刻，得到大量成功经验的启迪和感召。DevOps 社区的 Meetup 活动正在定期的在各个城市举办，总有一场属于你的社区 Meetup 活动即将发生。\n希望《独角兽项目》是你补习 DevOps 理念的最后一本书，你必须将其付诸于实际行动。DevOps最后要落实并消失在每个开发者日常的工作中，这是一次没有终点的旅程，应该是一局没有结局的游戏。多说无益，让我们在 DevOps 社区里见。\n","date":"2021-06-23T08:14:40+08:00","image":"https://martinliu.cn/img/2021/06/guild-1573610501.jpg","permalink":"https://martinliu.cn/blog/the-unicorn-project-review-devops-in-china/","title":"《独角兽项目》读后感及中国 DevOps 社区之观察"},{"content":"Terraform 1.0\u0026ndash;现在GA了\u0026ndash;标志着你的自动化工作流程的互操作性、易于升级和维护方面的一个重要里程碑。\nTerraform 拥有数以亿计的下载量、成千上万的贡献和令人难以置信的社区，是最广泛采用的基础设施即代码工具。达到 1.0 是一个重要的里程碑。\n本文来自：https://www.hashicorp.com/blog/announcing-hashicorp-terraform-1-0-general-availability\n6 月 8 日，在 HashiConf 欧洲会议上，我们很高兴地宣布HashiCorp Terraform 1.0全面上市，这是您自动化工作流程的互操作性、易于升级和维护的一个重要里程碑。Terraform 1.0立即可供下载，也可在HashiCorp Terraform Cloud 中使用。HashiCorp Terraform已经被大小公司的个人和团队广泛使用，成为多云配置和自动化的标准。这篇文章介绍了新的内容，以及1.0的命名对Terraform用户的意义。\n更好的 Terraform State 互操作性 Terraform 在互操作性方面取得了巨大的进步。Terraform state 现在可以在0.14.x、0.15.x和1.0.x版本之间交叉兼容。远程状态数据源的兼容性现在已经回传，支持0.12.30、0.13.6、0.14.0、0.15.0和1.0.x版本。\n改进升级体验 从 Terraform 0.15 开始，一直到1.x的生命周期，你现在可以升级到新的 Terraform 版本，你的工作流程将继续运行，就像之前那些版本一样。使用Terraform 1.x不需要升级工具、重构或其他改变。\n延长维护期 所有Terraform 1.x版本将有至少18个月的维护期。这意味着HashiCorp将继续调查1.0版本的错误和发布功能，至少在这段时间内。这些修复可能会在后续的1.x版本中发布，而不一定是增量的1.0.x版本。\nTerraform插件SDK v1的寿命结束 Terraform插件SDK是一个框架，可以让开发者创建和维护Terraform供应商。HashiCorp将在2021年7月31日结束对插件SDK第一版的支持。Terraform CLI和Terraform Cloud的用户不受此影响，不需要采取任何行动。我们鼓励受到影响的 Terraform Provider 的维护者使用我们的升级指南，转移到Terraform Plugin SDK的第二版本。按照我们的教程，开发您的Provider。其他信息可以在Terraform提供者社区讨论论坛中找到。Terraform插件SDK v1版的生命终结时间表。\n1.0版本对Terraform意味着什么？ 1.0版本是一个巨大的成就，对于Terraform来说更是如此。对于许多为该项目做出贡献的人或参与超过100,000,000次下载的人来说，这已经是一个漫长的过程。但在HashiCorp，我们以一致的、透明的方式对待产品版本和1.0的指定，基于四个关键要求，正如2017年4月关于Packer 1.0发布的博文中所记录的那样。\n达到1.0的第一个要求是产品已经被广泛部署，在生产中经过多年的硬化。Terraform自2014年首次发布以来，一直在配置和管理基础设施，并得到了从零售业（星巴克）到证券交易所（TMX集团、德意志交易所集团）到自动驾驶汽车（Cruise）等广泛行业的信任。\n第二个要求是，主要的用例要被理解并得到良好的支持。Mitchell Hashimoto和Armon Dadgar早在2014年创建Terraform时，就已经想到了几个用例。从那时起，超过1500名贡献者开启了超过11000个 PR（GitHub 的贡献方式），这些请求增加了新的功能，并支持新的用例，这是我们从未想象过的。\n第三个要求规定了一个明确的用户体验。Terraform用户从不同的角度来处理他们的工作流程，因此我们专注于创建直观的用户界面；清晰的文档；全面的、自定进度的学习平台；以及互动的、由教师指导的研讨会。\n第四个要求是确保产品的技术架构是成熟和稳定的。\nTerraform 1.0以更大的互操作性、更容易的升级以及重要的维护期来巩固你的自动化工作流程和Terraform功能集的稳定性的形式满足了所有四个要求。\n","date":"2021-06-15T09:15:22+08:00","image":"https://martinliu.cn/img/2021/06/0gLZ2oH.png","permalink":"https://martinliu.cn/blog/hashicorp-terraform-1-0-general-availability-cn/","title":"Hashicorp 的 Terraform 1.0 正式 GA 了！"},{"content":"本文是翻译整理的 Gartner 的行业调查报告，原文在：https://www.gartner.com/doc/reprints?id=1-25RAD0H3\u0026ct=210407\u0026st=sb\n概述 主要发现 AIOps平台在企业中的应用正在迅速增长。I\u0026amp;O（基础设施和运维）领导人正在为COVID-19后的环境进行规划，主要参考当前的实际成果，而非理想的目标。 AIOps平台的产品分为两类：领域无关的和以领域为中心的解决方案。然而，在处理高度多元化数据集的灵活性方面的需求正在逐渐提升，这正在对市场产生重大影响，并使AIOps平台向领域无关的功能性方向转变。 企业已经开始采用AIOps平台来对比和替换一些类别的传统监控工具。例如，监控 IaaS 和可观察性正在完全在 AIOps 平台内完成，特别是当企业的整个IT服务部署都在云里时。 企业正在增加将 AIOps 用于IT运维管理（ITOM）的各方面，并使其在DevOps 和 SRE 的实践中的使用应用场景更加成熟。 建议 专注于基础设施、运维和云管理的 I\u0026amp;O 领导人应该。\n通过采用渐进式方法，从取代基于规则的事件分析开始，然后再扩展到以领域为中心的工作流程中，如应用程序和网络的诊断，优先考虑实际成果，而不是理想中的目标。 通过允许根据使用场景来选择的方法，在以领域为中心的AIOps或与领域无关的AIOps之间作出选择。在使用以领域为中心的AIOps功能点时，要将其内置于监控工具中，服务于一次性的特定用例，同时在路线图上规划部署能兼顾多种用例的，领域无关的独立解决方案。 通过选择一个支持与ITSM工具双向整合的AIOps平台，实现任务自动化、知识管理和变更分析。小心那些只提供基本搜索和显示功能的工具。 通过AIOps平台所支持的以上这三个方面，实现对整个ITOM的持续洞察：观测、干预和行动（observe, engage and act）。 市场定义 本报告于2021年4月19日修订。你正在查看的文件是更正后的版本。欲了解更多信息，请参见gartner.com上的 更正页面。\nAIOps 平台通过结合数据存储和分析功能，满足I\u0026amp;O领导者对运维支持的需求，根据IT部门为应对数字化转型而产生的数据，向有关团队提供相关的洞见。该能力是数据流水线的一部分，包括数据的摄人和存储，然后是数据整形和分析，然后转向可视化层。分析能力包括统计技术和人工智能技术的混合，但考虑到用户的成熟度，与人工智能层的互动界面对I\u0026amp;O来说是最小化、甚至是不存在的。\n市场描述 AIOps 平台广泛的强化了一些列 IT 实践，包括 I\u0026amp;O（基础架构/运维）、DevOps、SRE 和服务管理。然而，更集中的成果是在 I\u0026amp;O 领域，包括异常检测、诊断信息、事件关联和根本原因分析（RCA），以改善监控、服务管理和自动化任务。\nAIOps平台的核心功能包括：\n摄入\nAIOps 平台可以从多个领域、信息提供源进行数据摄取、索引和规范化事件或监控数据，包括基础设施、网络、应用程序、云或现有监控工具（用于跨领域分析）（见注2）。该平台必须至少在两个方面，使用机器学习的使能（enable）数据分析，包括。\n摄入点的实时分析（流分析）。 存储数据的历史分析 拓扑\nAIOps 平台发现并建立IT资产的统一拓扑结构，包括应用程序，和其它相关领域。拓扑结构可以表达物理上的连接性、逻辑上的依赖性或捕捉到IT资产和服务之间其他维度的关系。\n关联\nAIOps 平台对多个监控领域或来源的事件进行关联和压缩（抑制），减少不必要的人工干预。关联功能结合了时间和拓扑结构来分组相关的事件。\n识别\nAIOps 平台处理事件和监控数据，从而检测或预测重要的事件或事故。该平台不断地从操作员的输入和优化的机制中学习和强化重要事件的独特模式。\n修复\nAIOps 平台通过操作员的调校或观察，不断的学习和改进每个重要事件和操作响应之间的关联性。AIOps 平台可能会提供一个建议，自动化响应或触发外部自动化系统。\nAIOps 不仅仅是一个数据存储和检索系统。此外，该平台不限于趋势分析、预测和查询大量数据集的能力。\nAIOps 的目标是通过策划和提高摄入数据的质量，以便 I\u0026amp;O 的领导者能够将多种用例推向相关的合适实践或角色。例如，模式发现可以有助于预测新出现的行为，IT 实体之间的关系，以及（IT工件、用户和代理）的基准行为，从而识别出异常情况，并给业务所有者提供相关背景。分析也促成了自动化的洞察力，简化了根本原因的定位，并使能了运用自动化解决所已发现问题的行动（见图1）。\n图1: AIOps 跨多 IT 运维监控(ITOM)领域使能持续生成洞见 图片翻译如下：\nReal-time and historical data : 实时和历史数据\nEvents Metrics, Traces, Topology : 事件 指标，追踪，拓扑\nIncidents, dependencies and changes : 事故、依赖和变更\nObserve （monitoring）：观测（监控）\nHistorical analysis 历史分析 Anomaly Detection 异常检测 Performance analysis 性能分析 Correlation and contextualization 关联和上下文化 Engage （ITSM）：干预（ITSM）\nTask Automation 任务自动化 Change Risk analysis 变更风险分析 Performance Analysis 性能分析 Knowledge Management 知识管理 Act （automation） ： 行动 （自动化）\nScripts 脚本 Runbooks 运行手册 ARA 市场方向 市场转向领域无关的 AIOps 领域无关的平台正在作为一个独立的市场出现，与以领域为中心的AIOps平台不同（见注3）。这是因为在三到五年渐进式的路线图中，可以灵活地摄取日益多样化的数据集。这种路线图上的用例不仅仅关注异常状态识别，还包括行为分析、客户参与和识别潜在机会。未来的市场指南报告将专注于领域无关的 AIOps。\n随着企业在应用 AIOps 方面的成熟，他们需要一个跨越 I\u0026amp;O、DevOps、SRE的统一的领域无关平台，在某些情况下还需要包括安全实践。\nGartner 看到 I\u0026amp;O 领导人正在与高级管理层讨论相关的KPI（关键绩效指标）和仪表盘。在所有这些情况下，以领域为中心的工具则出现了明显的差异，它更聚焦在异常检测和减少错误告警方面。AIOps 已经成为许多以领域为中心的市场中的一个决定性特性。\nAIOps：以领域为中心的工具中的必备功能 以领域为中心的 AIOps 已经扩展到多个 ITOM 细分市场，包括可观测性和自动化工具市场。它是一些市场的决定性特性。比如说。\nAIOps 能力是 APM 工具的决定性特性之一（见[应用性能监控魔力象限]报告）。 在 ITIM 和 NPMD 市场，分析被认为是一种核心能力，但供应商已经开始提供AIOps能力，以支持各种产出，如提升洞察和诊断力。 许多ITSM供应商通过投资自开发平台或与 AIOps 平台供应商合作，将AIOps能力纳入其中（见[IT服务管理工具魔力象限]）。AITSM 的概念通过在 ITSM 工具上应用人工智能的上下文、建议、行动和界面，为 I\u0026amp;O 人员带来了有效性、效率和降低错误（见[利用 AITSM的4个领域来发展ITSM工具和实践]）。 以领域为中心的 AIOps 方法对那些数据种类有限（即只有少数点状解决方案）并优先考虑少数重点用例的组织有效。这类组织对同时查看多个孤岛数据的需求或能力都比较有限。随着组织内用例的增加，他们可能会转向领域无关的工具。\n仅仅关注以领域为中心的方法的供应商将在那些还没有准备好利用领域诊断工具的优势的客户身上获得成功。然而，随着越来越多的企业希望转向领域无关的选项，只关注以领域为中心的技术的供应商将发现自己被排除在市场的讨论之外。\n持续的关注和增长 AIOps 继续的增长和对整个 ITOM 市场的影响，估计2020年的市场规模在9亿至15亿美元之间，2020年至2025年的复合年增长率约为15%（见[市场机会图：全球IT运维管理]）。采用和方向正受到两个独立但最终相关的领域的严重影响。\n数字化业务转型 从被动应对问题过渡到主动解决问题 数字化业务转型正在推动着 AIOps 市场的发展，因为更多的业务运维被数字化，分析不断增长的数据量变得更加关键和困难。随着数据量达到或超过每分钟千兆字节，跨越十几个不同的领域，人类已经不可能手动分析数据了。\n随着企业继续进行数字化转型，他们不再奢望在问题发生后才作出响应。相反，他们必须变得积极主动，在影响到用户的体验之前就解决掉潜在的问题。\nAIOps 市场继续朝着更广泛和更好的解决方案发展，在这两个目标下，依然同时仍然保持着以领域为中心的方法和领域无关的方法之间的区分（见注3）。未来的状态是一个统一的 AIOps 平台试图取代问题日益增多的领域为中心的工具。Gartner 预计会看到越来越多的专业层，获奖在嵌入设备中包含分析和训练有素的模型。最终，分析技术将被嵌入到构成以领域为中心的AIOps的不同监控技术中，以至于以领域为中心的AIOps被包含在多种监控市场的定义中。\n此外，一些供应商正在尝试将领域无关和以领域为中心的方式混合起来，在其孤立的工具之上提供领域诊断的AIOps功能。在日益动态的IT架构中，由于必须更新相关规则的速度，基于规则的事件关联已经让位于基于人工智能的关联（见[使用AIOps的数据驱动方法来提高IT运维监控工具的洞察力]）。\n低准入门槛 开源技术的商品化降低了该领域许多供应商的准入门槛，为数据采集、存储和可视化工具提供了许多选择。这些与领域无关的采集、存储和展示技术相对容易部署和整合，引发了许多以领域为中心的供应商，包括系统集成商和管理服务提供商的产品开发或改进。用于跨指标、追踪和日志领域的诊断数据采集的开源工具，包括 Prometheus、Elastic Beats、Jaeger 和 Fluentd。对于数据可视化，Gartner 遇到了许多利用 Grafana 实现的方案，无论数据存储在哪里。\n尽管 AIOps 尚未成熟，但只要使用案例合适，AIOps 就会被认为是企业内部的一个有价值的工具，并能长期保持持有的状态（见图2）。\n图 2: 组织计划持续使用 CMP 和 AIOps\n市场分析 尽管 AIOp s技术已经存在多年，但成功的部署还需要时间和努力，包括终端用户的结构化路线图。实施通常会遇到一些问题，包括数据摄取、提供上下文相关的分析和较长的价值实现时间。许多 AIOps 平台工具部署的价值实现时间是以月或年计算的，这导致了对该细分市场的不满和幻灭。然而，企业应该毫不怀疑。\nIT运维的未来不可能不包括 AIOps。这是由于数据量和变化速度的快速增长（以应用交付速度和事件驱动的商业模式为例），不能依靠人类从数据中挖掘出洞见。\n人类根本不可能对其IT系统每秒产生的成千上万的事件进行理解。\n为了更清楚地了解市场是如何发展的，以及供应商彼此之间的定位，请考虑以下属性。\n数据摄取和处理 机器学习（ML）分析 补救措施 数据摄入和处理 AIOps 平台必须能够摄取静态（历史）数据和动态（实时、流）数据。这些平台可以摄取、索引和存储日志、事件数据、指标、追踪以及图表和文档数据（见注释2）。\n这些用于IT运维的工具必须直接在摄取点上做实时数据分析，而不需要在分析前将数据保存到数据库。它们还必须提供跨越多个实时和历史数据流的关联分析。\n机器学习分析 AIOps 平台使用以下类型的分析方法。\n统计学、概率分析 单变量和多变量分析的结合，包括使用相关、聚类、分类和跨IT实体捕获的指标进行推断。 自动模式发现和预测 发现隐含描述历史和/或流数据中的相关性的模式、集群或群体。然后，这些模式可用于预测具有不同程度概率的事件。 异常检测 使用前述组件发现的模式来确定正常行为，然后辨别与正常行为的偏差，包括单变量和多变量。超越了单纯的异常值检测，它们必须与业务影响和其他并发流程（如发布管理）相关联，才能充分发挥作用，而不是产生出更多的告警噪音（见[使用AI技术增强DevOps的决策能力]）。 可能原因判定 对通过自动模式发现和摄取图数据建立的关联网络进行修剪，以确定连接因果关系的因果关系链。 拓扑分析 AIOps平台可以使用应用程序、网络、基础设施或其他拓扑结构来提供上下文分析。从拓扑结构内的数据中得出的模式将建立相关性，并说明隐藏的依赖关系。将拓扑结构作为因果关系判断的一部分，可以大大增加其准确性和有效性。 规范性建议 建议解决一个问题的方案。这些建议可能是基于对重复出现的问题的历史解决方案（部落知识）的数据库，或通过众包确定。 补救措施 随着技术的成熟，用户将能够利用该平台的建议，实现行动阶段（见注4）。这方面的步骤如图3所示。\n图3: AI 辅助自动化的未来 —问题的分类和补救\n图片翻译：\n1 开始于已知的\n在一个部落知识库中记录成功的解决方案 将问题进行分类 2 当前和历史的对照\n在数据库将一类问题与一组已知解决方案进行匹配 众包 3 建议\n建议一组可能的解决方案 4 执行和评估\n运行解决方案（提供）（ARA/运行手册） 跟踪解决方案效果 对效果投票 一个被称为 \u0026ldquo;自我驱动的ITOM \u0026ldquo;的自动化、闭环的流程是非常令人向往的，但这仍然是一种愿望。在商业工具中，除了那些简单的自动 \u0026ldquo;弹出服务器 \u0026ldquo;或 “创建工单 \u0026ldquo;类型的脚本外，很少看到规范性的解决方案。有可能从规范性工具中获得自动行动的候选者是那些低风险的。这些是那些如果失败或导致意外的副作用，造成的损失相对较小。根据环境的不同，手工的预定操作，如补丁更新，以及执行工作负载优化的行动，如启动一个额外的虚拟机（VM）或容器，可能是成功的。\n价值实现时间 Gartner 客户的一个共同抱怨是，部署、配置和从AIOps解决方案中获取价值所需的时间可能长达六个月，在极端情况下，可能长达两年。AIOps是一项新兴技术，这意味着该领域的最佳实践仍在不断发展。但是，当潜在的回报在时间跨度上如此遥远时，企业不愿意投资于一个产品。\n为了应对这种情况，供应商正在采取举措，加快部署速度。这些措施包括。\n转向基于SaaS的部署 改进通用接口的开箱即用的集成方式 基于现场测试的最佳实践，在系统中建立可重复的工作流 减少系统产生的误报数量 在为AIOps的投资回报建立商业案例时，I\u0026amp;O 领导人必须与供应商讨论其实施的预期价值时间。在许多情况下，预计会有一个有限的概念验证，以证明集成在现实环境中如何运作。\nDevOps 中的 AIOps 作为IT运维工具与DevOps流水线整合的 \u0026ldquo;左移 \u0026ldquo;大趋势的一部分，早期采用者正在开发流水线的早期尝试AIOps。结合越来越多的自动化使用，开发人员正在使用人工智能来更快、更安全地交付软件，在生产中更容易管理。图4显示了AIOps 存在于 DevOps 流水线中的例子。 图4：在应用程序的生命周期中，在一系列的使用案例中应用AIOps平台\n图片翻译：\n识别代码中的风险 日志文件分析 时间关联、异常分析，RCA 数字化代理（智能客服）/自动化，变更 NLP 在 ITSM 工具中被大量采用，但一些APM供应商已经开始将NLP作为其AIOps能力的一部分。一个主要目标是为DevOps团队实现更灵活的ChatOps，并为APM数据和自动化提供更好的接口。\n代表性厂商 市场介绍 AIOps平台供应商拥有广泛的功能，并在继续增长。供应商在其数据摄取和开箱即用的用例方面存在差异，只需最小的配置即可使用。在表1中，我们提供了一个有代表性的供应商样本列表，提供领域无关的AIOps平台功能。该表中的一些供应商也提供以领域为中心的产品。\n表2包括以领域为中心的AIOps供应商，在某些情况下，他们专注于一个以上的领域。随着AIOps功能开始成为APM和ITSM等不同领域的决定性特性，Gartner将在本市场指南的未来版本中关注领域无关的AIOps供应商。\n表1: 领域无关的AIOps平台市场的代表厂商\n厂商 产品,服务或者解决方案 名称 BigPanda BigPanda BMC TrueSight Operations Management, Helix Platform Broadcom-CA Technologies DX Operational Intelligence Devo (formerly Logtrust) Devo Digitate ignio Elastic Elasticsearch IBM IBM Cloud Pak for Watson AIOps Interlink Software Interlink Software Logz.io Log Management Moogsoft Moogsoft PagerDuty PagerDuty ServiceNow IT Operations Management (ITOM) Splunk Splunk Enterprise, Splunk Cloud StackState StackState Sumo Logic Sumo Logic Source: Gartner (April 2021)\n表2: 以领域为中心的AIOps平台市场的代表厂商\n厂商 产品,服务或者解决方案 名称 供应商擅长的领域 Aisera Aisera ITSM Cisco AppDynamics APM Datadog Datadog APM APM Digital.ai Numerify ITSM Dynatrace Dynatrace APM, ITIM Espressive Barista Case Management ITSM ExtraHop ExtraHop Reveal(x) for IT Operations NPMD Harness Continuous Integration, Continuous Delivery, Continuous Efficiency Platforms DevOps IPsoft (Amelia) DigitalWorkforce.ai Platform ITSM Kentik Kentik NPMD OverOps OverOps Dev Pico Corvil NPMD New Relic New Relic One Platform APM, ITIM OpsRamp OpsRamp ITIM ScienceLogic SL1 Platform ITIM Virtana Virtana Platform ITIM Zenoss Zenoss ITIM Source: Gartner (April 2021)\n*本市场指南中所列的供应商并不意味着是一份详尽的清单。本节旨在提供对市场及其产品的更多了解。\n市场建议 使用一个自上而下的 AIOps 框架 AIOps的使用案例跨越了从IT操作员到业务线所有者甚至CEO的各个层次。\n在实践中，这些平台只具备开箱即用的异常检测和事件关联能力。这意味着对IT操作员来说，开箱即用的相关性相当高，而终端用户必须创造与人员相关的结果，如 I\u0026amp;O 领导、系统管理员、架构师和LOB所有者。\n该平台的分析能力利用算法和模型来支持基于数据集的结果，这些数据集可能质量差、不完整且缺乏统一性。结果并不总是通用或相似的；因此，算法的价值是有限的。由于IT的复杂性和不断变化的性质，即使是AIOps平台所利用的模型，如果没有持续的反馈机制，也会失去相关性。\n**例如，在监控策略中，确定AIOps如何将数据转化为与目标人物的相关性，以及如何帮助解决各自人物的目的（见注5）。随后，从IT运维中的可视化现状开始，描绘出通往目标的以下步骤（见[采用AIOps的解决方案路径]）。\n以最终目标为起点的目标路线图 通向目标的中间步骤 IT运维的现有状态（噪音事件、基于静态阈值的告警或利用动态阈值） 选择最适合为路线图上的第一步提供开箱即用功能的AIOps供应商，并提供符合组织路线图的平台（例如，帮助组织以最小的努力从事件关联推进到动态阈值到行为分析）。随着用例的成熟，请注意这些平台的可移植性挑战（见注6）。\n基于洞见的自动化 一些企业有一个目标，导致对已发现的异常情况进行自动化补救。任何自动化举措都是基于一定程度的标准化。这是大规模部署自动化行动的一个主要抑制因素。成熟度高的IT组织更喜欢自动化的洞察力，而不是自动化的行动，这是一个切实的目标。I\u0026amp;O领导应该优先考虑那些能减少IT操作人员视觉负担的工具。例如，AIOps平台应该强调出需要人类关注的领域，而不是对多个图表进行可视化分析。\nCOVID-19疫情要求企业从根本上改变排查方式和采用AIOps用例的方式，因为向居家工作的转变暴露了现有做法的缺点。例如，在运维中心，有人会提出一个 \u0026ldquo;问题\u0026rdquo;，不同的小组会大声喊出他们对 \u0026ldquo;答案 \u0026ldquo;的看法。高管们看到了一个机会，在起草一个能够长期保持的战略时，重新审视综合运维工具、流程和人员的基本方面（见注5的图5）。\n在2019年，Gartner的客户有一个理想的目标，即设计与LOB所有者相关的仪表盘。这个过程中，一些企业花了10个月到两年的时间。两个主要因素是透明度和用于使业务领导人推动决策的上下文信息，与旨在让业务领导人了解情况的报告相比。疫情大流行开始后，大多数企业关注基本面和减少风险，把自己限制在现有的开箱即用的用例上，如事件关联性。在COVID-19大流行之前，Gartner看到企业提出了理想的目标，而这些目标在今天的AIOps工具中可能还没有开箱即用。\n与不同角色的关联性 AIOps平台被不同的团队采用，如DevOps、SRE、IT运维、网络安全（见[安全信息和事件管理魔力象限]），以及业务领导人。所需的用例和原始数据根据采用该平台的团队及其成熟度而不同。\nDevOps团队主要专注于日志摄取和分析。随着DevOps实践的成熟，用例从对生产前的关注扩大到包括用户参与、质量和业务相关性等生产指标。这就产生了对新的KPI的需求，在多个版本之间进行比较，并关注产品和平台。考虑到这种情况，选择能够摄取埋点的数据（追踪、指标和日志）的平台，并减轻为DevOps提供平台和产品视图的工作。\nIT运维团队通常需要指标和日志摄取的组合，然后是分析。这个过程从事件关联开始，随着团队的成熟，扩大到基于指标和日志分析的行为分析。这里的主要目标是异常检测和诊断信息，然后是根本原因分析。其他用例包括通过使用脚本的自动行动，其中AIOps识别与自动行动相关的触发器。选择那些能够灵活地摄取事件、日志和指标的平台，并为I\u0026amp;O的至少一个优先用例提供开箱即用的功能。\n企业领导更关注用户参与度，而应用性能只是影响整体参与度的一个参数。在一些全球性的组织中，业务领导已经不再区分员工和客户，所以这里的 \u0026ldquo;用户 \u0026ldquo;既指员工也指客户。这个旅程通常从基于IT的用户影响的相关性开始，但扩大到包括技术、人员和现有流程的效率和生产力等定性的关键绩效指标。在成熟的组织中，更好的参与而不是减员是这种关键绩效指标背后的驱动力。对于这样的场景，选择专注于聚类和人口统计学的平台，并在不同的数据集上提供因果洞察力，包括情感和满意度。\nSRE实践通常有与IT运维和DevOps用例重叠的目标。通常，这些都是跨越两个实践的成熟用例。例如，事件关联和日志摄取不是SRE团队的主要目标。他们的重点领域包括IT架构评估。对于SRE用例，选择为IT架构提供实时拓扑和依赖性洞见的平台作为主要用例之一。\n首字母缩写词和词汇表术语 APM Application performance monitoring 应用性能监控 BAM Business activity monitoring 业务活动监控 DA Domain-agnostic 领域无关 DC Domain-centric 领域为中心 ITIM IT infrastructure monitoring IT 基础架构监控 ITOM IT operations management IT 运维管理 ITSM IT service monitoring IT 服务监控 NLP Natural language processing 自然语言处理 NPMD Network performance monitoring and diagnostics 网络性能监控和诊断 SIEM Security information and event management 安全信息和事件管理 证据 1 Gartner的2020年通过自动化、持续质量和DevOps实现业务敏捷性研究于2020年6月至8月在北美和西欧已部署或正在使用DevOps的服务提供商、云供应商和终端用户组织工作的205名受访者中进行了在线调查。符合条件的组织的年收入至少为5亿美元，并要求主要在银行和金融服务、政府、保险、医疗机构和零售业中运维。受访者必须在其组织的IT职能部门工作，其职称低于C-suite级别，并且与组织中的最高主管相差两层或更多。受访者的角色必须主要集中在应用开发、基础设施和运维，或商业智能和信息管理。在这些重点领域，他们还被要求执行相关的角色/活动。这项研究是由关注数字商业趋势的Gartner分析师和Gartner的研究数据和分析团队合作开发的。\n这项研究的结果并不代表全球调查结果或整个市场，而是反映受访者和受访公司的情绪。\n在过去的12个月里，AIOps构成了Gartner客户关于IT性能分析的所有咨询中的40%的谈话内容。这些咨询的主题包括。\n技术和市场意识 平台选择 构建与购买决策 现有AIOps部署的优化 新部署情况下的部署策略 在DevOps、I\u0026amp;O、安全和SRE团队之间共享一个共同平台的利与弊 IT内部和外部的多种AIOps使用案例，以帮助可视化、决策和诊断。 在大流行病中，大多数用例都与事件关联有关。\n注1: 代表性供应商选择 本研究中列出的供应商是根据具有以下一个或两个特征而挑选出来的样本。\n领域无关的解决方案，能够从多个来源摄取数据，包括历史和实时流。 以领域为中心的解决方案，能够从特定领域或特定框架或实践的数据中摄取数据（例如，网络、应用、IT基础设施、DevOps或ITSM领域）。 不同的产品，包括专有的、开源的、免费的和商业化的版本，包括跨越企业内部和基于SaaS的部署方案。 注2: AIOps 平台的数据源 AIOps 的数据源包括:\nAPI Application logs 应用日志 CRM 数据 客户数据 事件 图 ITSM 元数据 指标 社交媒体 追踪 布线 不幸的是，无论一个给定的数据集有多大，更新有多频繁，限制在一个单一的数据源往往会限制对系统行为的洞察力。现代IT系统\u0026ndash;具有模块化和动态性\u0026ndash;需要一个多视角的方法来理解它们在被观察时正在发生什么。\n注 3: 领域无关和领域中心的AIOps **领域无关的AIOps -**供应商以通用的AIOps平台进入市场。这些产品往往主要依靠监控工具来执行数据采集，并迎合最广泛的使用情况。\n**领域中心的AIOps -**供应商拥有核心组件，但是一组有限的使用场景。以他们基本上做着与以前相同的事情，但现在他们用数学（算法）代替了规则、启发式方法和指纹。这些供应商专注于一个领域（例如，网络、端点系统或APM）。然而，以领域为中心的解决方案供应商已经做出了一些努力，将这些类别混合起来，发展到从他们自己的埋点工具以外的来源摄取数据，并将这些数据纳入他们的分析。\n注4: 基于规范性建议的自动化行动所面临的挑战 自动化执行行动分为多个类别。\n可以提前计划的预定性质的任务（例如，补丁管理或新构建的部署）。 不能提前计划好的任务，但有已知的触发器，可能会或不可能经常出现。在这种情况下，程序是有据可查的（例如，虚拟化环境中的工作负载优化）。 具有不可预测的触发器的任务，其行动是众所周知的，但没有很好的文件记录（例如，已知的异常情况）。 I\u0026amp;O领导通常不希望将行动完全交给机器，并要求在触发自动化之前至少有一个验证步骤。这种缺乏信任是阻碍自动化行动普遍使用的主要障碍之一。\n在这三种自动化行动中，我们看到对第三类行动的兴趣最大；然而，处理这类行动的技术困难是具有挑战性的，因此，到目前为止，它的采用是最小的。\n注5: AIOps 作为 IT 监控策略的一部分 Figure 5: AIOps as Part of an IT Monitoring Strategy\n注 6: 可移植性 随着企业采用AIOps的功能模型和质量成果的成熟，供应商转换变得困难。切换到不同的供应商来复制现有的高质量仪表盘将需要时间，这就消除了通过直接成本节约获得的任何价值。Gartner观察到，在部署比较成熟的企业中，正是因为这个原因，才不愿意在续约时更换供应商。\n需要可行的选择来挑战现有的供应商，这就产生了关于跨供应商的算法的可移植性问题。这种需求来自于一些成熟的企业，在这些企业中，AIOps的采用已经很成熟。市场仍处于高速增长阶段，我们至少要在几年后才能看到企业对可移植性的压力增加，以及供应商作为差异化的回应。\n一些供应商正在提出转移学习，这仍然处于初级阶段。在其较简单的形式中，终端用户可以选择通过使用历史数据训练一个选定的模型。该算法的结果与实时结果进行比较。一旦结果显示出相当的准确性和可接受的误差范围，终端用户就可以使用相同的算法来分析实时数据。这种能力在生产前和生产环境之间或在边缘和数据中心环境之间效果最好。更复杂的用例的演变将需要供应商和最终用户方面的成熟和高级技能。\n","date":"2021-04-28T17:22:22+08:00","image":"https://martinliu.cn/img/2021/4/AIOps-an-Industrial-Benchmark-2048x719.jpg","permalink":"https://martinliu.cn/blog/gartner-aiops-platform-market-guide-2021/","title":"2021 年 Gartner  AIops 平台市场指南报告"},{"content":"开源科普讲座简介：这是给大学校园的老师和同学们定制的免费公益讲座。在最近的20年里，开源软件已经了席卷全球。当今企业应用开源技术和云计算创作着巨大的社会和商业价值，大学生应该怎样了解、学习和参与开源技术？这成了所有相关学科的同学们不可规避的话题。我们想通过这样一个专题讲座交流的形式，帮助大家按照从由来到未来发展的逻辑梳理开源软件技术的发展。结合我（刘征）20年的外企工作经历，帮助大家深度剖析一家典型的来起源于开源社区的公司，通过这个公司的变迁我们可以看到开源企业所能取得的成功和面临的挑战。Elastic Stack 这个技术栈的核心是 Elasticsearch，这是一个被广泛深度应用的开源大数据搜索平台，中国的一线互联网公司的各种流行产品的背后也都有着它的身影，让我们一起简单理解一下这个技术栈的使用方法，希望它能在校园的研究工作、同学的毕业设计项目等等方面有所帮助。本讲座是注重IT知识的非商业宣传讲座，为了有助于增加同学们的就业竞争力，在最后一个是交流互动环节，我们可以做一些就业形势、求职和职业发展等方面的答疑。\n下面是本次交流见过的概要内容介绍，希望能引起大家的兴趣，如果有任何建议和疑问也可以随时和我直接联系。\n开源用20年改变了整个IT行业 开源方式是在开源社区内进行思考和协作的一种形式。这一理念基于知识自由和核心原则：透明、协作、交付、包容和社区。社区的思想交流和软件开发推动了以下行业的创新、科学和技术进步：教育、政府、法律、医疗保健和制造业。这项活动提供了一种通过源代码协作、共享和协助实现个人及团体目标的方式。\n开源软件是协作性的，依靠社区生产和同行评审来使用、更改和共享源代码。开发人员分享洞察、构想和代码，共同和单独创建更多创新的软件解决方案。这种可扩展且灵活的软件可确保任何拥有源代码的人都能将其修改、增强和重新分发，从而提高可复用性和可访问性。开源软件基于对等生产和大规模协作的基本原则，从而为最终用户创造更可持续的软件开发体验。\n封源软件 (CSS) 是不向公众分发的专有软件。这类软件进行了加密，因此仅创建该代码的原始作者有权合法复制、修改、更新和编辑源代码。闭源软件会限制最终用户对应用可以执行的操作，防止用户修改、共享、复制或重新发布源代码。\n除了开源和闭源软件之外，FOSS（自由和开源软件）允许用户从更有哲理的角度访问软件。在自由和开源软件中，自由软件基金会 (FSF) 保护用户自由，开源促进会 (OSI) 确保可靠软件的技术价值。有各种各样的免费软件许可证，可供商业使用、修改和销售，包括：GPL、LGPL 和 BSD 许可证。\n一些最受欢迎的开源软件许可证包括：\nMIT 许可证©：MIT 许可证是一种免费的软件许可证，允许用户修改原始代码，而且限制要求非常少。 GNU General Public© (GPL)：GNU 是一系列免费的软件许可证，可确保最终用户能够运行、研究、共享和修改软件。 Apache®：Apache License 2.0 是一种免费的软件许可证，允许用户出于任何目的使用、修改和分发软件。 BSD：此许可证对开发人员的限制较少，允许用户使用和修改代码而不必共享修改。 MySQL™：MySQL 是一个开源数据库管理系统，具有两个单独的许可证 - mySQL Standard Edition 和 MySQL Enterprise Edition。 SUSE：SUSE Linux 建立在开源 Linux 内核上，并随系统和应用软件一起分发。 Ubuntu®：Ubuntu 是一个 Linux 发行版，由在桌面、云端和物联网中发布的免费和开源软件组成。 开源软件大事记：\n在 1969 年 AT\u0026amp;T® 贝尔实验室，Unix 做为一种专有但可许可的产品诞生。很快加州大学伯克利分校开发了自己的 Unix 操作系统，名为 Berkley Software Distribution（BSD 许可证）的学术版本。BSD 和 AT\u0026amp;T 的 System V 版最终合并成为统一的第七版 Unix，然后进一步演进为：Sun Solaris、FreeBSD、NetBSD 和 OpenBSD。 1984 年，Richard Stallman 创建了一个名为 GNU (GNU\u0026rsquo;s Not Unix) 的自由 Unix 克隆。此版本是开放的，可根据需要自由使用、修改和重新分发。Richard Stallman 是 Open Source 界的伟大人物之一, 他是gcc, gdb, emacs的作者。 1991 年，Linus Torvalds 创建了名为“Linux”或 Linux 内核的操作系统内核。通过与 FSF 和 BSD 组件相结合，Linux 成为一个完整的操作系统。Linux 正式踏上了颠覆整个 IT 行业和改造这个世界的使命，知道今天无不知，无人不晓的云计算和智能硬件，知道工业物联网和火星登录计划。 市值过百亿的 Elastic 公司曲折的开源旅程 Elastic 公司的开源故事起源于创始人 Shay 和妻子的菜谱的故事。现在 Elastic 是一家员工进 2000 人的上市公司，它帮助企业实时大规模地使用数据，完成企业搜索，确保可观测性和安全。Elastic 解决方案基于一个免费的开放技术栈。该技术栈可以部署在任何地方，帮助用户从任何类型的数据中快速获取可作为行动依据的洞见，从搜索文档一直到监控基础架构，再到检测网络攻击威胁。全球各地已有数千家企业利用Elastic 解决方案来支持关键任务系统，包括思科、Goldman Sachs、微软、The Mayo Clinic、NASA、《纽约时报》、维基百科和Verizon等等。Elastic 成立于2012年，已在纽约证券交易所（NYSE）上市，股票代码为ESTC。今天它的股票市值已经超过百亿，从开源开放，到免费开放；从 Appache v2 许可到 Elastic V2 + SSPL 许可，在最近短短的 3 年里到底这家公司都经历了什么？这家公司的开源历程能给予我们怎样的启发？\n轻松入手 Elastic Stack 搜索技术栈 Elastic Stack 技术栈包含了一组开源项目。 “ELK”是三个重要组成开源项目的首字母缩写，这三个项目分别是：Elasticsearch、Logstash 和 Kibana。Elasticsearch 是一个搜索和分析引擎。Logstash 是服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到诸如 Elasticsearch 等“存储库”中。Kibana 则可以让用户在 Elasticsearch 中使用图形和图表对数据进行可视化。\nElastic Stack 就是 ELK Stack，但是更加灵活，可以帮助人们出色完成各项事务。下面我们演示一下内容：\nElasticsearch 和 Kibana 的安装 使用 Kibana 可视化分析和展示航公公司航班信息、电商平台订单和Web 网络服务器的日志。 导入最近几年的电影数据，尝试从多个角度分析和展示这些数据 开源及就业答疑 在这个环节里，我们也准备了一些求职准备的经验技巧。\n软件专业学生如何构建无敌求职简历 软件行业里工作岗位的分工和配合 在 996 和 007 的企业中工作是怎样的体验 最后，希望和同学们做自由交流，内容范围和问题不限。\n参考文档：\nhttps://www.ibm.com/cn-zh/topics/open-source https://www.elastic.co/cn/ https://www.elastic.co/cn/what-is/elk-stack https://ld.sogou.com/article/i5634372.htm?ch=lds.pc.sh.media.all https://www.163.com/dy/article/G0NG79CD0543QP26.html ","date":"2021-04-27T09:48:32+08:00","image":"https://martinliu.cn/img/cos/2021-04-27-opensource.jpg","permalink":"https://martinliu.cn/blog/elastic-university-campus-intro/","title":"探究改变了整个行业的全球开源大潮"},{"content":"我们不可能忽视 Scrum 的知名度。多年来，Scrum 是全球大多数公司在敏捷框架中的首选；只有少数公司会挑战它。但最近，发生了一些变化，组织正在失去对Scrum的信任。在未能获得有意义的结果之后，在许多地方，人们正在用 SAFe、Kanban 或其他框架取代 Scrum。\n除了这些不满 Scrum 的组织，有些经验丰富的专业人士也不愿意与Scrum共舞。很多人甚至觉得被称为产品经理（Product Owner）或 Scrum Master 都很尴尬。市场正在向新的方向转变，Scrum还会有空间吗？\n公司想做敏捷，但他们难以放弃旧的指令和管控风格。\n让我来阐述一下，为什么我认为 Scrum 的游戏可能已经结束了。 请注意 这篇文章的内容是基于我过去十年的经验和观察。这也是为什么我邀请你也分享你的观点。\n作者 本文出处：https://medium.com/serious-scrum/sorry-scrum-the-game-might-be-over-for-you-915227f3a0d\n作者：David Pereira Head of Product Management @virtualidentity Course: How to be a strong Product Owner: http://bit.ly/30ylNEH\nScrum不是一个流程 第一个软件是在1948年才出现的，那时候软件开发还是个新鲜事物。我猜汤姆-基尔本无法想象软件开发会给世界带来多么快的进步。\n计算机科学家汤姆-基尔本负责编写了世界上第一个软件，该软件于1948年6月21日上午11时在英国曼彻斯特大学运行。—\nMicah Yost, A Brief History of Software Development\n在新千禧年之前，公司缺乏符合客户期望的技术。大多数公司专注于围绕软件开发改进流程。尽管所有的努力都是为了实施像 Rational Unified Process统一流程这样的重磅流程，但质量还是有问题，客户也还是不满意。构建无用的软件让许多人感到沮丧；软件行业需要一场革命。\n虽然像 Scrum 和 eXtreme Programming 这样的敏捷框架已经存在许久，但在2001年《敏捷宣言》-（Agile Manifesto）出台后，才大大改变了全球软件的开发方式。在那之后，Scrum框架成为最受欢迎的替代品。\n从千禧年的初期情况来看，Scrum 能解决软件开发的所有问题吗？我们必须去了解问题的根本原因，但很多公司忽略了这一步，反而求助于寻找新的流程。仅仅依靠替换人们工作方式的流程是不够的。这就是大多数组织未能从Scrum 中获益的原因。\n根本原因不是流程，而是缺乏敏捷的思维方式。\n我们以足球为例，在瓜迪奥拉(Pep Guardiola)的领导下，巴塞罗那在4年内赢得了14个冠军。从2008年到2012年，巴塞罗那绝对是世界上最强的足球队。很多人将成功归功于瓜迪奥拉执教球队的方式。其中一个显著的方面是主导比赛；巴塞罗那经常拥有70%以上的控球率。这是否意味着将 \u0026ldquo;Tiki Taka \u0026ldquo; 运用到另外一支球队后，他们就能达到类似的效果呢？\n瓜迪奥拉从2013年到2016年执教拜仁慕尼黑，他应用了和巴塞罗那一样的风格。然而，所取得的成功与巴萨不相上下；在拜仁慕尼黑，他获得了5个国家冠军，却没有获得欧冠冠军。要想实现伟大的成就，仅仅靠一个‘流程’是不够的，还需要其它更多的东西。\n把Scrum当做流程的公司都失败了。如果还没有更重大的改变，任何敏捷框架都无法带领团队走向成功。除非公司解决了他们的组织型障碍（dysfunctions），否则环境不会让团队发挥的更出色。\n我观察过很多虚弱无力的 Scrum 团队，因为环境的组织型障碍。最常见的组织障碍是。\n缺乏信任 缺少方向 根据职位确定优先次序 微观管理（micromanagement） 对于这些有组织型障碍的公司来说，Scrum应用失效是不可避免的。最后，Scrum还要背这个锅。\nScrum 框架并不适合畏惧改变的组织。不改变其文化，就不可能用 Scrum 取得成功。许多人对 Scrum 的角色、事件和工件了如指掌，但很少有人知道背后的价值观。如果不活用 Scrum 背后的价值观，就不可能实现 Scrum 的承诺。\n为什么Scrum即将崩塌？ Scrum 自称简单易行，其实很难掌握。几乎我认识的每个人都同意这句话，然而，我要质疑 Scrum 有多简单。框架的一个关键部分经常被忽略，试着问一些团队的价值观是什么？你会惊讶的发现，几乎没有人知道。不过，价值观仍然是 Scrum 的一个关键部分。\nScrum 的成功使用取决于人们是否能更熟练地运用这五种价值观。 承诺、专注、开放、尊重和勇气。\n— The Scrum Guide, November 2020\n当组织把 Scrum 当作一个流程来实施时，挫折是不可避免的。从设计上看，Scrum 是不完整的，没有一个团队能够在不适应其场景的情况下取得成功。例如，产品管理并不是 Scrum 的一部分，然而，它却是交付有意义产品的关键学科。\n要想利用 Scrum 获得成功，组织必须经历一场大规模的转型。不幸的是，大多数高管都不愿意去准备一个能让团队茁壮成长的环境。我在企业中遇到过以下几种范式。\n赋权 vs. 微观管理\n成果 vs. 产出\n协调/对齐 vs. 共识\n承担风险 vs. 遵循计划\n\u0026ldquo;高层管理者们认为，拥有真正自我管理的团队风险太大。这就是为什么 Scrum 会遇到玻璃天花板的原因。\u0026rdquo; — Willem-Jan Ageling, Scrum Has Hit the Glass Ceiling\n高层管理人员们往往无法充分给个人授权，因为他们想继续自己的控制。所以他们才会走捷径。首先，改变执行力。然后，如果 Scrum 证明了它的价值，那再来改变文化。好吧，这样做是行不通的，结果是大家都很沮丧。当Scrum 变成了一个过场（译者注：此处突出一下形同虚设的空架子流程的含义，请酌情理解），角色就会变异成毫无意义的东西。让我来分享一下我的一些心得。\nPhoto by Maria Teneva on Unsplash\n产品负责人/经理（Product owner） 如果不能对优先级负责，产品负责人就会像服务员一样。他们接受订单，建议配菜，然后把订单交给厨房。做一个接单员是令人沮丧的，你唯一的义务是管理利益相关者的期望，并用做和开发人员沟通的桥梁。\n不幸的是，与产品负责人角色的变异更多的是规则而不是例外。这就是为什么我在想，是否有人可以成为 Scrum产品负责人。当我回顾我的职业生涯时，也许我曾经就差点变成这样的人，但从来没有像 Scrum 指南所推荐的那样，被完全的授权过。我的问题是：Scrum产品负责人在现实的企业中存在吗？\n你能举出多少家公司的产品负责人真正的完全拥有产品决策的最终决定权？如果他们没有最终决定权，这些人还是产品负责人吗？然而，有成千上万的人声称自己是产品所有者，却不拥有任何产品。—\nMaarten Dalmijn , Will the real Product Owner please stand up?\n在反模式之上，我注意到很多有产品思维的人对产品负责人这个角色失去了兴趣。他们觉得很难把它和产品经理联系起来。虽然公司经常雇佣产品负责人，但由于 Marty Cagan 所推崇的看法，很多专业人士都不好意思这样称呼，他声称产品负责人不是一份工作，而是一个角色，而且这份工作比 Scrum 所建议的要多得多。\n开发人员 开发者是决定实际如何开展工作的人，他们负责实现，使用哪种技术栈，等等。这是一个美丽的幻觉（理论）。但在实践中，我从未见过这种情况。常见的是有一个首席技术官（CTO），一个技术负责人，或者其他头衔的什么人，他们不仅要来做决策，还要管理开发者。\nScrum 所宣称的开发者有自主权，但他们得到了吗？我认为自主的情况很少见。说起来也很悲哀，但大多数开发者所收到的命令都是要遵守的；只是很少有开发者被授权在没有截止日期的情况下解决问题。\nScrum 开发者在幻想世界中可能会和 Scrum产品所有者工作在一起，但在现实中却不是。我们最常见的是开发者被封印在了特性工厂里。\nScrum Master Scrum Master 是 Scrum 中最遭受鄙视的角色。没有 Scrum Master 的 Scrum 团队是很常见的，因为公司不愿意雇佣专人来做这个工作。不过，即便有些公司雇佣了 Scrum Master ，但还是会经常让他们虚弱无力。\nScrum Master 的失效无法避免，因为他们也不能催生出任何必需的改变，能让 Scrum 蓬勃发展起来。\nScrum Master 和其他角色也没有什么不同。要找到一个人，他能够完全像Scrum指南中所建议的那样，成为真正的 Scrum Master 是不太可能的。Scrum Master 通常无力促进组织中所需要的变化。\nScrum 还会活下去吗？ 许多有经验的专业人士已经厌倦了 Scrum，他们对它失去了信心。他们想要一些其他的东西，这些专业人士正在寻找机会尝试其它的框架。\n高管们对变革的恐惧阻碍了 Scrum 团队的发展。一连串错误的决定和错误的观念可能会导致 Scrum 走向灭亡。高层管理者不能将其先天不足的指令和管控风格留在过去。\n一个可悲的结果可能就会发生，SAFe，这个瀑布模型的卧槽马，它已经准备好要上位了。\n我很害怕 SAFe，因为它是一个沉重的流程，它看起来一点也不像是一个敏捷的方法。这台沉重的机器怎么能让人背得滚瓜烂熟呢？我真不知道他们凭什么敢说这也是敏捷。\nSAFe 5.0\nScrum可能需要重启才能活下来 Scrum 角色的魅力已经大不如前。很多公司对 Scrum 的错误认知，导致专业人士抵触与之合作。在 Scrum 成为一个流程的场景下，人们也不想成为 Scrum Master 或产品所有者。\n我相信 Scrum 需要重新开始才能保持存在的意义。\n我们所处的时代与20年前不同。在2001年，Scrum 是一个新生的孩子。世界已经改变了。现在 Scrum 是一种商品。为了让 Scrum 还维持在前线，创造者们需要有勇气去接受框架的核心，并解决那些阻碍。其中一些（可能的）阻碍可能是人家的血牛。想想（Scrum Master 和 Product Owner）认证产业。\n— Willem-Jan Ageling, Will Scrum Fall Victim to Its Own Success?\n不管发生了什么，那些勇于改变自己内核的公司还是能在 Scrum 中脱颖而出。这从来都不是为了定义一个流程，而是为了拥有一种专注于更快地交付价值的文化。希望尚在，一些大胆的公司能拥抱变化，他们所表现出的迹象是。\n首席产品官（Chief Product Officer）成了高管团队的成员。 高层管理人员专注于给出方向而不是指令。 Scrum团队被授权去试验各种用来达成关键成果的方案。 产品探索（Product Discovery）的建立。高管们知道，投入适当的时间去发现那些值得解决的问题是必不可少的工作。 ","date":"2021-04-10T22:21:29+08:00","image":"https://martinliu.cn/img/cos/2021-04-10-0_IFV2UEaD1Vj4S_to.jpg","permalink":"https://martinliu.cn/blog/sorry-scrum-the-game-might-be-over-for-you-cn/","title":"对不起Scrum，你的游戏可能已经结束了!"},{"content":"【译文】上周，我和我的几位非常资深的同事都在评论说，有很多新的DevOps工具正在出现，而且每天都越来越难跟踪它们，以及它们在DevOps 领域的定位。我问了他们几个工具，Ansible、Terraform、Salt、Chef、Bamboo、CloudFormation这些工具的定位在哪里？我为什么要用这个而不是那个？它们甚至是同一种东西吗？我是不是漏掉了一个主要角色？我得到了什么，一些白眼和问题。所以，我想我会做一些研究，阅读，并试图让我们所有人理解它，以便我们可以将那些产品都分类到我们都熟悉的类别或用途。\n原文：https://levelup.gitconnected.com/the-10-minute-read-to-understanding-devops-tools-bc4ac807a25d\n在我们开始谈论DevOps工具和类别之前，让我们退一步讨论几个基本的（但往往是超载的）术语以及它们的含义。\n计算机/服务器 - Computer/Server： 具有中央处理器（CPU）、内存（RAM）、本地存储（磁盘）并运行操作系统的物理设备。\n虚拟机 - Virtual Machine：在主机上运行的计算机系统的模拟器（虚拟机管理程序）；vm 通常可以在CPU、内存和磁盘使用方面与其他操作系统隔离。\n容器\u0026ndash;Containers：打包一个软件及其所有依赖，使其能够在任何基础设施上统一、一致地运行。Docker容器是最流行的。它们允许你打包一堆东西（你的软件、配置和其他软件），以便于部署和传输。你可以把容器看作是虚拟化的下一代进化（继虚拟机之后）。\n网络设备 - Network Device：在设备之间路由网络流量的硬件。例如路由器、负载平衡器和防火墙。\n软件 - Software：编码并在操作系统上运行的代码。\nDevOps - 传统上有 \u0026ldquo;开发\u0026rdquo;（你来构建它），还有 \u0026ldquo;运维\u0026rdquo;（我们将运行它），他们两者之间的一切都受制于作坊式的工作方式。从2010年左右开始，到2018年左右DevOps 已经发展为几乎无处不在的现象，DevOps的理念是：\u0026ldquo;一套实践，目的是在保证高质量的前提下，缩短从提交系统变更到变更投入正常生产环境之间的时间\u0026rdquo;。\n当你在考虑构建和运行一个非同寻常的系统时，其实还有很多不得不做的事情。以下是需要考虑到的传统的事项清单。\n获取计算机/服务器硬件 （Obtaining the computer/server hardware） 配置计算机/服务器硬件（操作系统、网络布线等）（Configuring the computer/server hardware (operating systems, network wiring, etc.)） 监控计算机/服务器硬件（Monitoring the computer/server hardware） 获取网络设备（负载均衡器、防火墙、路由器等）（Obtaining the network devices (load balancers, firewalls, routers, etc.)） 配置网络设备（Configuring the network devices） 监控网络设备（Monitoring the network devices） 编写软件（Constructing the software） 构建软件（Building the software） 测试软件（Testing the software） 软件打包（Packaging the software） 部署/发布软件（Deploying/releasing the software） 监测软件（Monitoring the software） 在DevOps之前，我们曾经有四个不同的团队在做这项工作。\nDeveloper 开发人员 — 他们会做 #7, #8 ，有时候包括 #10 QA 测试人员— 他们会做 #9 ，有时候包括 #11 System Administrator 系统管理员 — 他们会做 #1, #2, #3, #12 Network Administrator 网络管理员 — 他们会做 #4, #5, #6 对于硬件、网络设备和软件的配置，每个团队很可能会使用自己的一套脚本和工具，而且在很多情况下，会通过手工操作来实现 \u0026ldquo;软件发布\u0026rdquo;。\n随着DevOps的出现，对我来说，关键的想法是打破这些部门墙，让每个人都成为 \u0026ldquo;一个 \u0026quot; 团队的一部分，为所有事物的配置、部署和管理方式带来一致性。\n云\u0026ndash;Cloud：定义信息技术史上最流行的名词是很难的，但我喜欢那件T恤，上面写着 \u0026ldquo;没有云，只是别人的电脑\u0026rdquo;。最初，当云服务开始的时候，它们真的只是别人的电脑（或者运行在电脑上的虚拟机），或者存储。随着时间的推移，它们已经演变成到了现在的状态，包含很多很多的增值服务。硬件大部分已经被抽象掉了，现在大多数云服务中，你不能购买它们的硬件设备，但你可以购买这些硬件设备所提供的各种云服务。\n基础架构即代码(IAC)\u0026ndash;：一种新的能力或概念，它允许我们通过定义或配置文件来完整的定义数据中心中所有项目的设置，包括虚拟机、容器和网络设备。这个概念是我可以创建一些配置和一些脚本，然后使用我们即将讨论的一个工具来运行它们，它们会自动为我们按需配制出数据中心的所有服务。CI/CD是IAC的前身，多年来我们一直致力于自动化我们的构建/测试/集成/部署周期，在我们的云基础设施上做这个工作是一个自然的延伸。这带来了成本的降低，更快的上市时间，以及更小的风险（人为错误）。\n随着IAC的出现，许多传统的开发工具现在可以用于管理基础设施。像软件仓库、构建工具、CI/CD、代码分析器和测试工具等类别的工具（如下所列），传统上是由软件开发人员使用的，现在可以被DevOps工程师用来构建和维护基础设施。\nAGAIN: \u0026ldquo;随着DevOps的出现，对我来说，关键的理念是\u0026hellip;\u0026hellip;让每个人都成为\u0026rsquo;一个\u0026rsquo;团队的一部分，为所有事物的配置、部署和管理方式带来一致性。\u0026rdquo;\n因此，现在我们已经定义了以上基础术语/概念，让我回到试图对DevOps工具进行分类的任务，以使我们更容易确定什么工具是用于什么目的的。\n软件仓库 \u0026ndash; 管理软件版本的工具\u0026ndash;目前使用最广泛的是Git。 构建工具\u0026ndash;有些软件在打包或使用前需要编译，传统的构建工具包括Make、Ant、Maven和MSBuild。 持续集成工具\u0026ndash;在配置好以后，每次将代码提交到存储库中时，它都会对软件进行构建、部署和测试。这通常可以提高软件质量和上市时间。这个市场上最流行的工具是 Jenkins、Travis、TeamCity和Bamboo。 代码分析/审查工具\u0026ndash;这些工具可以查找代码中的错误，检查代码格式和质量，以及测试覆盖率。这些工具因编程语言而异。SonarQube是这个领域的一个流行工具，还有其他各种 \u0026ldquo;轻量的 \u0026ldquo;工具。 配置管理\u0026ndash;配置管理工具和数据库通常存储所有关于你的硬件和软件项目的信息，以及提供一个脚本和/或模板系统，用于自动化常见任务。在这个领域似乎有很多玩家。传统的玩家是Chef、Puppet和Salt Stack。 部署工具\u0026ndash;这些工具有助于软件的部署。许多CI工具也是CD（持续部署）工具，它们协助软件的部署。传统上在Ruby语言中，Capistrano工具被广泛使用；在Java语言中，Maven被很多人使用。所有的编排工具也都支持某种形式的部署。 编排工具\u0026ndash;这些工具配置、调度和管理计算机系统和软件。它们通常将 \u0026ldquo;自动化 \u0026ldquo;和 \u0026ldquo;工作流 \u0026ldquo;作为其服务的一部分。Kubernetes是一个非常流行的编排工具，它专注于容器。Terraform是一个非常流行的编排工具，它的关注点更广，包括云编排。另外，每个云提供商都有自己的一套工具（CloudFormation、GCP Deployment Manager, 和ARM）。 监控工具 - 这些工具允许监控硬件和软件。通常，它们包括监控代理程序，用于监视进程和日志文件，以确保系统的健康。Nagios是一种流行的监控工具。 测试工具 - 测试工具用于管理测试，以及测试自动化，包括性能和负载测试等。 当然，和其他任何一套产品一样，类别也不一定完全清晰。许多工具都是跨类别的，并提供两个或多个类别的功能。下面是我试图展示大多数非常流行的工具，并可视化它们在这些类别中的位置。\n正如你所看到的，有几个玩家，如Ansible、Terraform和云工具(AWS、GCP和Azure)，正试图通过他们的产品覆盖部署、配置管理和编排类别。老牌工具集Puppet、Chef和Salt Stack专注于配置管理和自动化，但已经扩展到编排和部署的。还有像GitLab和Azure DevOps这样的工具，几乎试图跨越DevOps的所有类别。\n我希望这个概述能帮助你了解DevOps的基础知识，可用工具的类别，以及目前市场上的各种产品如何在这些类别中的一个或多个类别中提供帮助。在Solution Street，多年来我们已经使用了许多这样的工具，对我们来说，没有一个单一的 \u0026ldquo;一招鲜 \u0026ldquo;的工具能胜任所有情况下使用。使用什么是基于所使用的技术，在哪里托管（以及未来可能在哪里托管），以及团队的人才和构成。\n教练观点：敏捷教练不能回避DevOps 工具链的话题，中低层管理人员更应该在宏观上深刻理解 SLDC 所有环节的技术概要和工具需求，需要具备基础的概念知识，具备和工程师讨论所必备的语言。工程师们更要有工具链整体优化的意识，而不仅仅是精通某个环节，或局限在与自己的上下游工具上，工作在这个系统中的所有人需要有全局协作和优化的意识，优化价值流的流量、流速，关注价值的产生。警惕\u0026mdash;-整个工具链的自动化程度越高，不一定工作效率越高，加班越少，公司盈利越多。它们其实是相互作用的。\n","date":"2021-04-02T22:34:09+08:00","image":"https://martinliu.cn/img/cos/2021-04-03-eggs-3216877_1920.jpeg","permalink":"https://martinliu.cn/blog/10-minute-read-to-understanding-devops-tools/","title":"10 分钟读懂 DevOps 工具链"},{"content":"可汗学员处理流量突然暴增的过程离不开 SRE 的设计和工作。他们的应对策略包括使用云和CDN。\n可汗学院是一家非营利性机构，其使命是为任何人、任何地方提供免费的世界级教育。\n本文原文出处：https://blog.khanacademy.org/how-khan-academy-successfully-handled-2-5x-traffic-in-a-week/\n这篇文章的发布时间在去年（2020 年 5 月），大约是全球疫情最严重的时候。以下是正文。\n说到快速扩展\u0026hellip;\n几个月前，我发布了一些关于扩展的想法，并承诺很快会发布更多的内容。好吧，说到快速扩展\u0026ndash;在3月份的短短两周内，可汗学院网站的使用量就增长到了去年同期的2.5倍，并且一直维持到现在。由于冠状病毒大流行，世界各地的学校都关闭了，学生、家长和老师都转向了远程教育，可汗学院能够做出反应，提供高质量的内容和课堂体验\u0026ndash;而且是免费的。在4月份，我们在平台上为3000万学习者提供了服务。最近一项针对家长的全国性调查发现，可汗学院是 \u0026ldquo;使用最多的在线资源\u0026rdquo;。\n我很自豪，我们吸纳了这种快速增长，同时并没有干扰到我们的用户。除了在几天内迅速做出反应以缓解压力点之外，我们还提前做好了准备，而这种准备也得到了回报。我们之所以能够轻松地进行扩展，很大程度上是因为我们的架构以及谨慎选择外部服务并正确使用它们的严谨做法。\n因此，在这篇文章中，我将讨论对我们网站的可扩展性起关键作用的架构方面。\n我们架构的两个基本组件在这里为我们提供了特别好的服务。我们使用谷歌云，包括AppEngine、Datastore和Memcache，以及Fastly CDN，它们是无服务器和缓存策略的支柱，这是我们扩展性的关键。\n无服务器基础设施 使用 GCP 的 AppEngine，这种完全管理的环境，意味着我们可以非常容易地扩展，几乎不费吹灰之力。即使在流量大幅增加的情况下，我们的网站也能保持良好的性能，而且干预最少。我们自己不需要担心负载平衡，因为服务器实例会根据需要启动，也不需要任何干预。我们同样使用 Datastore，它可以自动扩展存储和访问容量，与 App Engine 扩展 Web服务器实例的方式非常相似。\n缓存 Fastly CDN使我们能够缓存所有静态数据，并最大限度地减少服务器跳转。巨大的可扩展性，它还能帮助我们优化托管资源，在我们的App Engine无服务器模式中，托管资源的成本随着使用量的增加而线性增长。如架构图所示，所有的客户端请求都会经过Fastly，这样我们可以防止不必要的服务器流量，提高性能。我们主要从YouTube加载视频，其次从Fastly加载。这样也可以降低成本，以及保证视频的快速加载。\n除了在Fastly中缓存静态数据外，我们还广泛缓存常见的查询、用户偏好和会话数据，并利用这些来加快数据获取性能。我们除了围绕 Datastore 行使其他关键的最佳实践外，还大量使用Memcache，以确保快速响应时间。\n我们的网站可靠性(SRE)团队当然需要做好扎实的监控准备\u0026ndash;我们也是做到了。我们注意到头几天出现了一些降速，并发现是部署导致了这些衰减。在我们的要求下，Google 增加了我们的 Memcache 的容量，一周内我们就可以轻松恢复到正常的连续部署模式。这个速度是至关重要的，因为我们的团队正在快速的开发资源，以指导新网站用户尽可能轻松地上手使用我们的服务。\n总的来说，我们努力工作，谨慎选择服务，遵循最佳实践，并根据需要开发自己的服务。有了正确的技术、精心的准备，以及我们了不起的工程团队的现场调整，我们已经能够不间断地为现在比以往任何时候都更依赖我们的学生、家长和教师提供服务。\n","date":"2021-03-25T00:21:05+08:00","image":"https://martinliu.cn/img/cos/2021-03-24-sunrise-5863751_1920.png","permalink":"https://martinliu.cn/blog/how-khan-academy-successfully-handled-2-5x-traffic-in-a-week-cn/","title":"可汗学院如何在一周内成功处理2.5倍的流量？"},{"content":"你的事故管理与战斗机飞行员的有什么共同点？经验丰富的战斗机飞行员，Transposit 的 Anthony \u0026ldquo;AB \u0026quot; Bourke 说，他最近在DevOps企业峰会的快乐时光上做了这个演讲。\n教练观点：incident management 在目前的所有出版物中，甚至大部分翻译软件中，都被翻译为 “事件管理”。在 IT 行业中，这个词汇的首次出现大约是在 20 年前，从 ITIL 引入运维管理的时候，从第一波 ITIL 在国内传播布道的时候，它就一直被翻译为 “事件管理”，“事件” 其实是一个没有好坏之分，好恶差异的中性词，不带有严重后果的含义。但是如果你在美剧中，在美国 NBC 新闻频道仔细的听；incident 往往和某人遭遇交通事故受伤亡相关；和就在今天美国科罗拉多的一个商场里发生的 10 人死亡的枪击案件相关。大部分企业的 ITIL/ITSM 软件中事件管理流程里所管理的其实都是 Event Management，而不是事故。希望本文能引起大家的注意。本文中将其翻译为“事故管理”，事故应该是 Incident 这个单词在 IT 服务管理这个语境里应该有的，精确的含义。\n本文出处：https://www.transposit.com/blog/fighter-pilots-and-incident-management/\n想象一下。在你所从事的工作中，你是最棒的，你被招募为蓝天上的飞翔天使。\u0026ldquo;所以，现在我们希望你驾驶着你的喷气式飞机，在很低的高度上高速飞过大量的人群，并发出巨大的噪音。然后我们要做编队飞行，你和你领导机翼间隙只有18英寸。还有一件事我得提一下，有一半的时间里，我们希望你们是倒立的，倒过来的；所以就像你的IT业务服务遭受了灾难一般，后果非常严重\u0026rdquo;\n他说的没错。事实上，作为一名值守的工程师，在新冠疫情期间，应付的是应用系统发生的各种状况，值守工程师承受的压力比以往任何时候都大，有多少时候会有 \u0026ldquo;倒飞\u0026quot;的感觉？这可能是一种令人头晕目眩的体验。而失败的后果往往很严重，同时大家对 \u0026ldquo;完美任务 \u0026ldquo;的期望也从未如此的高。\n在事故管理的坚实基础上，我们可以从战斗机飞行员那里学到什么？能否帮助我们运行和保障业务关键任务服务的安全？\n如实汇报不可打折 虽然我们认为：飞行员所完成的史诗般的飞行，是他们工作中最重要的部分，但伯克强调，其实汇报与任务本身同等重要。\n每次任务结束后，无一例外的，战斗机飞行员在汇报上所花费的时间，几乎是他们飞行时间的两倍。事实上：\u0026ldquo;无论我们认为自己已经有多好了，无论我们的计划有多优秀，无论我们的技术有多完美，无论我们的人员素质多么无敌，其实战斗机飞行员并没有执行过所谓的完美任务。\u0026rdquo; 我们的大部分学习，并不是发生在任务或事故本身，而是发生在事后，是在我们恢复之后，在和同事讨论的过程中，用清醒的头脑看待所发生的事情。\n我们能，也应该将这种纪律性带入自己的事故管理实践中。\u0026ldquo;不要将这种汇报的概念，看作是只能在军队中发挥作用的东西，\u0026rdquo; 伯克说。\u0026ldquo;想一想，你是如何提高你在给予和接受反馈方面的标准的。\u0026rdquo; 你不仅会加速新员工的成长体验，而且你还会发现，你团队中经验丰富的人也能够突破他们自己的玻璃天花板，同时避免他们无法提升，无法适应不可避免的变化。\n透明度是汇报的关键 跟我们一起飞上一段旅程吧！假设你就是一名中级军官，你刚刚和一群军官一起执行训练任务归来，还有一名二星将军还在回家的路上。当你汇报任务时，你在视频中观察到，将军现在已经在目标之外的100英里了，而且他应该在离开目标50英里的时候，就将“主臂”置于保险状态，可是他现在的\u0026quot;主臂 \u0026ldquo;开关放了在手臂的位置上（这意味着武器仍然是发射就绪状态）。你会指出这个将军的操作失误么\u0026ndash;他可是负责着你的涨薪、晋升和降级？\n当伯克提出这个问题时，我们中的许多人都觉得，对一个权威人物，指出他们犯了一个错误的想法是非常恐怖的。但随后，他介绍了闭口不言的潜在后果。你们中队所驾驶的F16战机的载弹量是2000磅，它可以每分钟发射6000发子弹。在你返航接近基地时，错误的按下一个按钮，可能就是一个致命的错误，这会将自己部队的基地给摧毁掉。有了这些补充说明后，答案就很明显了。透明度不能是可有可无的。\n汇报的做法会让团队在下一次任务（或事故）来临时变得更强大，适应性更强。但汇报成功的奥秘并不神秘，但往往却求之不得：完全透明。\n在汇报过程中，官衔等级应该被抛弃，自我要放在一边。\u0026ldquo;当汇报室的门关上时，一些神奇的事情就会发生，\u0026ldquo;伯克说。\u0026ldquo;军衔铭牌从我们的胸前脱落了，我们举行的汇报并没有等级制度，唯一的目的就是学习和改善。\u0026rdquo; 伯克敦促队友成为 \u0026ldquo;自己最大的敌人\u0026rdquo;，暴露自己的错误，并承诺今后要做出改变。队友们不是将责任推给他人，而是从同伴那里获得信心。\n创造这种环境需要领导层有意识地付出努力，为各种等级的队友提供一个安全的空间，让他们坦诚相待。\u0026ldquo;我们的IT领导者必须找到一种方法，来创造这样的环境，让他们的员工能够给他们提供所需的诚实、实时的反馈，以帮助他们做出正确的决策，使他们领先于威胁，领先于竞争者，领先于不可避免的变化。\u0026rdquo;\n通过事后回顾总结提升事故管理 接受伯克的说法：\u0026ldquo;汇报是世界上最强大的工具，组织中人员的经验可以得到加速度成长，帮助你团队中的每个人都成为奇才，并推动产生更好的成果。\u0026rdquo; 如果我们真正想实践持续改进，事后总结应该是一致的、彻底的、广泛分享的。\n第一步是确保你的团队在每一个事件发生后都要进行事后分析。 其次，事后总结需要检查事故解决过程中实际发生的细节，而不仅仅是产生问题的原因。在一个安全的环境中，团队成员会很自在地分享他们可以做得更好的地方，并确定需要改进的地方。 最后，还要在整个组织内分享学习成果，这样经验就不会被忽略，否则就无法积累组织的知识。你永远也不知道，谁可能需要在下一次事故中实施这些经验，这些学习将帮助他们更好地准备起来，应对各种状况。 我们的任务可能在飞行高度上有所不同，但在原则上非常相似。承受极端的压力。高风险。以及永无止境的学习空间。借鉴战斗机飞行员的实战经验，我们可以成为自己组织中的特立独行者，将我们的流程提升到新的高度。透明度、诚实，以及对学习和改进的承诺，将会使我们的事故管理飞速发展。\n","date":"2021-03-23T19:45:57+08:00","image":"https://martinliu.cn/img/cos/2021-03-23-f-16-fighter-pilot-1-scaled.jpg","permalink":"https://martinliu.cn/blog/fighter-pilots-and-incident-management-cn/","title":"战斗机飞行员如何进行事故管理（译文）"},{"content":"本文的原文地址：[https://thechief.io/c/editorial/future-DevOps -15-trends-2021/](https://thechief.io/c/editorial/future-DevOps -15-trends-2021/ ) 本文是一篇译文，旨在学习，并分享给社区。\nDevOps 和整个IT运维是一个不断发展的领域，本文的趋势就是证明。总是需要跟上趋势并利用其优势。\nDevOps 正在与机器学习和人工智能等各种技术创新不断发展和融合，这些创新将在2021年占据更多的领域。\n学习这些趋势，并在你的 DevOps 实践中实施它们，将使你在这个革命性的领域中保持活力。\n在过去十年的引入中，DevOps 已经成长为许多IT公司不可或缺的一部分。\n专家预测，到2025年，DevOps 市场规模将达到128.5亿美元。在软件工程中实施 DevOps 所带来的效率和众多优势，是其被大量采用的关键驱动力。\n年复一年，软件开发领域总有一些新的实践出现，有些则被抛弃。\n在本文中，我们将探讨 DevOps 的上升趋势和实践，以及对2021年该行业的期望。\n1-DevSecOps 将成为新的 DevOps 随着企业拥抱无服务器、Docker、Kubernetes和其他现代云技术，安全将一如既往地成为高度优先级，成为 DevOps 的默认部分。\n与 DevOps \u0026ndash;开发团队和IT团队的融合类似，DevSecOps 将是将安全融入开发和IT运维团队。\n技术研究公司国际数据公司(IDC)预测，到2024年，DevSecOps 将推动亚太地区至少50%的新应用，这让 DevSecOps 从2021年开始有了成长的乐土。\n2-AIOps 的实施率将上升 自2017年以来，采用人工智能和机器学习来增强、自动化和管理IT运维，是 DevOps 过程中的革命性改变。\nGartner 的研究指出，到2023年，40%的DevOps 团队将利用人工智能进行IT运维（AIOps）来增强应用和基础设施监控工具。\n随着超过30%的IT组织已经利用机器学习和人工智能，越来越多的组织将采用 AIOps 来提高关键 DevOps 任务的效率和自动化程度，为IT操作人员腾出时间用于更有价值的业务活动。\n3-基础架构自动化（IA）将更占主导地位 基础设施管理工具将帮助 DevOps 团队将自动化引入交付、配置和IT基础设施管理。\nIA 应用可以无缝地自动化IT基础设施的交付、配置和管理，帮助 IT 团队提高工作效率和可靠性。\n2021年，企业将开始用企业级的 IA 工具取代自定义设置，实现部署和配置的自动化。\n4-混沌工程将成为常规的测试技术 混沌工程\u0026ndash;在生产中对软件进行实验，以建立对系统抵御突发事故能力的信心的学科，在 DevOps 中会变得更加重要。\n软件被要求具有高效和冗余性，混沌工程提供了这方面的测试以及更多。\nGartner 提出，到2023年，40%的组织将实施混沌工程作为 DevOps 的一部分，这将减少高达 20% 的意外停机时间。\n5-在 DevOps 流程中实现更多自动化 实际上，每个IT组织都在以某种方式使用自动化。Business wire 的一份报告显示，美国61%的组织广泛使用自动化。\n企业正在意识到自动化的力量和好处，并将其引入到 DevOps 的每一个层面，从开发，到部署和管理阶段。\n在2021年，DevOps 将获得并使用更多先进的自动化工具来评估容易出错的人工执行任务，并更好地在 DevOps 发展中加速开发和部署。\n事实的更广泛的大流行，很多公司正在并将继续进行大量的自动化工作，这是前所未有的。\n6-从设计到部署，公司将采用混合云 随着2020年整个行业经历的转变，远程工作成为新的常态，企业将全面拥抱混合运维。随着企业对其技术堆栈进行的现代化改造，从而利用云的优势，混合云将成为部署的新常态，以及一般的业务。\n企业将开始同时使用内部私有云部署和公有云来进行IT运维。\n7-利用 AgileOps 实现更敏捷的软件交付 AgileOps 结合了成熟的敏捷和 DevOps 技术，为I\u0026amp;O团队提高敏捷性、管理软件开发和快速响应需求。\n快速实时响应用户需求的需求不断增加，将推动 AgileOps 在IT运维中的进一步发展。\n8-基础设施即代码（IaC）将蓬勃发展 IaC 提供了一种通过配置文件来管理IT基础设施的手段，包括服务器、网络、存储设备（内部和云端）。\n通过 IaC，软件工程师可以通过运行一个脚本，来构建一套完整的基础设施，提供部署相同配置的一致性、可靠性，并提高软件开发环境的效率。\n基础设施即代码(IaC)的快速恢复、减少停机时间等优势，将推动更多公司在运维中采用它。\n9-DataOps的趋势是真实的，并将更加成熟 DataOps 将通过使用机器学习模型来预测事故或中断，从而彻底改变 DevOps。DataOps 使用预测分析，拥有彻底改变 DevOps 的潜力。\nItamar Ben Hemo 是 Rivery 的CEO和联合创始人，他写道。\n就像DevOps将软件开发系统化了一样，DataOps旨在加速数据的收集、处理和分析。正如CIO所指出的，\u0026ldquo;IDC在\u0026rsquo;数据到见解\u0026rsquo;的管道中定义了四个核心阶段。识别数据、收集数据、转换数据和分析数据。这些阶段也共同构成了这门新兴学科 DataOps 的核心要素。\u0026rdquo;\n根据Nexla进行的一项调查，73%的公司计划投资DataOps来管理数据团队，关于他们如何使用数据，他们的团队结构和数据挑战发现，73%的公司正在投资DataOps。\n10-无服务器架构将被广泛采用 无服务器(Serverless)计算为应用和软件部署提供了可扩展性，而无需物理硬件成本。\n由于企业正在寻求减少和最大限度地利用开支，以缓解新冠疫情的影响，更多的公司将迁移到无服务器架构，消除管理基础设施的责任，允许他们 \u0026ldquo;为你使用的东西付费\u0026rdquo;。\n将会有一个强有力无服务器的诉求，即我们将把代码推送到云端，其余的操作将由云提供商完成。\n11-DevOps 将更深的实施 Kubernetes 越来越多的公司将开始看到Kubernetes提供的灵活性、可扩展性、自动化、高可用性和可移植性等优势，将带来直接的经济和运维效益，从而开始更深入的应用它。\n12-边缘计算将被重视 组织正在需要处理收集数据的地方依靠边缘计算，以获得更好的延迟、成本优化和分析。\n随着IT操作人员进一步研究过滤监控数据，边缘计算将为DevOps提供这方面的优势，从而在2021年得到更多的应用。\n13-迁移到微服务变得很重要 通过实施微服务，企业将能够控制应用程序并自动管理软件版本，而且风险更低。\n商业企业在2021年及以后继续加速向云计算转移。他们越来越多地以灵活性为代价，尝试微服务带来的新技术栈。\n14-NoOps将来到运维场景（再次） NoOps 的思想是去除DevOps中所有的平台管理部分，减少开发者和基础设施之间的摩擦。\n随着 DevOps 中各种自动化和 AI 的兴起，NoOps 将在2021年登场，之后开始经历颠覆性的增长。\n15-GitOps将研究院 GitOps 是一种集部署、监控、管理于一体的构建云应用的运维模式。GitOps 允许 DevOps 使用开发者工具来驱动运维，在DevOps中建立了一个 \u0026ldquo;你构建，你负责\u0026rdquo; 的流程。\n如果你想了解更多关于 GitOps的信息，请查看我们的播客集GitOps: This is What You Need to Know.\n","date":"2021-03-21T00:05:58+08:00","image":"https://martinliu.cn/img/2021/03/The-Future-Is-Bright.jpg","permalink":"https://martinliu.cn/blog/future-devops-15-trends-2021/","title":" DevOps  的未来：2021 年的 15 个趋势"},{"content":"全球 DevOps + SRE 精选资讯\n本期有 6 个公司的服务出现了宕机事故，一如既往的为你精选了十几篇值得学习的内容。\n[EN] May your queries flow and your pagers stay silent. \u0026ndash;Dave, Betsy, Niall, Stephen, and Ken\n【译】：愿你的咨询队列和传呼机都保持静默。\n宕机 Fastly 3 月事故一览 Fastly是一家 CDN 服务提供商，每个月的事故披露条数大约是 20 到 30 条。本月（三月）已经可以在 https://status.fastly.com/history 看到 23 条事故披露通告。主要内容有三种：事故时间线记录，事故回顾和计划内活动（扩容等）。\n回顾三月份的事故历史，事故类型组要是：\n区域性和全球性的性能事故。 网络路由和 DNS 故障 数据中心计划内的维护、扩容和新上线（新加坡）。 目前一共有 8 个事故回顾。浏览一下大致内容主要是对过去发生过的事故的确认。每一条事故回顾中精确的描述了事故影响起始时间点和影响范围。\n教练观点：看起来他们三月份的日子过的不咋样，不知道这个月的错误预算是否快烧完了。\nOVH Cloud 数据中心发生火灾 这是一家服务器托管/云服务器提供商，数据中心主要在欧洲中西部和美国东岸。\n3 月 10 日这次发生火灾的是位于法国Strasbourg的一个数据中心，该数据中心园区里有 4 栋大楼。从新闻图片上看到有一栋大楼几乎彻底烧毁。\n该公司的创始人/CEO 第一时间在 Twitter 上发布和更新着火灾的状态。\n从这可以看到，数据中心园区中的 SBG2 大楼发生火灾，因此直接关闭里其它的大楼。他每天在 Twitter 上更新一次，在公司官网上 https://www.ovh.com/world/news/press/cpl1787.fire-our-strasbourg-site?124 也可以看到每天一次的更新。\n至今火灾的原因还没有说明，从每日的更新里还可以看到，火灾的影响目前没有完全消除，其它数据中心的电池还有冒烟的情况出现。\n火灾恢复的过程包括：\n对每个大楼的可用状态更新，SBG-3 大楼已经恢复到了 40%可用的状态，团队工作在重启服务器的过程中。 其它三个大楼在逐一恢复抢修中，主要包括这些工作：重启电源供应，重启网络服务，重启服务器。 可以看到他们的救灾工作的三个优先级：\n恢复各个大楼的服务。 在其他数据中心为客户制备新的服务器（承诺了1.5 万台新服务器） 与所有受到影响的客户一起实施 DRP 计划。（灾难恢复计划） 以上三项救灾工作的数据都是日更在以上的网页中。\n教练观点：这个数据中心可谓是非常罕见的大规模灾难，救灾速度和进展还是比较缓慢的，但愿受影响的公司都有自己的扩域高可用容灾方案，希望 DRP 计划执行的顺利有效。\n俄罗斯发生大规模域名解析故障 在 3 月10日，由于俄罗斯的网监局（roscomnadzor 联邦通信、信息技术和大众媒体监督局）对Twitter 的短域名服务 t[.]co 不当屏蔽，导致了全境所有包含了 t.co 的子域名都无法访问，包括例如：Microsoft[.]com 和 Reddit[.]com 的域名，还有很多其它躺枪的域名。\n参考Twitter 上的信息如下：\n教练观点：感觉这个错误犯的有点低级了。\nDyn DNS 服务器故障 这是 Oracle 云的提供的 DNS 服务，本次故障导致大部分客户的 DNS 服务解析失败或者降级，影响范围是所有相关客户。\n调查得到的主要根因：Oracle Public DNS 基础设施实施配置变更是发生了问题。\nChef 服务发生大量 5xx 错误 Chef 的服务不经常发生故障，这次 api.chef.io 服务发生了大量 5xx 错误增多的事故，错误的对象是索引集群。目前故障已经排除，服务恢复了正常。\nGitHub 3 月事故 https://www.githubstatus.com/history 在这个页面上可以看到本月已经发生了 7 次事故。在 3 个严重事故中，有 2 个的事故影响时间接近 2 小时。3-15 日的事故影响了 GitHub Actions 服务。12 日的事故中影响到了绝大多数服务的可用性，但是恢复的还比较快。\n教练观点：我本月体验到了一次 GitHub Actions 构建报错挂住僵死的问题，后来继续提交，GitHub Actions 的 pipeline 又恢复正常工作了。持续时间不太长。\n新闻 \u0016Take the 2021 State of DevOps Survey, be part of our 10-year history 这是我跟踪最长时间的 DevOps 状态调查报告，以前是和 DORA 合作的，在 DORA 被 Google Cloud 收编了以后，Puppet 有开始找的其它大拿继续这个调查。对于计划做行业调查的朋友，还是可以学习一下，这套问卷的设问。\nCD Foundation Announces Industry Initiative to Standardize Events from CI/CD Systems 持续交付基金会发生了，宣布行业级 CI/CD 系统的标准化事件的号召。他们搞了一个 Events SIG 厂商中立的兴趣讨论小组，这个计划对以后所有 CI/CD 流水线系统间的互操作性比较重要。\n软件发布 Java 16 发布 AWS EC2 发布了新的 X2gd 实例，这是一块 ARM-based Graviton2-powered 高内存实例。可达 1TB 内存和 3.8TB 的SSD 存储。 Git 2.31 发布 Ghost 4.0 开源 CMS 系统 Audacity 3.0.0 开源音频编辑软件 SQLite 3.35 发布 文章 本周推荐如下经常文章。\n战斗机飞行员和事故管理有什么共同点？ 我觉得战斗机飞行员对每一次任务，无论成功与否，都会有一个回顾，这真的很新鲜。总有一些东西需要学习。杰西卡-阿贝尔森\u0026ndash;Transposit\nHeroku的事故响应 Heroku应用事故管理系统，指定一名事故指挥官，负责保持事故的正常进行，并监督外部和内部的沟通。Guillaume Winter - Heroku\n可汗学院如何在一周内成功处理2.5倍的流量？ 这个故事正在变得很常见：当大范围居家办公开始时，可汗学员的流量突然暴增。他们的策略包括使用云和CDN。Marta Kosarchyn - 可汗学院\n根基：确保站点可靠性 下面是对Squarespace如何做SRE的精彩总结。Franklin Angulo - Squarespace\n[增量：可靠性] 大规模的可靠性。 Deliveroo、DigitalOcean、Fastly和Headspace的领导们分享了他们的组织是如何看待可靠性和弹性的，以及他们对开始可靠性之旅的工程机构的建议。每位领导都回答了一系列关于他们的组织如何处理可靠性的问题，给出了一个有趣的比较和对比的概述。\n「增量：可靠性案例分析」弹性作为Freshworks的适应性 利用在一场毁灭性的飓风之后制定的灾难计划，Freshworks在这场大流行中幸存下来，并在大流行前的最后期限前交付了一个重要的新产品。伊普西塔-阿加瓦尔\u0026ndash;增量公司\n什么是金丝雀部署？ 本篇解释了什么是金丝雀部署，它如何帮助您，以及金丝雀部署与蓝/绿部署的区别。LaunchDarkly\n如何以成长的心态打造SRE团队？ 这篇文章解释了成长型思维方式的含义，并展示了它如何应用于SRE。艾米丽-阿诺特\u0026ndash;Blameless\n","date":"2021-03-16T19:23:15+08:00","image":"https://martinliu.cn/images/weeklyupdate.jpg","permalink":"https://martinliu.cn/blog/devopscoach-weekly-7/","title":"DevOps 教练周刊 7"},{"content":"2020 年是不寻常的疫情年，所有行业都受到了巨大的影响， SRE 纯分布式工作方式的转型也是本报告的亮点之一。报告从 4 个方面详细介绍了疫情年中 SRE 的众生相。\n本报告出自：https://pages.catchpoint.com/2020-sre-report\n本文是个人学习的结果，非 Catchpint 官方出品，观点尽量与官方保持一致，但个别地方可能难免会出现偏差，有任何质疑请参考原文，或者与我交流。\n概要 SRE 调查贡献者 Catchpoint 要特别感谢 Sanjeev Sharma、Marc Hornbeek、Archana Joshi 和 Niladri Choudhuri。他们的见解和贡献为整个报告奠定了基础。\n我们还要特别感谢 Nithyanand Mehta。Nith 关于成熟度的内部白皮书为本报告的一些关键谈话点提供了灵感。\n感谢 Eveline Oehrlich 和 DevOps Institute 的同事。他们的反馈和时间是至关重要的贡献，超过了本文档所能捕捉到的内容。\n支持伙伴 如果没有 Blameless、Gremlin、Honeycomb、NS1、LaunchDarkly 和 Packet 这些了不起的合作伙伴，Catchpoint就 不可能开展本次 \u0026lsquo;SRE from Home\u0026rsquo; 的调查。\n前言 长期以来，人们一直在讨论客户期望值不断提高的恶性循环，认为这是推动在快速、边缘分布式的环境中提供服务的复杂性不断增加的原因。可靠的方式。今年，我们特别考虑到在家工作的突然增加；我们认为我们的员工和客户一样分布在世界各地。\n我们真的很感激大家为 2020 年的 SRE 报告提供数据，这样就有了两组清晰的数据。今年的报告包括 \u0026ldquo;在家工作前 \u0026ldquo;和 \u0026ldquo;在家工作后 \u0026ldquo;两个时间段的调查结果和数据，提供了业界最独特的视角之一，说明了 2020 年里 SRE 的特殊意义。\n我们评估了600多百名调查对象的数据。在分析数据的同时，我们希望能对当今 SRE 先锋们的趋势、现状和面临的挑战进行真实、人性化的观察。\n我们衷心感谢为本报告做出贡献的所有个人，现在我们也同样感谢您，读者。我们希望您能像我们享受研究和写作一样，享受阅读的乐趣。\n与Catchpoint以前的 SRE 报告一样，我们考虑了那些被认定为从事 SRE 类工作的个人的数据，尽管头衔可能还没有用到 \u0026quot; SRE \u0026ldquo;。\n介绍 从\u0026quot;当你要求软件工程师设计一个运维团队时会发生什么？\u0026rdquo; 这个问题出发，将会得出的答案是：\u0026rdquo; SRE 团队负责其服务的可用性、延迟、性能、效率、变更管理、监控、应急响应和容量规划。\u0026rdquo; 如果说 SRE 是广义的 DevOps 原则的狭义实施，那么它们的主要区别就是 SRE 的核心重点是可靠性。\n以上述问答为基础，今年的 SRE 2020报告强调了一个目标，这个目标可能是关于与所有相关从业者的共同目标，无论他们的头衔是什么： 通过设计可观测的系统来防止服务中断，而不是去被动的修复服务中断 。让我们从一个明确的融合点开始，并向后延伸，使大型或小型组织都能根据这个 2020 年的基线数据进行自我评估。\n如果一个共同的目标是解决复杂的问题，那么这个旅程应该是什么样的呢？在一个由边缘计算工作推动的微服务世界中，这个旅程涉及到的组件比以前更多了，这些现在需要在在家工作的现实中重新评估这些组件。这包括暴露出那些可能会被忽视，或以前并不存在的领域。考虑诸如士气、员工体验和人类健康等问题，与传统的资产类别，如组织结构、工具堆栈、硬件和软件一起考虑。\n关键要点1 ：可观测性组件存在，而可观测性存在么？ 找出你所提供的服务在哪里汇聚成了典型的 数字体验消费点；从那里往后梳理。不仅要考虑到你的代码，还要考虑到网络、第三方和所有交付链中的组件；从客户的应用体验好坏的角度来评估 可观测性三个支柱。问自己：\u0026ldquo;客户的体验是由于那些代码、互联网和网络、第三方或其他交付链组件所构成的？\u0026quot;。\n如果我们提供的能力是通往积极业务成果的门户，那么在当今这个边缘分布、以体验为中心的世界中，几乎没有人可以争驳斥，通过设计和构建可观测系统来进行预防是一种必要的能力。\n当提出 \u0026quot; SRE 使用的工具类别是什么？\u0026ldquo;这个问题时，高达93%的人选择了监控，而53%的人选择了可观测性。当我们深入到进一步的指标问题时，一束耀眼的光芒向我们提出了挑战，并邀请我们对一些监控性的进行深入研究。\n监控和告警 93% 仪表板 73% 基础设施作为代码 71% 分析与趋势 56% 应用程序发布和部署管理 55% APM代码追踪 53% 可观测性 53% 安全 47% 测试 41% 遥测 38% 混沌工程 26% ITSM工具 26% 价值流管理10% 如果说可观测性的学术定义是：\u0026ldquo;根据系统外部暴露的信息，可以推断出系统内部工作状态的好坏\u0026rdquo;，那么我们在说暴露的时候，一定要附加一个情境性的定义，通常是只对于 消费者、客户或者员工的体验。\n考虑一下: 如果一个用户的数字体验由第三方、网络（互联网和内部）、代码和基础设施组成，所有这些要素都汇聚在一个关键点上，就构成了我们所谓的体验。\n而不要拘泥于关于可观测性在实践、度量和追踪（三根支柱）的商业定义，谨防将过多的关注点放在 白盒内部。\n71%的受访者表示错误率是一种他们所跟踪的关键指标。表示客户满意度（数据见下一节）是一个高度优先级，但测量错误率而不是最终用户响应时间，将导致持续关注从内到外而不是从外到内。与其争论各种白盒与黑盒监控理论，不如专注于理解体验，进而研究用户体验交付的组件之间的关联性。\n贵组织跟踪以下哪些指标？\n错误率71% 终端用户响应时间69%。 MTTR 60% MTTD 42% 错误/性能预算 36% 同样值得讨论的是，第三方的关注度或可视性的泛滥。根据 HTTP Archive 的数据，93% 的页面至少包括一个第三方域名；平均一个页面包括 9 个不同的第三方域名！这说明，第三方域名的重要性。然而，只有 11% 的受访者表示他们的自动化工作流程扩展到了第三方供应商。\n鉴于可观测性的支柱也必须适用于第三方组件，也许可以理解为什么只关注白盒内部的引力。就像 SRE 致力于设计可观测性系统是相对新鲜的一样，使用数字体验监控来揭示第三方系统，并收集数据也是比较新的。不过，这里却蕴含着一个黄金机会，可以考虑将黑匣数字体验监控延伸到第三方。仅仅依靠白盒监控意味着你并不知道用户看到了什么，尤其是与第三方有关的情况。例如，无法加载的页面或无法导航的应用程序可能是 CDN、传输网络或 DNS 供应商状态不正常的后果。\n11%的受访者表示，事件管理的自动化工作流程包括含第三方供应商的所有的工作流程。 37%的受访者认为第三方是导致居家办公时事故增加的原因（仅次于流量/容量问题）。 使用了何种仿真监控策略？\n测试 API 测试网络 多步骤交易 测试 DNS 压力测试 测试 CDN 没用使用 对于仿真用户测试，这里的一个关键指标是，只有 39% 的用户在使用了仿真的多步骤交易来模拟用户体验。\n与其他监控特定组件（如DNS或CDN）的用例相比，或与完全不使用任何仿真监控的受访者相比。\nSRE团队在多大程度上实施了全面的应用程序和基础设施性能监控和告警？\n监控和告警的自动化程度高。监控系统足够智能，能够辨别是否需要对特定事件发出告警。44% 我们有系统级的性能监控和自动告警，但没有应用级的。 21% 我们可以看到一些应用和系统的情况，但在一些关键领域，我们没有能力监控。20% 有的只是实时监控的仪表盘。没有自动化的。 12% 没有实时监控，值守的团队会收到来自客户支持的人工提醒。 4% 89%的受访者表示他们执行监控活动，44%的受访者表示监控和告警是高度自动化的。这是个好消息，说明白盒内部考虑的周全。但坏消息是，对内部的明确关注导致我们想当然了，关注数字体验的外在黑盒监控仍然被误解。对于这一点，我们提供了以下观点，供企业在通过设计可观测系统成熟到预防措施时进行评估。\n找出你所提供的服务在哪里汇聚成了典型的 数字体验消费点；从那里往后梳理。不仅要考虑到你的代码，还要考虑到网络、第三方和所有交付链中的组件；从客户的应用体验好坏的角度来评估 可观测性三个支柱。问自己：\u0026ldquo;客户的体验是由于那些代码、互联网和网络、第三方或其他交付链组件所构成的？\u0026quot;。\n在服务层面是否有健康监控，以便能够检测到中断或性能问题（在服务层面）？\n每个服务都有自己的监控和告警，并且有自己的健康检查API，可以插入到我们的可观测性框架中。43% 有些服务有自己的监控和告警，有健康检查API，但有些服务却没有。27% 每个服务都有自己的监控和告警。没有健康检查API或可观测性框架。19% 没有服务级监控。 9% 不适用。我们的系统中没有独立的服务。我们都是单体应用。2% 可观测性就是要回答以前无法回答的问题，因为它与 \u0026ldquo;为什么\u0026quot;有关。\u0026ldquo;为什么\u0026quot;用户无法访问我的网站？\u0026ldquo;为什么\u0026quot;用户无法访问自己的数据？\u0026ldquo;为什么\u0026quot;用户的情绪如此失望？\n回答 \u0026ldquo;为什么\u0026quot;的能力应该由一个框架来驱动，而不是由某个单点工具。这是一个如此重要的指标性问题，我们提出来作为本节的结尾。如果43%的受访者将他们的数据插入可观测性能力框架，那么57%的受访者则没有这样做。在下一节中，我们将通过一些关键的 \u0026ldquo;开发\u0026rdquo; 与 \u0026ldquo;运维\u0026quot;数据来进一步探索这一差距。\n关键要点 2 ：人肉运维负荷的代价 实施 DevOps 的 SRE 原则，通过设计和构建可观测性的系统来预防事故。努力将可靠性进一步向左移动，获得降低成本、团队调整和业务收益等成果。以开发工作与运维工作各占一半时间为基准，在运维工作中 On-Call 值守的比例不超过 25%。然后，当你向着预防的最终目标进行管理场景的迭代时，找出制约因素，从而消除约束点。达成最后成果以奠定了一个 SRE 团队的基础。当你消除约束点时，之后相应的更新你的场景。\n如果维持系统的成本有高达90%是发生在系统的部署之后（即向右转移），那么为什么企业还是以操作型、被动式为主的方式来进行？在这本章的这个小节中，我们探讨了这一问题，并提出企业的 SRE 有机会向左转移，帮助企业履行所有的工作，并转化为成熟的、可观测性的能力。\nGoogle 建议应该有一个上限目标，即50%的运维工作和50%的开发工作（或者称为\u0026quot;55分\u0026rdquo;）。在理想情况下，运维工作的数量应该比这少得多。运维工作中的 On-Call 部分应该不超过25%。开发活动与运维活动各占一半工作量的目标似乎是一个空想。根据调查数据显示，大部分工作都是以运维类活动为主。\nSRE 的工作时间中开发工作的比例占多少\n当受访者被问到：“SRE 的工作时间中开发工作的比例占多少？”这个问题时，只有 14% 的人表示超过 50%。\n当被问到基本相同的问题时（但列出具体的选择让人们选择），如 \u0026quot; 在这些活动中哪些活动是SRE工作的一部分？\u0026ldquo;时，结果令人大开眼界。\n25% : 选择开发活动（如：开发应用，写有助于运维的软件） 75% : 选择运维活动（如：处理工单，事故响应） 在家工作两个半月后，净增10%的受访者表示，他们的活动已经转变为包含更多的运维工作。\n居家工作的 Dev vs Ops\n在家工作以来，你的工作活动有什么变化？（Dev vs Ops） 太多的开发 5% 多了一些开发 11% 大致相同 57% 更多运维 17% 太多的运维 9% 在你的组织中，谁在执行 SRE 工作活动？\n我们有一个专门的SRE团队，独立于其他运营/管理团队。46% DevOps团队处理SRE活动。19% 业务和系统管理小组负责SRE活动。16% SRE活动在全组织范围内开展，而不是局限于一个团队。13% SRE对我们来说还是个新事物，我们还不清楚这是否需要单独的。7% 如果我们都在通过设计和实施可观测系统来进行预防，那么我们还有很长的路要走。首先，我们要走的路很长。最重要的是，考虑采用\u0026rdquo;建立它，就会实现\u0026ldquo;的方法来改造一个 SRE 组织。首先要从识别那些作为是DevOps 的 SRE 工作开始。根据我们的调查，83%的人认为自己在做 SRE 活动。不过，我们提醒大家，你认为正在从事的 SRE 活动，并不意味着你是一个 SRE 。这是因为我们必须将其作为一个整体来考虑，而不是将其作为一部分或几块。 SRE 团队的定义越来越明确，但跨度也越来越大。在不同的焦点上，确实使 SRE 工作被埋没或隐藏起来。\n46%的人声称有一个专门的 SRE 团队。然而，53%的人表示，他们在生命周期的后期才参与其中，因此遇到了挑战，52%的人表示说他们花了太多时间排错（稍后再谈）：关键的 SRE 反模式指标。\n对事故和问题作出反应是 SRE 生活的一部分。如果我们重新提出了一个核心目标，即通过设计预防措施来实现可观测系统，那么旅程的阶段可能是这样的。\n被动的 -\u0026gt; 主动的 -\u0026gt; 前瞻/预防的\n在这种情况下，我们问 SRE 们都进行哪些被动性活动。在这一问题上，我们问道：\u0026rdquo; SRE 从事哪些被动活动？这里的目的是帮助确定公司可能在哪些方面开始成熟起来。根据自己的业务和组织的背景，从被动到主动。\n从每一个问题的结果来看，事后回顾和应对系统产生的告警分别名列前茅。然而，读者查看这些结果的另一种方法，是将他们分类看。然后判断你是否应该在某个分类上更成熟。例如，如果事后回顾类型与分析包括 SLI 和 SLO 在内的度量指标有重叠，然后再考虑是否可以将整体分析作为预防之路的起点。\n在你的组织内， SRE 参与了哪些 \u0026ldquo;被动 \u0026ldquo;活动？\n通过计划的活动对问题进行事后分析。80% 响应系统生成的告警信息 75% 分析指标，包括 SLI、SLO、SLA等指标 72% 文档记录所获的知识 69% 基础设施问题的维修 68% On-Call 轮值 68% 审查并回应客户报告的支持工单 58% 一般行政任务（如进度报告、内务管理）49% 重现客户报告的问题 47% 为客户安装、配置和/或调试应用程序。41% 如果没有人在做救火的反应，那么我们可以认为我们所做的一切都是主动的。与其孤立地辩论一项活动的性质，不如转移话题，提问\u0026quot;我们这样做能防止什么事情发生？\u0026quot;。这样，在讨论 SRE 章程是什么样子的时候，对话就可以转向基于结果的方式。理想情况下，我们希望将服务运维优化到不再需要持续的人力工作的程度，这样 SRE 团队就可以专注于高价值的活动。\n你在哪些 \u0026ldquo;主动\u0026quot;活动上花费了适度或大量的时间？\n自动化任务，使其无需手动执行。61% 监控和分析系统指标，以发现可能导致未来出现故障或SLA问题的趋势。56% 支持部署后行动 54% SRE专用系统规划 53% 编写优化运维操作的软件 48% 与开发部门合作，帮助开发应用程序 42% 系统的预防性维护 41% 容量规划活动 38% 通过混沌工程等实践进行弹性检查。19% 作为 SRE 工作的一部分， SRE 要做哪些活动？\n监控 89% 事故响应/故障单和解决升级问题 83% 指标分析 78% 帮助基础设施和业务能力规划的努力 74% 与开发部门合作，帮助他们开发应用程序 74% 记录所获知识 71% 编写软件帮助操作 65% 质量保证测试和发布 30% 当去掉主动或被动的限定词，问\u0026rdquo; SRE 在这些活动中，哪些是作为 SRE 工作的一部分\u0026quot;时，我们看到监控和事故管理被列为首要活动。同样重要的是，编写优化运维操作的软件被排在第五位。牢记开发应该是最主要的活动类型（相对于运维），考虑是什么原因导致了目前的状态。\n章程是否不正确或不存在？ 是否没有考虑到 SRE 原则的必要性？ 是否没有评估以客户为中心提供服务的方法？ 还能问什么？接着问\u0026quot;为什么\u0026rdquo;？ 一旦 SRE 的工作和价值得到认可，就可以开始得到回报。为了帮助获得支持，将对话与某种业务背景联系起来。例如，当可靠性被提前考虑而不是推迟考虑时，就会降低系统的拥有成本。让一个可靠的系统，更加可靠要容易得多。\n将谈话的重点放在解决复杂问题和实现业务目标的动力和愿望上；将这一数据点作为基线。\n您如何考虑 SRE 和DevOps团队的关系？\n41% 的人说DevOps和 SRE 是同一个团队的一部分。 26% 的人说DevOps和 SRE 是互补的。 19% 表示不知道 11% 表示二者是竞争关系 在度量变更的业务影响方面，这些指标各有多重要？\n客户满意度下降 82% 收入损失 79% 客户流失 79% 雇员生产力下降 69% 社交媒体的吐槽 59% 幸运的是，调查对象能够阐明如何从业务角度衡量成功。\n修炼能力是获得正向业务成果的通道。当进行\u0026quot;我们为什么需要 SRE \u0026ldquo;的对话时，不要只谈能力或只谈积极的结果。相反，要将它们结合起来，说\u0026quot;这些能力将帮助我们实现这些结果\u0026rdquo;。\n有多少个专职与 SRE 活动的团队成员？\n在本节结束时，有一个巨大的机会，可以在早期阶段将被动的业务工作向左移。从\u0026quot;不仅仅是帮助开发\u0026rdquo;，而是\u0026quot;从工作结果中获取反馈，并将其作为一种投资，用于帮助构建/提升产品或服务的可观测性\u0026rdquo;。例如，在 SRE 拿起那个传呼机后（开始 OnCall 工作），他们所记录的注意事项，可能会引指导下一波服务的开发工作，以避免落入相同的坑。\n我们最后的想法是， SRE 参与整体生命周期的想法适用于任何组织的规模。换句话说，旅程的各个阶段还是一样的。\n实施 DevOps 的 SRE 原则，通过设计和构建可观测性的系统来预防事故。努力将可靠性进一步向左移动，获得降低成本、团队调整和业务收益等成果。以开发工作与运维工作各占一半时间为基准，在运维工作中 On-Call 值守的比例不超过 25%。然后，当你向着预防的最终目标进行管理场景的迭代时，找出制约因素，从而消除约束点。达成最后成果以奠定了一个 SRE 团队的基础。当你消除约束点时，之后相应的更新你的场景。\n关键要点3 ：远程工作转型带来了机遇和挑战 将新出现的或以前被忽视的挑战转化为战略上差异化的机会。关注士气、员工体验、工作/生活平衡、员工参与度和情绪等挑战，可以展示公司员工至上的心态，吸引或留住顶尖人才。\n任何其他头衔的 SRE 仍然会创造商业价值。但是，企业是否重视他们的 SRE 呢？\n如果说，\u0026ldquo;正确对待你的员工，他们就会正确对待你的客户 \u0026ldquo;只是一句座右铭，那么现在愿它成为你的战斗口号。\n在 SRE 2020 调查问卷的一组有关在家工作前的问题中，受访者指出了他们面临的一些关键挑战。然后，在两个半月的在家工作后，又有更多的挑战浮出了水面。\n这包括以前可能被忽视的挑战，或者对一些人来说不存在的挑战，它们都浮出了水面。诸如士气、员工体验、工作/生活平衡、员工参与度和情绪等挑战；现在企业有机会将其转化为战略性的差异化资产了，公司展示出员工至上的心态。换句话说，如果说 \u0026ldquo;正确对待你的员工，他们就会正确对待你的客户\u0026quot;这句话，在以前只是一句座右铭，那么现在愿它成为一个战斗口号。\n居家工作之前\n哪些问题具有一定或极强的挑战性？\n常常在生命周期后期参与 53% 调试时间过长 52% 缺乏其他团队的支持 47% 培训预算不足 46% 监控技术过于耗时 45% 在非办公时间经常提供支持 39% 工作压力过大，缺乏支持 38% 工具预算不足 36% 居家工作之后\n\u0026lsquo;在家\u0026rsquo;后，你面临着哪些问题？\n工作/生活平衡 60% 团队沟通 56% 重点/清晰度 51% 设施，包括设备和宽带 42% 隔离/鼓励 41% 激励 39% 心理健康、压力或情绪健康 37%； 工具技术栈 23% 界定成功指标 22% On-Call 值守 12% 其他 7% \u0026ldquo;在这段经历中，我发现我发现：每天在家带孩子是压力最大的部分。一般来说，保持工作与生活的平衡是很困难的，但当你经常失去注意力时，很难不觉得自己和其他人是一样的努力工作（即使你的公司是支持你的）。\u0026rdquo;\n\u0026ndash; 受访者反馈\n在我们 2019 年的 SRE 报告中，得分高的琐事泛滥是最严重的，59%的受访者认为组织中的琐事太多。在我们的 SRE 2020 报告中，我们重新验证了这一发现，并扩展到按分布式的数据形式展示。\nSRE 的工作有百分之多少是琐事？\nSRE 的工作有百分之多少是琐事？\n41%的受访者表示，他们的工作有一半或更多是琐事。考虑到： 1）高琐事率 2）附加问题中60%的受访者将工作/生活平衡列为在家工作后的头号挑战，我们建议企业从战略上考虑降低职业倦怠（透支/996）的方案。\n在此，我们将琐事（本身可能正是人们时常需要的精神激活剂）与倦怠（我们要避免的结果）区分开来。\n一个组织在处理大量的工作时，要考虑到缺乏自动化的根本原因。如果结论是由于缺乏技能或人力，那么前进的道路可能会与长期积累的大量技术债务不同。\n如果团队的目标一致，或者优先级一致，那么自动化能力是否可以扩大？首先梳理开发+运维是否有根本性的缺失？最起码，在\u0026quot;开发\u0026quot;与\u0026quot;运维\u0026quot;时间各占一半的情况下，要有一个基准线，以了解工作量的差距。然后，与管理者对话，使团队有一个合理的期望；而不是，例如，觉得他们应该做到‘零运维’的工作。\nSRE 的琐事主要来源是那些？\n可以自动化的人工维护任务 29% 关于可自动化的应用程序发布的工作 19% 可以自动化的人工值守任务 18% 解决假阳性/阴性问题 16% 非紧急服务相关信息 13% 解决与服务无关的信息 12% 使用自动化进行自修复的问题和事件的百分比是多少？\n45%的人说监控技术太耗时。这是一个机会，可以通过可观测性能力将重点放在预防措施上，同时还可以扩展到使用软件（而不是人）来解释数据，并判断是否需要采取行动。与其生成告警，再要求人来决定是否需要采取行动，到不如只在应该由人采取行动的时候，才触发告警。然后让系统实际执行行动。\n为了帮助企业实现这种向可操作性告警方向转变，我们说：\u0026ldquo;你不可能对所有的事情都进行监控和告警，所以先从最重要的事情：开始对‘用户体验’监控和告警\u0026rdquo;。在这种情况下，各种人工智能(\u0026ldquo;AI\u0026rdquo;)或机器学习(\u0026ldquo;ML\u0026rdquo;)能力才可能会有用武之地。\n16%的人认为解决假阳性/阴性是一个主要的苦恼来源。\n您是否使用自动化工具进行容量规划和制备？\n手工容量规划+自动化制备 手工制备+自动化容量规划 容量规划和制备都是手工的 是的，容量规划和制备都是自动化的 容量规划根据预算周期或者是否冻结走 看到这个数据，我们有些惊讶。在我们的2018年 SRE 报告中，65%的受访者表示，他们全部或部分使用云计算。我们预计这个数字从那时起就会增加（尽管我们今年没有明确提出这个问题）。随着云提供的各种功能，包括各种 \u0026ldquo;特性/函数即服务\u0026rdquo;，我们对评估什么是可自动化的，以减少琐事和随后的透支的建议仍然是相同的：当在分析组织中为何存在大量琐事时，缺乏自动化解决方案，最可能被认为是根本原因。那如果得出的根因结论却是：技能或能力的欠缺呢？那么在前方的道路上，可能就不会在长期的积累大量技术债务了。\n您的 SRE 团队成员有哪些培训和认证？\n内部辅导和培训方案 78% 云厂商认证（如 AWS，GCP，Azure） 51% 工具厂商的培训或特殊工具 40% 个人或者团队参加第三方 DevOps 课程 29% 个人或者团队参加第三方 SRE 课程 24% 个人或者团队参加第三方 ITILv3 课程 16% 缺乏预算和培训（来自前面的挑战清单），再加上大量的琐事，就会导致透支。正如我们增编问题的数据所显示的那样，这些问题更加严重，工作/生活平衡（60%）和专注/清晰（51%）是在家工作之后，关于‘幸福感’（well-bing）的两个最高挑战。\n内部辅导和培训是之间存在着关联性的方案(78%)，但对 SRE 培训的预算不足。这表明内部计划可能不那么有效。该数据也让我们不得不问，是否调试时间过长（52%）？是因为培训在这里也是一个空白。既然内部培训是最主要的培训方式，那么就要看这些项目的效果。培训教练或团队领袖是否是该领域的专家？这是否是一个挑战？希望做内部培训是否是没有预算的直接后果？牢记我们的愿望是：让员工提高工作效率，那么深入的 SRE 培训 和扎实的理解 SRE 角色是必不可少的，通过设计和实施系统的可观测性，来实施预防措施的路线图。\n我们还是将缺乏工具预算的问题也纳入了培训的这一章节，因为缺乏预算是两者之间的共同主题。不幸的是，员工生产力下降的指标，是商业影响的第二低指标，因此投资于培训可能是应该开始做了。\n在 2019 年的 SRE 报告中，琐事和压力是首当其冲的焦点。我们可能用的是一些预期的反应来调查。\n你在家后面临哪些心理/个人幸福感的挑战？\n工作/生活平衡 60% 专注/清晰 51% 隔离 41% 动力 39% 精神健康、压力或情感幸福感 37% 其它 2% 以上问题的解决思路包括：\n使用自动化消除琐事 通过无职责文化，消除事故回顾的压力 通过可观测性的能力转换到主动度量，在根本上减少事件 大多数组织的强制在家工作的政策，都凸显了更加关注员工的幸福感的必要性。当读者看到这个关于在家的数据集时，请问：\u0026ldquo;这个数据集的结论，如何使年初调查数据的结论变得更好或更坏？\u0026quot;。例如，那些感觉到被隔离的人，在之前，他们会觉得沟通或缺乏支持是问题么？会对其有什么影响？他们会不会可能感到得到了更多或更少的支持？\n将新出现的，或以前被忽视的挑战转化为战略上的差异化机会。关注士气、员工体验、工作/生活平衡、员工参与度和情绪等挑战，可以展示公司员工至上的心态，以吸引或留住顶尖人才。\n关键要点4 ：远程 SRE 光明的未来 重新评估各种业务连续性方案。考虑是否需要调整恢复时间和恢复时间点。在进行灾难或连续性演习时，确定现在可以实施预防措施的机会领域。在您的 SRE 章程中记录任何新的洞见。\n在我们的 SRE 2018 年调查中，按《纽约时报》的风格，这个标题是这样说的。\n\u0026ldquo;如果你想远程工作， SRE 角色可能不适合你。虽然有些 SRE 是远程工作的，但 81% 的 SRE 表示，他们团队的所有或大部分工作都在办公室里进行的。\u0026rdquo;\n我们想到的第一个问题是：\u0026ldquo;当世界重新开放时，你的员工中，有百分之多少会首选\u0026quot;远程/在家办公\u0026rdquo;（有多少比例的人的次要选择是\u0026quot;现场/办公室\u0026rdquo;）？\u0026rdquo; 在一个异步、世事纷繁的时代，这个数据可能不会让你感到惊讶。\n预期远程工作人员的百分比\n考虑到从全员现场、到分布式劳动力的转变，我们希望进一步研究其他变化因素，为决策者提供一个投资方向。需要应对哪些新的挑战？事件管理是什么样的？如果没有了办公桌，将如何运行他们的灾难恢复桌面演习？\n我们不想在说\u0026quot;远程 SRE 的未来很遥远\u0026quot;的时候，做出\u0026quot;水很深 \u0026ldquo;式的说法。而是说，远程 SRE 的未来是光明的，但也要注意以下几点。\n\u0026ldquo;小学教师工资发的不够\u0026hellip;\u0026hellip;\u0026rdquo; \u0026ndash;调查对象\n牢记本报告之前关于希望通过设计和实施可观察系统来预防事故的评论。然后考虑这些直接、宏观的问题，对你的 SRE 章程有什么影响。\n主动式与被动式相比（向更多的被动式净增2%）没有开发与运维相比（向更多的运维净增10%）的差距那么大。在这里，我们再次参考在家工作前的数据，表明75%的受访者在做运维活动（而25%在做开发活动）。\n自从 \u0026ldquo;在家工作 \u0026ldquo;后，你的活动有什么变化？(主动与被动)\n太多主动了 4% 主动多些 14% 基本一致 60% 有点被动 16% 太被动了 4% 自从 \u0026ldquo;在家工作 \u0026ldquo;后，你的活动有什么变化？(开发与运维)\n太多开发了 5% 开发多了一些 11% 差不多持平 57% 运维多了一些 17% 太多运维了 9% 我们想了解事件的绝对数量以及相对数量（下一页）。需要提醒的是，\u0026ldquo;在家工作后\u0026quot;这组调查问题，在家工作的两个半月后提出的。\n在家后，你负责的站点或应用经历的事故更多/少吗？\n无/零 17% 1 次 9% 2~5 次 42% 6~10 次 11% 要多得多 21% 对于，\u0026ldquo;自家工作以来，发生的事件多还是少\u0026rdquo;，数据形成了一条正态分布的钟形曲线。不过，在这个问题中，最突出的是7%的人不知道!\n在家后，你所负责的站点或应用经历了更多/少的事故 更少 9% 差不多相同 73% 更多事故 9% 不知道 7% 流量增长和/或容量问题 54% 第三方问题 37% 发布管理相关变更 25% 测试和质量控制 25% 安全 4% 其它 16% 流量和(或)容量问题的增加被认为是导致事故增加的首要因素。第三方被认为是第二大因素，这也是为什么，我们在本报告的第一部分中，讨论了有必要考虑如何处理第三方依赖的策略。\n我们想指出，只有那些表示自从在家工作后发生更多事故的受訪者们，才被问及这个问题。但我们想把数据包括在内，考虑到尽职。\n净+9%的受访者表示，自从在家之后，事件管理变得更加有效。这是一个令人振奋的数据，我们不知道更好的事件管理是否与公司做更少的发布有关（根据 Atlassian 的这个数据，66%的受访者已经放慢了他们软件的发布频率) 注意14%的受访者选择了无法评价和识别机会，看看是否是由于在家的原因。\n请评价贵公司自\u0026quot;在家\u0026quot;以来事故管理流程的有效性\n\u0026ldquo;在家 \u0026ldquo;时，效果较差（MTTR较高）5%。 大约相同的MTTR 66% \u0026ldquo;在家\u0026quot;时更有效(MTTR较低) 14%。 无法评价 14% 我们在 \u0026ldquo;在家后\u0026rdquo; 调查中问的最后一个直接问题是：\u0026ldquo;你或你团队中的任何人，是否不得不去现场？\u0026rdquo; 对于回答\u0026quot;是\u0026quot;这个问题的14%的人，我们后续的开放式问题：\u0026ldquo;有多少次？他们的答案各种都有，有总是和每班一个人（跟着太阳走）的，有只有一次和每两周一次的。\n从\u0026rsquo;在家\u0026rsquo;开始，你有没有不得不去现场过？\n是的 14% 不是 86% \u0026lsquo;在家\u0026rsquo;后，事故管理在哪些方面变得更具挑战性？\n检测事故发生/宕机 9％ 查明事故根本原因 9％ 向正确的团队升级 28% 修复根因 8% 验证修复是否成功 13%。 以上的都不是 51% 在我们努力结束今年的报告之际，我们提供最后一个数据点。公司重新评估他们将如何继续运营。我们问道：\u0026ldquo;你们多久执行一次针对在家场景的灾难恢复演练\u0026rdquo; 当你考虑到你的各种恢复时间可能是如何 受影响的情况下，考虑到以前的路径，到预防性的座右铭，因此你要努力设计和实施系统的可观察的问题。\n你们多久执行一次针对在家场景的灾难恢复演练？ 完全没有 40% 还没有；我们正在计划26% 随机19% 每月5% 每周5% 其它5% 可观测性是指能够回答\u0026quot;为什么我们客户体验到了这个效果？\u0026rdquo; 是不是因为第三方，应用代码、传输网络或其他交付链中的组件，如DNS或CDN？然后使用这些答案来迭代改进现有的，或新建的产品或服务。\n当\u0026quot;内建\u0026quot;可靠性时，要考虑到开发和运维之间的分裂。在您制定 SRE 章程时，您可以将其与业务工作进行比较。这里的目标是：尽早将可靠性纳入其中，因为提升一个已经靠谱了的系统，还是要来的要更容易些。\n最后，考虑到您的员工队伍的分布性质，并承认可能被忽视或被忽视的一系列挑战。无论存在与否，都要考虑到诸如，琐事、缺乏支持、工作/生活平衡，以及，孤独感可能会导致的某些操作规则或流程被取消，都要从根上重新进行评估。\n方法论 2020年1月，Catchpoint进行了一项通过电子邮件列表和社交媒体推广的 SRE 调查。 该调查询问了来自不同行业的技术专业人员，调查关于他们作为站点可靠性工程师 SRE 角色。通过报告，这组问题被称为\u0026quot;预先\u0026quot;问题集。\n2020年6月，Catchpoint 又进行了一项增补调查，加入了关于新冠疫情（COVID 19）后，居家办公的考虑。这组问题旨在询问各种\u0026quot;发生了什么变化\u0026quot;的问题，被称为\u0026quot;后疫情\u0026quot;或\u0026quot;在家 \u0026ldquo;问题集。\n在编写本报告时，收到了共有594名调查对象的反馈。在预定的时间里，其它人在格式化本报告和编写附录的过程中在也纷至沓来，统计周期的只对本报告的统计数字产生了较小的影响，不超过1%。\n","date":"2021-03-01T11:29:33+08:00","image":"https://martinliu.cn/img/2021/03/2020-sre-report.jpg","permalink":"https://martinliu.cn/blog/2020-sre-report-by-catchpoint/","title":"《2020 年 SRE 报告》by Catchpoint"},{"content":"本工作坊包括本地虚拟机版本、AWS 和腾讯云共三个版本，目标是用实践的方式理解 Elastic 可观测性解决方案。可观测性是解决运维云原生应用的复杂性和分布式式难点的关键所在。\n简介 Elastic 可观测性解决方案是基于 Elastic Stack 的一站式解决方案。该解决方案具有完备的日志、指标、APM 和可用性采集能力，可以在大规模/云原生的环境下，完成服务质量目标（SLO）的管理。本实战工作坊基于多层架构的宠物诊所为示例应用程序，手把手的引导参与者搭建可观测性管理平台，体验分层次的收集整合、分析、关联和搜索运维数据的全过程。\n为什么要做这个工作坊？ 从理论的理解到技术工具的实操掌握需要一个过程。\n关于可观测性的各种一小时左右的技术、方案、产品分享，完全无法让听众正确理解可观测性的相关概念 而通过实操性质的，上机动手实验则可以让新手迅速入门，使熟手快速全面的提高 大量 ELK 用户只使用到了日志管理的部分功能，还不了解任何一种可观测性管理方案的全貌 社区里的朋友们对可观测性心存大量误解，如“ APM 工具就等于可观测性” 等等，因此相关的正确观念和技术急需尽快普及 通过半天的实战演练，彻底学会相关知识。\n动手实验 本工作坊的最佳参与方式是在老师的引导下，在线下/线上同步进行。其次是在视频的指导下自学。所有动手实验的目标是：理解可观测性解决方案的各个组成部分，以及为什么要使用这些工具？而且这个整个方案的实施过程和顺序也是经过精心设计的，目标是让理论和实际彻底融会贯通。\n您将会学到：\n搭建单节点 Elasticsearch 服务，并且配置好 Kibana 管理图形管理界面。 学习可观测性的基本概念和实施步骤 搭建和配置服务健康检查的探针 部署采集操作系统性能监控指标的流程 配置操作系统日志的采集和分析工具 搭建用于 APM 追踪分析的后台服务 运行一个多层架构的宠物商店应用，对各个子服务进行 APM 监控埋点 配置常用的服务质量监控大屏 本工作坊课程基于如下的应用系统。\n应用基本概况：\n多层宠物商店应用系统 所有组件都部署在一个虚拟机上 包括前端、后端和内置的数据库 使用到的技术有 JavaScript、NodeJs 和 Java Spring 等。 本应用系统是被监控的对象 Elastic Stack 的基本状况：\n版本 7.9.3 组件 Elasticsearch、Kibana、APM、Filebeat、Metricbeat 和 Heatbeat。 实验环境：\n本地虚拟机环境，打包好的虚拟机里包含了所有必要的软件包和演示应用。 AWS 云环境，本课程所使用的公共 AMI 操作系统镜像：宁夏区 ami-0e5a0e294902966af 北京区 ami-0e1382088b62cb38d 腾讯云环境，基于腾讯云提供的 Elasticsearch 服务，演示用的虚拟机在制作中，稍后会发布到云市场。 阿里云环境，基于阿里云提供的 Elasticsearch 服务的课件正在开发中。 可观测性构建四步法 可观测性依赖于应用系统自身和监控工具平台的配合实现。\n分层次的构建可观测性的推荐过程如下：\nSTEP0：使用 Heatbeat 构建轻量灵活的服务健康检查能力 STEP1：使用 Metricbeat 构建全面细致的指标采集能力 STEP2：使用 Filebeat 构建高维度的日志采集能力 STEP3：使用 APM 构建分布式应用系统的全堆栈追踪能力 通过以上的四个构建步骤，使用 Elastic Stack 实施四大服务质量监控能力的构建，搭建了持续统一运维管理的工具平台。\n使用 SRE 基于‘用户旅程’或‘系统边界’的 SLO 分析设定方法，从 Elastic Stack 的已有数据采集能力中，选取第批直接可用的 SLI 采集点。在基于 SLO 的监控过程中，不断的优选 SLI，调整告警的数量和质量，为开发团队提供持续有效的反馈。\n使用 Canvas 的画布功能，定制如下的 SLO 监控大屏。\n工作坊课件 讲师 PPT 下载： https://docs.qq.com/slide/DUGRzYVVTU3ZxblBP\n本地虚拟机环境 可以使用本地的 VirtualBox 或者 VMWare 的虚拟机环境，配合以下课件完成所有练习。\n‘Elastic Stack 单节点搭建’ 课件 ‘Elastic 可观测性方案’ 课件 AWS 云计算环境 可以使用 AWS 云计算（中国区北京或宁夏区）环境，配合以下的课件完成所有练习。\n‘Elastic Stack 单节点搭建’ 课件 ‘Elastic 可观测性方案’ 课件 腾讯云计算环境 可以使用腾讯云计环境，配合以下的课件完成所有练习。\n在本环境下，不需要搭建 Elastic Stack 的服务器，参展下面课件的第二步骤，创建 Elasticsearch 服务集群。 ‘Elastic 可观测性方案’ 课件 腾讯云环境录播网址：腾讯课堂查看 阿里云计算环境 可以使用阿里云环境，配合以下的课件完成所有练习。\n课件开发中。\n如何参与本工作坊？ 本工作坊会在多个社区中举办，具体安排如下：\n定期在 Elastic 社区中举办可观测性主题的线上或者线下的社区活动，具体报名方式， 请关注 Elastic 公司的官方微公众号 “Elastic搜索”。 关注 Elastic 公司社区在百格的社区活动报名网址：https://www.bagevent.com/org/738410 Elasitc 用户日 专场活动，接受企业的团队预约，可以在约定的时间里，通过线上或者线下的方式进行，建议参与学习交流的人数在 10~20 人。 预约邮件： zheng.liu@elastic.co 由于 Elastic Stack 产品的更新迭代速度特别快，本工作坊的软件版本和学习课件也会不定期更新。欢迎大家积极参与 Elastic 技术社区的交流和学习活动。\n","date":"2021-02-06T10:36:12+08:00","image":"https://martinliu.cn/img/2021/Hubble_01.jpg","permalink":"https://martinliu.cn/blog/workshop-elastic-observability/","title":"Elastic 可观测性工作坊"},{"content":"最近更新了新的博客样式，再次搬迁回到了 GitHub 平台，并使用了 Github Action 的自动化 CI/CD 发布功能。这个是一个任何人都可以拥有的方案，现在用最简洁的语言分享给大家。\n选择将博客搭建在 Github 上的原因包括：\nGithub Pages 是一个免费使用的功能，在不强求网站访问速度，考虑持久性的情况下，Github Pages 不失为一根优秀的羊毛。 用 master 分支管理 hugo 站点的所有代码和文件（markdown、网站模板和图片），用 gh-pages 分支存放 Hugo 编译后的网站发布文件 Github Actions 功能实现了自动化的编译和部署功能，使用它所提供的工作流将 master 分支中的更新编译后发布到 gh-pages 分支中 而 Hugo 是一款比较流行的静态网站管理软件，可以在各种操作系统轻松的安装本地的博客环境，在本地的操作系统上实现博客的预览和测试。Hugo 的社区提供了大量的免费网站模板，不同类型的模板可以满足各种网站需求。\n选择 Hugo 博客主题 在 https://themes.gohugo.io/ 可以搜索到大量的免费网站模板。我这次选择了名为 “HUGO FUTURE IMPERFECT SLIM” 的模板。\n这是一个功能非常丰富的模板：\n界面简洁，兼具丰富的格式，博客文章有头图 带有侧栏 带有 ‘about’ ‘categories’ ‘contact’ 等独立页面格式，无头图 具有多语言支持和菜单选择 带有搜索页面 带有讨论功能 对我而言这些都是很快就都可以用到的功能。\nHugo 博客本地安装和配置新手指南，参考这两篇文章。\n零基础使用 Hugo 和 GitHub 搭建个人博客 使用 Hugo 生成静态博客教程 GitHub Pages 新手指南 在 https://pages.github.com/ 提供了视频和文字版本的新手指南教程。为了方便新手理解，下面就使用‘user or organization site’这个最常用的选项做简要说明：\n创建与自己的 Github 用户/组织 同名前缀的公开代码仓库，例如：zhangsan/zhangsan.github.io 选择在命令行里（前提是安装配置好了 Git，否则使用图形化界面 GitHub Desktop 工具） 克隆第一步创建的那个代码库到本地电脑的目录中。 创建只包含 ‘Hello World’ 为内容的主页测试文件。 推送本地的更新到 Github 服务器端 在本地的浏览器中查看测试网页 http://zhagnsan.github.io/ GitHub Pages 的新手指南已经包含在了上一节推荐的两篇文章中。\n使用 Github Actions 自动化发布博客更新 本地的测试环境是非常重要的，可以帮我们快速的掌握 Hugo 的基本使用方式，测试和选择网站模板。在模板确定了以后，就进入了日常的内容更新过程中，平常内容更新的工作都是在 master 分支中进行。并不会在本地操作 gh-pages 分支，这个分支里只会存放的是 Hugo 编译之后结果内容，即 public 目录中的内容。\n你可以在代码库的 Actions 标签页面中，创建一个默认的演示工作流文件，在本地做一个测试更新，用 push 动作测试触发和执行它。从无到有的创建新工作流文件的过程在这里不讲解。\n在本使用 Github Actions 的功能的主要目的如下：\n通过 master 分支的 push 事件，触发自动化工作流，即 CI/CD 工作流，这里是持续部署的过程。 将 master 分支的内容签出，使用新配置的 Hugo 软件构建全站的所有内容 将构建后的结果发布更新到 gh-pages 分支中。 下面是我所使用的工作流代码和注释。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # 将 Hubo 博客构建后部署到 Github Pages name: Deploy github-pages # 在 master 主干分支的任何 push 事件都会触发本 DevOps 工作流水线 on: push: branches: [ master ] # 以下是本串行执行工作流的所有组成部分 jobs: # 这里只定义了一个名为 \u0026#34;deploy\u0026#34; 的多步骤作业 build-deploy-hugo-blog: # 将后续的所有工作步骤都运行在最新版的 ubuntu 操作系统上 runs-on: ubuntu-latest # 本构建和部署作业的所有步骤定义如下 steps: # Step 1 - Checks-out 你的代码库到 $GITHUB_WORKSPACE - name: Checkout blog code repo uses: actions/checkout@v2 # 这是 Github 官方提供的一个动作模块 with: submodules: true # 同步更新所使用的 Hugo 模板 fetch-depth: 0 # 更新到该模板最新的版本 # Step 2 - 配置最新版本的 Hugo 环境 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 # 这是 Github Actions 市场中的一个动作模块 with: hugo-version: \u0026#39;latest\u0026#39; # Step 3 - 清理代码库中 public 目录中的内容 - name: Clean public directory run: rm -rf public # 彻底删除这个目录 # Step 4 - 用最新版本的 Hugo 构建个人博客站点 - name: Build blog site run: hugo --minify # Step 5 - 创建用于私有域名所需要的 CNAME 文件 - name: Create CNAME file run: echo \u0026#39;martinliu.cn\u0026#39; \u0026gt; public/CNAME # Step 6 - 将构建好的博客站点推送发布到 gh-pages 分支 - name: Deploy blog to Github-pages uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.DEPLOY_KEY }} publish_dir: ./public 后续事项 解决旧文章头图空白的问题 增加文章评论功能 增加 CDN 功能 ","date":"2021-02-06T00:00:00Z","image":"https://martinliu.cn/img/2019/03/pic03.jpg","permalink":"https://martinliu.cn/blog/github-hugo-blog/","title":"在 Github 上搭建基于 Hugo 的免费个人博客"},{"content":"全球 DevOps + SRE 精选资讯\n宕机 上一周新发的宕机事故。 近期全球重大宕机事故的分析总结、事后回顾。 May your queries flow and your pagers stay silent. \u0026ndash;Dave, Betsy, Niall, Stephen, and Ken\n上周新发事故 Zoom 无法开始和加入会议， 官方报道 https://status.zoom.us/incidents/1z2lrf4nrv8p Slack 多个功能模块服务降级，甚至无法使用，官方：https://status.slack.com//2020-08/960bbb3c9d49a3cc Let\u0026rsquo;s Encrypt 数据中心硬件方式故障导致 API 报错，官方：https://status.io/pages/incident/55957a99e800baa4470002da/5f45330250878c04bf3fb6eb NZX 新西兰证券交易所遭受重大DDoS攻击导致NZX停电，交易停止。媒体：https://www.stuff.co.nz/business/122562006/major-ddos-attack-causes-nzx-power-outage-trading-halt eBay宕机。服务器状态最新，DNS故障和服务不可用的错误错误，媒体：https://www.express.co.uk/life-style/science-technology/1329281/eBay-down-server-status-DNS-failure-service-unavailable-error Heroku 发生大量的 H100 报错，官方：https://status.heroku.com/incidents/2101 Fastly CDN 服务商的服务发生多区域性能故障，官方：https://status.fastly.com/incidents/p1lwmmv2j2gq Cloudflare 上周发生的这个问题，我的个人 blog 也遇到了，Google 的搜索索引服务记录了那些 500 错误，我也感到非常诧异；第三方传输供应商问题导致HTTP 5xx错误增加； 官方：https://www.cloudflarestatus.com/incidents/hptvkprkvp23 鳄鱼杯：2020年第二季度最大宕机颁 来源：https://statusgator.com/blog/2020/08/21/5-biggest-outages-of-q2-2020/\n任何可能发生的坏事都会发生。这句古老的谚语100%适用于技术行业，在这个行业中，崩溃和中断远比销售和营销团队希望我们想象的要常见得多。然而，与基础设施打交道的DevOps工程师知道，要确保所有东西都能一直按预期工作是多么困难\u0026ndash;并配置监控，实际跟踪系统的健康状况，帮助防止崩溃和停机。\n在StatusGator，我们监控800多个基于云的服务的状态页面，并向用户提供即时通知。我们拥有堆积如山的宕机和中断数据，并能看到全貌，因此我们决定每季度制定一份最高宕机时间列表。我们希望我们的发现能够激励DevOps工程师去看看其他人是如何处理服务中断的，以便他们能够提高自己的可靠性。\n请继续阅读，了解2020年第二季度的五大故障，以及Slack、Zoom、GitHub、IBM Cloud和T-Mobile在这些危机中如何行动。我们还对这些故障的结果进行了评级，并很乐意听到您对我们评级的看法。\n第一名 Slack 全球范围的服务中断, May 12, 2020 Slack是全球数千家公司的主要沟通方式，因此其稳定的正常运行时间是最重要的问题。因此，当用户在美国东部时间晚上7:30左右停止发送和接收Slack消息时，情况迅速升级为一个全面的问题。与之前的故障期间不同，这影响到了整个Slack生态系统：没有人能够登录Slack，也没有人能够收到任何通知。\u0026ldquo;Slack宕机了吗？\u0026quot;，用户们自问自答，答案是毋庸置疑的 \u0026ldquo;是！\u0026rdquo;\n美国东部时间晚上10:26，Slack报告全面恢复了服务，并再次为造成的不便道歉。更重要的是，他们在Medium上发表了一份详细的事后报告，解释了问题背后的原因，他们为克服这个问题所采取的行动，得出的结论，以及他们正在采取的措施，以消除类似情况再次发生的机会。\n欢迎阅读这篇事后总结，它的技术性很强，但即使是普通人也很容易理解。Slack在这里展示了他们对用户群成员\u0026ndash;包括开发者和大众用户群\u0026ndash;的关心，这篇文章所投射出的信心令人钦佩。\n这里需要注意的是，虽然问题本身是在美国东部时间上午8:30开始的，但直到美国东部时间晚上7:30左右，多名用户报告了Slack的问题，这个问题才完全被人察觉。在Slack团队意识到这一情况之前，他们在应用内部（当时大部分已经宕机）、Twitter上、Downdetector上、Slack网站（很快就宕机了）以及其他许多渠道进行了报告。\n第二名 Zoom 宕机, May 17, 2020 自冠状病毒大流行以来，随着越来越多的人远程工作和学习，Zoom的使用率急剧上升。Zoom状态页面的订阅量也是如此，自4月份以来，StatusGator中的订阅量急剧上升。\n除了企业被迫开始远程办公外，许多教会和其他公共组织也开始使用Zoom来举行周日弥撒、会议以及举办公共活动。因此，虽然周日不是工作日，但英国的许多付费账户很快就发现他们无法主持或加入Zoom会议（免费账户似乎没有受到影响）。这个问题通过多种渠道被报告，包括Twitter和监控Zoom状态的StatusGator。\nZoom发言人回应称，承认意识到了这一情况，并提到这只影响了一个子集的用户。然而，我们都知道子集可能是1%或99%，Zoom没有提供任何关于受影响用户量的说明。提供更透明的受影响用户的比例是一个高质量状态页面的标志，这是Zoom应该改进的地方。\n第三名 GitHub 又无法访问了. June 29, 2020 自从GitHub被微软以75亿美元收购后，GitHub似乎又下降了很多。原因尚未披露，我们只能猜测原因。也许是与GitHub基础设施与微软系统的整合有关。也许是因为GitHub的发展速度更快，增加了更多的功能。无论如何，从收购到现在已经快两年了，用户发现GitHub的持续宕机时间越来越长。我们对GitHub状态页面的独立分析证实，在过去的两年里，宕机变得更加频繁。\n微软正在努力将GitHub变成一个比以前更好的开发者场所。这家雷德蒙德巨头在今年早些时候让所有的付费计划变得更加实惠，并免费提供一些关键功能，将更多的工具放在IT专业人士的手中。微软、苹果、AWS、谷歌、Facebook和其他数千家公司使用GitHub来存储和运行他们的代码仓库，因此它的正常运行时间是最重要的。\n然而，GitHub在2020年6月29日出现了两个小时的故障。整个网站及其服务都无法访问，因此许多开发人员甚至无法推送代码或部署他们的应用程序，因为GitHub集成的数量没有响应。自然，这引起了很大的反响，并导致GitHub除了状态页面外，还推出了每月的可用性报告，对每次中断的原因和结果进行了详细的解释。\n第四名 IBM Cloud 挂了，服务状态页面有更新, June 10, 2020 任何基于云的服务都会犯的最大错误之一就是将其状态页面托管在自己的基础设施上。看来IBM云就是这么做的，所以当它的整个基础设施在6月份有几个小时无法访问的时候，它的状态页面也随之而来。我们本可以期待IBM在今年3月的达拉斯宕机事件后得出一些结论，但是，显然，他们并没有理会，或者说没有做出足够的努力。\n于是，在2020年6月10日，IBM云基础设施在全球范围内宕机。这次宕机使得Watson AI、IBM Cloud Foundry、Kubernetes Service、云对象存储、身份访问和管理、VPS的VPN、App Connect等功能完全无法访问。幸运的是，IBM Cloud状态页面只在中断初期无法使用，后来才断断续续地可用。这也是为什么StatusGator还能向订阅了IBM Cloud状态页面的用户发送提醒的原因。\n该公司完全没有告知中断的原因，以及为缓解影响所采取的措施。后来从一个独立的监控服务机构了解到，一个第三方网络提供商广泛使用了流量路线，导致IBM云配置带宽严重受限。IBM专家对系统进行了重新配置，并恢复了运行，但随后并没有官方的解释或公告\u0026ndash;这让用户非常失望。\n这不是IBM第一次在公共关系上失败，我们认为，也不会是最后一次。这可能是他们尽管提供了多样化的有竞争力的云服务，却远远落后于AWS、谷歌云平台、微软Azure和其他云服务商的原因之一。\n但IBM能做什么呢？自然是有一个独立的状态页面! 下面只是他们可以使用的一些变种。\n第五名 T-Mobile冲洗其网络下水道，2020年6月15日 作为美国、欧盟和英国最大的移动网络运营商之一，T-Mobile最近发现自己正处于一场完美的风暴之中，它在美国各地连续13个小时无法提供语音和短信服务。外界观察家马修-普林斯（Matthew Prince，CEO@Cloudflare）认为，\u0026ldquo;T-Mobile对他们的网络进行了一些改变，但这些改变出了问题，导致他们的用户出现了一连串的故障\u0026rdquo;。他还表示，\u0026ldquo;这场灾难几乎可以肯定完全是T-Mobile团队自己造成的\u0026rdquo;。\n相反，T-Mobile技术总裁Neville Ray在推特上表示，虽然这确实是一个 \u0026ldquo;影响全国用户语音和文字服务的重大问题\u0026rdquo;，但它源于第三方供应商的系统故障，T-Mobile的工程师正在努力修复。随后，他在博客中详细阐述了这一话题，并对故障原因进行了解释。\n引用雷先生的话说：\u0026ldquo;据悉，触发事件是东南部的第三方供应商的租用光纤电路故障。这是每一个移动网络都会发生的事情，所以我们与我们的供应商合作，建立冗余和弹性，以确保这种类型的电路故障不会影响客户。这种冗余让我们失败了，导致了过载的情况，然后又因为其他因素而变得更加复杂\u0026rsquo;。这导致IP池过载，美国所有地区都发生了崩溃。\n由于无法接触到大多数服务，T-Mobile的客户开始报告Facebook、Instagram和其他平台无法使用，而实际上离线的是他们的移动运营商网络。Business Insider报道称，虽然T-mobile客户将故障归咎于AT\u0026amp;T和Verizon，但这两家运营商都是在正常的负载水平下运营的。不过，前述Neville Ray的帖子表示，T-Mobile正在采取一切必要措施，通过为所有核心系统建立双重弹性和冗余措施，确保未来不可能发生此类事件。\n可以看到，公司无法明确表达自己的立场，从一开始就不愿意承担失败的责任，以及在故障发生后缺乏透明度，都没能让T-mobile毫无污点地走出困境。这甚至导致了他们面临大规模DDoS攻击却未能击退的传闻。\nStatusGator为第二季参赛者颁奖 让我们根据这些宕机事件的发现、相关公司的沟通以及每个事件的结果来评定。\n新闻 软件发布 Kubernetes 1.19 发布了， 它由34项增强功能组成。10个增强版转为稳定版，15个增强版在测试版，9个增强版在alpha版。 AWS 发布新的 EBS 卷类型 (io2) 提高 100x 持久性，和 10x 倍的 IOPS/GiB Tekton Hub 预览版上线，随着该项目对底层流水线和构建的定义的日臻成熟，开放出一个相关的自由市场也是必然的，开源生态催生出来的上下游技术提供和消费的模式正在普及中，无周边生态的很难获利和发展，https://hub-preview.tekton.dev/ DevOps 大会/峰会 中国 DevOps 社区流水线大赛 \u0026ndash; Pipeline Craft Championship 8 月 18 日开始为期两个月，免费活动 报名：https://wj.qq.com/s2/6852880/c181 活动官网：https://Pipeline.devopsmeetup.com SnykCon 将在10月21日/22日举行一个关于所有应用安全和 DevOps 的在线活动。免费注册，CFP现在开放。 https://snyk.io/snykcon/ 推荐和分享你感兴趣的大会和峰会给我和其它人吧？发邮件到：martin@devopscoach.org\n文章 这是一篇很好的文章，讲述了在整个组织中获得变革的支持时，自动化这个词所带来的问题，以及为什么观念很重要。\nhttps://blogs.starcio.com/2020/08/avoid-calling-it-automation.html\n什么是Kubernetes Operators，为什么它对SRE很重要？\n在Kubernetes Operators: 自动化容器编排平台》中，作者Jason Dobies和Joshua Wood将Operators描述为 \u0026ldquo;其应用的自动化站点可靠性工程师\u0026rdquo;。鉴于SRE的多方面经验和多样化的工作量，这是一个大胆的说法。那么，Operators到底能做什么呢？\nhttps://www.blameless.com/blog/what-is-a-kubernetes-operators-and-how-to-automate-sre\n探讨遗留IT系统的隐秘世界。探讨了一些值得注意的事件，以及我们需要更多地了解如何建立可长期运行的系统。\nhttps://spectrum.ieee.org/computing/it/inside-hidden-world-legacy-it-systems\n一篇文章，讲述了随着组织的发展，增加一个总括性的平台团队的风险，以及为什么向平台组件和重用发展可以更具扩展性。\nhttps://kislayverma.com/organizations/a-case-against-platform-teams/\nNoOps Go on Cloud Run\nhttps://medium.com/@peter.malina/noops-go-on-cloud-run-689d92215c5c\n工具 werf/werf : GitOps 交付工具 ovh/cds : 企业级持续交付和 DevOps 自动化开源平台， markphelps/flipt 一个现代的功能开关方案 fluxcd/toolkit ： 用 GitOps 的方式组装 CD 流水线的体验版工具包。 学习资源 本周推荐如下 B 站学习资源。\nJenkins+Ansible+Gitlab自动化部署（CI/CD）\nhttps://www.bilibili.com/video/BV1Dp411Z7Lf 持续集成在工作中的应用。 通俗易懂ElasticSearch 项目实践课程\nhttps://www.bilibili.com/video/BV1wA411n7LY 搜房网实例项目讲解 【Python趣味教学】99%相似度！手把手教你用Python制作超级玛丽游戏\nhttps://www.bilibili.com/video/BV1G54y197C2 前26集都在这了，爱编程的小伙伴们，一起来重现童年经典吧！ Kubernetes教程 k8s企业级DevOps实践\nhttps://www.bilibili.com/video/BV1c64y1F7wP k8s是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。 ","date":"2020-08-31T00:11:01+08:00","image":"https://martinliu.cn/images/weeklyupdate.jpg","permalink":"https://martinliu.cn/blog/devopscoach-weekly-6/","title":"DevOps 教练周刊 6"},{"content":"最近发布的 Elastic Stack 7.9 ，带来了很多新的特性。Elastic Agent 统一集成数据采集代理是一大亮点。另外还看增加了企业搜索、端点安全防护等组件。Ingest Manager 统一 Beat 配置管理功能让我们向 SaaS 风格的监控工具又迈进了一步。由代理端自行注册到后端，在后端统一纳管所有被管理服务器，将是一种以后非常通用的模式。这样做的好处是：将数据采集端点的配置工作量和复杂度降低到最低。Beats 的各种相关独立模块也在平行的发布，这种双轨模式也可以让用户更弹性的做出选择，能最大程度的保持旧版本部署环境管理模式的延续性。 Ingest manager 的前提条件是：后台 ES 需要启用 api key 安全，启用 ES 客户端的 HTTPS 访问。我们也可以看到这两个功能选项也有其非常广泛的应用需求。本文将用最简单的文字，向你描述一套 3 节点的 ES 集群的搭建方式，这套系统的核心特性如下：\n启用用户名和密码认证 启用集群内 es 节点间 transport.ssl 通讯加密 启用 es 的 http 客户端 http.ssl 加密通讯 安装脚本中包括创建数字证书的必要命令（没猜错的话，大部分人可能会在这一步花费大量时间） 演示环境介绍 我使用的是本地的测试环境，环境配置如下：\nMac OS vagrant virtualBox - CentOS 8 Elastic Stack 7.9.0 ip 和主机名分配见 Vagrantfile 文件 Vagrant 的 vagrant-hostsupdater 插件实现了 Mac OS 主机和所有虚拟机的 host 文件 DNS 解析的同步，保证所有相关虚拟机都可以解析其它虚拟机的 FQDN，尽量模拟生产环境。 本文所使用的所有配置文件和安装脚本见：https://github.com/DevOps-Coach/elasticstack.git\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ➜ elasticstack git:(master) ✗ vagrant up es1 es2 es3 Bringing machine \u0026#39;es1\u0026#39; up with \u0026#39;virtualbox\u0026#39; provider... Bringing machine \u0026#39;es2\u0026#39; up with \u0026#39;virtualbox\u0026#39; provider... Bringing machine \u0026#39;es3\u0026#39; up with \u0026#39;virtualbox\u0026#39; provider... ==\u0026gt; es1: Importing base box \u0026#39;bento/centos-8\u0026#39;... ==\u0026gt; es1: Matching MAC address for NAT networking... ==\u0026gt; es1: Checking if box \u0026#39;bento/centos-8\u0026#39; version \u0026#39;202002.04.0\u0026#39; is up to date... 省略中间大量输出。。。。。。 es3: ● elasticsearch.service - Elasticsearch es3: Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; enabled; vendor preset: disabled) es3: Active: active (running) since Thu 2020-08-27 05:55:21 UTC; 223ms ago es3: Docs: https://www.elastic.co es3: Main PID: 4205 (java) es3: Tasks: 41 (limit: 11499) es3: Memory: 1.2G es3: CGroup: /system.slice/elasticsearch.service es3: ├─4205 /usr/share/elasticsearch/jdk/bin/java -Xshare:auto -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -XX:+ShowCodeDetailsInExceptionMessages -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dio.netty.allocator.numDirectArenas=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.locale.providers=SPI,COMPAT -Xms1g -Xmx1g -XX:+UseG1GC -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -Djava.io.tmpdir=/tmp/elasticsearch-14730718416313121303 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/var/lib/elasticsearch -XX:ErrorFile=/var/log/elasticsearch/hs_err_pid%p.log -Xlog:gc*,gc+age=trace,safepoint:file=/var/log/elasticsearch/gc.log:utctime,pid,tags:filecount=32,filesize=64m -XX:MaxDirectMemorySize=536870912 -Des.path.home=/usr/share/elasticsearch -Des.path.conf=/etc/elasticsearch -Des.distribution.flavor=default -Des.distribution.type=rpm -Des.bundled_jdk=true -cp /usr/share/elasticsearch/lib/* org.elasticsearch.bootstrap.Elasticsearch -p /var/run/elasticsearch/elasticsearch.pid --quiet es3: └─4360 /usr/share/elasticsearch/modules/x-pack-ml/platform/linux-x86_64/bin/controller es3: es3: Aug 27 05:54:54 es3.zenlab.local systemd[1]: Starting Elasticsearch... es3: Aug 27 05:55:21 es3.zenlab.local systemd[1]: Started Elasticsearch. es3: Provisioning script works good! es3: Please access Elasticsearch https://192.168.50.13:9200 最后的系统登录验证命令：\n1 2 3 4 5 6 ➜ elasticstack git:(master) ✗ curl --cacert certs/ca/ca.crt -u elastic \u0026#39;https://es1.zenlab.local:9200/_cat/nodes?v\u0026#39; Enter host password for user \u0026#39;elastic\u0026#39;: ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 192.168.50.13 26 95 8 0.03 0.31 0.18 dilmrt - es3 192.168.50.12 33 95 0 0.01 0.14 0.09 dilmrt - es2 192.168.50.11 36 93 1 0.06 0.16 0.12 dilmrt * es1 以上命令需要输入 elastic 用户的密码，es1 节点初始化了所有 Elasticsearch 内置用户的密码，需要复制 console 中的那一段密码信息备用。\n创建以上所有数字证书和秘钥文件的种子文件是 certs/instance.yml ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # instance.yml instances: - name: \u0026#39;es1\u0026#39; ip: [\u0026#39;192.168.50.11\u0026#39;] dns: [ \u0026#39;es1.zenlab.local\u0026#39; ] - name: \u0026#34;es2\u0026#34; ip: [\u0026#39;192.168.50.12\u0026#39;] dns: [ \u0026#39;es2.zenlab.local\u0026#39; ] - name: \u0026#39;es3\u0026#39; ip: [\u0026#39;192.168.50.13\u0026#39;] dns: [ \u0026#39;es3.zenlab.local\u0026#39; ] - name: \u0026#39;es4\u0026#39; ip: [\u0026#39;192.168.50.14\u0026#39;] dns: [ \u0026#39;es4.zenlab.local\u0026#39; ] - name: \u0026#34;es5\u0026#34; ip: [\u0026#39;192.168.50.15\u0026#39;] dns: [ \u0026#39;es5.zenlab.local\u0026#39; ] - name: \u0026#39;es6\u0026#39; ip: [\u0026#39;192.168.50.16\u0026#39;] dns: [ \u0026#39;es6.zenlab.local\u0026#39; ] - name: \u0026#39;es7\u0026#39; ip: [\u0026#39;192.168.50.17\u0026#39;] dns: [ \u0026#39;es1.zenlab.local\u0026#39; ] - name: \u0026#34;es8\u0026#34; ip: [\u0026#39;192.168.50.18\u0026#39;] dns: [ \u0026#39;es2.zenlab.local\u0026#39; ] - name: \u0026#39;es9\u0026#39; ip: [\u0026#39;192.168.50.19\u0026#39;] dns: [ \u0026#39;es3.zenlab.local\u0026#39; ] - name: \u0026#39;lk\u0026#39; ip: [\u0026#39;192.168.50.20\u0026#39;] dns: [ \u0026#39;lk.zenlab.local\u0026#39; ] 这里一次性生产了所有我这个本地测试环境里可能用到的数字证书文件。\nElasticsearch 安装脚本 下面是第一个 Elasticsearch 节点的安装脚本和注释，pre-install-es1.sh ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #!/bin/bash # author: Martin Liu # url:martinliu.cn #指定安装的版本 elastic_version=\u0026#39;7.9.0\u0026#39; #开始安装流程 echo \u0026#34;Provisioning a Elasticsearch \u0026#34;$elastic_version\u0026#34; Server...\u0026#34; sudo date \u0026gt; /etc/vagrant_provisioned_at #配置 ES 需要的操作系统参数 sudo swapoff -a sudo sysctl -w vm.max_map_count=262144 sudo sysctl -p sudo sh -c \u0026#34;echo \u0026#39;elasticsearch - nofile 65535\u0026#39; \u0026gt;\u0026gt; /etc/security/limits.conf\u0026#34; #设置个性化 SSH 登录提示信息 sudo sh -c \u0026#34;echo \u0026#39;**** -- -- -- -- -- -- -- -- ****\u0026#39; \u0026gt; /etc/motd\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;**** Welcome to Elastic Stack Labs\u0026#39; \u0026gt;\u0026gt; /etc/motd\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;**** -- -- -- -- -- -- -- -- ****\u0026#39; \u0026gt;\u0026gt; /etc/motd\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;*\u0026#39; \u0026gt;\u0026gt; /etc/motd\u0026#34; #安装 ES 软件包 sudo rpm -ivh /vagrant/rpm/elasticsearch-$elastic_version-x86_64.rpm #创建 ES 集群内部通信加密数字证书，提前清理旧的证书文件和目录 sudo rm -f /vagrant/certs/certs.zip sudo rm -rf /vagrant/certs/es* sudo rm -rf /vagrant/certs/ca sudo rm -rf /vagrant/certs/lk sudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert -in /vagrant/certs/instance.yml -pem -out /vagrant/certs/certs.zip -s #解压缩所有证书备用 sudo /usr/bin/unzip /vagrant/certs/certs.zip -d /vagrant/certs/ #部署节点需要的秘钥 sudo cp /vagrant/certs/ca/ca.crt /etc/elasticsearch/ sudo cp /vagrant/certs/es1/* /etc/elasticsearch/ #更新 ES 默认的配置文件 sudo cp /vagrant/es1.yml /etc/elasticsearch/elasticsearch.yml #配置和启动 ES 系统服务 sudo systemctl daemon-reload sudo systemctl enable elasticsearch.service sudo systemctl start elasticsearch.service sudo systemctl status elasticsearch #初始化 ES 服务器内建用户的密码，这些密码需要在控制台上复制保存备用 sudo /usr/share/elasticsearch/bin/elasticsearch-setup-passwords auto -b #成功顺利的完成了安装 echo Provisioning script works good! echo Please access Elasticsearch https://192.168.50.11:9200 说明：你也可以参考以上脚本手工执行，如果是非 Vagrant 环境，请注意替换各个命令中相关文件的路径。第二个和第三个节点的安装脚本稍有不同，详情见代码库。\nElasticsearch 配置文件 下面是第一个 Elasticsearch 节点的参考配置文件， es1.yml ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 # ---------------------------------- Cluster ----------------------------------- #设定集群名称 cluster.name: elk4devops # ------------------------------------ Node ------------------------------------ #设定节点名称，此处使用的是 hostname node.name: es1 # ----------------------------------- Paths ------------------------------------ #设定 es 服务器数据目录 path.data: /var/lib/elasticsearch #设定 es 服务器日志目录 path.logs: /var/log/elasticsearch # ---------------------------------- Network ----------------------------------- #设定此节点加入网络的名称，这里使用的是 FQDN network.host: es1.zenlab.local # --------------------------------- Discovery ---------------------------------- #设定初始的 master 节点为 es1 cluster.initial_master_nodes: [\u0026#34;es1\u0026#34;] discovery.seed_hosts: [\u0026#34;es1.zenlab.local\u0026#34;] # ------------------------------- TLS and Cert --------------------------------- #启用用户名和密码认证 xpack.security.enabled: true #启用 ES 集群内加密传输 xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.certificate_authorities: ca.crt xpack.security.transport.ssl.key: ${node.name}.key xpack.security.transport.ssl.certificate: ${node.name}.crt #启用 ES 集群客户端访问加密 xpack.security.http.ssl.enabled: true xpack.security.http.ssl.certificate_authorities: ca.crt xpack.security.http.ssl.key: ${node.name}.key xpack.security.http.ssl.certificate: ${node.name}.crt # For Elastic Agent xpack.security.authc.api_key.enabled: true #启用监控数据收集 xpack.monitoring.collection.enabled: true # ------------------------------- App Search --------------------------------- #提前为 App Search 做好准备 action.auto_create_index: \u0026#34;.app-search-*-logs-*,-.app-search-*,+*\u0026#34; 说明：第二个和第三个节点的配置文件稍有不同，详情见代码库。\n总结 在三节点集群的搭建过程中，最好建议启用各种安全和加密选项，用配置安装脚本最小化工作量；这样一步到位的安全性，可以为后续增加其他 Elastic Stack 的产品组件打下良好的基础，ES 集群的配置尽量完善，尽量覆盖后期的其他各种潜在需求，减少未来配置变更的工作量，让后续的测试越来越轻松。\n","date":"2020-08-27T13:54:46+08:00","image":"https://martinliu.cn/images/abstract-6.jpg","permalink":"https://martinliu.cn/blog/elasticsearch-3-nodes-cluster-setup/","title":"Elasticsearch 3 节点集群搭建 (7.9.0)"},{"content":"宕机 上一周新发的宕机事故。 近期全球重大宕机事故的分析总结、事后回顾。 May your queries flow and your pagers stay silent. \u0026ndash;Dave, Betsy, Niall, Stephen, and Ken\nEquinix 重大电力故障让数据中心客户大发雷霆 关于 Equinix ：Equinix 是全球领先的数据运营商，目前在美洲、亚太、欧洲及中东 14 个国家（地区）的 31 个市场运营着 94 个国际业务交换。 消息来源 CBR https://www.cbronline.com/news/equinix-outage 教练点评：数据中心 UPS 的单点故障并不稀奇，但是这次 Equinix 的事故堪称史诗级事故。\n\u0026ldquo;经历如此严重的停电，显然是不可接受的\u0026rdquo;\n北京时间 8 月 19 日 8 点 10 分更新：最后的电路似乎已经在 8 月 18 日晚间约 22 点 20 分恢复；在停电开始后约 18 小时。\n数据中心巨头 Equinix 表示，在其位于伦敦码头区的 IBX LD8 数据中心遭遇长时间停电后，它已经为所有客户恢复了机架\u0026ndash;该问题使数百名客户（包括几家 ISP）的服务从北京时间凌晨 4:30 开始离线；使许多人对缓慢的电力恢复深感沮丧。\n\u0026ldquo;Equinix 工程师已将问题的根本原因诊断为 UPS（不间断电源）系统故障，我们正在与客户合作，以尽量减少影响。该公司在北京时间 8 月 18 日 12:04 的首次公开声明中表示：\u0026ldquo;我们对由此造成的任何不便感到遗憾。(ISP Giganet 负责人 Matthew Skipsey 早些时候将 Equinix 缺乏沟通描述为 \u0026ldquo;糟糕透顶\u0026rdquo;)。\n多名客户指出，该问题是 Galaxy UPS 系统(由施耐德销售)中的输出静态开关出现故障。该开关将关键负载连接到 UPS 的条件电源或旁路电源的原始电源。停电时间的长短表明，LD8 的 A+B 交流电源是来自同一个 UPS。期望其直流供应商确保弹性和依赖单一数据中心的 ISP 正在吸取惨痛教训。\n伦敦互联网交易所 LINX 同时表示，约有 150 名 LINX 会员直接受到此次事件的影响。(到 13:42，LINX 的所有设备都恢复了。该组织有 900 多个 ASN 从 80 多个不同的国家连接）。)\n受影响的一个客户是 ISP Giganet。它告诉客户。\u0026ldquo;我们仍在等待我们的网络架恢复供电 继 Equinix 和他们的承包商在早期故障后将电源迁移到新的基础设施上之后。\n\u0026ldquo;可悲的是，仍然没有估计的修复时间，这是最令人沮丧的。他们已向我们保证，他们将在可能的情况下提供这一信息。Equinix 不断被追问最新情况。正如您所了解的那样，这是一个 P1 问题，影响着许多 100 多家其他运营商/ISP\u0026ndash;所以它被赋予了最大的优先级。\u0026rdquo;\n据了解，英国电信也是受影响的公司之一。数据中心的访问控制系统已经被中断，一个客户，马修-斯基普西说，\u0026ldquo;所以一切[是]通过双向无线电手动运行，然后通过其他地方打电话。疯狂的时代。这是一个 MBORC 的地狱。\u0026rdquo;\nEquinix 表示，它允许客户 \u0026ldquo;更灵活地访问 LD8\u0026rdquo;，因为它争分夺秒地解决这个问题，\u0026ldquo;在我们的 COVID-19 限制内工作\u0026rdquo;。\nGiganet 补充道：\u0026ldquo;我们已经在凌晨 4.23 时左右失去了我们 2 个 Equinix LD8 机架中的 1 个机架的两个 A+B 馈线。此前，根据 Equinix 的报告，UPS 出现故障，然后触发了数据中心的火警。我们失去电源的机架上安装着我们的核心 Juniper MX 路由器和 Cisco LNS。瞻博网络 MX 路由器是我们的核心设备，LD8 中的一切功能都需要它，包括终止一些专线连接以及为我们的 vDC 平台提供连接。我们所有的设备电源都是由数据中心提供的\u0026rsquo;多样化\u0026rsquo;A+B 电源双馈\u0026ndash;但是经过这次事件，我们怀疑是缺乏弹性，在事件解决后一定会提出来，因为经历如此严重的断电显然是不可接受的。\u0026rdquo;\nGoogle 公司的云平台和 G Stuit 系列事故 来源官方 https://status.cloud.google.com/incident/zall/20008#20008005 Google Cloud Infrastructure Components Incident #20008 GCP 多个产品发生故障：App Engine, Cloud Storage 和 Cloud Logging G Suit 多个模块和功能：Gmail, Drive, Docs/Editor, Chat, Meet, Keep, Voice, Jamboard, Admin Console 事故时间：August 19, 2020, from 20:55 to 03:30 诊断：AppEngine 的部署会报错，访问 GCS 桶时的高延迟，以及 Cloud Logging 中的日志条目丢失。G Suit 多种产品报错和无法使用。 详细的事故总结报告https://static.googleusercontent.com/media/www.google.com/zh-CN//appsstatus/ir/bd9m3vkqwpvkk4j.pdf 根本原因 许多 Google 服务使用一个通用的、内部的、分布式的系统来存储不可变的、非结构化的数据，也就是二进制大对象，或者说 blob。这个 blob 存储系统包含一个与 Google 内部客户端服务对接的前端，一个处理元数据操作的中层，以及一个用于存储数据的后端。blobs 本身。当客户端向前端提出请求时，元数据操作被转发到元数据服务，元数据服务与存储服务进行通信。 来自另一个 Google 服务的流量增加开始使元数据服务超载，导致任务变得不健康，请求的延迟增加。这种延迟促使这些操作的过度重试，导致资源耗尽。自动化系统试图启动新的元数据任务。然而，其中许多任务立即被其收到的流量所淹没，而这些任务也被淹没。由于资源枯竭，分配到的资源不足。这一问题因以下原因而更加严重： 策略用于取消和重试失败的请求，这对流量造成了倍增效应。 与其他产品相比，谷歌云存储受到的影响较小。虽然谷歌云存储是建立在 同一个 blob 存储系统，GCS 的元数据层大多与受影响的元数据层隔离。谷歌内部元数据服务。对于 \u0026ldquo;美国\u0026rdquo;，GCS 元数据隔离的迁移正在进行中。多区域，而所有其他迁移工作已经完成。因此，对全球通信系统客户的影响是 减少，这种影响仅限于 \u0026ldquo;美国 \u0026ldquo;多区域。 教练点评：从事发时刻到 Google 工程师收到告警的时刻（20：58）之间只有短短的 3 分钟，在一个小时内受影响的各个 GCP 服务就开始了并行的调查和补救措施。在 23：00 定位到 blob 存储是根因故障，并实施配置变更，消除了大多数的内部错误。这正是 SRE 中所讨论的重大事故应急流程的有效执行，能快速有效的恢复服务。可以看出 Google 团队在事故响应方面的训练有素。\nSpotify 来源官方 Twitter 账号： https://twitter.com/SpotifyStatus/status/1296064517504409600 这好像是由于 TLS 证书过期导致的。 其它媒体报道： https://www.teiss.co.uk/spotify-outage-expired-tls-cert/ 据报道，周三发生了影响音乐流媒体服务 Spotify 的长达一小时的大规模中断，原因是该公司未能在 TLS 证书到期前更新。 不过，Cloudflare 的网络工程师 Louis Poinsignon 提供了 Spotify 系统内部到底发生了什么事情的线索。据他介绍，该公司显然没有及时更新 TLS 证书，证书过期导致中断。在 TLS 证书更新后，Spotify 的服务很快就恢复了在线。 教练点评：Spotify 的特有的团队工作开发模式一直是一种学习的榜样，很难想象他们的服务会在这样简单的问题上翻船。\n新闻 DevOps 大会/峰会 中国 DevOps 社区流水线大赛 \u0026ndash; Pipeline Craft Championship\n8 月 18 日开始为期两个月，免费活动 报名：https://wj.qq.com/s2/6852880/c181 活动官网：https://Pipeline.devopsmeetup.com GitLab 的大会 \u0026ndash; Commit: You belong here\n8 月 26 日 线上免费峰会 https://about.gitlab.com/events/commit/ 推荐你感兴趣的大会和峰会，发邮件到：martin@devopscoach.org\nGrafana Labs 喜提 B 轮 5000 万美元融资 来源官方：https://grafana.com/about/press/2020-08-17-series-b-announcement/ 8 月 27 日宣布 Grafana Labs 还宣布了 Grafana 加速器计划（GAP），以培养在更广泛的 Grafana 生态系统中进行创新的早期公司和副业项目。GAP 将提供免费的 Grafana Cloud 和 Grafana Enterprise 订阅、现金补助、股权融资以及进入 Grafana Labs 核心开发者的内部通道。 教练点评：这个 CNCF 的热门项目终于迈向了商业化的第一步，随着企业订阅模式的形成，且看后续的创新开发和社区经营是否也能一浪高过一浪。\n文章 《 Ops 工作的未来 》\n一篇关于运维角色变化的好文章。对于那些想知道现代运维是什么样子的人来说，有一些很好的提示，包括供应商管理、外包基础设施和理解社会技术系统的重要性。\nhttps://acloudguru.com/blog/engineering/the-future-of-ops-jobs\n《 NAT 是如何工作的 》\n对于任何想要更好地了解这个网络领域的人来说，这是一本很好的 NAT 网络介绍。好的图和例子，还有很多细节。\nhttps://tailscale.com/blog/how-nat-traversal-works/\n《 如何打造给董事会看的软件开发 KPI 报表 》\n度量标准有很多不同的用途，包括向组织高层报告。这篇文章探讨了用于董事会对话的工程 KPI。\nhttps://codeclimate.com/blog/engineering-kpis-board-deck/\n《 马丁富乐老师：单链接通道 》\n有没有想过确保服务之间的消息保持有序，并为任何丢失的消息建立重试机制？这篇文章描述了一个具体的模式，但也是一组关于分布式计算模式的文章的一部分，值得探讨。\nhttps://martinfowler.com/articles/patterns-of-distributed-systems/single-socket-channel.html\n《 提升事故回顾质量的套路 》\n事故回顾越来越常见，但往往很难做好。这段视频和详细的文字记录有各种改进流程的技巧。\nhttps://www.blameless.com/blog/improving-postmortems-paul-osman\n《 应用日志开发的最佳实践 》\n即使你不是用 Java 编写应用程序，掌握一些关于日志工作的知识通常也是有用的，因为你可能最终会至少运行一些 Java 应用程序。这些帖子提供了一个坚实的基础。\nhttps://sematext.com/blog/java-logging/\nhttps://sematext.com/blog/java-logging-best-practices/\n工具 标签对于大规模管理 AWS 资源至关重要。Awstaghelper 提供了一个命令行工具，可以轻松地在广泛的 AWS 资源中向 CSV 文件或从 CSV 文件中添加和管理标签。\nhttps://github.com/mpostument/awstaghelper\nGitOps 工具包是一套可组合的 API 和专门的工具，可用于在 Kubernetes 之上构建一个持续交付平台。它们应该可以为 Flux 的 v2 提供基础，但也可以用来构建其他有趣的高级工具，采用同样的控制循环方法。\nhttps://toolkit.fluxcd.io/\nKip 是一个虚拟 Kubelet 提供商，它允许 Kubernetes 集群透明地将 pods 发射到自己的云实例上。如果你需要额外的工作负载隔离，这很方便。\nhttps://github.com/elotl/kip\n学习资源 这里推荐一些值得关注和学习的免费视频学习资料。\n教练点评：B 站里的相关视频是不可忽视的学习资源。善加利用，就可以加速获取知识的进度。\n波波老师的系列课程\nhttps://space.bilibili.com/518029478/video 包括 k8s 和微服务等 DevOps 技术 【SpringBoot 项目实战】 2020 最新在线教育 spring boot 分布式项目实战\n系统后端接口部分，使用目前流行的 SpringBoot+SpringCloud 进行微服务架构，使用 Feign、Gateway、Hystrix，以及阿里巴巴的 Nacos 等组件搭建了项目的基础环境。项目中还使用 MyBatisPlus 进行持久层的操作，使用了 OAuth2+JWT 实现了分布式的访问，项目中整合了 SpringSecurity 进行了权限控制。除此之外，项目中使用了阿里巴巴的 EasyExcel 实现对 Excel 的读写操作，使用了 Redis 进行首页数据的缓存，使用 Git 进行代码的版本控制 https://www.bilibili.com/video/BV1y7411y7am 播放量： 10w+ 2019 谷粒商城微服务 SpringBoot,Dubbo,MySql 高级,Redis 秒杀,ElasticSearch,ActiveMQ,SSO 单点登\nhttps://www.bilibili.com/video/BV1B4411V7cA 2019 谷粒商城微服务 SpringBoot, zookeep 注册中心, Dubbo, MySql 高级, ElasticSearch, ActiveMQ, 通用 mapper, 解决秒杀, SSO 单点登录, OAuth2 协议三方登录, 第三方支付接口对接, Redis lua 脚本, Redis 秒杀, Redis 分布式锁, 集群搭建, 分布式, sku,spu 表结构介绍, 等等技术结合使用~~~~~~~~~~~ 播放量： 10w+ Git+GitHub 教程\nhttps://www.bilibili.com/video/BV1pW411A7a5 Git 是先进的分布式版本控制系统，而 Github 是常用的 Git 代码托管中心。 本套教程内容丰富、详实，囊括：Git 安装过程、本地库基本操作、远程基本操作、基于分支的 Gitflow 工作流、跨团队协作的 Forking 工作流、Eclipse 中的 Git 版本控制以及 Git 对 Eclipse 特定文件忽略的配置方法。还通过展示 Git 内部版本管理机制，让你了解 到 Git 高效操作的底层逻辑。教程的最后完整演示了 Gitlab 服务器的搭建过程。 播放量： 21w+ GitLab 与 GitFlow 的简单使用\nhttps://www.bilibili.com/video/BV1Wb411e7ec 播放量： 1w+ ","date":"2020-08-25T15:20:51+08:00","image":"https://martinliu.cn/images/weeklyupdate.jpg","permalink":"https://martinliu.cn/blog/devopscoach-weekly-5/","title":"DevOps Coach 周刊 5"},{"content":"宕机 上一周新发的宕机事故。 近期全球重大宕机事故的分析总结、事后回顾。 May your queries flow and your pagers stay silent. \u0026ndash;Dave, Betsy, Niall, Stephen, and Kent\n新闻 项目发布速递 Azure Functions 的 PowerShell 7 支持现在是 GA，如果在 PowerShell 中编写无服务器函数对你有吸引力。 Go 1.15 - 流行的编程语言。 AWS Glue 2.0 - AWS 上的 ETL 作业服务。 Node 14.8.0 - 服务器端 JavaScript 运行时。 DevOps 大会/峰会 中国 DevOps 社区流水线大赛 \u0026ndash; Pipeline Craft Championship\n8 月 18 日开始为期两个月，免费活动 报名：https://wj.qq.com/s2/6852880/c181 活动官网：https://Pipeline.devopsmeetup.com 提交大议信息发邮件到：martin@devopscoach.org\n文章 编写 Kubernetes Operators 的 7 个最佳实践。SRE 的观点\nManuel Dewald，红帽公司 https://www.openshift.com/blog/7-best-practices-for-writing-kubernetes-operators-an-sre-perspective DevNation 技术讲座：每个用户都应该知道的 10 个很棒的 Kubernetes 工具\nAlex Soto 和 Burr Sutter，红帽公司。 https://www.twitch.tv/videos/709079582?t=00h01m01s 变化的世界, 变化的 Mozilla (但裁员 250 名员工) 非常悲伤的消息从 Mozilla, 火狐的创造者, 本周，他们已- 经裁掉了一个明显的数量的员工，他们的商业需求驱动.\nhttps://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/ 用 Prometheus 和 Grafana 进行系统监控。\n监控超级饲料。分布式系统的历史和挑战。 https://flightaware.engineering/systems-monitoring-with-prometheus-grafana/ 在 Git 中想做的事情以及如何做这些事情？\n一些一般的 GIT 技巧 https://stu2b50.dev/posts/things-you-wante9665 公布 Kubernetes 的 Pulumi 开源新项目\n宣布新功能，推进 Pulumi 的 Kubernetes 支持部署自动化、云原生生态系统集成和 Pulumi 的简单采用。 https://www.pulumi.com/blog/new-kubernetes-superpowers/ Mirantis 收购了 Kubernetes 的 IDE\u0026ndash;Lens - TechCrunch\n最近收购了 Docker 企业业务的公司 Mirantis 今天宣布收购了 Lens。 https://techcrunch.com/2020/08/13/mirantis-acquires-lens-an-ide-for-kubernetes/ MySQL 性能调优\n技巧、脚本和工具 https://haydenjames.io/mysql-performance-tuning-tips-scripts-tools/ \u0026ldquo;第一天 \u0026ldquo;云原生组织\n在这里，我提出了一个云原生架构，以促进任何组织内的创新和实验的动态文化。 https://medium.com/lambda-lego/day-one-cloud-native-organisations-250b4e181a8d 从单体架构到微服务。架构和数据管理\n在本文中，我们分析了从单体架构到微服务架构的转变，深入探讨了微服务通信类型，并以一个零售应用为例，研究了服务之间通信的最佳实践。 https://epsagon.com/development/monolithic-to-microservices-architecture-data-management/ 工具 https://github.com/mingrammer/diagrams\n云系统架构原型设计的 \u0026ldquo;图表即代码\u0026rdquo;（Diagram as Code）\nhttps://github.com/linkedin/shiv\nshiv 是一个命令行实用程序，用于构建完全自包含的 Python zipapps，就像 PEP 441 中概述的那样，但包含了所有的依赖关系。\nhttps://github.com/hazelcast/hazelcast-jet\n开源的分布式流和批处理技术\nhttps://github.com/abe-winter/automigrate\n使用 git 版本的 SQL 模式+自动迁移它们。\nhttps://github.com/soraxas/shsh\n一个多线程管理器，用于管理 shell 脚本、函数、独立的二进制文件、tab-completions 等。\nhttps://github.com/dutchcoders/cloudman\n管理 ec2 实例的文本用户界面。\nhttps://github.com/diego3g/rocketredis\n一个漂亮的 Redis GUI\n","date":"2020-08-17T18:43:26+08:00","image":"https://martinliu.cn/images/weeklyupdate.jpg","permalink":"https://martinliu.cn/blog/devopscoach-weekly-4/","title":"DevOps Coach 周刊 4"},{"content":"宕机 上一周新发的宕机事故。 近期全球重大宕机事故的分析总结、事后回顾。 上周新发宕机事故 Discord 这个值得注意的是，它涉及到谷歌云平台中所谓的 \u0026ldquo;吵闹邻居 \u0026ldquo;情况。https://discord.statuspage.io/incidents/bnv0wbddzz2x Slack 更新缓存基础架构的坑。从2020年7月23日晚上9:00 PDT到2020年8月1日下午5:17 PDT，客户在使用各种API端点时可能会出现滞后或故障。我们于7月29日开始调查这一问题，并将这些问题追溯到最近对我们的缓存基础设施进行的一项变更，旨在增加该基础设施的容量。一个不可预见的副作用导致一小部分API请求需要更长的时间来处理并最终超时。我们在8月1日恢复了这一更改，所有受影响的客户的问题都得到了解决。8月6日, 6:49 AM GMT+8 https://status.slack.com//2020-07/7d32ad54b0703c47 佳能 遭遇勒索软件攻击，Maze宣称对此事负责 来源： https://www.zdnet.com/article/canon-suffers-ransomware-attack-maze-claims-responsibility/ Steam 服务器目前已经瘫痪 https://gamerant.com/steam-servers-down-8-05/ Fastly 著名 CDN 服务器最近又出性能事故了， 影响范围，Edge Cloud Services (Fastly API, 快速配置应用, TLS 制备) https://status.fastly.com/incidents/d6ljy97shb0p 关于 Quay.io 宕机事故回顾 来源官网： https://www.openshift.com/blog/about-the-quay.io-outage-post-mortem 时间线：5 月 19 日第一次宕机，28 日第二次宕机，这些事故影响了大多数 quay.io 服务的用户。 Red Hat SRE 团队对本次事件的经验总结： 关于谁和什么人在使用你的服务，你永远都不可能有足够的参考数据。 由于Quay \u0026ldquo;一直是正常工作\u0026rdquo;，我们从来不需要花太多时间分析我们的流量模式，处理负载的行为。这创造了一种虚假的安全感，即服务将无限期地扩展。 当服务出现故障时，恢复是你的首要任务。 由于Quay在第一次中断期间不断出现数据库死锁的情况，我们的标准流程并没有明确的实现服务恢复的预期目标。这就导致我们花了更多的时间进行分析和收集数据，希望找到根本原因，而不是把所有的精力都放在让客户恢复运行上。 要了解你的每一个服务功能的影响。 App Registry很少被我们的客户使用，所以它不是我们团队的主要优先事项。当你的产品中有很少使用的功能时，bug就不会被提交，开发人员也不会再看代码。我们很容易认为这不会给团队带来任何负担\u0026ndash;直到它突然成为重大事件的一部分。 关于 Heroku 事故 #2090 的后续分析 概述：此次事件涉及Heroku的基础设施提供商（大概是AWS）的DNS故障。这次事故的坑是 DNS。 来源官网：https://status.heroku.com/incidents/2090 重要看点：为了给DNS查询提供内部IP地址，我们的服务提供商运行自己的内部DNS服务。这些DNS服务是确保在同一地区运行的基础设施之间建立最快连接的根本。当这些 DNS 服务不可用时，服务之间无法建立新的内部连接。与应用程序或数据服务的外部连接不会受到影响。在此次事件中，我们在一个地区的基础设施子集上经历了这些DNS服务的间歇性故障，包括我们运维的Heroku大部分内部服务的地方。 经验总结：我们正在审查我们如何应对服务提供商的DNS故障或降级，以确保我们能够尽快发现并解决任何未来的问题。 LinkedIn 最近的 Hadoop 事故总结：理论 vs. 实战 概述：LinkedIn的这起事件影响了多个内部客户，他们对耐用性和延迟的要求各不相同，使得恢复变得复杂。 来源官网：https://engineering.linkedin.com/blog/2020/learnings-from-a-recent-hadoop-incident 学习制度化：一场大型事件结束后，总会有一些心得体会。以下是我们正在跟进的几条。 为Hadoop基础设施建立一个强大和更全面的主机生命周期管理。 建立更好地理解我们在负载下各数据中心的网络行为，并确保按需修改网络路由的自动化方式。 目前，我们正在Azure上构建下一代基础设施，包括Hadoop协议栈。就中期而言，我们将有一个额外的集群，该集群建立在一个完全不同的技术栈上，这应该会进一步帮助我们实现冗余。 调查其他架构的可行性，作为我们Azure迁移的一部分。例如，我们可以将数据摄取一次，然后将相同的数据复制到 D/R Cluster中，并通过数据布局和查询规划优化来吃掉延迟成本。我们正在采用Apache Iceberg作为我们的表格式。有了Iceberg，我们应该可以更好地对受影响的文件进行针对性的恢复。在我们当前架构的临时，我们已经建立了几个工具，让我们能够辅助恢复（例如，恢复除损坏数据以外的所有数据，更容易从另一个集群恢复大文件等），并围绕它建立了运行本，以便于访问。 努力审计我们的流程，以确保它们有定义良好的灾难恢复协议。 增加我们的灾难演练的频率，此外，还要审查灾难演练中流程的表现与他们所述的恢复策略的评分卡。 继续研究我们的工具，围绕着理解世系，因为事实证明它在识别流和数据的依赖性方面非常有用。这也将提供理解生态系统端到端的连接图的能力\u0026ndash;这在灾难恢复等大型协调事件中是非常宝贵的。 一些流量所有者在他们的应用工作流本身中增强了弹性。例如，对延迟敏感的应用，产生关键业务小时和每日指标的应用，正在应用逻辑本身中进行明确的数据呆滞性与弹性的权衡。 专注于提高我们预测数据恢复的数据可用性SLA的能力，以便在这种性质的事件再次发生时有能力快速发布。我们的内部数据消费者可以使用这些SLA，并在恢复协议的决策选择方面做出明智的决定。 GitHub可用性报告 \u0026ndash; 2020年7月 概述：相信很多人都经历了 GitHub 7 月13 日的事故。该事故持续了4 小时 25 分钟。以下报告包括对涉及Kubernetes pods和DNS服务受损的事件的描述。 来源官网：https://github.blog/2020-08-05-github-availability-report-july-2020/ 要点回顾： 事件的起因是我们的生产型 Kubernetes Pods 开始被标记为不可用。这在我们的集群中层出不穷，导致容量减少，最终导致我们的服务瘫痪。对Pods的调查显示，Pod中的一个容器超过了其定义的内存限制并被终止。尽管该容器不需要处理生产流量，但Kubernetes的性质要求所有容器都是健康的，Pod才能被标记为可用。 一般情况下，当一个Pod运行到这种故障模式时，集群会在一分钟左右恢复。在这种情况下，Pod中的容器被配置为ImagePullPolicy为Always，它指示Kubernetes每次都要获取新的容器镜像。然而，由于之前完成了一次例行的DNS维护操作，我们的集群无法成功到达我们的注册表，导致Pods无法启动。当为了缓解而触发了重新部署时，这个问题的影响就增加了，我们看到这个故障开始在我们的生产集群中传播。直到我们使用缓存的DNS记录重新启动进程，我们才得以成功获取容器镜像，重新部署，并恢复我们的服务。 后续事项：展望未来，我们已经确定了本季度要解决的一些领域。 加强监控，确保Pod重启不会再基于这种相同的模式而失败 尽量减少我们对镜像仓库的依赖。 在DNS变更期间扩大验证范围 重新评估所有现有的Kubernetes部署策略 新闻 项目发布速递 Nano 5.0 — The popular simple Unix text editor. Julia 1.5 — High performance, dynamically typed language. Mastodon 3.2 — Federated social app. Django 3.1 — Python-based Web application framework. Alacritty 0.5 — Simplicity-focused terminal emulator. Terraform 0.13 General Availability DevOps 大会/峰会 KubeCon + CloudNativeCon 欧洲 2020\n8 月 17 – 20， 免费 报名： https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/ Commit 峰会\n8 月 26 ~ 27， GitLab 免费 报名：https://about.gitlab.com/events/commit/ DevOps Fusion\n8 月 26 日， 免费 报名：https://swisstestingday.ch/en/ DevOpsCon 伦敦 2020\n8 月 31 日 ~ 9 月 3 日，收费 报名： https://devopscon.io/ 提交大议信息发邮件到：martin@devopscoach.org\n文章 麦肯锡：《十种 \u0026ldquo;反模式\u0026rdquo;，让技术转型脱轨。》\n大型组织转型项目的反模式清单。在选择技术、技术管理、路线图等方面都有很好的建议。 https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/ten-antipatterns-that-are-derailing-technology-transformations AWS：《为运维可视化构建仪表板》\n一篇关于仪表盘设计的好文章，有很多道理、提示、技巧和例子。 https://aws.amazon.com/builders-library/building-dashboards-for-operational-visibility/ LearnK8s：《验证Kubernetes YAML的最佳实践和策略》\n看看对验证和测试Kubernetes配置文件有用的几个工具。有用的对比表和每个不同工具的例子。 https://learnk8s.io/validating-kubernetes-yaml 推荐 Arrested DevOps 这个网站，它是帮助你实现理解、开发良好实践、运营你的团队和组织的播客，以获得最大的DevOps妙用。\n关于Service Mesh和SMI规范的所有事情的讨论。 https://www.arresteddevops.com/service-mesh/ Dev.to：《使用Conftest、Regula和OPA保护你的Terraform管道安全》\n关于使用Conftest和Regula帮助编写安全的Terraform代码和测试作为CI流程的一部分的帖子。 https://dev.to/prince_of_pasta/securing-your-terraform-pipelines-with-conftest-regula-and-opa-4hkh 无罪网：《事件回顾从小白到大师》\nUnder Armour（！）的首席SRE对他们如何进行SRE有很多有趣的事情可以分享。我喜欢他们对事件回顾的方法，即从1:1采访相关人员开始。保罗-奥斯曼\u0026ndash;Under Armour（无罪峰会）。 https://www.blameless.com/blog/improving-postmortems-paul-osman medium.com 《主要的DevOps挑战以及如何应对这些挑战？》\nDevOps通过提供高效的解决方案，帮助加快交付速度，鼓励团队之间的协作，并促进敏捷环境，推动组织走向更美好的未来。 https://medium.com/faun/major-devops-challenges-and-how-to-address-them-3b4d7b6ee50b 工具 Open Service Mesh是一个新的轻量级、可扩展的、用于动态微服务环境的服务网状结构。它提供了开箱即用的可观察性功能，并使用SMI进行配置。\nhttps://openservicemesh.io/\nhttps://github.com/openservicemesh/osm\nSysbox是一个新的容器运行时，它可以让你更容易地在容器中运行低级软件，比如Systemd、Docker和Kubernetes。由于可插拔的运行时功能，你也可以用Docker运行它。\nhttps://github.com/nestybox/sysbox\n我们开始看到应用框架和开发者工具为在Kubernetes等平台上运行提供高级抽象。Tye是一个有趣的.NET工具，它可以简化在云原生平台上运行.NET应用程序。\nhttps://github.com/dotnet/tye\nTurandot允许在Kubernetes中使用TOSCA。TOSCA提供了一种高级服务描述，旨在实现底层基础设施之间的可移植性和互操作性。\nhttps://turandot.puccini.cloud/\nCopper是一个Kubernetes的配置文件验证器。它支持使用内置的Javascript DSL编写定制测试。\nhttps://github.com/cloud66-oss/copper\n","date":"2020-08-11T15:03:54+08:00","image":"https://martinliu.cn/images/weeklyupdate.jpg","permalink":"https://martinliu.cn/blog/devopscoach-weekly-3/","title":"DevOps Coach 周刊 3"},{"content":"概述 使用 Elastic Stack 的各种 Beats 模块可以彻底的终结在服务器上手工捞日志查指标的扭曲实践。利用腾讯云提供的 Elasticsearch 服务，可以轻松搞定大规模云环境的运维。本文一次性的帮你梳理清楚了，必备的基础操作，确保你能用 Elastic Stack 安全、稳定和扩展的持续监控你的生产环境。\n创建 ES 集群 登录腾讯云服务控制台，查询并进入 Elasticsearc 服务，点击新建按钮，创建 Elasticsearch 集群。如下图所示。\n集群配置说明：\n北京区 7.5.1 - 白金版 单可用区 冷热模式 本实例其它参数保持默认，可以根据实际业务需求修改这些参数。\n点击下一步后，设置 Elasticsearch 集群的超级用户名和密码。\n在几分钟之后这个集群就成功创建了。查看下面这些基础的配置。\n启用 Kibana 内网地址： http://es-ot7wei87.internal.kibana.tencentelasticsearch.com:5601 用于 Bests 的 Setup 命令 启用 Kibana 公网地址： https://es-ot7wei87.kibana.tencentelasticsearch.com:5601 用户Elastic Stack 的初始化配置，如创建角色和调整索引生命周期策略等。 这样我们就有了一个安全、可扩展和性能足够的 ES 后台服务。\n创建 Beats 写入角色和用户 登录 Kibana ，点击角色和用户管理，创建用于 Beast 配置文件的‘只写’权限用户。\n创建 beats-writer 角色 创建 beats-writer 用户，该用户只赋予beats-writer角色，自定义一个安全的复杂密码。 Beats-write 角色设置如下图所示：\n这个用户会用到后面的所有 Beats 配置文件中，用最小化权限用户极大的降低了数据泄露的风险。\nBeats 初始化配置 登录准备好的一个 Linux 服务器，在这台机器上做 Beats 相关的初始化工作；也就是要执行一些列的 setup 命令；这些命令的作用是：\n在 ES 后台加载索引模板，以及索引的 ILM 策略。 加载 Kibana 相关的对象和可视化仪表板。 注意这是一次性的工作，在一个虚拟机上，只需要成功执行一次。\nSSH 登录到准备的 Linux 服务器上，首先需要安装相关 beats 的 rpm 安装包，安装命令在这里忽略，否则无法执行这些命令。 安装好 filebeat 和 metricbeat 的rpm 包后， 执行下面参考命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 filebeat setup -e \\ -E output.logstash.enabled=false \\ -E output.elasticsearch.hosts=[\u0026#39;192.168.0.43:9200\u0026#39;] \\ -E output.elasticsearch.username=elastic \\ -E output.elasticsearch.password=YourPassWord \\ -E setup.kibana.host=es-ot7wei87.internal.kibana.tencentelasticsearch.com:5601 metricbeat setup -e \\ -E output.elasticsearch.hosts=[\u0026#39;192.168.0.43:9200\u0026#39;] \\ -E output.elasticsearch.username=elastic \\ -E output.elasticsearch.password=YourPassWord \\ -E setup.kibana.host=es-ot7wei87.internal.kibana.tencentelasticsearch.com:5601 运行以上命令的时候 Beats 处于默认安装的状态，这些命令行参数是必要的查收，有了这些参数 beats 会忽略默认的配置文件。\n以上命令根据需求，如果需要使用到其它的 Beats，请使用相关的 setup 命令。其中的 es 和 kibana 相关信息需求参考上一步创建的 es 集群信息。\n以上所有命令成功之后，登录 Kibana 界面，点击 Dashboard 菜单，这里应该已经加载了很多仪表板。目前为止 Elastic Stack 后台就初始化成功了。\n在节点上正式部署 Beats 参考和修改安装脚本，一键式安装和配置 Beats\n1 2 3 git clone https://github.com/martinliu/elastic-stack-lab.git cd tencent sh add-agent.sh 成功执行完以上脚本后，相关的 beats 服务应是正常运行的状态。执行完这个命令之后，在 Linux 服务器上使用检查服务是否正常运行 sudo systemctl status filebeat ；使用这个命令应该可以看到filebeat 服务都是正常运行的。\n这个脚本所使用的配置文件中的要点：\n删除了所有和数据摄入无关的配置（例如 es 和 kibana 的配置和初始化等） 加入了最小化的必要的最佳实践参数集合 建议根据需求增加 beats 相关的模块 根据需求加入必要的 Beat 配置参数 实例配置文件如。\nfilebeat.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #=========================== Filebeat inputs ============================= filebeat.inputs: - type: log enabled: false paths: - /var/log/*.log #============================= Filebeat modules =============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true reload.period: 60s #-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: hosts: [\u0026#34;${INT_ES_SRV}\u0026#34;] password: ${BEATS_WRITER_PW} username: ${BEATS_WRITER_USERNAME} #================================ Processors ===================================== processors: - add_host_metadata: netinfo.enabled: true cache.ttl: 5m - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ - add_fields: target: \u0026#39;\u0026#39; fields: service.name: \u0026#39;Joint Lab\u0026#39; service.id: \u0026#39;es-qq\u0026#39; #==================== Best Practice Configuration ========================== setup.ilm.check_exists: false logging.level: error queue.spool: ~ monitoring: enabled: true metricbeat.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # =========================== Modules configuration ============================ metricbeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true reload.period: 10s #-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: hosts: [\u0026#34;${INT_ES_SRV}\u0026#34;] password: ${BEATS_WRITER_PW} username: ${BEATS_WRITER_USERNAME} #================================ Processors ===================================== processors: - add_host_metadata: netinfo.enabled: true cache.ttl: 5m - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ - add_fields: target: \u0026#39;\u0026#39; fields: service.name: \u0026#39;Joint Lab\u0026#39; service.id: \u0026#39;es-qq\u0026#39; #==================== Best Practice Configuration ========================== setup.ilm.check_exists: false logging.level: error queue.spool: ~ monitoring: enabled: true 以上配置文件使用了这些通用最佳实践配置参数。\n使用 ECS 扩展字段，丰富上下文含义 启用 beats 端点监控 用 keystore 隐藏所有敏感信息 1 2 3 4 5 6 7 8 9 10 11 12 #禁用索引 ilm 策略检查，避免无用动作 setup.ilm.check_exists: false #把Beats自身的日志记录调到最低级别降低 logging.level: error #开启本地默认的端点缓存行为 queue.spool: ~ #启用端点的监控 monitoring: enabled: true 排错方法 filebeat setup 不成功 在任何 beats 首次做 setup 命令的时候，它可能是会在分钟级别成功结束。如果发生失败或者卡顿的情况，可以等一下，等更长时间看看。不成功的话，需要反复执行，排查 es 和 kibana 服务是否能正常工作。知道陈功了，才能进行下一步的安装工作。\n配置文件错误导致的服务不能启动 由于上面的定制化配置文件也可能出现错误，特别是在首次部署这个配置文件的时候，可以先把日志级别 error 哪一行注释掉，把启动服务那两行也注释掉。\n然后在命令行执行 filebeat -e 查看整个 feilebeat 的启动过程，这个命令会读取定制化的配置文件，然后开始连接后台 es 服务，然后进入正常数据传送的状态。这个过程中如果有任何配置错误，也可以直观的看到相关信息，直到调整到正常的状态。\n以上过程的调整好了以后，一定要通过 git 版本管理起来，然后可以放心的在其它节点上执行 beast 的一键式部署工作。\n总结 以上是在 Beats 部署相关基础最佳实践，也就是说在生产环境中 ES 后台和 beats 的搭配，以及本文所涉及的内容都是基线配置。建议根据自己的需求做更多的调优，这里使用 shell 脚本的方式部署 beats 和相关的配置，shell 脚本适合用于演示原理，建议替换成你所熟悉的自动化运维工具，例如 ansible 等工具。从而保证更大规模的自动化部署和维护。\n本相关的配置文件和脚本位于：https://github.com/martinliu/elastic-stack-lab.git\n","date":"2020-08-07T17:14:20+08:00","image":"https://martinliu.cn/images/abstract-6.jpg","permalink":"https://martinliu.cn/blog/beats-implement-on-qcloud/","title":"腾讯云下部署 Elastic Stack 各种 Beat 的最佳实践"},{"content":"宕机 上周全球重大宕机事故清单。\nFacebook 具英媒体报道：7月 28 日 12：20pm， Facebook, Instagram 和 WhatsApp 这三款用户的一半以上的用户，无法加载出页面，无法正常使用服务。 Facebook 官方还没有关于这次事故的回应。实际上整个欧洲大陆，特别是葡萄牙和西班牙的故障更要严重一些。原因不明。 影响范围：London, Birmingham 和 Manchester. 来源： https://metro.co.uk/2020/07/28/facebook-instagram-whatsapp-13048914/ fastly - 知名 CDN 服务商 官方声明：Fastly的网络具有内置冗余和自动故障转移路由，以确保最佳性能和正常运行时间。但当网络问题出现时，我们认为我们的客户应该得到清晰、透明的沟通，这样他们才能保持对我们的服务和团队的信任。当我们重新分配流量、升级硬件或在极少数情况下我们的网络不提供流量时，我们会在这里发布通知。如果您遇到问题而没有看到张贴的通知，请发送电子邮件至 support@fastly.com 寻求帮助。 影响范围：North America (Ashburn (BWI), Ashburn (DCA), Ashburn (IAD), Ashburn (WDC), Atlanta (FTY), Atlanta (PDK), Dallas (DAL), Dallas (DFW), Jacksonville (JAX)). 来源：https://status.fastly.com/history Heroku 官方声明：JUL 28, 2020 09:15 UTC Heroku 平台的很大的部分都遭受到可用性故障。然后开始和他们的服务提供商一起解决问题。一个多小时后平台恢复了正常。 来源：https://status.heroku.com/incidents/2090 新闻 DevOps实践的采用与组织拥抱数字化转型齐头并进。这两个短语都有被过度使用的风险，但这些帖子讨论了一些有用的心理模型，以帮助聚焦对话。\nhttps://aws.amazon.com/blogs/enterprise-strategy/mental-models-for-digital-transformation/ https://aws.amazon.com/blogs/enterprise-strategy/mental-models-to-clarify-the-goals-for-of-digital-transformation-part-2/ 开发者平台的哪些属性会导致采用？下面的文章是专门关于大规模边缘平台的，但对于任何为开发者构建各种平台的人来说，包括在内部平台团队中这样做的人来说，都是很好的阅读。\nhttps://blog.cloudflare.com/cloudflare-workers-serverless-week/ 当第一次接受DevOps实践和云服务时，在大型组织中通常会建立一个卓越中心。在采取这种方法时，需要避免一些陷阱，下面的文章将讨论这些陷阱。\nhttps://www.contino.io/insights/cloud-centre-of-excellence-2020 最近的DevSecCon在线会议的视频都可以看到，其中涵盖了一系列有趣的主题，包括基础设施作为代码安全、持续审计合规、供应链攻击等。\nhttps://www.mydevsecops.io/post/devseccon24 关于无服务器架构和单体应用之间的权衡，主要集中在较小规模的应用上，是一个不错的讨论。\nhttps://dev.to/iamcherta/my-monolith-doesn-t-fit-in-your-serverless-311o 一篇关于linux内核新特性的深度技术文章，这些特性应该会让非特权容器更受欢迎。对seccomp的细节也做了很好的介绍。\nhttps://people.kernel.org/brauner/the-seccomp-notifier-new-frontiers-in-unprivileged-container-development 基于角色的访问控制在保护Kubernetes的安全方面发挥着重要作用。这个方便的网站将文章、工具和官方文档收集在一起。\nhttps://rbac.dev/ 对于任何使用Serverless技术的人来说，这是一项有趣的调查，来自该领域的众多公司。我期待着结果公布时的到来。\nhttps://codingsans.typeform.com/to/mPinnC 文章 LaunchDarkly从基于 Polling 的架构开始，最终迁移到向客户推送变化量（Streaming）。Dawn Parzych\u0026ndash;LaunchDarkly。\nhttps://launchdarkly.com/blog/launchdarklys-evolution-from-polling-to-streaming/ 一个更简单的分布式跟踪的替代方案，用于故障排除。 简要概述了分布式追踪的一些问题，以及涉及人工智能的另一种方式的建议。 Larry Lancaster - Zebrium\nhttps://www.zebrium.com/blog/virtual-tracing-a-simpler-alternative-to-distributed-tracing-for-troubleshooting 谷歌云 对 Classroom 的故障总结报告 2020-07-07 这是Google在7月7日对其Google Classroom 事件的事后报告。\nhttps://static.googleusercontent.com/media/www.google.com/en//appsstatus/ir/u5sinmib27yly4i.pdf 面向领域的微服务架构介绍 长期以来，Uber一直是微服务的倡导者。现在，凭借几年的经验，他们分享了他们所学到的经验，以及如何处理一些陷阱。Adam Gluck - Uber\nhttps://eng.uber.com/microservice-architecture/ 通过远程事件响应使PagerDuty始终保持开启状态。 本文开篇就从PagerDuty的角度对Cloudflare中断的情况进行了有趣的描述。Dave Bresci - PagerDuty\nhttps://www.pagerduty.com/blog/remote-incident-response/ 安全是设计出来的？ 这篇文章反映了两种不同的安全理念。\n工程设计应确保系统的安全。 单纯的设计不能保证系统的安全 Lorin Hochstein https://surfingcomplexity.blog/2020/07/28/safe-by-design/ 我们能做的就是发现问题 你不能用可用性指标来告知你的系统是否足够可靠，因为它们只能在你出现问题时告诉你。 Lorin Hochstein\nhttps://surfingcomplexity.blog/2020/07/28/all-we-can-do-is-find-problems/ 工具推荐 管理 K8s 命令行工具的工具，所有命令行工具一站式搞定，一键式安装很多 k8s 集群基础。\nhttps://github.com/alexellis/arkade/ 一个在文件系统之上的文件系统。\nhttps://github.com/carlosgaldino/gotenksfs 一个 Cloud-Native API Gateway\nhttps://github.com/apache/apisix 一个简单而全面的容器漏洞扫描器，适用于CI。\nhttps://github.com/aquasecurity/trivy ","date":"2020-08-03T22:26:23+08:00","image":"https://martinliu.cn/images/weeklyupdate.jpg","permalink":"https://martinliu.cn/blog/devopscoach-weekly-2/","title":"DevOps Coach 周刊 2"},{"content":"用跟踪的方式调试计算机程序的调用堆栈的实践其实由来已久，这种方法可能仅次于用 print 输出各种信息。在云原生的时代里，我们还会遭遇工具过剩的情况，工具之间的相生相克加剧了实施分布式追踪的难度。\n总的来说有三个基础难点：\n生成追踪数据难。对已有应用系统的代码库进行埋点处理的挑战巨大，你的应用程序系统的模式可能也不符合埋点的模式需求。 采集存储追踪数据难。捕获和管理大量追踪数据包，即照顾到查询和使用的需求，又要设定成本合理的数据存储策略，处理数据收集能力的扩缩容。 从数据中获益难。如何理解和使用数据产生可执行行动，如何用它优化微服务的遥测，怎么将它的利益扩展到各个相关团队。 分布式追踪系统的实施结果是落地一条能深度洞察目标系统的工具。让人们能轻松的理解局部和整体的状态，特别是在请求堆栈中的任何局部服务出现故障时，可以最快速的定位故障根源。\n上图是用追踪数据生成的服务地图。\n上图是一次用户请求的全部细节，还可以一键式的跳转到相应的日志或者指标。\n以上三个难点覆盖了部署实施分布式追踪系统的核心领域。\n埋点 OpenTelemetry是目前受到广泛支持的埋点框架，对棕地应用和绿地应用进行埋点处理的挑战是不同的，需要遵循不同的额最佳实践。 部署 在理解了目标追踪应用系统的运行时状态后，最好使用一种弹性的方式收集和存储追踪数据。满足分析数据量需求的同时平衡存储成本。 收益 将其与日志和指标工具关联起来，定义和监控重要有意义的监控点，用于优化系统性能基线，并最小化 MTTR。 在云计算、Kubernetes、容器化大行其道的今天，分布式追踪的实施是不是正处在进退维谷的尴尬境地呢？其实并非如此，特别是监控运维挑战越高的应用，其实越需要需要使用分布式追踪 APM 工具。分布式追踪对云原生的容器化微服务应用尤为适用。APM 对单纯使用日志和指标的场景具有极大的补充和提高作用，而且它是可观测性策略的关键组成部分。\n总的来说分布式追踪工具可以通过追踪的方式展现请求在系统中的流动状态。流行的开源埋点框架使之与应用的编程语言、运行时环境无关，可以适配与所有类型的应用和服务。有些 APM 工具可以支持运行时埋点（或称为运行框架埋点），在不改变代码的情况下采集追踪数据。APM 的实施虽然有一定难度，但是当开始实施埋点处理，收集追踪数据以后，相关的价值和收益也就会慢慢显现出来了。\n参考：\nhttps://opentelemetry.io/ https://www.elastic.co/cn/apm ","date":"2020-08-02T20:48:30+08:00","image":"https://martinliu.cn/images/abstract-3.jpg","permalink":"https://martinliu.cn/blog/apm-why-it-so-hard/","title":"APM 分布式追踪为何这么难？"},{"content":"前言 DBA 可能是经常被其它团队依赖的一种角色、团队，因此他们也会有着很长的等待队列，也经常是事故救火中的英雄和常客。DevOps 强调用跨角色的学习和培训来解决这种依赖，也就是 DevOps 工作三步法的第三步，学习与持续改进。 本文写给所有的应用开发者，希望大家能多学习一些 DBA 知识，减少对专家 DBA 的依赖，加速你们的业务的交付，消除由于等待而造成的浪费。\n本文转载自：https://hakibenita.com/sql-tricks-application-dba\n以下是正文原文：\n当我开始我的开发生涯时，我的第一份工作是DBA。那时，在AWS RDS、Azure、Google Cloud和其余云服务之前，有两种类型的DBA。\n基础设施 DBA 负责建立数据库配置存储，并负责备份和复制。设置好数据库后，基础架构DBA会时不时地冒出来做一些 \u0026ldquo;实例调整\u0026rdquo;，比如调整缓存的大小。\n应用 DBA 从基础架构DBA那里得到了一个干净的数据库，并负责模式设计：创建表、索引、约束和调优SQL。应用DBA也是实现ETL流程和数据迁移的人。在使用存储过程的团队中，应用DBA也会维护这些存储过程。\n应用DBA通常是开发团队的一部分。他们会拥有深厚的领域知识，所以通常他们只会在一两个项目上工作。基础架构DBA通常是某个IT团队的一部分，他们会同时在多个项目上工作。\n我是一名应用DBA 我从来没有任何欲望去摆弄备份或调整存储（我相信这很迷人！）。直到今天，我都喜欢说自己是一个懂得开发应用的DBA，而不是一个懂得数据库的开发者。\n在本文中，我将分享我一路走来收集到的一些关于数据库开发的非浅显技巧。\nBe that guy\u0026hellip;Image by CommitStrip\n只更新需要更新的内容 UPDATE是一个相对昂贵的操作。为了加快UPDATE命令的速度，最好确保只更新需要更新的内容。\n以这个查询为例，它对电子邮件列进行了标准化处理。\n1 2 3 db=# UPDATE users SET email = lower(email); UPDATE 1010000 Time: 1583.935 ms (00:01.584) 看起来很无辜吧，查询更新了1010,000个用户的邮箱。但是，真的需要更新所有的行吗？\n1 2 3 4 db=# UPDATE users SET email = lower(email) db-# WHERE email != lower(email); UPDATE 10000 Time: 299.470 ms 只需要更新10000行。通过减少受影响的行数，执行时间从1.5秒降到了不到300ms。更新的行数少了，也节省了后期的数据库维护工作。\n这种类型的大更新在数据迁移脚本中非常常见。所以下次写迁移脚本时，一定要只更新需要更新的内容。\n在批量加载过程中禁用约束和索引 约束是关系型数据库的重要组成部分：它们能保持数据的一致性和可靠性。不过它们的好处是有代价的，在加载或更新大量行时最明显。\n为了演示，为一个存储设置一个小模式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 DROP TABLE IF EXISTS product CASCADE; CREATE TABLE product ( id serial PRIMARY KEY, name TEXT NOT NULL, price INT NOT NULL ); INSERT INTO product (name, price) SELECT random()::text, (random() * 1000)::int FROM generate_series(0, 10000); DROP TABLE IF EXISTS customer CASCADE; CREATE TABLE customer ( id serial PRIMARY KEY, name TEXT NOT NULL ); INSERT INTO customer (name) SELECT random()::text FROM generate_series(0, 100000); DROP TABLE IF EXISTS sale; CREATE TABLE sale ( id serial PRIMARY KEY, created timestamptz NOT NULL, product_id int NOT NULL, customer_id int NOT NULL ); 模式定义了不同类型的约束，如 \u0026ldquo;非空 \u0026ldquo;和唯一约束。\n要设置一个基线，首先要向销售表添加外键，然后将一些数据加载到表中:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 db=# ALTER TABLE sale ADD CONSTRAINT sale_product_fk db-# FOREIGN KEY (product_id) REFERENCES product(id); ALTER TABLE Time: 18.413 ms db=# ALTER TABLE sale ADD CONSTRAINT sale_customer_fk db-# FOREIGN KEY (customer_id) REFERENCES customer(id); ALTER TABLE Time: 5.464 ms db=# CREATE INDEX sale_created_ix ON sale(created); CREATE INDEX Time: 12.605 ms db=# INSERT INTO SALE (created, product_id, customer_id) db-# SELECT db-# now() - interval \u0026#39;1 hour\u0026#39; * random() * 1000, db-# (random() * 10000)::int + 1, db-# (random() * 100000)::int + 1 db-# FROM generate_series(1, 1000000); INSERT 0 1000000 Time: 15410.234 ms (00:15.410) 定义约束和索引后，将100万行加载到表中，耗时约15.4s。\n接下来，尝试先将数据加载到表中，然后才添加约束和索引。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 db=# INSERT INTO SALE (created, product_id, customer_id) db-# SELECT db-# now() - interval \u0026#39;1 hour\u0026#39; * random() * 1000, db-# (random() * 10000)::int + 1, db-# (random() * 100000)::int + 1 db-# FROM generate_series(1, 1000000); INSERT 0 1000000 Time: 2277.824 ms (00:02.278) db=# ALTER TABLE sale ADD CONSTRAINT sale_product_fk db-# FOREIGN KEY (product_id) REFERENCES product(id); ALTER TABLE Time: 169.193 ms db=# ALTER TABLE sale ADD CONSTRAINT sale_customer_fk db-# FOREIGN KEY (customer_id) REFERENCES customer(id); ALTER TABLE Time: 185.633 ms db=# CREATE INDEX sale_created_ix ON sale(created); CREATE INDEX Time: 484.244 ms 将数据加载到没有索引和约束的表中，速度快了很多，2.27s，而之前是15.4s。在数据加载到表中后创建索引和约束花了一点时间，但总体上整个过程快了很多，3.1s，而之前是15.4s。\n遗憾的是，对于索引，PostgreSQL并没有提供一个简单的方法，除了放弃和重新创建索引。在其他数据库中，如Oracle，你可以禁用和启用索引，而不必重新创建索引。\n中间数据中使用 UNLOGGED 的表 当你修改PostgreSQL中的数据时，修改的内容会被写入提前写日志（WAL）。WAL用于维护完整性，在恢复期间快速推进数据库，并维护复制。\n写入WAL是经常需要的，但在某些情况下，你可能愿意放弃它的一些用途来使事情变得更快。一个例子是中间表。\n中间表是一次性的表，它存储了用于实现某些过程的临时数据。例如，ETL过程中一个非常常见的模式是将数据从CSV文件加载到中间表，清理数据，然后加载到目标表。在这种用例中，中间表是一次性的，在备份或复制中没有用处。\n在灾难发生时不需要恢复的中间表，以及在副本中不需要的中间表，可以设置为 UNLOGGED。\n1 CREATE UNLOGGED TABLE staging_table ( /* table definition */ ); **注意：**在使用UNLOGGED之前，请务必了解其全部含义。\n使用 WITH 和 RETURNING 实施完成的流程 假设你有一个用户表，你发现表中有一些重复的内容。\n表的设置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 CREATE TABLE users ( id SERIAL PRIMARY KEY, email TEXT UNIQUE ); CREATE TABLE orders ( id SERIAL PRIMARY KEY, user_id INT, CONSTRAINT orders_user_fk FOREIGN KEY (user_id) REFERENCES USERS(id) ); INSERT INTO users (email) VALUES (\u0026#39;foo@bar.baz\u0026#39;), (\u0026#39;me@hakibenita.com\u0026#39;), (\u0026#39;ME@hakibenita.com\u0026#39;); INSERT INTO orders (user_id) VALUES (1), (1), (2), (3), (3); 表的内容：\n1 2 3 4 5 6 7 8 9 10 db=# SELECT u.id, u.email, o.id as order_id FROM orders o JOIN users u ON o.user_id = u.id; id | email | order_id ----+-------------------+---------- 1 | foo@bar.baz | 1 1 | foo@bar.baz | 2 2 | me@hakibenita.com | 3 3 | ME@hakibenita.com | 4 3 | ME@hakibenita.com | 5 用户haki benita注册了两次，一次是用邮箱ME@hakibenita.com，另一次是用me@hakibenita.com。由于我们在将邮件插入表中时没有将其规范化，现在我们必须处理重复的问题。\n为了合并重复的用户，我们要。\n通过小写的电子邮件来识别重复的用户。 更新订单以引用其中一个重复的用户。 从用户表中删除重复的用户 整合重复用户的一种方法是使用中间表。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 db=# CREATE UNLOGGED TABLE duplicate_users AS db-# SELECT db-# lower(email) AS normalized_email, db-# min(id) AS convert_to_user, db-# array_remove(ARRAY_AGG(id), min(id)) as convert_from_users db-# FROM db-# users db-# GROUP BY db-# normalized_email db-# HAVING db-# count(*) \u0026gt; 1; CREATE TABLE db=# SELECT * FROM duplicate_users; normalized_email | convert_to_user | convert_from_users -------------------+-----------------+-------------------- me@hakibenita.com | 2 | {3} 中间表持有重复用户的映射。对于每一个使用相同的标准化电子邮件地址出现不止一次的用户，我们定义最小ID的用户作为我们将所有重复用户转换为的用户。其他用户被保存在一个数组列中，这些用户的所有引用都将被更新。\n利用中间表，我们更新订单表中重复用户的引用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 db=# UPDATE db-# orders o db-# SET db-# user_id = du.convert_to_user db-# FROM db-# duplicate_users du db-# WHERE db-# o.user_id = ANY(du.convert_from_users); UPDATE 2 Now that there are no more references, we can safely delete the duplicate users from the users table: db=# DELETE FROM db-# users db-# WHERE db-# id IN ( db(# SELECT unnest(convert_from_users) db(# FROM duplicate_users db(# ); DELETE 1 请注意，我们使用了函数 unnest 来 \u0026ldquo;转置 \u0026ldquo;数组，即把每个数组元素变成一行。\n这就是结果：\n1 2 3 4 5 6 7 8 9 db=# SELECT u.id, u.email, o.id as order_id db-# FROM orders o JOIN users u ON o.user_id = u.id; id | email | order_id ----+-------------------+---------- 1 | foo@bar.baz | 1 1 | foo@bar.baz | 2 2 | me@hakibenita.com | 3 2 | me@hakibenita.com | 4 2 | me@hakibenita.com | 5 很好，用户3(ME@hakibenita.com)的所有出现都转换为用户2(me@hakibenita.com)。\n我们还可以验证重复的用户是否从用户表中被删除。\n1 2 3 4 5 6 db=# SELECT * FROM users; id | email ----+------------------- 1 | foo@bar.baz 2 | me@hakibenita.com 现在我们可以摆脱中间表了。\n1 2 db=# DROP TABLE duplicate_users; DROP TABLE 这个很好，但是非常长，需要清理! 有没有更好的方法？\n使用通用表表达式(CTE) 使用常见的表表达式，也就是所谓的WITH子句，我们只需要一条SQL语句就可以执行整个过程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 WITH duplicate_users AS ( SELECT min(id) AS convert_to_user, array_remove(ARRAY_AGG(id), min(id)) as convert_from_users FROM users GROUP BY lower(email) HAVING count(*) \u0026gt; 1 ), update_orders_of_duplicate_users AS ( UPDATE orders o SET user_id = du.convert_to_user FROM duplicate_users du WHERE o.user_id = ANY(du.convert_from_users) ) DELETE FROM users WHERE id IN ( SELECT unnest(convert_from_users) FROM duplicate_users ); 我们不创建中间表，而是创建一个通用的表表达式，并多次重复使用。\n从 CTE 返回结果 在WITH子句中执行DML的一个很好的特性是，你可以使用RETURNING关键字来返回数据。例如，让我们报告更新和删除的行数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 WITH duplicate_users AS ( SELECT min(id) AS convert_to_user, array_remove(ARRAY_AGG(id), min(id)) as convert_from_users FROM users GROUP BY lower(email) HAVING count(*) \u0026gt; 1 ), update_orders_of_duplicate_users AS ( UPDATE orders o SET user_id = du.convert_to_user FROM duplicate_users du WHERE o.user_id = ANY(du.convert_from_users) RETURNING o.id ), delete_duplicate_user AS ( DELETE FROM users WHERE id IN ( SELECT unnest(convert_from_users) FROM duplicate_users ) RETURNING id ) SELECT (SELECT count(*) FROM update_orders_of_duplicate_users) AS orders_updated, (SELECT count(*) FROM delete_duplicate_user) AS users_deleted ; 这个结果是:\n1 2 3 orders_updated | users_deleted ----------------+--------------- 2 | 1 这种方法的主要吸引力在于，整个过程是在一条命令中执行的，所以不需要管理一个事务，也不需要担心在过程失败时清理中间表。\n**注意：**Reddit上的一位读者给我指出了在普通表表达式中执行DML的一个可能无法预测的行为。\nWITH中的子语句相互之间以及与主查询同时执行。因此，当在WITH中使用数据修改语句时，指定的更新实际发生的顺序是不可预测的。\n这意味着你不能依赖独立子语句的执行顺序。看来，当子语句之间存在依赖关系时，比如在上面的例子中，你可以依靠依赖的子语句在被使用之前执行。\n避免在选择性低的列上使用索引 假设你有一个注册流程，用户用电子邮件地址注册。为了激活帐户，他们必须验证他们的电子邮件。你的表可以是这样的。\n1 2 3 4 5 6 db=# CREATE TABLE users ( db-# id serial, db-# username text, db-# activated boolean db-#); CREATE TABLE 你的大部分用户都是好公民，他们用有效的邮箱注册，并立即激活账号。让我们用用户数据来填充表格，其中大概有90%的用户被激活。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 db=# INSERT INTO users (username, activated) db-# SELECT db-# md5(random()::text) AS username, db-# random() \u0026lt; 0.9 AS activated db-# FROM db-# generate_series(1, 1000000); INSERT 0 1000000 db=# SELECT activated, count(*) FROM users GROUP BY activated; activated | count -----------+-------- f | 102567 t | 897433 db=# VACUUM ANALYZE users; VACUUM 要查询已激活和未激活的用户，你可能会想在列激活上创建一个索引。\n1 2 db=# CREATE INDEX users_activated_ix ON users(activated); CREATE INDEX 当你试图查询未激活的用户时，数据库正在使用索引。\n1 2 3 4 5 6 7 db=# EXPLAIN SELECT * FROM users WHERE NOT activated; QUERY PLAN -------------------------------------------------------------------------------------- Bitmap Heap Scan on users (cost=1923.32..11282.99 rows=102567 width=38) Filter: (NOT activated) -\u0026gt; Bitmap Index Scan on users_activated_ix (cost=0.00..1897.68 rows=102567 width=0) Index Cond: (activated = false) 数据库估计，过滤后会有102567个，这大概是表的10%。这与我们填充的数据是一致的，所以数据库对数据的感觉很好。\n但是，当你尝试查询激活用户时，你发现数据库决定不使用索引。\n1 2 3 4 5 db=# EXPLAIN SELECT * FROM users WHERE activated; QUERY PLAN --------------------------------------------------------------- Seq Scan on users (cost=0.00..18334.00 rows=897433 width=38) Filter: activated 很多开发人员在数据库没有使用索引的时候，往往会感到困惑。解释为什么索引并不总是最好的选择的一种方法是：如果你必须读取整个表，你会使用索引吗？\n答案可能是否定的，因为你为什么要这样做？从磁盘上读取是很昂贵的，你希望尽可能少地读取。例如，如果一个表是10MB，索引是1MB，要读取整个表，你就必须从磁盘上读取10MB。如果要使用索引来读取表，你就必须从磁盘上读取11MB。这是很浪费的。\n有了这样的理解，我们来看看PostgreSQL对表的收集统计。\n1 2 3 4 5 6 7 8 db=# SELECT attname, n_distinct, most_common_vals, most_common_freqs db-# FROM pg_stats db-# WHERE tablename = \u0026#39;users\u0026#39; AND attname=\u0026#39;activated\u0026#39;; ------------------+------------------------ attname | activated n_distinct | 2 most_common_vals | {t,f} most_common_freqs | {0.89743334,0.10256667} 当PostgreSQL分析该表时，发现激活的列有两个不同的值。most_common_vals列中的值t对应的是most_common_freqs列中的频率0.89743334，值f对应的是频率0.10256667。也就是说，经过分析，数据库估计表中89.74%是激活用户，其余10.26%是未激活用户。\n通过这些统计，PostgreSQL决定，如果希望90%的行满足条件，最好扫描整个表。过了这个阈值，数据库可能会决定使用或不使用索引，这取决于很多因素，没有一个经验法则可以使用。\n使用部分索引 在上一节中，我们在布尔值列上创建了一个索引，其中90%的值为真（激活用户）。当我们试图查询活跃用户时，数据库没有使用该索引。然而，当我们查询未激活的用户时，数据库却使用了该索引。\n这就引出了下一个问题\u0026hellip;\u0026hellip;如果数据库不打算使用索引来过滤活跃用户，那么我们为什么要首先使用索引呢？\n在回答这个问题之前，我们先来看看激活列上的完整索引有多大重量。\n1 2 3 4 5 db=# \\di+ users_activated_ix Schema | Name | Type | Owner | Table | Size --------+--------------------+-------+-------+-------+------ public | users_activated_ix | index | haki | users | 21 MB 索引是21MB。仅供参考，用户表是65MB。这意味着索引的重量约为表的32%。我们也知道~90%的索引可能不会被使用。\n在PostgreSQL中，有一种方法可以只在表的一部分创建索引，使用所谓的部分索引。\n1 2 3 db=# CREATE INDEX users_unactivated_partial_ix ON users(id) db-# WHERE not activated; CREATE INDEX 使用WHERE子句，我们限制了索引所索引的行。首先让我们确认一下它是否有效。\n1 2 3 4 db=# EXPLAIN SELECT * FROM users WHERE not activated; QUERY PLAN ------------------------------------------------------------------------------------------------ Index Scan using users_unactivated_partial_ix on users (cost=0.29..3493.60 rows=102567 width=38) 令人惊奇的是，数据库很聪明，它明白我们在查询中使用的谓词可以通过部分索引来满足。\n使用部分索引还有一个好处。\n1 2 3 4 5 db=# \\di+ users_unactivated_partial_ix List of relations Schema | Name | Type | Owner | Table | Size --------+------------------------------+-------+-------+-------+--------- public | users_unactivated_partial_ix | index | haki | users | 2216 kB 部分索引仅重2.2MB。列上的全索引重达21MB。部分索引的大小正好是全索引的10%，这与表中非活跃用户的比例相匹配。\n始终加载排序过的数据 这是我在代码评审中评论最多的事情之一。它不像其他提示那样直观，它对性能的影响很大。\n比如说你有一个大的销售事实表。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 db=# CREATE TABLE sale_fact (id serial, username text, sold_at date); CREATE TABLE Every night, during some ETL process, you load data into the table: db=# INSERT INTO sale_fact (username, sold_at) db-# SELECT db-# md5(random()::text) AS username, db-# \u0026#39;2020-01-01\u0026#39;::date + (interval \u0026#39;1 day\u0026#39;) * round(random() * 365 * 2) AS sold_at db-# FROM db-# generate_series(1, 100000); INSERT 0 100000 db=# VACUUM ANALYZE sale_fact; VACUUM 为了伪造一个加载过程，我们使用了随机数据。我们插入了10万行随机的用户名，销售日期从2020-01-01到未来两年。\n该表主要用于制作汇总销售报表。大多数报表都是通过日期来过滤，得到特定时期的销售情况。为了加快范围扫描，你可以在sold_at上创建一个索引。\n1 2 db=# CREATE INDEX sale_fact_sold_at_ix ON sale_fact(sold_at); CREATE INDEX 让我们看看一个查询的执行计划，以获取2020年6月的所有销售。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 db=# EXPLAIN (ANALYZE) db-# SELECT * db-# FROM sale_fact db-# WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN ----------------------------------------------------------------------------------------------- Bitmap Heap Scan on sale_fact (cost=108.30..1107.69 rows=4293 width=41) Recheck Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Heap Blocks: exact=927 -\u0026gt; Bitmap Index Scan on sale_fact_sold_at_ix (cost=0.00..107.22 rows=4293 width=0) Index Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Planning Time: 0.191 ms Execution Time: 5.906 ms 在执行了几次查询预热缓存后，时间稳定在约6ms。\nBitmap Scan 从执行计划来看，我们可以看到数据库使用了位图扫描。位图扫描的工作分为两个阶段。\n位图索引扫描。浏览整个索引sale_fact_sold_at_ix 并映射所有包含相关记录的表页。 位图堆扫描：读取包含相关行的页面。读取包含相关行的页面，并在这些页面中找到满足条件的行。 页面可以包含多条记录。第一步使用索引来查找页面。第二步检查这些页面里面的行，因此执行计划中的 \u0026ldquo;Recheck Cond \u0026ldquo;操作。\n这时，很多DBA和开发人员都会收工，继续进行下一个查询。BUT，有一个方法可以让这个查询变得更好。\nIndex Scan 为了让事情变得更好，我们会在加载数据的方式上做一个小小的改变。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 db=# TRUNCATE sale_fact; TRUNCATE TABLE db=# INSERT INTO sale_fact (username, sold_at) db-# SELECT db-# md5(random()::text) AS username, db-# \u0026#39;2020-01-01\u0026#39;::date + (interval \u0026#39;1 day\u0026#39;) * round(random() * 365 * 2) AS sold_at db-# FROM db-# generate_series(1, 100000) db-# ORDER BY sold_at; INSERT 0 100000 db=# VACUUM ANALYZE sale_fact; VACUUM 这次，我们加载的数据是按sold_at排序的。\n让我们看看现在完全相同的查询的执行计划是什么样子的。\n1 2 3 4 5 6 7 8 9 10 11 db=# EXPLAIN (ANALYZE) db-# SELECT * db-# FROM sale_fact db-# WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN --------------------------------------------------------------------------------------------- Index Scan using sale_fact_sold_at_ix on sale_fact (cost=0.29..184.73 rows=4272 width=41) Index Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Planning Time: 0.145 ms Execution Time: 2.294 ms 在运行了几次查询后，我们得到了一个稳定在2.3ms的轮回时间。与之前的查询耗时约6ms相比，我们得到了约60%的稳定节省。\n还有一点我们可以马上看到，这次数据库没有使用位图扫描，而是使用了 \u0026ldquo;常规 \u0026ldquo;索引扫描。为什么会这样呢？\nCorrelation 当数据库在分析一张表时，它会收集各种统计数据。其中一个统计是相关性。\n物理行排序和逻辑列值排序之间的统计相关性。这个范围从-1到+1。当该值接近-1或+1时，由于减少了对磁盘的随机访问，估计对该列进行索引扫描会比接近零时更便宜。\n正如官方文档所解释的那样，相关性衡量了特定列值在磁盘上的 \u0026ldquo;排序 \u0026ldquo;程度。\n当相关性为1，或接近1时，意味着表中的页在磁盘上的存储顺序与表中的行大致相同。这其实是很常见的。例如，自动递增的ID通常会有接近1的相关性。跟踪行创建时间的日期和时间戳列通常也会有接近于1的相关性。\n当相关性为-1时，表的页面相对于列的排序顺序是相反的。\n当相关性接近0时，意味着列中的值与表的页面存储方式没有相关性或相关性很小。\n回到我们的sale_fact表，当我们将数据加载到表中时，没有先进行排序，这些就是相关性。\n1 2 3 4 5 6 7 8 9 db=# SELECT tablename, attname, correlation db-# FROM pg_stats db=# WHERE tablename = \u0026#39;sale_fact\u0026#39;; tablename | attname | correlation -----------+----------+-------------- sale | id | 1 sale | username | -0.005344716 sale | sold_at | -0.011389783 自动生成的列id的相关性为1，sold_at列的相关性很低：连续的值分散在整个表中。\n当我们将排序数据加载到表中时，这些是数据库计算出的相关性。\n1 2 3 4 5 tablename | attname | correlation -----------+----------+---------------- sale_fact | id | 1 sale_fact | username | -0.00041992788 sale_fact | sold_at | 1 现在sold_at的相关性为1。\n那么为什么数据库在相关性较低的时候使用位图扫描，而在相关性接近1的时候使用索引扫描呢？\n当相关性为1时，数据库估计请求范围内的行很可能在连续的页面中。在这种情况下，索引扫描很可能读取很少的页面。 当相关性接近0时，数据库估计请求范围内的行很可能分散在整个表中。在这种情况下，使用位图扫描来映射存在行的表页是有意义的，只有这样才能获取行并应用条件。 下次将数据加载到表中时，请考虑如何查询数据，并确保以用于范围扫描的索引能够受益的方式进行排序。\nCLUSTER Command 另一种按特定索引对磁盘上的表进行 \u0026ldquo;排序 \u0026ldquo;的方法是使用CLUSTER命令。\n例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 db=# TRUNCATE sale_fact; TRUNCATE TABLE -- Insert rows without sorting db=# INSERT INTO sale_fact (username, sold_at) db-# SELECT db-# md5(random()::text) AS username, db-# \u0026#39;2020-01-01\u0026#39;::date + (interval \u0026#39;1 day\u0026#39;) * round(random() * 365 * 2) AS sold_at db-# FROM db-# generate_series(1, 100000) INSERT 0 100000 db=# ANALYZE sale_fact; ANALYZE db=# SELECT tablename, attname, correlation db-# FROM pg_stats db-# WHERE tablename = \u0026#39;sale_fact\u0026#39;; tablename | attname | correlation -----------+-----------+---------------- sale_fact | sold_at | -5.9702674e-05 sale_fact | id | 1 sale_fact | username | 0.010033822 我们按照随机顺序向表中加载数据，结果sold_at的相关性接近于零。\n为了按sold_at对表进行 \u0026ldquo;重新排列\u0026rdquo;，我们使用CLUSTER命令，根据索引sale_fact_sold_at_ix对磁盘上的表进行排序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 db=# CLUSTER sale_fact USING sale_fact_sold_at_ix; CLUSTER db=# ANALYZE sale_fact; ANALYZE db=# SELECT tablename, attname, correlation db-# FROM pg_stats db-# WHERE tablename = \u0026#39;sale_fact\u0026#39;; tablename | attname | correlation -----------+----------+-------------- sale_fact | sold_at | 1 sale_fact | id | -0.002239401 sale_fact | username | 0.013389298 表格聚类后，我们可以看到sold_at的相关性为1。\n关于CLUSTER命令需要注意的一些事情。\n通过特定列对表进行聚类可能会影响其他列的相关性。例如，请看我们将表按sold_at聚类后，列id的相关性。 CLUSTER是一个重度、阻塞的操作，所以请确保不要在活表上执行。 基于这两个原因，最好是将数据分类插入，不要依赖CLUSTER。\n使用 BRIN 索引高相关性的列 说到索引，大多数开发人员会想到B-Tree索引。但是，PostgreSQL提供了其他类型的索引，比如BRIN。\nBRIN是为处理非常大的表而设计的，在这些表中，某些列与它们在表中的物理位置有一些自然的关联。\nBRIN是Block Range Index的缩写。根据文档，BRIN索引对于相关性高的列效果最好。正如我们在前面的章节中已经看到的，一些字段如自动递增的ID和时间戳与表的物理结构有天然的相关性，因此它们是BRIN索引的良好候选。\n在某些情况下，与类似的B-Tree索引相比，BRIN索引在大小和性能上可以提供更好的 \u0026ldquo;性价比\u0026rdquo;。\nBRIN索引的工作原理是将值的范围保持在表内相邻的若干页内。假设我们在一列中有这些值，每个值都是单表页。\n1, 2, 3, 4, 5, 6, 7, 8, 9\nBRIN索引在表中相邻页的范围内工作。如果相邻页数设置为3，索引将把表格分为以下范围：\n[1,2,3], [4,5,6], [7,8,9]\n对于每个范围，BRIN指数保持最小值和最大值。\n[1–3], [4–6], [7–9]\n利用上面的索引，尝试搜索数值5。\n[1–3] - Definitely not here [4–6] - Might be here [7–9] - Definitely not here 利用BRIN索引，我们设法将搜索范围限制在4-6块。\n让我们再举一个例子，这次列中的值会有一个接近于零的相关性，这意味着它们没有被排序。\n[2,9,5], [1,4,7], [3,8,6]\n将3个相邻的块进行索引，会产生以下范围。\n[2–9], [1–7], [3–8]\n让我们试着搜索一下数值5。\n[2–9] - 可能在这 [1–7] - 可能在这 [3–8] - 可能在这\n在这种情况下，索引根本没有限制搜索，因此它是没有用的。\n理解 pages_per_range 相邻页面的数量由参数pages_per_range决定。每个范围的页数会影响BRIN索引的大小和精度。\n大的pages_per_range会产生一个小而不准确的索引。 小的pages_per_range会产生更大更准确的索引。 默认的页面_per_range为128页。\n为了演示，让我们在2个相邻页面的范围上创建一个BRIN索引，并搜索值5。\n[1–2] - 肯定不在这 [3–4] - 肯定不在这 [5–6] - 可能在这 [7–8] - 肯定不在这 [9] - 肯定不在这 使用每个范围为2页的索引，我们能够将搜索限制在第5和第6块。当范围为3页时，索引将搜索范围限制在4、5和6块。\n两个索引之间的另一个区别是，当范围是3页时，我们只需要保留3个范围。当范围为2时，我们必须保留5个范围，所以索引更大。\n创建 BRIN 索引\n使用之前的sales_fact，让我们在sold_at列上创建一个BRIN索引。\n1 2 3 db=# CREATE INDEX sale_fact_sold_at_bix ON sale_fact db-# USING BRIN(sold_at) WITH (pages_per_range = 128); CREATE INDEX 这就创建了一个BRIN索引，默认的页面_per_range = 128。\n让我们尝试查询销售日期的范围。\n1 2 3 4 5 6 7 8 9 10 11 12 13 db=# EXPLAIN (ANALYZE) db-# SELECT * db-# FROM sale_fact db-# WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN -------------------------------------------------------------------------------------------- Bitmap Heap Scan on sale_fact (cost=13.11..1135.61 rows=4319 width=41) Recheck Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Rows Removed by Index Recheck: 23130 Heap Blocks: lossy=256 -\u0026gt; Bitmap Index Scan on sale_fact_sold_at_bix (cost=0.00..12.03 rows=12500 width=0) Index Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Execution Time: 8.877 ms 数据库使用我们的BRIN索引得到了一系列的销售日期，但这不是有趣的部分\u0026hellip;\u0026hellip;。\n优化 pages_per_range\n根据执行计划，数据库从使用索引找到的页面中删除了23130条记录。这可能表明我们为索引设置的范围对于这个特定的查询来说太大。让我们尝试创建一个每个范围内页数较少的索引。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 db=# CREATE INDEX sale_fact_sold_at_bix64 ON sale_fact db-# USING BRIN(sold_at) WITH (pages_per_range = 64); CREATE INDEX db=# EXPLAIN (ANALYZE) db- SELECT * db- FROM sale_fact db- WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN --------------------------------------------------------------------------------------------- Bitmap Heap Scan on sale_fact (cost=13.10..1048.10 rows=4319 width=41) Recheck Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Rows Removed by Index Recheck: 9434 Heap Blocks: lossy=128 -\u0026gt; Bitmap Index Scan on sale_fact_sold_at_bix64 (cost=0.00..12.02 rows=6667 width=0) Index Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Execution Time: 5.491 ms 在每个范围为64页的情况下，数据库从使用索引找到的页面中删除的记录较少，只删除了9,434条，而当范围为128页时，删除了23,130条。这意味着数据库需要做更少的IO，查询速度也稍快，约5.5ms，而不是约8.9ms。\n用不同的pages_per_range值测试索引，产生了以下结果。\n1 2 3 4 5 6 PAGES_PER_RANGE ROWS_REMOVED_BY_INDEX_RECHECK 128 23,130 64 9,434 8 874 4 446 2 446 我们可以看到，当我们减少pages_per_range时，索引更加准确，并且从使用索引找到的页面中删除的行数更少。\n注意，我们针对一个非常特殊的查询进行了优化。这对于演示目的来说是可以的，但在实际生活中，最好使用满足大多数查询需求的值。\n评估指数大小\nBRIN索引的另一大卖点是其大小。在前面的章节中，我们在sold_at字段上创建了一个B-Tree索引。该索引的大小是2224kB。page_per_range=128的BRIN索引的大小只有48kb。这比B-Tree索引小了46倍。\n1 2 3 4 Schema | Name | Type | Owner | Table | Size --------+-----------------------+-------+-------+-----------+------- public | sale_fact_sold_at_bix | index | haki | sale_fact | 48 kB public | sale_fact_sold_at_ix | index | haki | sale_fact | 2224 kB BRIN索引的大小也会受到pages_per_range的影响。例如，page_per_range=2的BRIN索引重56kb，仅比48kb稍大。\n让索引 \u0026ldquo;不可见\u0026rdquo; PostgreSQL有一个很好的功能，叫做事务性DDL。在使用Oracle多年后，我已经习惯了诸如CREATE、DROP和ALTER等结束事务的DDL命令。然而，在PostgreSQL中，你可以在事务中执行DDL命令，而且只有当事务提交时，更改才会生效。\n正如我最近发现的那样，使用事务性DDL，你可以使索引不可见! 当你想看看一个执行计划在没有一些索引的情况下是什么样子的时候，这就很方便了。\n例如，在上一节的sale_fact表中，我们在sold_at上创建了一个索引。获取7月份销售额的执行计划是这样的。\n1 2 3 4 5 6 7 8 db=# EXPLAIN db-# SELECT * db-# FROM sale_fact db-# WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN -------------------------------------------------------------------------------------------- Index Scan using sale_fact_sold_at_ix on sale_fact (cost=0.42..182.80 rows=4319 width=41) Index Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date))P 为了看看如果索引sale_fact_sold_at_ix不存在，执行计划会是什么，我们可以在一个事务里面放弃索引，然后立即回滚。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 db=# BEGIN; BEGIN db=# DROP INDEX sale_fact_sold_at_ix; DROP INDEX db=# EXPLAIN db-# SELECT * db-# FROM sale_fact db-# WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN --------------------------------------------------------------------------------- Seq Scan on sale_fact (cost=0.00..2435.00 rows=4319 width=41) Filter: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) db=# ROLLBACK; ROLLBACK 我们首先使用BEGIN开始一个事务。然后我们放弃索引并生成一个执行计划。注意，现在执行计划使用了全表扫描，就像索引不存在一样。此时事务仍在进行中，所以还没有丢弃索引。为了在不丢弃索引的情况下完成事务，我们使用ROLLBACK命令回滚事务。\n现在，确保索引仍然存在。\n1 2 3 4 5 db=# \\di+ sale_fact_sold_at_ix List of relations Schema | Name | Type | Owner | Table | Size --------+----------------------+-------+-------+-----------+--------- public | sale_fact_sold_at_ix | index | haki | sale_fact | 2224 kB 其他不支持事务性DDL的数据库提供了其他方法来实现同样的目标。例如，Oracle让你将一个索引标记为不可见，这将导致优化器忽略它。\n注意：在事务内部丢弃索引会在事务处于活动状态时锁定表的并发选择、插入、更新和删除。请在测试环境中谨慎使用，并避免在生产数据库中使用。\n不要在圆周时间安排长期运行的流程 众所周知，当一只股票的价格达到一个漂亮的整数，如10元、100元、1000元时，就会发生奇怪的事情，这是投资者都知道的事实。正如下面的文章所解释的。\n[\u0026hellip; \u0026hellip;]资产的价格可能会有一个困难的时间 超过一个整数，如50元或100元/股。大多数没有经验的交易者倾向于在价格处于整数时买入或卖出资产，因为他们更有可能觉得一只股票在这种水平上的价值相当高。\n开发商在这个意义上与投资者并没有什么不同。当他们需要安排一个长期运行的过程时，他们通常会把时间安排在一个整点。\n这种在圆周时间安排任务的倾向，会在这些时间内造成一些异常的负载。所以，如果你需要安排一些长期运行的进程，如果你在其他时间安排，你有更好的机会找到一个系统在休息。\n另一个好主意是给任务的日程安排应用一个随机的延迟，这样它就不会每次都在同一时间运行。这样，即使另一个任务安排在同一时间运行，也不会有大问题。如果你使用systemd定时器单元来安排任务，你可以使用RandomizedDelaySec选项来实现。\n结束语 本文涵盖了我自己经验中的一些琐碎和非琐碎的技巧。其中有些技巧很容易实现，有些则需要更深入地了解数据库的工作原理。数据库是大多数现代系统的支柱，所以花一些时间来了解它们的工作原理对任何开发人员来说都是一项很好的投资!\n","date":"2020-07-31T22:23:44+08:00","image":"https://martinliu.cn/images/abstract-1.jpg","permalink":"https://martinliu.cn/blog/sql-tricks-application-dba/","title":"应用开发 DBA 技巧集锦"},{"content":"新闻 又到了一年一度的时间。定期的Puppet Devops状态调查已经开始。今年的重点是变革管理、持续交付和自服务平台之间的关系。 https://polls.onresearch.net/xsurvey/20JT028/20JT028T1/Survey.aspx?ckie=true\n文档和设计在构建强大的系统中起着至关重要的作用。这篇文章探讨了为什么设计文档是有用的，以及它们应该包含什么样的内容。 https://www.industrialempathy.com/posts/design-docs-at-google/\n一份关于公共Terraform代码安全状况的新报告。对于任何使用Terraform配置服务的人来说，一些有用的数据和一些好的提示。 https://bridgecrew.io/blog/state-of-open-source-terraform-security-report-2020/\n看看如何使用 Azure Pipelines 自动验证 sysmon 配置。 https://medium.com/falconforce/using-azure-pipelines-to-validate-my-sysmon-configuration-48315dba7571\n这是一个很好的大规模迁移低级组件的故事，在这个案例中是一个应用服务器。金丝雀的推出、上游贡献、性能和其他有趣的话题。 https://about.gitlab.com/blog/2020/07/08/migrating-to-puma-on-gitlab/\n拥抱云原生技术和工作方式会带来挑战，本帖记录了其中一些挑战，包括安全、缺乏专业知识、发布周期缓慢等。 https://www.cloudops.com/2020/07/top-7-challenges-to-becoming-cloud-native/\n文章 “How could they be so stupid?” 上周知名Twitter 账号入侵事件出现了更多细节，导致一些人说出了上面这句话。这里有一个看法，如何看待这不是 \u0026ldquo;愚蠢 \u0026ldquo;的问题。Lorin Hochstein https://surfingcomplexity.blog/2020/07/20/how-could-they-be-so-stupid/\nData Consistency Checks 你的数据库中的数据应该是一致的\u0026hellip;\u0026hellip;但话说回来，事故不应该发生，对吗？Slack接受在他们的规模下，数据经常会出问题，他们有框架和一套工具来处理它。Paul Hammond and Samantha Stoller — Slack https://slack.engineering/data-consistency-checks-e73261318f96\nObstacles to Learning from Incidents 我从这篇文章中学到了很多东西。我最喜欢的障碍是 \u0026ldquo;通过差异化来拉开距离\u0026rdquo;，比如 \u0026ldquo;我们绝对不会以这种方式应对事件\u0026rdquo;。Thai Wood — Learning from Incidents https://www.learningfromincidents.io/blog/obstacles-to-learning-from-incidents\nYou don’t need SRE. What you need is SRE. […] SRE，也就是谷歌定义的SRE，对于大多数组织来说并不适用。Sanjeev Sharma https://sdarchitect.blog/2020/02/20/you-dont-need-sre-what-you-need-is-sre/\nQuestionable Advice: “What’s the critical path?” 专家建议，当你试图弄清楚你的关键路径是什么（以及为什么你想知道它是什么）时，应该问什么问题。Charity Majors https://charity.wtf/2020/07/24/questionable-advice-whats-the-critical-path/\nThinking About Your Humans With J. Paul Reed 这个播客集有点像J.Paul Reed和Tim Heckman在https://srefromhome.com/的联合演讲的预览。我喜欢他们把这场传染病大流行称为长达数月的事件，并指出如果你总是在事件中，那么你永远不会在事件中。Julie Gunderson and Mandi Walls — Page it to the Limit https://www.pageittothelimit.com/thinking-about-your-humans/\nRebuilding messaging: How we bootstrapped our platform 我喜欢一个好的双写故事。以下是LinkedIn如何过渡到新的消息存储机制。 Pradhan Cadabam and Jingxuan (Rex) Zhang — LinkedIn https://engineering.linkedin.com/blog/2020/bootstrapping-our-new-messaging-platform\nUsing Automation and SLOs to Create Margin in your Systems 在系统中留有余地，使其具有适应能力，并利用SLO(同情地)来推动优先事项的确定。 https://thechief.io/c/blameless/using-automation-and-slos-create-margin-your-systems/\nHow to Classify Incidents 如何对事件进行分类 什么是事件分类？为什么要对事件进行分类？事件严重性与优先级，以及如何创建事件类别？ https://thechief.io/c/blameless/how-classify-incidents/\n宕机 上周全球重大宕机事故清单。\nGarmin 作为佳明手表和 app 的用户，我体验到了这场 24+小时的服务中断 https://spectrumlocalnews.com/nys/rochester/ap-online/2020/07/24/garmin-fitness-tracking-service-goes-down-frustrating-users Snapchat 打不开 app，黑屏，无法使用摄像头相关功能 https://screenrant.com/snapchat-down-app-slow-response-messages-not-sent-issues/ Tweetdeck Twitter 客户的工具服务发生故障。 https://www.independent.co.uk/life-style/gadgets-and-tech/news/tweetdeck-down-twitter-not-working-loading-a9633636.html GGPoker 在 World Series of Poker (WSOP) 世界扑克大赛赛事期间发生一些列问题. https://portswigger.net/daily-swig/online-poker-operator-hit-by-ddos-attack-on-opening-day-of-wsop-event Fastly (control plane) Full disclosure: Fastly is my employer. https://status.fastly.com/incidents/7q2psqf255wl Squarespace 这一周非常痛苦，在July 21 事故后发生的相关事件： *July 21 https://status.squarespace.com/incidents/hh3p432jcq03 July 22 (包含事件详细分析) https://status.squarespace.com/incidents/3cgg1171wyvz *July 24 https://status.squarespace.com/incidents/x63nssl9kzvm July 24 https://status.squarespace.com/incidents/v6ql728f1f4d Google Cloud Platform 几个谷歌云平台组件受到影响，包括 7 层负载均衡器。 https://status.cloud.google.com/incident/zall/20006 工具 https://github.com/flant/shell-operator Shell-operator是一个在Kubernetes集群中运行事件驱动脚本的工具。\nhttps://github.com/Fizzadar/pyinfra pyinfra在大规模的基础架构中实现了超快的自动化。它可以用于临时命令执行、服务部署、配置管理等。\npython #配置管理 https://github.com/alerta/alerta Alerta 监测系统\nhttps://github.com/GoogleCloudPlatform/terraformer CLI工具可以从现有的基础设施中生成terraform文件（反向Terraform）。\n基础设施即代码 https://github.com/visenger/awesome-mlops MLOps的精选参考资料清单。\ngithub https://github.com/cycloidio/inframap 读取你的tfstate或HCL，为每个提供者生成一个特定的图表，只显示最重要/相关的资源。\nterraform https://github.com/Hack-with-Github/Awesome-Hacking 一个为黑客、Pentesters和安全研究人员提供的各种令人敬畏的列表的集合。\ngithub #安全 https://github.com/box/kube-iptables-tailer kube-iptables-tailer做的正是你所期望的。它将底层的iptables数据暴露给kubectl，方便发现服务在Kubernetes中互相通信的尝试和失败。\nhttps://github.com/Stono/kconmon Kconmon是一个Kubernetes连通性监控工具，它可以运行频繁的测试（tcp、udp和dns），并公开Prometheus指标，这些指标富含节点名称，以及位置信息（如区域），使您能够关联可用性区域或节点之间的问题。\n","date":"2020-07-28T10:35:19+08:00","image":"https://martinliu.cn/images/weeklyupdate.jpg","permalink":"https://martinliu.cn/blog/devopscoach-weekly-1/","title":"DevOps Coach 周刊 1"},{"content":"\n今天介绍一个本地 Kubernetes 开发的利器 Skaffold。 这是我偶然间发现的一个工具，询问了一下周围的人，居然还没有人用过。测试之后，确实有一种不吐不快的感觉。\n简介 Skaffold Google 开发的一个开源项目。是一个非常轻量的命令行工具，就是一个可执行文件。它的主页上是这样的介绍它的。\n轻量：Skaffold只是一个客户端工具。由于集群上不需要任何的相关组件，您的集群没有任何开销或维护负担。 运行在任何地方：Skaffold是与世界分享你的项目的最简单的方法：\u0026ldquo;git clone\u0026rdquo;，然后 \u0026ldquo;skaffold run\u0026rdquo;。此外，你还可以使用配置文件、本地用户配置、环境变量和标志来轻松地集成不同环境的差异。 功能丰富：Skaffold拥有许多Kubernetes原生开发的基本功能，包括基于策略的打镜像标签、资源端口转发和日志、文件同步等。 优化你的开发：Skaffold使内部循环紧密，高度优化，让您在开发的同时得到即时反馈。 客户评价 \u0026ldquo;我们的客户很喜欢[Kubernetes]，但一直给我们反馈说在Kubernetes上开发很麻烦。Skaffold一针见血地解决了这个问题。以前需要几分钟才能部署的docker镜像或配置的更改，现在只需要几秒钟。Skaffold的插件架构使我们能够部署到Helm或Kustomize，并使用各种docker构建插件，如Kaniko。Skaffold用一个精简的工具取代了我们定制的实用程序和脚本集合，并且易于使用。\u0026rdquo; Warren Strange，ForgeRock的工程总监。\n\u0026ldquo;当我们评估我们可以使用Kubernetes的工作流程时，Skaffold脱颖而出，成为我们在开发和部署中都想要的工具。它为我们提供了一个跨应用程序的通用入口点，我们也可以为CI/CD重用。现在，我们所有的Kubernetes应用的CI/CD管道在构建和部署时都使用Skaffold。\u0026rdquo; Taylor Barrella，Quora的软件工程师\n\u0026ldquo;Skaffold是一个了不起的工具，它为我们简化了开发和交付。Skaffold通过覆盖两个维度，击中了我们的甜蜜点。第一，从本地开发、集成测试到交付的整个开发周期。第二，Skaffold让我们能够在Linux、OSX和Windows上独立开发，不需要特定的平台逻辑。\u0026rdquo; Martin Höfling，TNG技术咨询有限公司首席顾问\n推荐首次测试流程 前置条件，你的开发用工作电脑上已经安装了它需要调用的 kubectl 和 docker 命令，kubectl 需要有至少一个可用的配置，这个配置可以指向任一一个你有权限部署的 Kubernetes 集群。\n我在 macOS 上，直接运行 ‌brew install skaffold 即可，其它系统参考：https://skaffold.dev/docs/install/\n克隆 Skaffold 的代码库到本地，获取必要的测试应用代码。\n‌git clone https://github.com/GoogleContainerTools/skaffold\n进入代码库中的‘hello world’示例应用。\n执行：‌cd skaffold/examples/getting-started\n执行 ‌skaffold dev ，你会看到 Skaffold 进入了这个项目的构建和运行的状态，执行结果是持续的输出 ”[getting-started] Hello world!“\n现在 Skaffold 就进入了 /getting-started 的监视状态。观察任何代码文件的修改存盘动作，每次代码的变更会触发 Skaffold 流水线的执行，skaffold.yaml 文件中描述了本地流水线中的相关动作：\n使用 Dockerfile 从源头构建Docker镜像。 用Docker镜像的内容的sha256哈希值来打上标签。 更新 Kubernetes manifest k8s-pod.yaml，以使用上一步构建的镜像。 使用 kubectl apply -f 部署 Kubernetes manifest。 从已部署的应用程序取回日志在本地控制台显示。 现在用代码编辑器打开这个项目唯一的程序文件 main.go ，修改其中的 Hello World 为其它你想到的词，保存后，观察构建的过程。\n推荐微服务测试 参考以下视频，测试 Skaffold 代码库中的 microservice 项目。\nSkaffold 流水线阶段 Skaffold 主要会用到五个阶段。\n其所有阶段如下：\nInit ： generate a starting point for Skaffold configuration Build ：build images with different builders Tag ： tag images based on different policies Test ：test images with structure tests Deploy ：deploy with kubectl, kustomize or helm File Sync ： sync changed files directly to containers Log ： Tailing tail logs from workloads Port Forwarding ：forward ports from services and arbitrary resources to localhost Cleanup ： cleanup manifests and images 当你启动Skaffold时，它就会收集你项目中的源代码，并使用你所选择的工具构建工件；工件一旦成功构建，就会根据你的需要进行标记，并推送到你指定的仓库中。在工作流程的最后，Skaffold还帮助你将工件部署到你的Kubernetes集群中，同样使用你喜欢的工具。\nSkaffold允许你跳过各个阶段。例如，如果你在本地使用Minikube运行Kubernetes，Skaffold不会将工件推送到远程仓库。\n每个阶段的详情见：https://skaffold.dev/docs/pipeline-stages/\n架构设计 Skaffold 秉承着插件化的设计思想。\n以上架构内置了对下来工具的支持：\nBuild Dockerfile locally, in-cluster with kaniko or on cloud using Google Cloud Build Jib Maven and Jib Gradle locally or on cloud using Google Cloud Build Bazel locally Cloud Native Buildpacks locally or on cloud using Google Cloud Build Custom script locally or in-cluster Test container-structure-test Tag Git tagger Sha256 tagger\nEnv Template tagger\nDateTime tagger\nDeploy\nKubernetes Command-Line Interface (kubectl) Helm kustomize 总结 Skaffold 确实让基于 Kubernetes 的开发者的本地工作环境更加优化和整洁了。希望本文对你的工作有所帮助。\n","date":"2020-07-15T00:09:53+08:00","image":"https://martinliu.cn/images/abstract-1.jpg","permalink":"https://martinliu.cn/blog/skaffold-make-local-k8s-dev-easy/","title":"Skaffold 让 K8s 开发者更加酸爽"},{"content":"本文概要：配置 ES 3 节点全加密，Kibana 的 SSL 加密配置，Beats 的高可靠性加密传输，用 RBAC 怎样把权限控制到最小，在配置文件中消除明文密码，这些你都做到了么？如何保证安全、能适应和可扩展的配置 Elastic Stack 技术栈，让我们从 Bests 的角度开始讲解。\n前言 本文使用的软版本：\nElastic Stack 7.8.0 macOS 10.15.5 Vagrant 2.2.9 VirtualBox 6.0 CentOS 8.0 下面的配置和测试过程基于以下 Vagrantfile ，你可以在其它任何同等的环境中测试下面的所有配置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # -*- mode: ruby -*- # vi: set ft=ruby : # Every Vagrant development environment requires a box. You can search for # boxes at https://atlas.hashicorp.com/search. BOX_IMAGE = \u0026#34;bento/centos-8\u0026#34; ES_COUNT = 3 NODE_COUNT = 4 Vagrant.configure(\u0026#34;2\u0026#34;) do |config| #设置所有 guest 使用相同的静态 dns 解析 /etc/hosts config.vm.provision :hosts, :sync_hosts =\u0026gt; true #用 vagrant 默认密钥对 ssh 登录 config.ssh.insert_key = false # 用于部署 Elasticsearch 服务器的集群 (1..ES_COUNT).each do |i| config.vm.define \u0026#34;es#{i}\u0026#34; do |es_config| es_config.vm.box = BOX_IMAGE es_config.vm.hostname = \u0026#34;es#{i}.zenlab.local\u0026#34; es_config.vm.network :private_network, ip: \u0026#34;192.168.50.#{i + 10}\u0026#34; es_config.vm.provision :hosts, :sync_hosts =\u0026gt; true es_config.vm.provider :virtualbox do |vb| vb.memory = 2048 vb.cpus = 1 end es_config.vm.provision :shell, path: \u0026#39;pre-install-ES.sh\u0026#39; end end # 用于部署 Kibana、Logstash 、APM Server、Heatbeat 和 Packetbeat config.vm.define \u0026#34;lk\u0026#34; do |lk_config| lk_config.vm.box = BOX_IMAGE lk_config.vm.hostname = \u0026#34;lk.zenlab.local\u0026#34; lk_config.vm.network :private_network, ip: \u0026#34;192.168.50.20\u0026#34; lk_config.vm.network \u0026#39;forwarded_port\u0026#39;, guest: 5601, host: 5601 lk_config.vm.provision :hosts, :sync_hosts =\u0026gt; true lk_config.vm.provider :virtualbox do |vb| vb.memory = 1024 vb.cpus = 1 end #logstash_config.vm.provision :shell, path: \u0026#39;pre-install-ES.sh\u0026#39; end # 两个被管理节点，用于部署监控应用和各种 Beats 代理 (1..NODE_COUNT).each do |i| config.vm.define \u0026#34;node#{i}\u0026#34; do |node_config| node_config.vm.box = BOX_IMAGE node_config.vm.hostname = \u0026#34;node#{i}.zenlab.local\u0026#34; node_config.vm.network :private_network, ip: \u0026#34;192.168.50.#{i + 20}\u0026#34; node_config.vm.provider :virtualbox do |vb| vb.memory = 1024 vb.cpus = 1 end node_config.vm.provision :shell, path: \u0026#39;pre-install-beats.sh\u0026#39; end end # Install avahi on all machines config.vm.provision \u0026#34;shell\u0026#34;, inline: \u0026lt;\u0026lt;-SHELL sh -c \u0026#34;echo \u0026#39;Welcome to Elastic Stack!\u0026#39;\u0026#34; SHELL end 注：下文中所有路径中的 /vagrant/ 目录是本 vagrant 测试环境中，所有虚拟机的共享目录，是所有节点上配置文件的原路径。如果你使用的不是 vagrant 环境，你需要在下面的测试中适当的替换。\n三节点 Elasticsearch 服务器集群 在每个节点上使用下面的初始化脚本，部署 Elasticsearch 服务器。\n使用vagrant up es1 es2 es3命令创建并启动 ES 服务器三个节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # pre-install-ES.sh elastic_version=\u0026#39;7.8.0\u0026#39; echo \u0026#34;Provisioning a Elasticsearch \u0026#34;$elastic_version\u0026#34; Server...\u0026#34; sudo date \u0026gt; /etc/vagrant_provisioned_at sudo swapoff -a sudo sysctl -w vm.max_map_count=262144 sudo sysctl -p sudo sh -c \u0026#34;echo \u0026#39;elasticsearch - nofile 65535\u0026#39; \u0026gt;\u0026gt; /etc/security/limits.conf\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;**** -- -- -- -- -- -- -- -- ****\u0026#39; \u0026gt; /etc/motd\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;**** Welcome to Elastic Stack Labs\u0026#39; \u0026gt;\u0026gt; /etc/motd\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;**** -- -- -- -- -- -- -- -- ****\u0026#39; \u0026gt;\u0026gt; /etc/motd\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;*\u0026#39; \u0026gt;\u0026gt; /etc/motd\u0026#34; sudo rpm -ivh /vagrant/rpm/elasticsearch-$elastic_version-x86_64.rpm 上面的脚本简单的初始化了几个操作系统参数，然后完成了 rpm 包的安装。非vagrant 环境的需要手工上传 rpm 安装文件，和运行以上的命令。\n配置首个 ES 服务器节点 登录 es1 节点vagrant ssh es1 ；\n创建用于节点间传输所需要的数字证书和秘钥文件，下面是所使用的种子文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # instance.yml instances: - name: \u0026#39;es1\u0026#39; ip: [\u0026#39;192.168.50.11\u0026#39;] dns: [ \u0026#39;es1.zenlab.local\u0026#39; ] - name: \u0026#34;es2\u0026#34; ip: [\u0026#39;192.168.50.12\u0026#39;] dns: [ \u0026#39;es2.zenlab.local\u0026#39; ] - name: \u0026#39;es3\u0026#39; ip: [\u0026#39;192.168.50.13\u0026#39;] dns: [ \u0026#39;es3.zenlab.local\u0026#39; ] - name: \u0026#39;lk\u0026#39; ip: [\u0026#39;192.168.50.20\u0026#39;] dns: [ \u0026#39;lk.zenlab.local\u0026#39; ] 用 elasticsearch-certutil 创建证书文件包。\n1 sudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert --ca --pem --in /vagrant/certs/instance.yml --out /vagrant/certs/certs.zip 将得到的 zip 文件解压缩在适当的目录里备用。\n重要步骤：在 Elasticsearch 的配置文件目录中放置必要的数字证书文件。\n1 2 3 4 sudo mkdir /etc/elasticsearch/certs sudo cp /vagrant/certs/ca/ca.crt /etc/elasticsearch/certs sudo cp /vagrant/certs/es1/* /etc/elasticsearch/certs sudo ls /etc/elasticsearch/certs 在 certs 目录中有三个文件：\nca.crt CA 根证书 es1.crt 服务器证书 es1.key 私钥文件 CA 根证书是在所有节点上发起对 ES 服务的 HTTPS 服务所需要的客户端证书。 es1.crt 和 es1.key 这样的必要对需要在所有 ES 节点上部署，用于 ES 节点间的 transport 协议加密传输，每个 ES 节点都是用自己的密钥对文件。\n在 ES1 的主配置文件中打开安全选项和其它必要配置，示例配置文件如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # elasticsearch.yml # ---------------------------------- Cluster ----------------------------------- cluster.name: elk4devops # ------------------------------------ Node ------------------------------------ node.name: es1 # ----------------------------------- Paths ------------------------------------ path.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch # ---------------------------------- Network ----------------------------------- network.host: es1.zenlab.local # --------------------------------- Discovery ---------------------------------- cluster.initial_master_nodes: [\u0026#34;es1\u0026#34;] discovery.seed_hosts: [ \u0026#34;es1.zenlab.local\u0026#34; ] # ------------------------------- TLS and Cert --------------------------------- xpack.security.enabled: true #外部服务加密配置 xpack.security.http.ssl.enabled: true xpack.security.http.ssl.key: certs/es1.key xpack.security.http.ssl.certificate: certs/es1.crt xpack.security.http.ssl.certificate_authorities: certs/ca.crt #集群内通讯加密配置 xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.key: certs/es1.key xpack.security.transport.ssl.certificate: certs/es1.crt xpack.security.transport.ssl.certificate_authorities: certs/ca.crt xpack.monitoring.collection.enabled: true # ------------------------------- App Search --------------------------------- action.auto_create_index: \u0026#34;.app-search-*-logs-*,-.app-search-*,+*\u0026#34; 使用以上配置文件覆盖Elasticsearch 默认的配置文件，首次启动第一个 ES 节点的服务。\n1 2 3 sudo cp /vagrant/elasticsearch.yml /etc/elasticsearch/elasticsearch.yml sudo systemctl daemon-reload sudo systemctl start elasticsearch 用下面的命令查看启动日志，直到 elasticsearch 服务正常启动。\n1 sudo tail -f /var/log/elasticsearch/elk4devops.log 用下面的命令初始化 Elasticsearch 系统内置账号为随机复杂密码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 sudo /usr/share/elasticsearch/bin/elasticsearch-setup-passwords auto -u \u0026#34;https://es1.zenlab.local:9200\u0026#34; -b Changed password for user apm_system PASSWORD apm_system = irpVThXpbFDrdq2rBQUC Changed password for user kibana_system PASSWORD kibana_system = CxGNlkqQMbcp6u6XuCbk Changed password for user kibana PASSWORD kibana = CxGNlkqQMbcp6u6XuCbk Changed password for user logstash_system PASSWORD logstash_system = EOUiCyQQ97IHwUJs8Eum Changed password for user beats_system PASSWORD beats_system = EF8OdPmcpy1bUCgFVQ90 Changed password for user remote_monitoring_user PASSWORD remote_monitoring_user = 3ZRBVo5Omu33McoOKgwE Changed password for user elastic PASSWORD elastic = ZSzN2idoU6hFa4f0ulPP 将上面随机生成的密码保存在安全的地方备用，这些内置的超级用户权限大，一旦遗失了密码，可能会造成重大的数据泄露。\n用上面创建的账户测试第一个 ES 节点是否可以通过 https 正常访问，这里也测试 ca 公钥的可用性。\n1 curl --cacert /vagrant/certs/ca/ca.crt -u elastic \u0026#39;https://es1.zenlab.local:9200/_cat/nodes?v\u0026#39; 在 es1 服务器的命令行运行以上命令，输入 elastic 的密码。应该可以看到正常的输出。/vagrant/certs/ca/ca.crt 这个路径替换成你的环境中的相关 ca 证书文件路径。\n配置第二个和第三个 ES 服务器节点 剩下的两个节点在加入集群之前都已经通过初始化脚本安装完了 rpm 安装包。剩下的就是逐个节点的部署之前生产的证书文件和修改后的 elasticsearc.yml 主配置文件。在本文档参考的环境中使用如下命令。\n登录 es 2 vagrant ssh es2\n配置 es2 的证书和秘钥文件，下面的复制原路径需要替换成你所使用的实际路径。\n1 2 3 4 sudo mkdir /etc/elasticsearch/certs sudo cp /vagrant/certs/ca/ca.crt /etc/elasticsearch/certs sudo cp /vagrant/certs/es2/* /etc/elasticsearch/certs sudo ls /etc/elasticsearch/certs 部署 es2 的配置文件，然后启动这个节点的 Elasticsearch 服务。\n1 2 3 sudo cp /vagrant/elasticsearch2.yml /etc/elasticsearch/elasticsearch.yml sudo systemctl daemon-reload sudo systemctl start elasticsearch elasticsearch2.yml 文件的内容如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # ---------------------------------- Cluster ----------------------------------- cluster.name: elk4devops # ------------------------------------ Node ------------------------------------ node.name: es2 # ----------------------------------- Paths ------------------------------------ path.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch # ---------------------------------- Network ----------------------------------- network.host: es2.zenlab.local # --------------------------------- Discovery ---------------------------------- cluster.initial_master_nodes: [\u0026#34;es1\u0026#34;] discovery.seed_hosts: [ \u0026#34;es1.zenlab.local\u0026#34; ] # ------------------------------- TLS and Cert --------------------------------- xpack.security.enabled: true xpack.security.http.ssl.enabled: true xpack.security.http.ssl.key: certs/es2.key xpack.security.http.ssl.certificate: certs/es2.crt xpack.security.http.ssl.certificate_authorities: certs/ca.crt xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.key: certs/es2.key xpack.security.transport.ssl.certificate: certs/es2.crt xpack.security.transport.ssl.certificate_authorities: certs/ca.crt xpack.monitoring.collection.enabled: true # ------------------------------- App Search --------------------------------- action.auto_create_index: \u0026#34;.app-search-*-logs-*,-.app-search-*,+*\u0026#34; 在 es2 的命令用下面的命令查看是否该节点正常加入了集群。\n1 2 3 4 5 curl --cacert /vagrant/certs/ca/ca.crt -u elastic \u0026#39;https://es1.zenlab.local:9200/_cat/nodes?v\u0026#39; Enter host password for user \u0026#39;elastic\u0026#39;: ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 192.168.50.11 37 94 0 0.00 0.05 0.06 dilmrt * es1 192.168.50.12 17 96 9 0.49 0.20 0.07 dilmrt - es2 注意上面 ca.crt 文件的路径，要输入的是 elasstic 用户的密码。 正常情况下两个节点都会出现在结果清单中。\n用相似的命令初始化和启动 es3 节点的服务。es3 的主配置文件样例如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # ---------------------------------- Cluster ----------------------------------- cluster.name: elk4devops # ------------------------------------ Node ------------------------------------ node.name: es3 # ----------------------------------- Paths ------------------------------------ path.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch # ---------------------------------- Network ----------------------------------- network.host: es3.zenlab.local # --------------------------------- Discovery ---------------------------------- cluster.initial_master_nodes: [\u0026#34;es1\u0026#34;] discovery.seed_hosts: [ \u0026#34;es1.zenlab.local\u0026#34; ] # ------------------------------- TLS and Cert --------------------------------- xpack.security.enabled: true xpack.security.http.ssl.enabled: true xpack.security.http.ssl.key: certs/es3.key xpack.security.http.ssl.certificate: certs/es3.crt xpack.security.http.ssl.certificate_authorities: certs/ca.crt xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.key: certs/es3.key xpack.security.transport.ssl.certificate: certs/es3.crt xpack.security.transport.ssl.certificate_authorities: certs/ca.crt xpack.monitoring.collection.enabled: true # ------------------------------- App Search --------------------------------- action.auto_create_index: \u0026#34;.app-search-*-logs-*,-.app-search-*,+*\u0026#34; 最终集群的测试状态如下：\n1 2 3 4 5 6 [vagrant@es1 ~]$ curl --cacert /vagrant/certs/ca/ca.crt -u elastic \u0026#39;https://es1.zenlab.local:9200/_cat/nodes?v\u0026#39; Enter host password for user \u0026#39;elastic\u0026#39;: ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 192.168.50.11 20 96 6 0.18 0.09 0.03 dilmrt * es1 192.168.50.13 50 96 2 0.02 0.07 0.03 dilmrt - es3 192.168.50.12 25 96 1 0.00 0.02 0.00 dilmrt - es2 配置 Kibana 服务器 服务是必要的的管理界面，是数据搜索、可视化的重要工具。在 Elasticsearch 服务打开了外部 https 加密访问的情况下，Kibana 服务器的安装和配置也需要做如下调整。\nKibana 的 rpm 安装这里省略。下面直接进入相关的主要配置步骤。\n复制用于链接 ES 集群的证书\n1 2 3 4 sudo mkdir /etc/kibana/certs sudo cp /vagrant/certs/ca/ca.crt /etc/kibana/certs sudo cp /vagrant/certs/lk/* /etc/kibana/certs sudo ls /etc/kibana/certs 修改默认的 kibana.yml 配置文件，然后覆盖默认的配置文件后启动 kibana 服务。\n1 2 3 sudo cp /vagrant/kibna.yml /etc/kibana/kibana.yml sudo cat /etc/kibana/kibana.yml sudo systemctl start kibana 监控 kibana 的启动日志，直到它正常启动。\n1 sudo tail -f /var/log/messages 启动后，使用浏览器访问 https://lk.zenlab.lcoal:5601 Kibana 服务，使用 elastic 用户的密码登录，确保 Kibana 正常启动。\n配置权限 Beats 账号 在使用 Beats 采集监控数据的时候，Beats 的配置文件中需要配置一个后台 Elasticsearch 服务访问账号，安全起见需求需要将这个账号配置为只写权限。配置步骤如下。\n在 Kibana 的用户管理中创建名为 beats-writer 的角色，如下图所示。\n以上这个角色拥有 filebeat 和 Metricbeat 两个索引的访问权限，这里是为了评估用户角色管理的工作量，否则可以每个索引单独设置一套必要权限的角色和用户，从而实现更安全的防护。\n然后创建名为 beats-writer 的用户，设置一个密码，将它赋予 beats-writer 的角色（上面创建的）。\n这样它就可以用于所有 Beats 节点的配置了。\n初始化首个 Beats 节点 在 vagrant 测试环境中启动第一个用于测试 Beats 的节点。\nvagrant up node1\n这里使用了初始脚本安装相关的 rpm 安装包。\n1 2 3 4 5 6 7 8 9 10 11 12 #!/bin/bash # author: Martin Liu # url:martinliu.cn elastic_version=\u0026#39;7.8.0\u0026#39; echo \u0026#34;Installing a Filebeat \u0026#34;$elastic_version\u0026#34; agent...\u0026#34; sudo rpm -ivh /vagrant/rpm/filebeat-$elastic_version-x86_64.rpm sudo systemctl enable filebeat.service sudo rpm -ivh /vagrant/rpm/metricbeat-$elastic_version-x86_64.rpm sudo systemctl enable metricbeat.service sudo rpm -ivh /vagrant/rpm/auditbeat-$elastic_version-x86_64.rpm sudo systemctl enable auditbeat.service 登录该节点进行 Beats 的初始化配置。目前 Elasticsearch 集群还是空白的，还没有初始化任何 Beats 相关的索引、可视化和仪表板。这个初始化工作是通过，每种 Beats 的 setup 命令完成的。这个 setup 命令只需要在一个节点上成功执行一次即可，其它节点的配置文件中，连 setup 命令相关的配置都不需要。\n这里使用的 filebeat.yml 参考文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 #=========================== Filebeat inputs ============================= filebeat.inputs: - type: log enabled: false paths: - /var/log/*.log #============================= Filebeat modules =============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true reload.period: 5s #==================== Elasticsearch template setting ========================== setup.template.settings: index.number_of_shards: 1 index.codec: best_compression #============================== Kibana ===================================== setup.kibana: host: \u0026#34;https://lk.zenlab.local:5601\u0026#34; #-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: hosts: [\u0026#34;es1.zenlab.local:9200\u0026#34;] username: \u0026#34;elastic\u0026#34; password: \u0026#34;1l1lqVMMWMbLI6DCH0dQ\u0026#34; protocol: https #================================ Processors ===================================== processors: - add_host_metadata: netinfo.enabled: true cache.ttl: 5m geo: name: bj-dc-01 location: 35.5528, 116.2360 continent_name: Asia country_iso_code: CN region_name: Beijing region_iso_code: CN-BJ city_name: Beijing - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ 目前的计划是配置 Beats 直接访问 Elasticsearch 后台服务，不通过 Logstash 中转。以后增加这个参考配置。\n在执行 filebeat setup 命令之前，还需要在 Beats 节点上部署上面生成的 ca 公钥文件。参考命令如下。\n1 2 3 sudo update-ca-trust enable sudo cp /vagrant/certs/ca/ca.crt /etc/pki/ca-trust/source/anchors/ sudo update-ca-trust extract 这里把 ca.crt 公钥文件部署到了 CentOS 操作系统的的可信 CA 发放机构的目录中，其它操作系统中的这个证书路径可能不同，需要做替换，包括以上的证书更新命令也可能需要调整。\n经过以上的配置之后，用之前的 curl 命令测试一下是否这个证书生效了。\n1 2 3 4 5 6 [vagrant@es1 ~]$ curl -u elastic \u0026#39;https://es1.zenlab.local:9200/_cat/nodes?v\u0026#39; Enter host password for user \u0026#39;elastic\u0026#39;: ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 192.168.50.11 20 96 6 0.18 0.09 0.03 dilmrt * es1 192.168.50.13 50 96 2 0.02 0.07 0.03 dilmrt - es3 192.168.50.12 25 96 1 0.00 0.02 0.00 dilmrt - es2 这次在参数中故意省略了 ca 证书文件路径，如果 curl 可以正常访问，那么 Beats 程序也可以，而且不需要在 Beats 配置文件中生命公钥的路径，更有利于在以后切换到另外一套 CA 秘钥后，配置文件的更新工作。\n这里省略 Beats 配置文件的展示，参考一下命令做初始化前的准备。\n1 2 3 sudo cp -f /vagrant/filebeat.yml /etc/filebeat/filebeat.yml sudo cp -f /vagrant/metricbeat.yml /etc/metricbeat/metricbeat.yml sudo filebeat modules enable system 为了测试的方便起见，在 filebeat.yml 和 metricbeat.yml 文件中使用了超级用户 elastic ，如果这个动作伴随着 Elastic Stack 的版本升级需要经常发生，此处需要配置一个 Beats setup 用的专用角色和账户，从而避免多次使用超级用户。\n下面运行 setup 命令：\n1 2 filebeat setup metricbeat setup 这两个命令正常运行后，在 Kibana 里会增加增加相关的索引、pipeline、可视化和仪表板等对象。\n使用下面的命令测试 filebeat 和 metricbeat 是否能正常的采集数据并传输到后台。\n1 2 filebeat -e metricbeat -e 如果报错的话，将 level 在配置文件中设置为 debug，方便调试。调试成功之后，应该在 Kibana 的界面中，可以看到 node1 节点，点击后能看到实时更新过来的日志和监控指标。\n在新的节点上部署 Beats 在新的需要部署 Beats 的节点上，可以使用下面的脚本配置和部署。\nadd-agent.sh\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #!/bin/bash # author: Martin Liu # url:martinliu.cn elastic_version=\u0026#39;7.8.0\u0026#39; b_user=\u0026#39;beats-writer\u0026#39; b_pwd=\u0026#39;DevOps1234\u0026#39; echo \u0026#34;############## Installing a Beats \u0026#34;$elastic_version\u0026#34; agent...\u0026#34; sudo rpm -ivh /vagrant/rpm/filebeat-$elastic_version-x86_64.rpm sudo systemctl enable filebeat.service sudo filebeat modules enable system sudo rpm -ivh /vagrant/rpm/metricbeat-$elastic_version-x86_64.rpm sudo systemctl enable metricbeat.service echo \u0026#34;################### Setup Public CA...\u0026#34; sudo update-ca-trust enable sudo cp /vagrant/certs/ca/ca.crt /etc/pki/ca-trust/source/anchors/ sudo update-ca-trust extract echo \u0026#34;################### Update Beats configuration files ...\u0026#34; sudo cp -f /vagrant/filebeat-v1.yml /etc/filebeat/filebeat.yml sudo cp -f /vagrant/metricbeat-v1.yml /etc/metricbeat/metricbeat.yml echo \u0026#34;################### Setup Keystor for Beats ...\u0026#34; echo $b_user | sudo filebeat keystore add BEATS_WRITER_USERNAME --stdin --force echo $b_pwd | sudo filebeat keystore add BEATS_WRITER_PW --stdin --force echo $b_user | sudo metricbeat keystore add BEATS_WRITER_USERNAME --stdin --force echo $b_pwd | sudo metricbeat keystore add BEATS_WRITER_PW --stdin --force echo \u0026#34;################### Start Beats services ...\u0026#34; sudo systemctl start metricbeat.service sudo systemctl start filebeat.service 简单说明以上脚本的功能：\n用 rpm 安装包安装所需要的 Beats，filebeat 开启 system 模块。 在目标操作系统里部署必须的 ca 证书到默认路径中，并启用。从而省略在所有 beats 文件中生命公钥文件的路径。 覆盖更新默认的 Beats 配置文件。 创建并初始化 Beats 配置文件中所需要的 beats-writer 用户名和密码。从而消除消除所有明文密码。以上脚本只需要在节点上更新的时候才允许，允许后删除，从而不会留下任何明文密码和账户信息。Beats 的任何模块配置中，如果需要配置任何密码账户也需要如法炮制，从而保证基本的安全性。 启动 Beats 服务 以上脚本所使用的配置文件文件如下。\nfilebeat-v1.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 filebeat.inputs: - type: log enabled: false paths: - /var/log/*.log #============================= Filebeat modules =============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true reload.period: 60s #-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: hosts: [\u0026#34;es1.zenlab.local:9200\u0026#34;,\u0026#34;es2.zenlab.local:9200\u0026#34;,\u0026#34;es3.zenlab.local:9200\u0026#34;] password: ${BEATS_WRITER_PW} username: ${BEATS_WRITER_USERNAME} protocol: https #================================ Processors ===================================== processors: - add_host_metadata: netinfo.enabled: true cache.ttl: 5m geo: name: bj-dc-01 location: 35.5528, 116.2360 continent_name: Asia country_iso_code: CN region_name: Beijing region_iso_code: CN-BJ city_name: Beijing - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ - add_fields: target: \u0026#39;\u0026#39; fields: service.name: \u0026#39;Elastic Cloud\u0026#39; service.id: \u0026#39;ec-ww\u0026#39; #==================== Best Practice Configuration ========================== setup.ilm.check_exists: false logging.level: error queue.spool: ~ metricbeat.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # =========================== Modules configuration ============================ metricbeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true reload.period: 120s #-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: hosts: [\u0026#34;es1.zenlab.local:9200\u0026#34;,\u0026#34;es2.zenlab.local:9200\u0026#34;,\u0026#34;es3.zenlab.local:9200\u0026#34;] password: ${BEATS_WRITER_PW} username: ${BEATS_WRITER_USERNAME} protocol: https #================================ Processors ===================================== processors: - add_host_metadata: netinfo.enabled: true cache.ttl: 5m geo: name: bj-dc-01 location: 35.5528, 116.2360 continent_name: Asia country_iso_code: CN region_name: Beijing region_iso_code: CN-BJ city_name: Beijing - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ - add_fields: target: \u0026#39;\u0026#39; fields: service.name: \u0026#39;Elastic Cloud\u0026#39; service.id: \u0026#39;ec-ww\u0026#39; #==================== Best Practice Configuration ========================== setup.ilm.check_exists: false logging.level: error queue.spool: ~ 解释一下相关的重要配置。\nnetinfo.enabled: true 收集所有网卡的配置信息，覆盖多块网卡的情况 geo: 地理位置信息对以后基于位置的查询打下基础，这对于监控和信息安全都非常重要。为以后基于 host 的上下文关联打下基础，方便在 apm、log、metric、heartbeat 和机器学习的界面中相互跳转。 add_fields: 在 fields 下面维护 ECS 数据定义中的必要的有意义的数据，在网上查询 ECS 的数据定义，这些字段可以优化以后的搜索逻辑。 最后一段是其它必要的最佳实践设置 output.elasticsearch : 这里使用了三个 ES 节点的链接地址，这里应该使用至少 2 个 Elasticsearch 集群中的 ingest 节点。 总结 本文没有展开说明和配置的地方包括：对 Best 节点的工作状态的监控；对索引生命周期规则的调优（用尽磁盘），冷热数据的自动化迁移规则。\n完成的配置包括：\n配置 ES 3 节点集群内部的 TLS 加密传输，对外的 HTTPS 加密协议服务 Kibana 基于证书的 SSL 加密配置 Beats 的高可靠性后台传输数据，TLS加密传输数据 用基于角色的访问控制，创建了只写权限的 beats-writer 角色和用户。 用 beats 的 keystore 将配置文件中的明文密码消除。 ","date":"2020-06-21T18:42:56+08:00","image":"https://martinliu.cn/images/locked-up.jpg","permalink":"https://martinliu.cn/blog/build-security-in-elastic-stack/","title":"Beats 摄入数据的最佳实践"},{"content":"中国 DevOps 社区在最近两年期间得到了长足的发展，从最初的单一官网站点，发展到现在的社区官网、社区峰会官网、社区论坛、社区微信公众号和社区服务号等多种对外公众界面。在这些网站平台之后的是 20 多位社区志愿者们的辛勤工作和贡献。\n社区官网最初是在 GitHub 上通过 Github-page 的免费空间发布的，在购买了收费的 Hugo 模板之后；网站的代码有了转为私有仓库的需求，因此CODING就从 GitHub 迁移到了 GitLab；当时 Github 还没有免费不限数量的私有仓库，而且 Github 也不能免费实现 20+ 社区代码贡献者的组队维护多个项目。GitLab 总的来说能满足目前的所有社区开发和协作需求：这些需求包括无限私有仓库，足够数量的代码协作人员，免费的 CI 构建和发布功能。GitLab 平台也可以实现 GitLab-page 的静态网站托管服务，但是，如果代码仓库设置为通过 page 实现静态网站发布的情况，需要整个代码库设置为对外公开访问，而这与代码库本身依然需要保持私密矛盾。因此社区的小伙伴也无奈的在 GitLab 上维护代码，然后将 hugo 构建后的结果再发布到 Github-page 的项目去。\n根据以上社区网站代码库迁移的经历，下面总结一下中国 DevOps 社区在网站开发维护和配套 CI/CD 方面的总体需求：\n实现多人（20+志愿者）私有和共有代码仓库的协作，相关工作包括社区网站内容维护和新功能开发，社区书籍和技术白皮书协作翻译等。 实现 OKR 风格的社区网站开发相关工作管理，季度目标制定，任务跟踪等。 实现 Scrum 风格的软件项目计划、分配和跟踪；统一规划开发和运维相关的所有任务；与季度 OKR 相关联。 实现自动化的 CI、CD 流水线。 自动化和快速的部署软件项目工件（Artifacts）到腾讯云服务器（和其它相关服务），包括静态网页到 Nginx 服务器的发布，到云存储的发布，目前也可能即将会用到 K8s 服务/Serverless 服务的发布。 基于目前社区的相关工作需求，我们在三个平台之间进行了综合的对比和评测：GitLab（免费版）、Jira Cloud（免费版） 和 CODING - 高级版（腾讯云 DevOps 平台服务）。总的来说我们需要一种能满足以上所有需求的、集成化的 DevOps 工具 SaaS 平台服务。\n在开始 DevOps 平台选项之前，值得再次研究一下上面这幅图。重申一下，这幅图表达了两个意思：\nDevOps 是持续不断的循环，并不是单向的多少次重复的流程。理想情况下一次循环对应着敏捷开发的一个迭代，每个迭代 done 的定义并不是编码完成就结束了，还包括后面的测试和运维的所有工作，应该管理到从开发到上线过程中的所有工作。本次迭代的结果可以作为下一个迭代的输入之一。 DevOps 工具平台需要支持的每一次循环中包括的阶段有：计划、构建、持续集成、部署、运维、持续反馈（监控）；如果某个阶段无法直接实现，用其他独立工具实现也不是不可以，例如持续监控阶段（但是监控的状态必须实时透明的反馈给DevOps循环中的所有人）。 下面我们分阶段的描述以上三个 DevOps 工具平台的实际结果，每个阶段中会提出不同的功能需求点，然后横向比对三个工具的优缺点。声明这里是基于中国 DevOps 社区的实际需求做出的工具平台的需求使用体验调研，这些调研结果决定了最后平台选择的决定。\n计划 - Plan OKR 管理 ： \u0026ndash; 传统的社区项目规划往往是技术导向，或者比较就事论事的安排某些开发和维护工作。而中国 DevOps 社区更希望能应用高于项目本身一个层级的 OKR 概念来统筹所有项目的工作。需要用一个顶级目标对应多个KR，每个 KR 能关联到不同项目中的各种工作，也需要能跟踪孤立的 KR。\nGitLab ：在 Gitlab 官方文档和网上并没有查到的 OKR 的实现方式。 Jira Cloud：默认云服务没有 OKR 的功能，不过可以通过两种方式实现：安装第三方 App，使用 Structure 功能扩展实现。实际测试了一个名为 OKR for Jira （by Digital Toucan）的 App；能满足需求。在 OKR 关联界面中可以关联项目 issue，在 issue 的界面里也可以关联 KR；实现双向关联和跟踪。 CODING：在团队管理页面的‘团队目标’功能里有内置的 OKR 管理功能。功能性完全满足社区需求。可以在一个平面的可折叠页面中管理大量的 OKR 条目。O 的完成进度可以根据 KR 的进展自动计算，KR 的完成度可以手工拖到，也可以根据所连接的项目状态自动计算，所有条目的排序可以自由拖动。操作简洁方便。在项目工作的界面里不能关联到 OKR。 下图是 OKR for Jira 免费 app 的截图： 下面是 CODING 中管理 OKR 的界面截图。 项目规划/协同 ： \u0026ndash; 社区网站相关工作需要在每一个项目的执行过程中实现需求分析、工作分解、工作分配和进度追踪等功能。并不需要实现高级的企业产品路线图和Eprics的管理，由于并不开发复杂的商业产品，至少目前工作的复杂度没有这个需求。\nGitLab：项目管理功能齐全，而且包含可定制的看板功能（Scum board / Kanban board），里程碑和 Todos 也是比较特色的功能。具备Issue 状态和代码PR 自动化的关联。 Jira Cloud：默认项目管理丰富，Issue 的默认查看视图有多种方式支持各种看板。Issue 的查看、编辑和相关操作非常符合开发者视角的思路，可以从 Issue 上一键式的创建分支，并且看到分支代码提交、构建和部署的各种状态。 CODING：支持项目中的 Backlog 规划，管理迭代、Epric、需求、任务和缺陷。它可以很方便的定制每一种工作的状态和工作流，特别符合国人默认流程定制的需求。支持项目中的模块管理。操作比较简洁直观可用。一个项目中可以容纳和管理多个代码库。 下面是 CODING 中管理项目协同中的任务管理，虽然没有看板展示的模式，不过用拖拽的方式可以方便的对 Backlog 中的工作条目做迭代规划，点击每个工作条目都可以对其进行编辑修改。\n构建 - Build 代码托管 ： 社区需要使用 Git 代码仓库管理各种网站和应用的代码开发，包括markdown 格式的网站内容更新，主要是用基于主干的开发，或者部分功能分支的方式。\nGitLab：功能强大和丰富的代码仓库管理，支持丰富的合并请求（MR）策略。 Jira Cloud：通过 bitbucket 实现代码仓库管理。从源码到提交、分支、PR 等等都可以关联和跳转。 CODING：虽然不是老牌的 Git 仓库工具，它可以支持 git 和 SVN 仓库。能满足代码的提交、分支、合并请求、版本、对比等功能。功能完全满足需求。 云端开发工具 ： 如果开发者在不能访问自己的工作电脑的情况下，还是需要可以访问到一个功能齐全的线上代码编辑环境。确保社区参与者能够容易的参与相关开发工作。\nGitLab：代码库中的每个文件都可以通过 Web IDE 功能打开，能实现代码的语法检查、提交变化提示、Markdonwn 编辑/预览等功能。具备一定的可用性。 Jira Cloud：在 bitbucket 中选取文件点击编辑后，能进入一个基本的文本文件编辑模式。无其他高级功能，很难胜任稍微复杂一些的程序代码变更。 CODING：代码库中的代码文件可以支持在线的编辑，具有一定的语法加亮和变更对比功能，能提供基础的线上开发能力。同时还提供了全功能的线上 IDE 环境 https://cloudstudio.net/，这个功能很类似于一个线上版本的 vs code，它可以拉取 git 仓库地址，并在与之的多种语言环境中开展代码开发工作。 代码检查 ： 在尽可能的提供代码质量扫码、评估和反馈会对每个社区开发者的工作质量提供帮助，需要帮助社区小伙伴们开发出高质量和安全的社区网站代码。\nGitLab：可以集成第三方的代码扫码服务，在 CI 的过程中调用第三方服务实现。 Jira Cloud：同上。 CODING：内置了一套简洁的代码扫描功能，可以针对不同的开发语言定制各种代码扫描方案，实现代码检查、质量评估、路径过滤等功能。扫描结果可以生成在总体概览视图报表和任务管理清单。 下图是一个代码扫描方案编辑示例。 私有制品库/镜像仓库 ： 随着后期复杂社区项目的开发，以及容器化和微服务化的趋势。需要使用轻量的解决方案予以满足。\nGitLab：为每个项目提供包管理（支持通用、Conan、Maven，NPM、NuGet、PyPi）和 Docker 镜像仓库。满足在一个内的制品管理。 Jira Cloud：需要集成第三方的服务实现。 CODING：为每个项目提供了各种类型的制品仓库，包括：Generic、Docker, Maven, NPM, PyPi, Helm, Composer, NuGet, Conan。可以设置项目内、团队内和公开的访问范围权限。 编译构建 ： 需要提供自动化的编译构建能力，通过自动化的 CI 流水线给开发者快速的反馈，提供友好的 DevOps 流水线构建和修订界面。平台提供免费的构建算力，能够按需要自行接入构建节点和 K8S 环境。\nGitLab：提供基于 gitlab-ci.yml 文件的 Pipeline as Code 的流水线管理模式。无流水线的图形编辑界面。可以通过部署 Runner 的方式扩展构建环境到外部的服务器上，或者 k8s 的环境中。 Jira Cloud：在 Bitbucket 中提供基于 bitbucket-pipelines.yml 文件的 Pipeline as Code 的流水线管理模式。无流水线的图形编辑界面。这个流水线的后台应该是一个共享的基于 Bamboo 的SaaS 服务，还没有发现扩展这个部署环境的方法。 CODING：提供基于 Jenkins 的 CI 服务。也就是说 CODING 服务用套娃的方式包装了 Jenkins 服务，通过共享的构建服务提供基础的构建算力，如果需要的话也可以和 GitLab 一样扩展到外部的构建服务器或者 K8s 服务集群。这里 CODING 还提供了 构建服务到腾讯云的相关服务的集成。因此它能提供 Jenkins+ 的服务能力，对于 Jenkins 服务的构建能力这里就不在赘述。由于 Jenkins 流水线技术比较普及。社区的同学用了半天的时间实现了社区官网构建发布流水线的调试。将基于 Hugo 的网站构建结果用 ssh 命令的方式发布到腾讯云里的 Nginx 服务器的目录中。 下图是在图形流水线编辑器中对标准模板的调试，这里简单的实现了构建和打包的过程，在部署的步骤里，通过远程 ssh 的命令实现了对网站发布包到腾讯云虚拟机的部署。 总结 以上是中国 DevOps 社区对 DevOps 工具平台服务的选型测试过程的一部分总结，这里仅仅从社区的实际工作需求出发，通过试用对比的方式探索了几种平台。总的来说腾讯的 CODING 平台使用体验要好于其它两个服务。具体说有以下几个方面：\nCODING 的页面访问速度非常快，由于是相对比较年轻的产品，目前它比起 Jira 和 GitLab 还处于婴儿期；因此这种够用就好的阶段也降低了对复杂高级产品的认知难度。通过 git 命令下载和提交代码的速度非常快。 OKR 的管理功能具备够用的可用性。 流水线功能同支持图形的流水线编辑和自控制的 Jenkins 文件。如果已经具备了一定的 Jenkins 能力，你就能快速上手开始构建和部署项目了。这个界面整合良好的套娃服务其实还具备了一定的可迁移性。 与腾讯云服务的良好互访问性。如果已经使用了腾讯云的服务，那么 CODING 的部署流水线将对其非常友好，易于衔接已有资源。 后续还将按需测试和对比 DevOps 循环中的其它阶段。如果你也感兴趣参与中国 DevOps 社区的相关志愿者开发工作，请随时和我联系。也希望对此感兴趣的小伙伴能报名参与我们的这种主题评测活动。\n","date":"2020-06-21T18:42:56+08:00","permalink":"https://martinliu.cn/blog/a-comparison-of-devops-tools-p1/","title":"徘徊在 3 种 DevOps 平台服务之间难以抉择（上）"},{"content":"简介 Elastic Workplace Search 提供了一个统一的搜索体验，从而便于任何人在任何时间找到所需的文档信息。为企业搭建了一个横跨所有工作内容、所有团队和真相的统一搜索参考平台。\n这个搜索平台能够对接各种数据源，并且实现文档内容级别的索引，目前所支持的数据源包括：OneDrive、SharePoint、ServiceNow、Box、Dropbox、Github、Github Enterprise、Google Drive、JIRA、Confluence、Salesforce、Zendesk 等。\n它具有以下特点：\n配置部署简单，缩短了系统上线和等待时间。不像是传统的消耗数个月甚至一年都无法完成的搜索项目，这个解决方案可以让企业在几天或几周内就能投入使用。 个性化定制的搜索体验。通过 Elasticsearch 所提供的搜索能力，管理员可以控制企业、团队级别的数据源，个体用户可以控制自己的私有数据源，所有级别上都可以调整相关度权重，从而提高搜索结果的准确性和实用性 提供各种自然语言的和关键字的搜索。系统提供了强大的语言分析和关键字检测能力，用户可以使用任意关键字和搜索开关轻松的搜索到所需的信息。 具备丰富的开箱即用功能：无须开发即可实现用户管理、数据源管理、基于用户和组的数据源可见性设置、数据源对不同用户和组的权重等功能。 系统安装配置 本文的假设，文中所使用的安装包和需要部署的配置文件都在 /vagrant 这个目录下面。下面的所有命令中都假设从这个目录里选用和复制。配置文件见代码库：https://github.com/martinliu/elastic-labs\n本文所使用的安装测试环境是：\nCentOS Server 8 JDK 11 Elasticsearch 7.6.1 Kibana 7.6.1 Elastic Workplace Search 7.6.1 下面使用 vagrant up 一键式拉起基础测试环境的说明，请参考之前的文章。本测试所使用的基础 ES 安装脚本如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 echo I am provisioning a Elasticsearch Server... date \u0026gt; /etc/vagrant_provisioned_at sudo swapoff -a sudo sysctl -w vm.max_map_count=262144 sysctl -p sudo sh -c \u0026#34;echo \u0026#39;elasticsearch - nofile 65535\u0026#39; \u0026gt;\u0026gt; /etc/security/limits.conf\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;**** -- -- -- -- -- -- -- -- ****\u0026#39; \u0026gt; /etc/motd\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;**** Welcome to Elastic Stack Labs\u0026#39; \u0026gt;\u0026gt; /etc/motd\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;**** -- -- -- -- -- -- -- -- ****\u0026#39; \u0026gt;\u0026gt; /etc/motd\u0026#34; sudo sh -c \u0026#34;echo \u0026#39;*\u0026#39; \u0026gt;\u0026gt; /etc/motd\u0026#34; sudo rpm -ivh /vagrant/rpm/elasticsearch-7.6.1-x86_64.rpm sudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert -out /etc/elasticsearch/elastic-certificates.p12 -pass \u0026#34;\u0026#34; sudo chmod 660 /etc/elasticsearch/elastic-certificates.p12 sudo cp /vagrant/elasticsearch/elasticsearch.yml /etc/elasticsearch/elasticsearch.yml sudo systemctl daemon-reload sudo systemctl start elasticsearch.service sudo systemctl status elasticsearch sudo /usr/share/elasticsearch/bin/elasticsearch-setup-passwords auto -b echo Provisioning script works good! echo Please go to http://192.168.50.10:9200/ using above passwords 这段脚本配合 vagrant 的 provision 功能使用，它本来就是一段 shell 脚本，可以可以独立执行，它的输出结果如下。\n使用 vagrant up 命令拉起了测试虚拟机之后，在屏幕的输出信息中复制出 elastic 用户的密码。\n1 2 3 4 5 6 7 8 9 10 11 12 master1: Changed password for user apm_system master1: PASSWORD apm_system = XAZnaek3wm0GxN3OHwhP master1: Changed password for user kibana master1: PASSWORD kibana = sUg8OaYqh4f55GzoYApk master1: Changed password for user logstash_system master1: PASSWORD logstash_system = RLthIQOH3aOFLVKqaTMu master1: Changed password for user beats_system master1: PASSWORD beats_system = 73yH90G3hvrzYgVDnG3y master1: Changed password for user remote_monitoring_user master1: PASSWORD remote_monitoring_user = Sk9J77H9QFPsOZtVQJld master1: Changed password for user elastic master1: PASSWORD elastic = OeR3gADZ1Fw1cgc90pwE 本示例使用了 elasticsearc-native 的用户认证模式。 为了方便起见，安装了 Kibana 7.6.1 ，过程此处忽略；在 Kibana 的用户管理中创建如下用户：\nsales1 、 sales2 dev1 、 dev2 示例如下图所示。\n这些是测试用户，用于 Elastic Workplace Search 的测试中。\n安装 Elastic Enterprise Search Elastic Enterprise Search 需要 JDK 8 或者 JDK 11， 本实例安装了 Oracle JDK 11。\nsudo rpm -ivh /vagrant/rpm/jdk-11.0.6_linux-x64_bin.rpm\n复制 Enterprise Search 的安装包到 /opt 目录下，解压缩这个安装包。\n1 2 3 sudo cp /vagrant/rpm/enterprise-search-7.6.0.tar.gz.tar /opt sudo cd /opt sudo tar zxvf /opt/enterprise-search-7.6.0.tar.gz.tar 在 Enterprise Search 的配置文件中加入 elastic 用户的密码等配置信息。并且将配置文件部署到测试服务器中。本实例的配置文件 enterprise-search.yml 内容如下。\n1 2 3 4 5 6 7 8 elasticsearch.username: elastic elasticsearch.password: eZhp0h2ZTPKchlxxwwex elasticsearch.host: http://192.168.50.10:9200 allow_es_settings_modification: true ent_search.auth.source: elasticsearch-native ent_search.external_url: http://192.168.50.10:3002 ent_search.listen_host: 0.0.0.0 ent_search.listen_port: 3002 将以上目标配置文件复制到 Elastic Workplace Search 的配置文件目录中，覆盖默认配置文件。\n1 sudo cp /vagrant/enterprise-search/enterprise-search.yml /opt/enterprise-search-7.6.0/config/enterprise-search.yml 启动 Enterprise Search 服务器，并且设置默认的管理员密码。\n1 sudo ENT_SEARCH_DEFAULT_PASSWORD=martin1demo /opt/enterprise-search-7.6.0/bin/enterprise-search 在启动的过程中，关注一下的屏幕输出信息，则表示一切正常。\n1 2 3 4 5 6 7 8 9 10 *** Default user credentials have been setup. These are only printed once, so please ensure they are recorded. *** username: enterprise_search password: martin1demo No secret management encryption keys were provided. Your secrets will be stored unencrypted. You can use the following generated encryption key in your config file to store new encrypted secrets: secret_management.encryption_keys: [911f804cd11f7bc2dd338743ea1752b0b7cd2589cc80060159ed94a918bc09d3] 等待服务器启动正常后，参考相关文档。完成 Github、Jira 和 Confluence 等数据源的配置。\n配置数据源 见介绍文档 https://www.elastic.co/guide/en/workplace-search/current/workplace-search-content-sources.html\nConfluence Cloud Confluence Server Dropbox GitHub Google Drive Jira Cloud Jira Server OneDrive Salesforce ServiceNow SharePoint Online Zendesk 除了默认支持以上数据源外，还可以使用 Custom API 实现自己的数据源接入。数据源的类型分：\n组织级：可以分配给个人和用户组 私有级：用户个体接入某个数据源，而仅供自己使用 GitHub 数据源对接 首先你需要属于 GitHub 的一个组织，或者多个组织，然后在某个组织，或者几个组织做为一个数据源，对接到 Elastic Workplace Search 中。具体的配置步骤如下.\n在 GitHub 中找到需要搜索的组织，每个 repo 的 issue 和 pr 都是全文搜索的目标。 在 GitHub 的账户中创建一个 OAuth App，图中 1、2、3、4 信息点需要和你的测试环境匹配。复制出 client ID 和 Client Secret 备用。\n在 Elastic Workplace Search 的数据源配置页面创建 GitHub 数据源。填入上一步的两个 ID。 保存以上配置后，在这一步点击 Connect GitHub。 在这一步选择需要搜索的组织，勾选后，点击完成连接配置。 正常连接成功后，就可以看到这个组织里所有 repo 中的 issue 和 pr 了。 Atlassion 数据源对接 支持对 Confluence 和 Jira 两款产品的云服务和本地部署的搜索。配置的过程非常简单， 如果你有多套独立的 Confluence 和 Jira 环境，那么就可以给每个需要搜索的环境配置一个数据源，并且按照需要将对它们的统一搜索配置到一个统一的搜索平台之内。\n配置文档见： https://www.elastic.co/guide/en/workplace-search/current/workplace-search-confluence-cloud-connector.html 和其它。下面是一个配置成功的 Jira 云服务的结果。\n如果所示，每套 Atlassion 环境的产品都可以仅仅通过配置接入这个搜索平台。Jira 中索引的内容类型如下：\nTask 子任务 长篇故事 Project Other 配置完成以后，默认的同步周期是 2 小时做一次增量索引。下图是用户对 Jira 和 Confluence 的两个本地部署服务器联合统一搜索的效果。管理员可设置任何一个人和用户组能搜索那些数据源，每个数据源在搜索结果中的权重排位。从而实现对任何一个用户组定制化搜索结果的作用。\n用户配置示例 本文的目标是给两个用户组的人分配不同的数据源权重，从而得到各异的搜索结果排名。下面是一些建议的思路和配置过程。\n这里把仅有的两个数据源设置成了组织级别的可搜索，也就是他可以进入任何一个合法用户的搜索清单中。加入是特定团队所使用的数据源，在这里需要关闭搜索开关。 本文使用的 Elasticsearc 原生用户的认证，示例中将用户名为 sales* 开头的的用户名分配到 Elastic Workplace Search 的 “销售\u0026amp;市场” 组中。 示例中将用户名为 dev* 开头的的用户名分配到 Elastic Workplace Search 的 “产品开发和运维” 组中。这里只是示例，你可以用任何已知用户与搜索用户组的对应，从而满足你的使用场景。 在组织级别的组属性设置中，先设置默认用户的数据源权重，这里使用默认的 1，也就是不区分两个数据源的权重，使用相同权重。 下面是对 “销售\u0026amp;市场” 组的数据源权重设置，这里假设这个组的人员可能更会搜索 Jira 中的关于项目开发、问题解决进展这类的信息，不会太关注工程师实际解决的代码相关的问题。因此将 Jira 中的权重从 1 增加到 5 ，从而在相同关键字中，提升 Jira 中搜索结果的整体排名。 同理为 “产品开发\u0026amp;运维” 团队设置 GitHub 的高权重。 最后在这个安全的选项设置中，开启了搜索用户可以自主添加数据源的情况，也就是说这部分是个性化的数据源，可能是自己所使用的网盘，或者个人的 GitHub 组织等等，都可以！用户可以将对自己有帮助的，需要搜索的数据源都自助式的添加上，从而提高自己的工作效率。 搜索效果确认 下面是用户 sales1 搜索 ealsticsearch 关键字的结果示意图。\n在上图中，搜索用户可以点击右侧的数据源图标，点选其中的一个数据源作为搜索范围，可以点击 All Time 时间设置条件，筛选出目标时段的文档等。还可以在搜索框中使用类似 ppt 等文件类型搜索条件。 搜索结果是故意设置的，这是 Jira 中的一个 pdf 附件，pdf 的原文也可以搜索，而且对于 销售\u0026amp;市场 用户组来说， Jira 的权重大于 GitHub 很多，因此即使 Github 中有四个匹配的结果，也就将其排了在了最下面。\n下图是 dev1 用户（属于产品开发\u0026amp;运维组）的登录后界面。这里显示了建议的搜索快捷短语 pull requests form last week ，页面上的搜索结果是按照数据源中最更新的文档靠前的规则排列的。 下面这个用户搜索可关键词 app search，从这个结果中可以看出，即使是在 GitHub 中的一半匹配（并无完整的 app search 这个词组出现在任何文档里）搜索结果的排名都比 Jira 中的完全命中的排名高。 测试总结 到目前为止，本文展示了一部分 Elastic Workplace Search 的基础功能。以及一些假象的搜索和配置场景，相信对此感兴趣的读者参考本文，也可以在 1 天之内完全实现以上所有的测试场景，从而为正确评估这个产品打下一个基础。\n如果，想进一步集成自己的资料库的话，可以参考自定义 API 的相关文档，开发自定义的数据源。这就是一个功能齐全的搜索平台，它可以非常方便的集成任何公司的环境中，并且实现集中统一搜索平台的效果。\nDevOps核心能力建设 如果你也是 DevOps 的实践者，如果你看过我之前写的关于 DevOps 状态调查报告和能力成长模型的相关文章，你可能对下图也有印象。\n这是 DORA 出的最新版本的 DevOps 能力成长模型，在 2019 年的DevOps 能力调查中，增加了对生产力工具的调查，该模型中所关注的三种生产力能力工具包括：\n各种有用易用的工具 互联网搜索 内网搜索 在这个部分有两项生产力影响因素能力是关于搜索的。在我国的很多工作环境中，特别是开发相关的工作，无 Internet 环境的纯内网是很普遍的。而内网上的 Atlassian 相关产品，微软相关产品又是最多用的；不同业务部门或者团队拥有自建的 Jira 或者 Confulence 服务器；在团队协作的时候，或者在执行跨部门的项目的时候，项目资料的统一搜索就成了问题。类似的需求和现象不胜枚举，希望本文介绍的 Elastic Workplace Search 统一搜索平台可以成为你的帮手，为你填补 DevOps 能力成长模型中关于 内网搜索 的这一项空白。当然，这个平台所支持的外网 SaaS 服务也是很多的，可以综合使用。\n","date":"2020-04-24T10:37:16+08:00","image":"https://martinliu.cn/images/abstract-1.jpg","permalink":"https://martinliu.cn/blog/getting-start-elastic-workplace-search/","title":"入门 Elastic Workplace Search"},{"content":"开发搜索功能从此再也不用犯愁了，有了 App Search ，为应用增加搜索功能一下子变得简单了很多。本文描述了如何轻松上手这套搜索平台的所有步骤。\n什么是 App Search? 这是一套强大的 API 和开发者工具集，以构建功能强大的面向用户的搜索应用为目标。相关详细介绍见 https://www.elastic.co/cn/app-search\n丰富的开箱即用功能:\n为相关性搜索应用场景而优化 拼写错误容忍 相关度调整 支持第三方 API 客户端，且具备强大的 API 独立的 API 日志和搜索分析 自动化扩展\u0026amp;运维支持 Search UI library 环境准备 测试环境现需要一台 Elasticsearch 服务器，或者和下面等同的环境。\n本文的环境描述如下：\nmacOS 10.15.4 vagrant 2.2.7 virtualbox 6.0.15 虚拟机模板 bento/centos-8 elasticsearch 7.6.1 app-search 7.6.1 jdk-11.06 本文的测试环境基于 Vagrant + VirtualBox 的组合环境搭建而成，基础安装工作可以一键完成。\n主要脚本 Vagrantfile、pre-install-ES.sh 请参考此代码库：\nhttps://github.com/martinliu/elastic-labs/tree/master/app-search\n开启并登陆这套安装环境的命令如下。\n1 2 vagrant up vagrant ssh 在以上命令的启动信息里找到如下的 elastic 用户密码部分备用。\n1 2 master1: Changed password for user elastic master1: PASSWORD elastic = eczHJ7NPrsO1B1BRA8SS 安装 App Search 浏览 App Search 的安装文档： https://swiftype.com/documentation/app-search/self-managed/installation\n安装 App Search 所需的 JDK 8 或者 11 ，本文安装的是 Oracle 的 JDK 11。本文假设所有的安装文件和已经编辑好的配置文件都放在了 /vagrant 目录下。\nsudo rpm -ivh /vagrant/rpm/jdk-11.0.6_linux-x64_bin.rpm\n安装 App Search 服务器。\nsudo rpm -ivh /vagrant/rpm/app-search-7.6.1.rpm\n浏览 App Search 服务器默认的配置文件，了解有哪些可用选项。\nsudo more /usr/share/app-search/config/app-search.yml\n将 Elasticsearch 服务器安装时产生的随机密码更新到 app-search.yml 文件中，并且定制它的内容如下：\n1 2 3 4 5 6 7 8 9 allow_es_settings_modification: true elasticsearch.host: http://192.168.50.10:9200 elasticsearch.username: elastic elasticsearch.password: eczHJ7NPrsO1B1BRA8SS app_search.external_url: http://192.168.50.10:3002 app_search.listen_host: 192.168.50.10 app_search.listen_port: 3002 log_directory: /var/log/app-search filebeat_log_directory: /var/log/app-search 将更新好的 app-search.yml 更新到它默认的路径中。\nsudo cp /vagrant/appsearch/app-search.yml /usr/share/app-search/config/app-search.yml\n启动 App Search 服务器。\nsudo /usr/share/app-search/bin/app-search\n在启动日志中，找到如下的默认用户名和密码。\n1 2 3 4 5 6 7 ######################################################### *** Default user credentials have been setup. These are only printed once, so please ensure they are recorded. *** username: app_search password: vjqmjhv2s5rzixjc ######################################################### 在服务器初始化启动完毕之后，用上面的用户名和密码，在浏览器中登录 App Search 服务器 http://192.168.50.10:3002\n到此为止，App Search 服务器的安装就完成了。它其实是一个基于 Elasticsearch 的搜索服务平台。\n它的特点是帮助开发者随心所欲的为已有的或者正在开发的项目增加功能强大的搜索功能，而且将搜索功能的实施成本降低到无痛点的程度。App Search 可以覆盖的使用场景如下：\nSaaS / web 应用 复杂的电商应用 客户支持服务站点 Geo 地理搜索 公司官网 内部的搜索 还有更多其他 创建名为 games 的搜索引擎 在首页的创建引擎的输入框中输入 games， 语言选择默认选项，点击创建。浏览新创建的引擎，点击左下角的菜单 Credentials，复制 privite-key 备用。\n找到这个搜索引擎的 API 调用网址备用。 http://192.168.50.10:3002/api/as/v1/\n通过 API 索引数据文档 需要通过 App Search 提供的 API 索引一份具有 4000+ 条数据的 json 文件。数据文件见代码库中的 video-games.json 。本文使用 Ruby 编写了一个上传脚本，见 upload.rb ，该脚本使用了名为 elastic-app-search 的客户端库。你可以使用其他编程语音，实现待接入系统和 App Search 服务器的对接，并与之保持同步，保持待搜索数据的更新。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # `gem install elastic-app-search progress_bar` require \u0026#39;elastic-app-search\u0026#39; require \u0026#39;json\u0026#39; require \u0026#39;progress_bar\u0026#39; API_ENDPOINT = \u0026#39;http://192.168.50.10:3002/api/as//v1/\u0026#39; API_KEY = \u0026#39;private-jdhcmi1yhy8wjxo6upb4qki3\u0026#39; ENGINE_NAME = \u0026#39;games\u0026#39; client = Elastic::AppSearch::Client.new(:api_key =\u0026gt; API_KEY, :api_endpoint =\u0026gt; API_ENDPOINT) file = File.read(\u0026#39;./video-games.json\u0026#39;) data = JSON.parse(file) bar = ProgressBar.new(data.count / 100) data.each_slice(100) do |slice| client.index_documents(ENGINE_NAME, slice) bar.increment! end 以上脚本中的 API_ENDPOINT 和 API_KEY 需要更新，与当前测试系统匹配。这个脚本的运行效果如下：\n1 2 ➜ app-search git:(master) ✗ ruby upload.rb [##########################################################################] [40/40] [100.00%] [00:54] [00:00] [ 0.73/s] 索引之后，在搜引擎的 Documents 页面，浏览索引后的数据，用 Query Tester 进行一些搜索，了解这些数据的内容，注意观察当前搜索的结果和排序。\n修订 Schema 开发者可以按照需要随时修改 Schema，实际上这是一个 Schema 的平台。 Schema 的修改后，数据即可生效，在这个过程中前端用户的搜索体验不会受到任何影响。\n修改三个字段的定义，并增加 language 字段，点击右上角的 Update Type 按钮生效。\n按需进行搜索设置 创建同义词 为 Pokemon 创建同义词 Pikachu，如下图所示。\n调整搜索字段的权重 为 globa_sales 增加 Functional Boost 1。 为 Name 增加 weight 3 ，点击右上角的 Save 保存。在这个过程中观察右侧的搜结果的动态变化，还可以做其他字段的修改，知道搜素结果满意为止。\n创建 curations 故意将某条搜索结果置顶，这有可能因为，这款游戏目前是热评游戏，是畅销爆款，是高利率商品，是广告商品，或者其他业务原因。可以给某个关键字，置顶一条或者多条搜索结果。下面将 pokemon 的 pokemon-ranger-ds-2006 这款产品置顶。点击右上角的 Query Tester 测试一下效果。\n创建用户端搜索界面 Reference UI 是提供给用户使用的搜索界面，它可以是只有一个输入框，也可以是比较复杂的条件查询。如下所示。\n调整之后点击 Create Preview 按钮，进入搜素界面的确认页面，尝试使用所设定的搜索功能。满意后点击右上角的 Download ZIP Package 按钮下载这个界面的所有代码。\n在本地解压缩这份搜索代码，并进行调试。\n在命令行，进入这个目录，先执行 npm install命令，然后执行npm start命令。\n1 2 3 4 5 6 7 8 9 Compiled successfully! You can now view app-search-reference-ui-react in the browser. Local: http://localhost:3000/ On Your Network: http://192.168.1.6:3000/ Note that the development build is not optimized. To create a production build, use npm run build. 在弹出的网页中，在本地测试这个搜索界面的可用性。最后运行 npm run build 命令，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 ➜ games-react-demo-ui git:(master) ✗ npm run build \u0026gt; app-search-reference-ui-react@1.2.0 build /Users/martin/code/elastic-labs/app-search/games-react-demo-ui \u0026gt; npm-run-all build-css build-js \u0026gt; app-search-reference-ui-react@1.2.0 build-css /Users/martin/code/elastic-labs/app-search/games-react-demo-ui \u0026gt; node-sass-chokidar src/ -o src/ No input files were found. \u0026gt; app-search-reference-ui-react@1.2.0 build-js /Users/martin/code/elastic-labs/app-search/games-react-demo-ui \u0026gt; node ./scripts/build-no-chunks.js Creating an optimized production build... Browserslist: caniuse-lite is outdated. Please run next command `npm update` Browserslist: caniuse-lite is outdated. Please run next command `npm update` Compiled successfully. File sizes after gzip: 109.1 KB build/static/js/main.2f745bc0.js 3.64 KB build/static/css/main.e43852a4.css The project was built assuming it is hosted at the server root. You can control this with the homepage field in your package.json. For example, add this to build it for GitHub Pages: \u0026#34;homepage\u0026#34; : \u0026#34;http://myname.github.io/myapp\u0026#34;, The build folder is ready to be deployed. You may serve it with a static server: npm install -g serve serve -s build Find out more about deployment here: https://bit.ly/CRA-deploy 最后将构建结果部署到一个目标的先安装的 Nginx 服务器上。\n1 2 sudo yum install -y nginx sudo mv -f build/* /usr/share/nginx/html 在浏览器中访问 Nginx 服务器 http://192.168.50.10/index.html 观察最终的实现效果。 总结 使用 App Search 搜索平台，开发者可以快速的开发出一套定制化的搜索系统，轻松的实现后台搜索业务逻辑的调整，并轻松的将用户搜索界面测试后部署上线。\n","date":"2020-04-11T09:36:49+08:00","image":"https://martinliu.cn/images/abstract-1.jpg","permalink":"https://martinliu.cn/blog/getting-start-elastic-app-search/","title":"随心所欲的为应用无痛添加搜索功能"},{"content":"代号为 COVID-19 的新型冠状病毒肺炎在全球肆虐着，剧情翻转的非常快，目前欧美已经成为了全球的重灾区。 本文介绍如何使用 Elastic Stack，实现对国内外疫情发展态势的分析。介绍一种简单易行的数据分析流程。说不定你也可以得出独到的高价值洞察。\n本文使用的 Elastic Stack 版本和环境如下：\nVagrant 的基础镜像 bento/centos-8 Elasticsearch 7.6.1 Kibana 7.6.1 Logstash 7.6.1 关于使用 Vagrant 环境搭建 Elastic Stack 的方法，见我之前的文章。本文的数据分析处理流程图如下所示。\n分析和展示丁香园数据 本文的目标分析数据源是 https://ncov.dxy.cn/ncovh5/view/pneumonia 这个也是我们最近一直在关注的关于中国的疫情公布平台。\n丁香园网页的数据被香港大学的 Isaac Lin 同学，通过他所开发的网络爬虫抓取加工后，用 API 的形式和 csv 数据文件的形式提供了出来，他的爬虫程序和结果数据给很多目前分析疫情的人带来了很大的帮助，有不少人去他的 blog 和 github 上点赞和评论的。\nhttps://github.com/BlankerL/DXY-COVID-19-Data/tree/master/csv https://lab.isaaclin.cn/nCoV/ 你可以用 Python 程序调用 Lin 同学的 API 然后在将处理后的结果写入 ES，这样的脚本可以参考 Rockybean 的这个 https://www.yuque.com/elastictalk/blog/et25?from=timeline。也可以用下面的命令将Github 的 csv 文件下载到本地，在做手工的数据分析，这样也等于是对林同学的数据内容和定义进行一次深入的探索，这也将更有益于你理解数据，方面后面使用 Kibana 做数据分析。\n在本机使用 git 做数据下载和同步的命令如下。\n1 2 3 git clone https://github.com/BlankerL/DXY-COVID-19-Data.git cd DXY-COVID-19-Data/ git pull 你也可以用用git pull命令在日后做数据更新，并进行后续的跟踪分析。\n同步到本地的数据也可以使用 Logstash 或者是 Filebeat 持续的同步到 ES 中，这样就可以在 Kibana 上看到每日的实时更新结果。\n导入数据并初始化索引 本文选择了最简单直接的方式，使用 Kibana 自带的数据导入功能，手工导入丁香园的 csv 时序数据文件 csv/DXYArea.csv。 如下图所示。\n这个工具是机器学习的周边工具 数据可视化器 ，它对这份数据做了初步的分析和识别，点击导入，然后在下面点击 Advancd ，进入高级设置，如下图所示：\n可以在 index name 中可以输入dxy-area-m5 作为本次新建的索引名称。 然后删除默认的 Mapping 定义，输入下面的重新重定义的数据结构。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 { \u0026#34;@timestamp\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, \u0026#34;continentEnglishName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;continentName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;countryEnglishName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;countryName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;provinceEnglishName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;provinceName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;province_confirmedCount\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;province_curedCount\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;province_deadCount\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;province_suspectedCount\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;province_zipCode\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;cityEnglishName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;cityName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;city_confirmedCount\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;city_curedCount\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;city_deadCount\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;city_suspectedCount\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;city_zipCode\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;level\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;geo_point\u0026#34; }, \u0026#34;is_china\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, \u0026#34;updateTime\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34; } } 对以上 Mapping 的简要说明：\n增加了字段 level, is_china 和 Location，你也可以加入你所需要的其它待用字段，所有新增无值字段都需要后期进行初始化。 level 定义了数据记录的级别为：国家、港澳台和省级。 is_china 定义了国内外数据标识 在导入后，本文使用的字段的批量初始化/维护是调用 /_update_by_query 方法，也可以是使用 ingest pipline 的方式，或者其它 Elastic Stack 中的其它替代功能。 如上图所示的数据导入成功之后，点击 View index in Discovery， 我们可以使用 Kibana 的 Discovery 功能来对所导入的数据进行分析和确认，特别是一些关键字段的数值。观察这些数据的格式和内容的含义是什么。使用 filter 功能了解数据的内容和特征。建议使用下面的 filter 和组合探索一下【也可以使用 kql 语言做查询，如果用 kql 做查询的话，也可以很方便的将这些查询条件进行复用】。\ncountryName:中国 NOT countryName:中国 countryName:中国 / provinceName:中国 countryName:中国 / NOT provinceName:中国 / cityName exists countryName:中国 / NOT provinceName:中国 / NOT cityName exists countryName:中国 / cityName: 境外输入 以上的 / 是多个 filter 叠加的含义，可以大概的猜测出下面的结论。\n中国国内数据 国外数据 中国省级统计数据 中国各省的各个城市的统计数据 中国的港澳台数据 中国海关所监控到的境外输入数据 为了后面使用省的名称做地图分析，这里需要查看数据中各个省英文名称，以广西为例，设置查询条件：provinceEnglishName Guangxi\n现在来浏览 Elastic Map 地图服务所引用的中国各省的中英文名称和代码，查看 https://maps.elastic.co/#file/china_provinces ；\n可以发现现所导入的数据和 Elastic 地图服务的官方数据不一致。\n下图是用 Excel 分析对比的结果，建议使用 Python、logstash 或者其它工具在导入的过程中对这个字段做预处理和校准。\n本文下面描述了 Dev Tool 中运行相关的数据优化和及校准脚本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 #维护is_china字段 POST dxy-area-m5/_update_by_query { \u0026#34;script\u0026#34;:{ \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;\u0026#34;\u0026#34; if (ctx._source.countryEnglishName == \u0026#34;China\u0026#34;) { ctx._source.is_china = true; } else { ctx._source.is_china = false; } \u0026#34;\u0026#34;\u0026#34; } } #维护 level 字段，对于中国的数据来说，如果省的名字是中国这就是国家级的统计数据 POST dxy-area-m5/_update_by_query { \u0026#34;script\u0026#34;:{ \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;\u0026#34;\u0026#34; if(ctx._source.provinceName == ctx._source.countryName){ ctx._source.level = \u0026#34;country\u0026#34; } else { if (ctx._source.cityName == null) { ctx._source.level = \u0026#34;cn-hmt\u0026#34; } else { ctx._source.level = \u0026#34;province\u0026#34; } } \u0026#34;\u0026#34;\u0026#34; } } #更新省的名字为国际代码 POST dxy-area-m5/_update_by_query { \u0026#34;script\u0026#34;:{ \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;\u0026#34;\u0026#34; if (ctx._source.provinceEnglishName == \u0026#34;Guangxi\u0026#34;) { ctx._source.provinceEnglishName = \u0026#34;Guangxi Zhuang Autonomous Region\u0026#34;; } if (ctx._source.provinceEnglishName == \u0026#34;Hong Kong\u0026#34;) { ctx._source.provinceEnglishName = \u0026#34;HongKong\u0026#34;; } if (ctx._source.provinceEnglishName == \u0026#34;Macao\u0026#34;) { ctx._source.provinceEnglishName = \u0026#34;Macau\u0026#34;; } if (ctx._source.provinceEnglishName == \u0026#34;Neimenggu\u0026#34;) { ctx._source.provinceEnglishName = \u0026#34;Inner Mongolia\u0026#34;; } if (ctx._source.provinceEnglishName == \u0026#34;Ningxia\u0026#34;) { ctx._source.provinceEnglishName = \u0026#34;Ningxia Hui Autonomous Region\u0026#34;; } if (ctx._source.provinceEnglishName == \u0026#34;Taiwan\u0026#34;) { ctx._source.provinceEnglishName = \u0026#34;Taiwan Province\u0026#34;; ctx._source.provinceName = \u0026#34;台湾省 (中华人民共和国)\u0026#34;; } if (ctx._source.provinceEnglishName == \u0026#34;Xizang\u0026#34;) { ctx._source.provinceEnglishName = \u0026#34;Tibet\u0026#34;; } if (ctx._source.cityName == \u0026#34;境外输入人员\u0026#34;) { ctx._source.cityName = \u0026#34;境外输入\u0026#34;; } \u0026#34;\u0026#34;\u0026#34; } } 注意：以上的三个 POST 方法调用的对象是 dxy-area-m5 ，这个索引的名字需要和你上面导入数据创建的索引一致。由于是手工初次处理这些数据，建议再次运行以上的一系列搜索过滤条件，确认这些目标字段和数据得到了正确的处理。\n可视化和展示数据 在分析数据就绪了以后，下面介绍一组通过 Kibana 进行数据可视化分析展示的思路和方法。\n💻 从 Discovery 界面中直接调用可视化视图创建 在 Discovery 的查询界面里，点击左侧 fields 清单中的 provinceName，或者其它想进行可视化分析的字段，点击后即可查看其中一部分的数值分布情况，点击下面的 Visualize 按钮。就可以进入可视化编辑模式。\n进入这个 field 的默认可视化配置模式，选择 Y 轴的指标为 province_confirmedCount 的最大值，然后在上方增加 is_china:true 和 level:province 过滤条件后，就可以得到下面的结果。\n还可以对 Buckets 里面 X 轴的值进行调整，使用省的名字。 这样基本上得出了确诊数省排名的结果。或者你还可以调整出其它的分析结论。在分析结束后，点击左上角的 Save ，将分析组合保存下来用于后期的仪表板的制作。\n💻 使用 Visualization 的 lens 功能探索数据 点击 New Visualization，选择左上角的 Lens 图标。在 CHANGE INDEX PATTERN 中选择目标的索引如：dxy-area-m5。 拖拽几个字段进入中间的显示区：continentName countryName province_confirmedCount 这些字段，也可以尝试将这些字段拖入右侧的 X 轴或者 Y 轴。\n拖入不同的位置，图形下方的建议可视化展示风格会随之变化，Lens 功能在预判和猜测你可能会用到的展示和分析组合。感受这些建议图形所提供的数据分析的线索。\n同样的，你也可以在上面使用过滤器和时间段选择功能，这些数据筛选条件发生变化之后，可视化的图形数据也会随之变化。\n使用 TSVB 时序数据可视化构造器 这个控件的功能稍微复杂一些，用下图说明它的用法。\n如上图所示，现在 Panel Options 里面设置需要使用的数据索引，以及其他参数。\n然后在 Data 中选择需要显示的数据指标，如上图中选择了全国累计确诊和累计治愈，两个指标。将他们放在一起更能回答这样一个问题：是否治愈的速度是足够的，如果治愈速度跟得上的话，说明医疗资源是足够用的，如果这两条线之间的落差比较大就危险了。\n上方的 TSVB 图形显示了所有数值和格式调整后的预览效果。可以无限的修订知道满意为止。这个控件天然支持指标数值、排行榜、速度表、Markdown 文本和数据表。可以切换到不同的视角看它的展示效果。\n使用地图展示省级累计数据 我们可以使用已经导入的数据在地图上显示省级的累计确诊和治愈人数。过程是这样的：\n点击 Kibana 左侧的 Maps 图标，创建一个新的地图。 创建图层，选择 EMS Boundaries ，选择这个图层所使用的基础地图为 China Provinces 点击 Add layer 按钮 在图层配置里输入图层名称缩放级别，透明度的设置 设置 Tooltip fields 的设置中增加 name(zh) ,中文的省名称 设置 Term Joins 的规则，点击 Join 关键字，设置索引中的数据和地图的关联。如下图所示，这就是我们为什么要把导入数据中的省英文名称与 EMS 的定义数据对齐了。 点击 and use metrics 设置在每个省上显示的数据。如下图所示。 最后设置 Layer Style， 将 Fill color 填色设置为 By Value， 选择省累计确诊，下面的颜色可以选择白色到深红的过度。 最后点击 Save \u0026amp; close 按钮。 这里的技术点在于：Elastic 地图中的基础数据（地理名称代码）必须和目标索引中的相关字段能够匹配上（join）上，然后才能将索引中的实际做聚合运算的字段根据地理名称进行处理，例如根据数值的大小，将各个省填充成不同的颜色，用 tooltips 显示这个省的数据信息。\n创建 Dashboard 仪表板 上面所设计的所有的图示和地图都是创建 Dashboard 的素材，等做了一些素材之后就可以做仪表板了。这个过程就是在空白的仪表板上逐渐加入合适的图表，然后不断调整图表布局的过程，然后呈现出一个阶段性的效果。如下图所示。\n世卫组织数据的处理和展示 浏览世卫组织的数据 https://github.com/CSSEGISandData/COVID-19\n基于以上数据可以制作一个如下的仪表板：\n这个仪表板中的地图是亮点，建议仔细学习研究一下。 这个仪表板的来源是一篇国外的文章： https://www.siscale.com/importing-covid-19-data-into-elasticsearch/\n我在一个小时左右，根据经验顺利的在我的实验环境里顺利生成了这个成果。下面是根据这篇文章怎么样使用 logstash 导入 Github 中世卫组织发布的数据，并持续与之保持同步。这里是他们的代码：https://github.com/siscale/covid-19-elk\n下面描述如何使用这份代码。首先你需要有一个安装好的切正常运行的 Elasticsearch 7.6.1 服务器，一个可以正常使用的 Kibana 7.6.1 服务器。在此基础之上，安装 logstash 服务器，修改并放好 logstash 的配置文件。 在 Kibana 的 Dev Tool 中导入索引的 Mapping。启动 logstash 服务器，等待和确认数据的传入。导入 Kibana 的相关对象。浏览查看和确认 siscale （国外一家 Elastic 的合作伙伴公司） 的作品。理解每个可视化展示控件的设计细节。\n你可以参考下面的安装步骤和注意事项。\n登录 Kibana，进入 Dev Tool 中，将文件 index-template-mapping.json 中的内容复制进去并点击执行按钮。 安装 Logstash 7.6.1 1 2 yum install java-11-openjdk-11.0.6.10-0.el8_1.x86_64 rpm -ivh logstash-7.6.1.rpm 将配置文件中的 /etc/logstash/covid-19-hashes.json 修改为 /usr/share/logstash/covid-19-hashes.json 然后把它们复制到 logstash 的配置目录中 1 cp logstash-github-covid-19-daily-reports-template.conf logstash-github-covid-19-time-series-template.conf /etc/logstash/conf.d/ 确保你的虚拟机（测试环境和 github 以及其他的国外基本正常的情况下）网络正常的情况下，启动 logstash 服务并且关注该服务的日志信息 1 2 sudo systemctl start logstash sudo tail -f /var/log/logstash/logstash-plain.log PS:在日志中可以看到 logstash 完全正常的启动成功，或者看到报错，这时候就需要停止 logstash 服务，并进行调整。直到服务彻底运行成功不报错。\n在 logstash 服务正常运行的情况下，世卫组织的数据是会被正常的导入到 ES 中的，你可以在 Discovery 中查看如下的查询结果。那么恭喜你，你已经和世卫组织的数据保持实时同步了。\n最后是导入该项目的仪表板对象。操作步骤参考：登录 kibana， 进入管理， 点击 Kibana 下面的 saved objeces ； 点击 import 按钮。选择 kibana-7.6.1-covid-19-dashboard.ndjson ，然后即可浏览名为 COVID 19 的仪表板了。导入后在 Kibana 的仪表板清单中选择查看名为 “COCID 19” 的仪表板。预祝你能看到和我相同的结果，建议仔细查看他们的地图设计，做的是非常的细致，如下图所示，它是三个图层叠加的显示效果。\n总结 最后希望你通过本文已经成功的展示出了以上的预期结果。下面简单总结一下相关知识点。\n对陌生数据集的首次探索可以是手动导入 csv 文件的手动过程 在导入的过程中需要做适当的 field mapping 的调整，和扩展，让后期的查询和数据分析更加清晰 对导入后的数据，充分利用 Discovery 的查询和分析能力，确定好数据校准和调优的更新策略 充分利用 ES 的批量查询修改 API，可以轻松快捷的实现数据修订。 地图的使用重点在地理信息代码和数据索引中的实际 field 的 join，因此需要特别设计和维护 join 的字段，确保他们的精确性。 仪表板的制作和设计依赖于各种图标的设计 Elastic Stack 在本案例中得到了充分而综合的运用。从 E 到 L 到 K 一个都不能少。建议大家能平衡掌握这个技术栈的各种技术能力，补足不太擅长的部分。\n本文参考的网址如下：\nhttps://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6 http://covid.surge.sh/ https://informationisbeautiful.net/visualizations/covid-19-coronavirus-infographic-datapack/ https://ncov.dxy.cn/ncovh5/view/pneumonia https://github.com/CSSEGISandData/COVID-19 https://lab.isaaclin.cn/nCoV/ https://github.com/siscale/covid-19-elk https://www.mapbox.cn/coronavirusmap/#3.35/28.47/109.74 https://ncov.deepeye.tech/ https://www.siscale.com/importing-covid-19-data-into-elasticsearch/ ","date":"2020-04-08T17:04:08+08:00","permalink":"https://martinliu.cn/blog/using-elastic-stack-for-monitoring-covid-19/","title":"使用 Elastic Stack 监控 Covid-19 疫情发展"},{"content":"当你满心欢喜的安装完了 vagrant 之后，在你第一次 vagrant up 命令的时候，是下载超时么？你的内心是什么感受？想放弃了么？\n其实你只需要找到国内的 box 文件镜像服务器，或者下载地址，然后手工下载对应的 Box 文件（操作系统镜像文件），并导入即可，本文将帮你铲除这只官方镜像文件下载失败的拦路虎。\nVagrant 的优势：\n虚拟机对于系统级开发和测试工作具有不可替代的作用 手工安装的虚拟机非常 准备工作 我的测试环境如下，如果你的测试环境和我的不同，但是本操作方法和过程也同样的适用于相似的环境。\n环境描述：\nmacOS catalina version 10.15.3 vagrant 2.2.4 Virtuabox 6.0.15r135660 如果你也百度了’ vagrant box 国内镜像‘的话，结果会使你很失望，清华大学等站点只是缓存了个别的镜像文件，并没有其它版本特别全面的网站，更没有完整的镜像。如果你知道其它国内的镜像站点请告诉我，我会增加到本文。\nUbuntu 的可以浏览这两个目标下载网址。\nhttps://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/vagrant/\n然后用vagrant 下面的命令就可以将 box 下载并且添加到本地。\nubuntu 18.04 LTS: vagrant box add https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/bionic/current/bionic-server-cloudimg-amd64-vagrant.box \u0026ndash;name ubuntu18\nubunt 16.04 LTS： vagrant box add https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/xenial/current/xenial-server-cloudimg-amd64-vagrant.box \u0026ndash;name ubuntu16\nubuntu14： vagrant box add https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/vagrant/trusty/current/trusty-server-cloudimg-amd64-vagrant-disk1.box \u0026ndash;name ubuntu14\n对于 CentOS 而言，它的官网整理的比较好，提供了各种格式的下载，可能需要科学上网才能访问到 Centos 的下载网址。\nhttp://cloud.centos.org/centos/7/vagrant/ http://cloud.centos.org/centos/8/vagrant/\n实战建议：你并不需要下载过多的 box 操作系统镜像文件，够用即可。建议将最近有可能使用到的 Box 文件用断点续传的多线程下载工具下载到本机磁盘备用。我下载了一些，关注的微信号‘ MyDevOps ’ 回复 box1 即可获得百度网盘下载地址，这个共享目录中有本文中所提到的所有 Box 文件。\n导入 Box 文件 用 vagrant box add 命令将本地下载好的 box 文件导入到 vagrant 的主目录中，macOS 下是在~/.vagrant/ 目录里。\n使用vagrant box list名先查看本地已有的 box 清单，下面的执行结果如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ➜ ~ vagrant box list Puppetlabs Ubuntu 12.04.2 x86_64, VBox 4.2.10, No Puppet or Chef (virtualbox, 0) bento/centos-7.1 (virtualbox, 2.2.2) bento/centos-7.2 (virtualbox, 2.3.1) bento/centos-8 (virtualbox, 202002.04.0) bento/ubuntu-16.04 (virtualbox, 0) coreos-alpha (virtualbox, 1451.2.0) geerlingguy/centos6 (virtualbox, 0) geerlingguy/centos7 (virtualbox, 0) geerlingguy/ubuntu1604 (virtualbox, 0) ubuntu/trusty64 (virtualbox, 20161207.0.0) ubuntu/trusty64 (virtualbox, 20170307.0.0) ubuntu/wily64 (virtualbox, 20160715.0.0) ubuntu/xenial64 (virtualbox, 20161214.0.1) ubuntu/xenial64 (virtualbox, 20170307.0.1) ➜ ~ 使用vagrant box add导入，并确认。 参考下面的执行过程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ➜ ~ vagrant box add ~/Downloads/box/bionic-server-cloudimg-amd64-vagrant.box --name ubuntu/bionic ==\u0026gt; box: Box file was not detected as metadata. Adding it directly... ==\u0026gt; box: Adding box \u0026#39;ubuntu/bionic\u0026#39; (v0) for provider: box: Unpacking necessary files from: file:///Users/martin/Downloads/box/bionic-server-cloudimg-amd64-vagrant.box ==\u0026gt; box: Successfully added box \u0026#39;ubuntu/bionic\u0026#39; (v0) for \u0026#39;virtualbox\u0026#39;! ➜ ~ vagrant box list Puppetlabs Ubuntu 12.04.2 x86_64, VBox 4.2.10, No Puppet or Chef (virtualbox, 0) bento/centos-7.1 (virtualbox, 2.2.2) bento/centos-7.2 (virtualbox, 2.3.1) bento/centos-8 (virtualbox, 202002.04.0) bento/ubuntu-16.04 (virtualbox, 0) coreos-alpha (virtualbox, 1451.2.0) geerlingguy/centos6 (virtualbox, 0) geerlingguy/centos7 (virtualbox, 0) geerlingguy/ubuntu1604 (virtualbox, 0) ubuntu/bionic (virtualbox, 0) ubuntu/trusty64 (virtualbox, 20161207.0.0) ubuntu/trusty64 (virtualbox, 20170307.0.0) ubuntu/wily64 (virtualbox, 20160715.0.0) ubuntu/xenial64 (virtualbox, 20161214.0.1) ubuntu/xenial64 (virtualbox, 20170307.0.1) ➜ ~ 校验所导入的 Box 创建一个测试目录，并执行vagrant init ubuntu/bionic ，然后使用 vagrant up 测试。\n1 2 3 4 5 6 7 ➜ test pwd /Users/martin/code/test ➜ test vagrant init ubuntu/bionic A `Vagrantfile` has been placed in this directory. You are now ready to `vagrant up` your first virtual environment! Please read the comments in the Vagrantfile as well as documentation on `vagrantup.com` for more information on using Vagrant. test 目录下面现在生成了一个默认的 Vagrantfile 文件，查看这个默认的 Vagrantfile 配置文件。这是一个很好的学习资料。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 ➜ test cat Vagrantfile # -*- mode: ruby -*- # vi: set ft=ruby : # All Vagrant configuration is done below. The \u0026#34;2\u0026#34; in Vagrant.configure # configures the configuration version (we support older styles for # backwards compatibility). Please don\u0026#39;t change it unless you know what # you\u0026#39;re doing. Vagrant.configure(\u0026#34;2\u0026#34;) do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box = \u0026#34;ubuntu/bionic\u0026#34; # Disable automatic box update checking. If you disable this, then # boxes will only be checked for updates when the user runs # `vagrant box outdated`. This is not recommended. # config.vm.box_check_update = false # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine. In the example below, # accessing \u0026#34;localhost:8080\u0026#34; will access port 80 on the guest machine. # NOTE: This will enable public access to the opened port # config.vm.network \u0026#34;forwarded_port\u0026#34;, guest: 80, host: 8080 # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine and only allow access # via 127.0.0.1 to disable public access # config.vm.network \u0026#34;forwarded_port\u0026#34;, guest: 80, host: 8080, host_ip: \u0026#34;127.0.0.1\u0026#34; # Create a private network, which allows host-only access to the machine # using a specific IP. # config.vm.network \u0026#34;private_network\u0026#34;, ip: \u0026#34;192.168.33.10\u0026#34; # Create a public network, which generally matched to bridged network. # Bridged networks make the machine appear as another physical device on # your network. # config.vm.network \u0026#34;public_network\u0026#34; # Share an additional folder to the guest VM. The first argument is # the path on the host to the actual folder. The second argument is # the path on the guest to mount the folder. And the optional third # argument is a set of non-required options. # config.vm.synced_folder \u0026#34;../data\u0026#34;, \u0026#34;/vagrant_data\u0026#34; # Provider-specific configuration so you can fine-tune various # backing providers for Vagrant. These expose provider-specific options. # Example for VirtualBox: # # config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| # # Display the VirtualBox GUI when booting the machine # vb.gui = true # # # Customize the amount of memory on the VM: # vb.memory = \u0026#34;1024\u0026#34; # end # # View the documentation for the provider you are using for more # information on available options. # Enable provisioning with a shell script. Additional provisioners such as # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the # documentation for more information about their specific syntax and use. # config.vm.provision \u0026#34;shell\u0026#34;, inline: \u0026lt;\u0026lt;-SHELL # apt-get update # apt-get install -y apache2 # SHELL end 现在可以踏实的运行 vagrant up 了，Ubuntu 的 Box 文件导入通常没有什么问题。默认配置的 Ubuntu 版本 bionic 的 vm 现在就正常启动了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 ➜ test vagrant up Bringing machine \u0026#39;default\u0026#39; up with \u0026#39;virtualbox\u0026#39; provider... ==\u0026gt; default: Importing base box \u0026#39;ubuntu/bionic\u0026#39;... ==\u0026gt; default: Matching MAC address for NAT networking... ==\u0026gt; default: Setting the name of the VM: test_default_1585496539631_90780 ==\u0026gt; default: Clearing any previously set network interfaces... ==\u0026gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat ==\u0026gt; default: Forwarding ports... default: 22 (guest) =\u0026gt; 2222 (host) (adapter 1) ==\u0026gt; default: Running \u0026#39;pre-boot\u0026#39; VM customizations... ==\u0026gt; default: Booting VM... ==\u0026gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key default: Warning: Connection reset. Retrying... default: default: Vagrant insecure key detected. Vagrant will automatically replace default: this with a newly generated keypair for better security. default: default: Inserting generated public key within guest... default: Removing insecure key from the guest if it\u0026#39;s present... default: Key inserted! Disconnecting and reconnecting using new SSH key... ==\u0026gt; default: Machine booted and ready! ==\u0026gt; default: Checking for guest additions in VM... default: The guest additions on this VM do not match the installed version of default: VirtualBox! In most cases this is fine, but in rare cases it can default: prevent things such as shared folders from working properly. If you see default: shared folder errors, please make sure the guest additions within the default: virtual machine match the version of VirtualBox you have installed on default: your host and reload your VM. default: default: Guest Additions Version: 5.2.34 default: VirtualBox Version: 6.0 ==\u0026gt; default: Mounting shared folders... default: /vagrant =\u0026gt; /Users/martin/code/test 现在 ssh 登录到这个崭新的 vm 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ➜ test vagrant ssh Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 4.15.0-91-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Sun Mar 29 15:42:53 UTC 2020 System load: 1.25 Processes: 99 Usage of /: 10.1% of 9.63GB Users logged in: 0 Memory usage: 12% IP address for enp0s3: 10.0.2.15 Swap usage: 0% 0 packages can be updated. 0 updates are security updates. vagrant@ubuntu-bionic:~$ top 导入 CentOS 7 可能遇到的问题 CentOS 7 和 8 的相关版本在我的测试环境中都出现了导入正常 vagrant up 异常的问题，通常网络搜索错误代码后，就可以解决了，如果有任何问题，欢迎到我的微信公众后台留言。\n总结 Vagrant 的功能性和必要性是非常高的，特别是对于天朝的码农而言，就更加重要了。它是 DevOps 工具链上的知名工具，而它的使用率和广泛性却不高。后续还会出这方面的系列内容，讲解更多关于 Vagrant 的优化和功能。\n2io\n","date":"2020-03-26T08:57:57+08:00","image":"https://martinliu.cn/images/vagrant-download-box.jpg","permalink":"https://martinliu.cn/blog/download-import-vagrant-box/","title":"如何在墙内正常导入 Vagrant 虚拟机模板"},{"content":"\n本文描述如何搭建一套具备用户名和密码安全认证的 Elastic Stack 系统，并开始使用 Filebeat 的基础模块实现分布式的日志收集。\n安装单节点 Elasticsearch 服务器，启用用户名和密码安全认证，并创建 TLS 数字证书备用 安装 Kibana 服务器，并配置与 Elasticsearch 服务的连接 安装和配置 Filebeat 代理程序，并配置 system 和 auditd 模块 使用 Kibana 监控 Filebeat 所采集的系统日志，并监控系统的状态 为了使你也获得与我一致的安装和测试体验，请先下载并浏览相本文所使用的代码库：https://github.com/martinliu/elastic-labs\n试验环境概述和启动 本文所使用相关软件以及版本。\nmacOS Catalina version 10.15.3 Vagrant 2.2.4 VirtalBox 6.0 操作系统镜像: bento/centos-8 (virtualbox, 202002.04.0) Elastic Stack 安装包（RPM） Elasticsearch 7.6.1 Kibana 7.6.1 Filebeat 7.6.1 使用 Vagrant 的目录共享功能，分享安装包到测试机的 /vagrant/rpm 目录下 注意事项：\n你也可以使用任何一台 CentOS 8 虚拟机或者云主机，则后续的安装命令和 rpm 安装包的路径需要有所变化。 Vagrant 文件中定义的虚拟机配置为 4 GB 内存，建议你的操作系统最低为 8GB 内存，推荐 16GB 或者更高， 本文也适用于 Linux 或 Windows 操作系统的 Vagrant 测试环境，需要提前下载并且准备好 bento/centos-8 的基础操作系统镜像。 启动测试环境。\n1 2 vagrant up vagrant status 安装 Elasticsearch 服务器 SSH 登录测试虚拟机。\nvagrant ssh\n执行 RPM 安装命令，安装 elasticsearch 服务器。\n1 2 3 4 5 6 cd /vagrant/rpm sudo rpm -ivh ./elasticsearch-7.6.1-x86_64.rpm sudo systemctl daemon-reload sudo systemctl enable elasticsearch.service sudo systemctl start elasticsearch.service sudo systemctl status elasticsearch.service 测试 Elasticsearch 服务是否功能正常 【 Dry run 】\ncurl localhost:9200\n期待的输出类似下面。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \u0026#34;name\u0026#34; : \u0026#34;elk-master\u0026#34;, \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;X4V2Yvc-SJ6ccjWbXQ5OmQ\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;7.6.1\u0026#34;, \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;rpm\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;aa751e09be0a5072e8570670309b1f12348f023b\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2020-02-29T00:15:25.529771Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;8.4.0\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34; } 浏览和学习 Elasticsearch 默认的配置文件。\nsudo cat /etc/elasticsearch/elasticsearch.yml\n使用 Elasticsearch 的精简版目标测试配置文件。\n1 2 3 sudo cp /vagrant/elasticsearch/elasticsearch.yml /etc/elasticsearch/elasticsearch.yml sudo systemctl restart elasticsearch.service sudo systemctl status elasticsearch.service 手工查看 Elasticsearch 服务器的日志，并确认服务启动正常。\nsudo tail -f /var/log/elasticsearch/my-elk.log\nCtl + c 终止以上日志查看，再次测试 Elasticsearch 服务。\ncurl localhost:9200\n替换为 IP 地址测试。\ncurl http://192.168.50.10:9200/\n配置 Elasticsearch 服务的 TLS 数字证书和身份验证 停止 Elasticsearch 服务。\nsudo systemctl stop elasticsearch.service\n创建 TLS 数字证书 1 2 3 cd /usr/share/elasticsearch sudo bin/elasticsearch-certutil cert -out /etc/elasticsearch/elastic-certificates.p12 -pass \u0026#34;\u0026#34; sudo chmod 660 /etc/elasticsearch/elastic-certificates.p12 更新 Elasticsearch 配置文件 手工打开 Elasticsearch 配置文件。\nsudo vi /etc/elasticsearch/elasticsearch.yml\n在配置文件的末端增加下面的配置段落。\n1 2 3 4 5 6 # ------------------------------- TLS and Cert --------------------------------- xpack.security.enabled: true xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.verification_mode: certificate xpack.security.transport.ssl.keystore.path: elastic-certificates.p12 xpack.security.transport.ssl.truststore.path: elastic-certificates.p12 重新启动配置 Elasticsearch 服务。\n1 2 sudo systemctl restart elasticsearch.service sudo systemctl status elasticsearch.service 确认服务已经正常启动。\nsudo tail -f /var/log/elasticsearch/my-elk.log\n创建 Elasticsearch 服务的用户密码 运行 Elasticsearch 的密码配置工具，为各种内置用户生成随机的密码。\n1 2 sudo cd /usr/share/elasticsearch sudo bin/elasticsearch-setup-passwords auto 将生成的密码信息妥善保存备用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Changed password for user apm_system PASSWORD apm_system = AHyg5HzJRZg8Fiva0buW Changed password for user kibana PASSWORD kibana = Kt72IXkiarlGr7do02Yp Changed password for user logstash_system PASSWORD logstash_system = Q9nnlOdf6V9kyPbbhqN7 Changed password for user beats_system PASSWORD beats_system = bLNrZDggPKRSKc35EG32 Changed password for user remote_monitoring_user PASSWORD remote_monitoring_user = o1pi2yTDnhrKBGcS6xqP Changed password for user elastic PASSWORD elastic = RO11xymgXTCD16ivTP33 在浏览器中访问http://192.168.50.10:9200/ ，测试并确认上面的 elastic 用户的密码。\n安装和配置 Kibana 服务器 执行 Kibana 安装命令\n1 2 cd /vagrant/rpm/ sudo rpm -ivh kibana-7.6.1-x86_64.rpm 查看并学习 Kibana 默认配置文件\nsudo cat /etc/kibana/kibana.yml\n更新默认配置文件，准备好 elastic 用户的密码，将其更新到 Kibana 配置文件中。\n1 2 3 sudo cp /vagrant/kibana/kibna.yml /etc/kibana/kibana.yml sudo systemctl start kibana.service sudo systemctl status kibana.service 查看重启的服务是否工作正常。\nsudo tail -f /var/log/messages\n在浏览器里测试登录 Kibana http://192.168.50.10:5601 ，使用 elastic 的用户名和密码。\n安装 filebeat 并配置 2 个模块 执行 Filebeat 安装包。\n1 2 cd /vagrant/rpm sudo rpm -ivh ./filebeat-7.6.1-x86_64.rpm 查看默认的 Filebeat 配置文件。\nsudo cat /etc/filebeat/filebeat.yml\n更新默认配置文件，准备好 elastic 用户的密码，将其更新到 Kibana 配置文件中。\nsudo cp /vagrant/filebeat/filebeat.yml /etc/filebeat/filebeat.yml\n查看 Filebeat 的默认日志监控模块。\nsudo filebeat modules list\n启用 Filebeat 的 System 和 Auditd 模块，监控系统日志和基础的操作系统安全信息。\nsudo filebeat modules enable system auditd\n查看 Filebeat 监控模块的配置文件。\n1 2 sudo cd /etc/filebeat sudo ls -l modules.d/ 建议查看以上启用的 System 和 Auditd 模块的配置文件。\n运行 Filebeat 在后台的初始化命令，在后台创建 Filebeat 所需要的索引 filebeat-* ，并导入所有模块相关的 Dashboard 等 Kibana 日志可视化分析工具。\nsudo filebeat setup\n在浏览器中登录 http://192.168.50.10:5601 Kibana 后，点击左侧的 Dashboard 图标，查看所有刚才导入的内容，搜索并打开 System 关键字的 Dasboard。\n在启动日志收集代理 Filebeat 服务前，运行一下命令测试 Filebeat 配置文件的正确性。\nsudo filebeat test config\n启动 Filebeat 服务，开始对这台操作系统的日志进行监控。\n1 2 sudo systemctl start filebeat sudo systemctl status filebeat 建议的测试 点击左侧的 Dicovery 图标，选中 Filebeat-* 索引，打开并一条日志数据，并查看所有字段；用 KQL 进行全文搜索。 点击左侧的 Dashboard 图标，搜索 system 关键字，查看一个仪表板的日志展示；搜索 audit 关键字，并查打开一个仪表板，在命令行中尝试 ssh localhost，多尝试几次，刷新 Audit 仪表板，观察数据是否发生了变化。 点击左侧的 Logs 图标，用鼠标上下滚动日志信息流， 点击右上角的开始 Live Stream 查看模式，观察日志信息流的自动滚动效果，在 KQL 搜素框中输入 tags : demo-service ，体验它的搜索建议功能，在 Highlight 中输入 http://192.168.50.10:5601/app/infra ，观察日志信息流显示的变化。 点击左侧的 SIEM 图标，看看这里都有什么内容。 后续 用启用 Filebeat 的 Elasticsearch, Kibana 日志监控模块 安装 Apache, MySQL 等软件，并开启 Filebeat 的日志监控模块 参考文档： https://www.elastic.co/guide/en/elasticsearch/reference/current/setting-system-settings.html\n","date":"2020-03-26T08:51:15+08:00","image":"https://martinliu.cn/images/abstract-1.jpg","permalink":"https://martinliu.cn/blog/elk-stack-install/","title":"最简化 Elasticsearch \u0026 Kibana \u0026 Filebeat 安装说明"},{"content":"SLA、SLI 和 SLO 是 SRE 工程实践里非常核心的概念，但是大家在同时提到这些概念的时候，经常容易混淆。\n长篇大论的文章反而容易使人更加疑惑，还不如画一张示意图说明一下，帮助大家一次性彻底梳理清楚这些不可以含糊不清的核心概念。说明一下，下图假设所讨论的 SLA 个数为 1，使用了软件工程中 ER 图的表达方式，但也有所变化。\n一图讲清 SLA、SLO、SLI\n本文不讲 why，只是帮助大家梳理清楚这些概念在以上人机系统中的相互关系。虽然不想做名词解释。但是为了方便起见，整理一个术语清单。\nSLA = Service Level Agreement = 服务质量/水平协议 SLO = Service Level Objective = 服务质量/水平目标 SLI = Services Level Indicator = 服务质量/水平指标 下面用人、事、物的逻辑进行阐释。\n人和事 用从上到下，从左到右的顺序。\n客户 - 每 1 个客户在使用产品服务时，都显性或隐性的基于某 1 个 SLA，SLA 和客户之间是一种 1 对 1 的文档关系，这份协议文档就显性或者隐性的存在于系统中。客户使用 1 种，或者 n 种连接方式访问产品服务的 1 个或者 n 个应用系统。\n销售 - SLA 本身是所销售产品服务的一部分，它规定了承诺给客户的产品功用和质量。基于 SLA，客户可以选择用付费或者免费的方式使用产品。1 个/份 SLA 的销售工作可以由 1 到 n 位销售完成。销售和客户都幻想着几乎完美的 SLA，这样代表企业利益的销售，以及产品的客户就都可以达到双赢的局面，皆大欢喜。\n产品 - 通过与销售的间接互动，或者直接的客户调研，产品经理能够确定应用系统所应该具有的功能和发展方向。\nSRE - SRE 和产品共同制定了每个 SLA 相关应用系统的 SLO，SLO 定量的定义了每 1 个应用系统所应该具备的服务质量，1 个应用系统的 SLO 被该产品服务的 SLO 文档定义，在该文档中 SLO 被映射到 1 个或者 n 个 SLI，每个 SLI 都需要用监控工具持续采集数据，通常它们的数值单位各不相同。所有 SLO 都是用百分比数值形式表达的，例如：99.99% 的成功率，90％ 的请求延迟 \u0026lt; 400 毫秒等。SRE 和产品经理/专家还应该共同关注运行应用系统的基础设施层，确保基础设施的可用性和容量足以满足目标数量的用户访问，而且还要考虑和设计底层资源的容灾和跨区多活等复杂场景。\n开发/运维 - 重要但暂不做讨论。\n事 用从下往上的顺序。\nIaaS 云服务 - 也可以是其它类型的可以供应用系统运行的环境。这里存在着 1 到 n 种子服务。它和上层的 n 个应用系统通常是 n 对 n 的关系。\n应用系统 - 1 个到 n 个应用系统构成了 1 个产品服务（内含SLA），在和客户的互动中实现着产品服务的业务价值。\n文档 - 以网页或者纸张的形式向用户描述了某个应用服务所提供的服务内容和质量信息。向用户提供这个文档并不是强制、显性和必须的。\n结束 请根据以上解释，结合你的实际工作场景，想象并描绘一下 SLA 、SLO 和 SLI 在你周围的人事物中关系网。在SRE 的工作实践中，定义 SLO，并梳理 SLI，将量化以后的目标和说明文档化，并让各个干系人认同并签署，是一项基础的起步工作。\n本文参考了 Google 出品的两本SRE 书籍，这两本书的英文版在 Google 的官网可以免费在线阅读。SRE Workbook 的简体中文版会在2020 年中出版。\n","date":"2020-03-05T17:37:29+11:00","image":"https://martinliu.cn/images/abstract-6.jpg","permalink":"https://martinliu.cn/blog/sre-sla-slo-sli/","title":"SLA、SLO 和 SLI 还是傻傻分不清么？"},{"content":"本文要覆盖的章节是《 How to use the research models》 这一章。双模型在今年的报告中首次出现了，它们是效能模型和生产力模型。为什么会存在两个模型？有什么区别？有什么相似之处？最重要的问题是，你怎么用它们来指导你的DevOps工作？\n本文的阅读建议：\n下载我整理的最新版的《DevOps能力成长模型》，含双模型分解图。 阅读和参考前5年的DevOps状态调查报告，了解今年这份报告的历史和发展历程。以前的文章中有下载链接/二维码。 阅读2019年的调查问卷的中文版，感谢中国DevOps社区翻译团队对英文原版问卷的翻译工作，如果你都不知道这些调查结果是通过什么问卷调查得出的，那真的是很可惜。如果你想用这套问卷工具在企业内部做调研，请使用前文中的免费调查服务申请流程。样例问卷的访问地址：https://www.wjx.cn/jq/43837840.aspx 在Google的网站上做极简版DevOps行业基础测试，它是6年行业调查结果数据库的首次对外开放。 模型是怎么诞生的？ 首先，我们需要了解一下这份持续了6年的报告是谁主导并开发的？这是一个怎样的团队？从DORA公司网站的这个页面上，可以看到团队人员介绍。https://devops-research.com/about.html 如下所示。\n不做其它任何解读和评论，只想请大家关注一下分析报告的主持者的title : Dr Nicole Forsgren, CEO and Chief Scientist ; 翻译一下 Nicole Forsgren 博士，CEO和首席科学家。她是一个长期的IT行业从业人员，最早专注于DevOps的行业调研员。她持有管理信息系统的博士学位和会计硕士学位。从社交媒体上可以看出她和行业大咖Jez Humber和Gene Kim都是好朋友。\n其次，如果你也回顾了所有往届的DevOps状态调查报告，我们应该能体会到这场历时6年行业调研的基本逻辑和脉络。在第一年就已经提出了四大黄金度量指标，并且以此为主线；每年反复验证状态，以及其他相关影响因素。使用了穷举的逻辑，每年根据行业的发展动态，根据和其它业内大咖的讨论，适当的加入新的调查点。当然每个调查的能力点也是需要每年反复确认和验证，调查点之间的逻辑关系也越来越明显，经过二次研究之后就形成了DevOps能力成长模型。\n最后，DevOps能力成长模型诞生于《Accelerate:The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations 》这本书。 https://www.amazon.com/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339\n在这本书里分模块（局部）的介绍了DevOps能力模型的影响逻辑关系，从转型型领导力一直推导出模型的最右侧：组织效能和非商业效能。这个模型应该就是历届DevOps状态调查研究背后的理论基础，当然它也应该是慢慢发展和完善出来的，起码数字转型这个话题是2018年才出现的热点。模型的数值计算算法，见近两年报告的附录部分。这个模型在本书中是从各个不同的局部关系逐渐介绍的。如下图所示：\nAccelerate全书的逻辑不仅在于介绍各种DevOp实践、技术、文化、领导力等等相关因素有哪些，更重要的是揭示出这些影响因素（能力点）之间的关联关系。在书的最后展示了DevOps能力成长模型的全图，如下图所示：\nAccelerate这本书也提供了这幅图的电子版下载链接：https://devops-research.com/assets/transformation_practices.pdf\n这是一份非常棒的学习资料，如果你还没有买本书的话，也可以下载学习这份精华资料。这份文档的总标题是：”调研总体策划“，除了模型之外该文档还提供了一张全面复杂的表格，表格的名字：”高效能团队，管理、领导力行为和实践调查表，由Steve Bell，Karen Whitley Bell“；如果你想对自己的组织进行全面的调研的话，这也是一份优秀的调研方案。调研的矩阵如下：\n纵向：文化、组织结构、直接学习和对齐价值、部署策略、通过分析提高流动性和训练有素的问题解决、工作方式节奏化\u0026amp;日常化 横向：团队实践、管理实践、领导力实践。 我很有幸2017年在北京DevOpsDays大会上参加Jez先生的培训，并获赠了Jez先生的签名版《Accelerate》纸版书，其实在这以前我已经购买了Kindle的电子版和Audible的有声书版。我反复研读了这本书的各种版本，再次强烈推荐所有DevOps相关的管理者一定要学习这本书。\n以书中的模型为基础，2018年的DevOps状态报告里以又进一步做了各种扩展，如果你读过去年的报告，你可以看到如下的各种局部的扩展。\n大家注意看2018年的这个局部模型图的标题”精益和敏捷实践“，这里也包含敏捷开发实践。我在反复琢磨这个模型之后，用Twitter私信问过Nicole博士。我问他为何没有专项调查过敏捷开发实践？模型上为何不给敏捷开发一个位置？她的回复是，我们之前已经调研过了，而且模型上也提到了。可能在全球的软件开发工程水平看，有可能Nicole博士团队认为敏捷开发应该是比较基础的软件开发实践，据我个人了解国外高水平公司要么都已经规范照做了，要么也有像Google这样的高水平公司确实也不显性的宣传自己是敏捷开发，甚至吐槽敏捷的。\n2018年对模型的扩展力度还是很大的，提出了很多新的调查项；为了能看到方便的看到一个DevOps能力模型的全景视图，我使用OmniGraffle软件基于《Accelerate》书中的模型，扩充绘制了如下的模型图：\n这幅图向我们完整的揭示了到2018年以来的所有DevOps调研点，有些点是经过多年反复验证的，有些是2018年新引入的。这幅图花了我几天时间，在这个过程中也反复的推敲了其中的逻辑关系。这幅图仅代表我个人的观点，不代表DORA和《Accelerate》书籍的任何观点；需要声明的是：我绘制的DevOps能力成长模型并非我的个人著作，引用了DORA和《Accelerate》的著作，但我力求精确无误的表达整个模型。再次声明，这个模型图非官方出品，是我的个人研究。\n研究模型的研究逻辑是穷举法，是从左到右的推导和影响关系。最新发布的2019年DevOps状态调查报告显示了新的变化，这触发了对以上模型的更新。本文将提供最新版高清大图的下载。\n为何两个模型？ 为何2019年会分化出两个模型，简单的讲：穷举的范围越来越大了，生产力作为一个新的全局共享目标进入了调查问卷的范围。我们之前社区的小伙伴已经将2019年的近100道调查题问题翻译成中文了，敬请参阅参考DevOps状态调研问卷。在翻译完那些题目后，我并没有意识到今年可能会新增出这样一个全局共享目标的调研对象，真的以为：这个效能模型（组织效能和非商业效能）会一条道走到最后。\n效能模型 对效能模型的更新变化如下图所示：\n生产力模型 新增的生产力模型令我感到相当意外，它的结构如下所示：\n总之，还无法预测明年的调研范围会有怎样的更新。可以确认的是行业DevOps的能力模型是在动态变化的，想跟上世界级的水平还必须不断刷新自己的能力组合。否则你的同行的对手可能早就一骑绝尘而去了。DevOps能力发展不是一个有限游戏（例如刷黄金5级），是每年都和整个行业一起发展的无限游戏。\n如何使用模型？ 2019年的报告中给出了模型的使用和阅读方法的官方解释，见2019年报告英文原版的27页。本文对其的解读如下。\n使用模型指导转型 识别你将要改善的能力点。模型中的每个被箭头所指向的方块被称之为构造，构造有单级构造，也有二级构造（如精益产品开发、软件开发实践），历年来的报告中已经为你展示和所有DevOps能力点，你现在需要做的是从中选择出你需要改进的候选能力点。\n开展加速度的组织转型需要一个前提条件，一个扎实的基础作为起点。报告中并没有解释这个条件，你需要自己理解。聚焦在转型所急需的那些候选能力点上，在多个候选能力点里选择出亟需改进的”约束点“「此处参考TOC限制理论，相关书籍《目标》」。想想：那些能力的不足造成了最大的延期？「记住这里说的是最大值，这需要一个量化的跨组织的分析调研」什么最让你头痛？什么是最大的问题？经过以上的引导问题的提示，从清单中选出3~5个候选优化发展的能力项，安排出专项人力和财力资源，先重拳出击改善第一波能力点。不要担心你还有其他的很多问题；现阶段不妨聚焦在那个最大的问题上；这样你才能将瓶颈（约束点）各个击破，发掘这个其他的协同功效，避免不必要的工作。这个部分基本上是经典TOC理论的应用，关于这个理论在DevOps实施中的详细使用方法描述，请参考《DevOps实践指南》的第二章 2.5 持续识别和改善约束点。\n以上DevOps转型工作还有其他的产出。那些追求SDO组织效能的组织还会得到这些收益，降低职业透支（996icu）和部署的痛，提高安全水平。附加的好处还包括，它能提高生产力，提高了生产力就可以获得工作生活平衡且降低职业透支。\n怎样阅读模型？ 报告使用了结构方程模型 （Structural equation modeling https://en.wikipedia.org/wiki/Structural_equation_modeling） ，来作为一种预测模型，用它测试各个构造之间的关系。模型中的每个方块就是一个调研度量的点，就是一个构造。剪头表示了构造之间的关系。一个大的包含多个构造的方框称之为二级构造。淡蓝色的构造表示一个控制变量，它用点线连接。\n在报告原文中，将第31页和57页的模型称之为全模型，见报告的27页的原文：”See pages 31 and 57 for full models.“；而在我的系列文章中，则将下图称之为全模型。\n以上阅读方法同样的适用于上图。总之请仔细理解了左下角的图例，正确的阅读和理解模型。不管你是将DevOps实践的实施视为组织转型也好，把它当做项目做也罢；当你识别你的目标的时候，都可以参考这个模型。\n两个研究模型的重叠 由于SDO效能和生产力在很多方面本来就是相关的。它们的产出都是使用各种优秀的方法创造和交付各种技术，从而为组织和个人交付价值。那些优化软件交付的支持工作也将使生产力受益，这也是理所当然的。虽然他们的某些诱因是相同的，它们看起来很相似，但是他们度量的产出确实不同的，报告团队也是组织了独立的分析调研。总之，SDO效能和生产力是两个不同的调研模型。\n重叠模型的妙用 当你在应用SDO效能模型的时候，可以在消减职业透支方面做出聪明点的投资，更高的生产力也同样能降低职业透支。因此这个应该是向各种组织和技术团队大力提倡的做法，由于工作需求是持续增长的。工作是没完没了的，这个项目完了，还有下一个项目。而我们需要注意，我们也要关注生活和工作的平衡，而降低职业透支。\n心理安全性文化也能对SDO效能、组织效能和生产力作出贡献。研究结果表明了创造和发展健康的文化对组织和个人都有好处。\n投资在代码可维护性、松耦合架构和监控方面，也能同时帮助SDO效能、生产力（它们是通过消减技术债间接的影响到生产力的）。好的工具和系统也非常值得关注。\n总结 通过本文我相信你已经可以正确的理解2019年状态报告中的模型了，模型包括SDO效能模型和生产力模型。包括我绘制的全模型。希望DORA官方能后续推出官方版模型全图。\n模型的意义在于：DevOps能力点是整个软件开发和交付行业都应该关注的，在投资DevOps实践的时候，需要能聚焦到组织各自不同的急需改进的能力约束点组合上。通过模型最右侧的组织级统一共享目标来度量和验证DevOps的实践是否实际有效。\nTOC是一个值得关注的问题解决套路，参考其它的相关文章和其它各种书籍。\n请关注DevOps教练的公众号，在后台输入2019，下载本文中各种模型的高清大图。\n","date":"2019-09-01T17:27:16+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/v1567000726/1-jafadjf.jpg","permalink":"https://martinliu.cn/blog/2019-state-devops-report-insight-2/","title":"怎样使用两个DevOps研究模型？"},{"content":"长期关注我的blog和微信公众号（DevOps教练）的朋友可以发现，我今年从这个调查问卷开始，陆续发布了一些列文章。如果给这些文章一个文集标题的话，那么应该是：死磕2019年加速度全球DevOps状态调查报告系列。 为了帮助大家充分利用这份优秀的行业报告，我会用一些列文章，分章节的解读这份长达80多页的报告。上一篇文章如果你已经解读了该报告的核心重要发现和看点。本文要覆盖的章节是 How do we compare 这一章。\n本文的阅读建议：\n先阅读和参考前5年的DevOps状态调查报告，了解今年这份报告的历史和发展历程。以前的文章中有下载链接/二维码。 阅读2019年的调查问卷的中文版，感谢中国DevOps社区翻译团队对英文原版问卷的翻译工作，如果你都不知道这些调查结果是通过什么问卷调查得出的，那真的是很可惜。如果你想用这套问卷工具在企业内部做调研，请使用前文中的免费调查服务申请流程。样例问卷的访问地址：https://www.wjx.cn/jq/43837840.aspx 在Google的网站上做极简版DevOps行业基础测试，它是6年行业调查结果数据库的首次对外开放。 WHY DEVOPS？ 这是一个可以持续反复问自己的问题，首先让我们澄清一件事情：为什么要做DevOps？\n是否是为了提高研发效能？是否是为了提高生产力？是否是为了提高效率？这些答案可能都对，也可都不对。对于一个组织而言：如果IT对它的使命和目标至关重要的情况下，组织对IT会产生强依赖关系，DevOps才对该组织才有意义。历年来的DevOps状态调查告诉我们：DevOps对于那些以IT为命脉的组织而言直观重要，对所有从事软件交付的组织广泛有效。\n从DevOps能力成长模型中可以看出，图中的诸多能力项都正向贡献/预测到最右侧的两个组织级别目标，他们是：组织效能和非商业效能（商业和非商业目标），它们是：\n盈利能力 （商业） 生产力 市场份额 （商业） 客户数量 （商业） 产品或服务的数量 （商业） 运营效率 客户满意度 （商业） 提供的产品或服务的质量 （商业） 实现组织或使命目标 如果你的某项/某几项DevOps实践能够直接贡献到以上的商业目标，或者说能持续的创造客户价值，即商业价值；那么你的DevOps就是成功的。反之，如果你仅仅期望研发效能、生产力、效率能够就等同于创造出了很多的客户价值，那是一种幻觉；这就像是：你经过了很多预赛和体能的准备，而在冠军争夺赛中，你依然名落孙山，当你的组织的绩效远远低于预期的商业目标的时候，你的各种XXX效率都是无用的。\n四大黄金度量指标 6年来的DevOps状态调查报告（我只关注DORA主导和执行的这个）已经在用量化的方式，帮助我们作出了精英表现者的画像，当然还有其它的落后者。可以明确的一点是：强者从四个维度上同时都表现强劲。（去年已经打破了常见的一个误区：过度的保守主义导致在组织四个指标之中做折中选择，常见的是牺牲吞吐量指标，确保稳定性，可是后果往往是相反的。）\n先来回顾和梳理所谓的四大黄金度量指标的分类：\n吞吐量\u0026ndash;部署频率：对于您工作的主要应用程序或服务，您的组织在生产环境进行代码部署或向最终用户做发布的频率。调查这个指标的问题见2019年加速度DevOps状态调查问卷中的第二部分的第二题。 吞吐量\u0026ndash;前置时间：对于您工作的主要应用程序或服务，从代码提交到在生产中成功运行的过程需要的时间。调查这个指标的问题见2019年加速度DevOps状态调查问卷中的第二部分的第一题。 稳定性\u0026ndash;服务恢复时间：对于您工作的主要应用程序或服务，当服务中断或出现影响用户Bug时（如：计划外中断、服务受损），恢复服务通常需要的时间。调查这个指标的问题见2019年加速度DevOps状态调查问卷中的第二部分的第四题。 稳定性\u0026ndash;变更失败率：对于您所工作的主要应用程序或服务，对于生产变更，或向最终用户发版的变更，百分之多少会导致服务质量下降（如：服务受损或服务中断），并需要进行后续的修复工作（需要热补丁、回滚，前向修复，打补丁修复）。调查这个指标的问题见2019年加速度DevOps状态调查问卷中的第二部分的第五题。 上面的四个指标是DevOps状态调查报告使用cluster算法做受众分类的主要依据，这个类聚分析的结果就是那张四大DevOps等级的泡泡图。\n在这个泡泡图中，我们可以看到有多少比例的受访者处于精英、高效、中等和低效的阵营。复述一下今年的一个重大发现：精英表现者已经从去年的高效能表现者集团中脱颖而出，他们在指标的绝对值和总体数量上都增长迅敏，增长率高达将近3倍。【DevOps教练点评：回顾一下这份报告的标题中加入的加速度的关键字，一旦某个组织的实施方法得当，一个持续优化的组织的整体效能就可能做上火箭，加速度的飞离地球。而加速度不足的企业则处于持续跌回地面的窘境。】\n这四大黄金度量指标的采集方法就是调查问卷中那些四个问题。对所有实践DevOps的组织而言，我们需要的是持续实施和优化追踪这些度量指标的方法和系统，确保能实时查看这四个指标的状态是最完美的。可是目前几乎还没有什么企业能够做到，手工分别统计上报，定期公布到全体IT部门也是非常可取的做法。总之，没有度量就不存在管理，就无从系统性的改进。\n我在行业里的表现如何？ 这是我写作本文想要回答的核心问题。如果你能够度量自己的四个黄金指标了，也能够随时拿出一组确切的数据，我们就能做行业基准测试比较了。\n这可能是Google收编DORA团队所买到的最有价值的一部分资产，历年来的DevOps调查问卷参与者的问卷答案数据库。Google今年将这个数据库向公众开放了，网址在 https://beta.devops-research.com/performance.html (这个网址应该不用科学上网，会出现证书错误提示，请忽略继续访问该页面)。在你回答了下面的五个问题后，就可以获得一份自己的行业基准测试报告。\n最后一个问题是，从13个行业中选择出一个最合适的所在行业。\n下图是你在整个所有行业里的横向对比。\n下图是你在所在行业里的横向对比。\n下图是四个黄金指标在四个表现级别/集团上的度量；表明你每个指标处于哪个等级。\n经过以上的最简版DevOps表现状态基准测试以后，你就看到了你在所有行业中和所在行业中的横向比较。当然，我们也能预测一下自己处于那个阵营和等级。然而，这并不是你的DevOps旅程的剧终情节。\n所有DevOps的实践者一旦上路以后，都是一条不归路的感觉，我们可以定期的关注我们的基准测试结果，并观察自己在动态变化的行业基线中的位置，而更重要的是：找到每个现阶段的改进空间，并且持续突破自己DevOps的能力瓶颈和极限。持续的无限制的加速度发展所有DevOps能力点才是这个DevOps旅程的终极意义。\n关于服务运维效能 服务效能指标是在去年的效能报告中新引进的，而在去年和今年的调查问卷和结果报告中并没有直接的关于这项指标的采集数据和结果。\n从上图中我们可以直接的理解一下，左侧的四大黄金指标都关乎于软件开发部门，而这个指标关乎于服务运维部门。去年并没有给出关于可用性指标的度量方法，今年也没有在调查问卷中做直接/显性的问题设置。只是在今年2019年的报告中做了进一步的解释，说这个可用性指标的实施方法论是SRE套路。我正在翻译SRE Workbook，这本书比起之前翻译的DevOps Handbook，更具有实操性。我们拭目以待，明年的状态调查问卷是如何对可用性设问和调查分析的。关于SRE的基础概念和实施方法，心急的朋友不妨参加中国DevOps社区今年10月在杭州举办的年度大会，我有一个关于SRE的主题分享，让我们一起讨论SRE的落地套路，让用SRE套路使我们的DevOps故事闭环。\n总之我们实践DevOps的时候要全局的关注“软件交付和运维效能”，简称SDO效能（software delivery and operational performance）；有O了才完整的闭环了。\n总结 本文写道这里，我认为你可以无障碍的阅读2019年加速度全球DevOps状态调查报告到第25页了。我们总结一下，你应该能理解吞吐量和稳定性的四大黄金度量指标的定义；持续度量和关注这些指标的正确方法；使用Google所提供的极简版度量工具，找到自己在行业中的定位和所处的效能级别。关注SDO效能的完整性，尝试了解和实践SRE实践，让你的DevOps体验闭环和完整起来。下一期死磕2019年加速度全球DevOps状态调查报告系列将为你呈现更新版本的DevOps能力成长模型，进一步讲解如何应用今年分化出来的两个研究模型：SDO和组织效能模型与生产力模型。\n","date":"2019-08-28T07:27:16+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/v1567000726/1-jafadjf.jpg","permalink":"https://martinliu.cn/blog/2019-state-devops-report-insight-1/","title":"如何做横向行业的DevOps表现基准测试？"},{"content":"凭借六年多的来自全球31,000多名专业人士的数据的研究，2019年加速发展状态报告是同类研究中规模最大、持续时间最长的研究。2019年加速度DevOps状态调查首发，首发的位置在Google Cloud网站上的Blog栏目，发布于产品新闻分类下。\n文章使用的主标签 DevOps 、SRE。 文章地址：https://cloud.google.com/blog/products/devops-sre/the-2019-accelerate-state-of-devops-elite-performance-productivity-and-scaling 下文为对Google文章原文的翻译和整理。并且加入了我本人的各种判断和见解。\n关于今年的DevOps状态调查报告有什么更新和变化？报告文章中给我们了一句话的概要介绍：今年会对部署工具链、云计算、灾难恢复和工作方式等主题进行深度调查。更详细的情况，详细的参过问卷调查的您自有评判。\n‘DevOps之研究和评估’（DORA）是通过数据驱动的洞察力，帮助组织实现DevOps和高效能组织的先驱，而Google Cloud很高兴地宣布推出2019年加速DevOps报告 。（前期文章介绍过DORA加入Google Cloud的细节） 该报告提供了DevOps行业的全景视图，为各种规模和所有行业的组织提供可操作的指导，从而提高他们的软件交付效能，最终使之成为精英DevOps实践者。\n2019年的新洞见 我们看到：有持续的证据表明了软件的速度、稳定性和可用性有助于提高组织绩效，今年我们能够发现一些关于推动DevOps高绩效表现，以及实践和功能的新洞见。 部分如下所示：\nDevOps已经‘跨越了鸿沟’：各个行业的组织继续地提高着他们的DevOps专业知识，特别是在表现最高那部分人群中。 精英表现者的比例几乎提高了两倍，目前他们占所有组织的20％。 这也得到了其他行业分析师报告的证实。【教练解读：精英表现者实现了从7%到20%的增长。】 精英表现者更有可能使用云计算 ：快速自动扩缩容、成本可见性和可靠性是云计算提供的一些关键优势。更具国家标准与技术研究院（NIST）定义的云计算所具有的五项特征功能，效能最高的DevOps团队比低效能团队在这些方面执行的可能性高24倍，5大特性包括按需的自助服务、广泛的网络访问、资源池，快速弹性和可度量的服务。 【教练解读：你们家使用的云计算是假的。】\n大多数云计算用户并未充分发挥其潜力 ：只有29％的使用云计算的受访者符合NIST上述的五项标准特征。 这证明了这样一个事实，即声称使用云计算的组织，未必采用了所有必要的云计算特征模式来实现精英水平的业绩，这也有可能会阻碍他们通过云计算获益。 【教练解读：你号称的优势正在阻碍你。】\n首次呈现出了行业差异性 ：在今年的报告中，零售行业在速度和稳定性方面都展示出了更好的表现。然而，与前几年保持一致的是，根据持续的证据表明，DevOps更好或更差的表现，并没有其行业的差异性。这依然表明：各种类型和规模的组织，包括金融服务、政府和零售等高度监管的行业，也都是可以通过应用DevOps实践来实现高水平的绩效。【教练解读：今年零售业做的很突出，还是你们进来刷榜了？】\nDevOps走进企业 - 第1部分 ：我们首次发现，根据证据显示大型企业组织（员工人数超过5,000人）的效能低于小型企业（员工人数少少于5,000人）。重量级的流程和控制措施，以及紧耦合的体系架构是导致较低速度，以及相关不稳定性的部分原因。【教练解读：大型组织的坑也更大。】\nDevOps走进企业 - 第2部分 ：我们的分析显示最高能的DevOps表现者（即高级和精英表现者），专注于通过结构化的解决方案来构建DevOps社区，这些解决方案包括以下四种模式之一：社区建设者、大学、涌现和实验者（Community Builders, University, Emergent, and Experimenters）。【教练解读：需要给它山之石提供存在的土壤。】\n没有“一刀切”的方法，成功有赖于一致的努力付出 ：在投资于DevOps的各项能力时，特别是在大型组织中，需要同时关注团队级别和组织级别的工作成果。在团队层面上，持续集成、自动化测试和监控等实践的一些工作投入运作良好。组织级能力包括：在多个部门和团队之间，设置系统体系结构或变更审批策略的能力。 该报告分解了这些能力并概述了应该采取的策略，因此您也可以执行相关的DevOps策略，并从中获得最大的效果。【教练解读：单纯的刷某个团队或者项目也是然并卵。】\n表现较差的组织比高级和精英表现者使用的软件更多 ：维护和支持私有商业软件的成本可能过高，这促使高级和精英表现者使用开源解决方案。 这和以前报告中的结果一致。 事实上， 2018年的加速度 DevOps报告就表明，精英表现者大量使用开源组件、库和平台的可能性是其它组织的 1.75倍。【教练解读：开源软件正在吞噬着整个世界。】\n你如何改进DevOps？ 今年的报告提供了有助于推动DevOps改进性能和生产力的两种研究模型。\n效能研究模型 着眼于哪些能让你提升组织绩效的结构和抓手，提供相关的云计算、持续交付、灾难恢复测试，明确变更管理和心理安全文化是如何对软件交付绩效产生积极作用的见解。 本次研究还发现重量级的变革流程是不起作用的。\n图片翻译参考：\n左侧的一列，从上至下：清晰的变更流程、重量级变更流程、灾难恢复测试、代码的可维护性、松耦合的架构、监控、主干开发、自动化部署。 中间的一列，从上至下：心理安全感文化、持续交付、云计算、持续集成、自动化测试。 右侧的一列，从上至下：行业（控制）企业（控制）、工作恢复、透支 图例，从上至下：结构、二级结构、团队或者组织的统一目标、控制变量、正向预测关系、双向影响、负面影响关系、粗体字-今年新的调查结果（左侧1～4，中间1） 生产力研究模型 表明：组织可以通过投资易于易用的工具和信息搜索引擎、心理安全文化，以及消除技术债务的方式来提高工程师的生产力。 提高生产力还有助于提高员工的工作-生活平衡，并降低职业透支（教练注释-996icu）。\n图片翻译参考：\n左侧的一列，从上至下：实用且易用的工具、内部搜索引擎、外部搜索引擎、代码可维护性。 中间的一列，从上至下：心理安全感文化、生产力、技术债、松耦合的架构、监控。 右侧的一列，从上至下：多年的经验（控制）、SDO效能、软件交付效能、可用性、组织级效能、透支 图例，从上至下：结构、正向预测关系、负面影响关系、团队或者组织的统一目标、控制变量、弱关联性、粗体字-今年新的调查结果（左侧1～4，中间1～2，右侧2） 今年的报告再次确认了连续第六年各种重要发现：首先，可以在不牺牲速度的情况下优化稳定性。 其次，DevOps通过影响商业和非商业目标为​​客户和最终用户提供价值。\n感谢为调查做出贡献的所有人。 我们希望此报告能够帮助各种规模，行业和地区的组织改进。 我们期待听到您对报告的想法和反馈。 您可以通过以下方式了解有关2019年加速状态报告的更多信息。\n相关材料和扩展 报告尝鲜试读 报告封面 关注点：DORA + Google， 新的赞助商的支持。\n报告目录 目录结构很类似，内容大不同。\nDevOps四大核心度量指标 四个级别的表现者在四大度量维度上的比较，以及今年的数据更新。\n精英表现者 他们始终遥遥领先。重点是所有的指标同时都好。\n两大研究模型的分化 效能模型 生产力模型 灾难恢复测试 灾难恢复测试和DevOps强相关。\n心理安全性 文化建设的一个关键组成。\nDevOps转型的策略一览表 你们都用了哪些推广DevOps的策略呢？抱歉并没有刷成熟度这一项。\n下载报告 目前Google的官网上提供了所有DORA的DevOps状态调查报告的下载包括2019年度最新的状态调查报告。为了方便国内DevOp实践者的学习，我将它下载到了百度网盘。请大家需要的按照一下方法下载阅读。\n报告下载方法：\n扫码下面的二维码，关注DevOps教练的微信公众号 进入DevOps教练的微信公众号的文字输入状态 输入数字 ： 2019 识别自动回复的二维码 下载pdf版本的2019加速度DevOps状态调查报告 使用2019调查问卷服务 前面的文章发布了2019DevOps问卷调查的中文翻译版本，https://martinliu.cn/posts/2019-state-devops-survey-chinese-version/ 这是对原版英文调查问卷的翻译，由中国DevOps社区翻译组完成，现在我们已经将它通过问卷星平台转化成了可以使用的调查服务。\n如果你的企业正在实施DevOps，如果你想了解一下这种称之为DevOps的科学的调查问卷，不妨可以通过下面的流程申请使用这个问卷服务：\n发邮件到 info@DevOpsChina.org ；邮件标题为 dora 2019 邮件内容请包含：公司名称、使用范围（全公司、团队）、使用其实时间、联系人姓名、联系人手机/微信、调查问卷的套数（题套问卷对应一个网站，可下载一份数据采集结果） 本服务为免费社区服务，在收到邮件后就会尽快为您提供所需要数量的网址，并在约定的结束时间发送调查结果到你的邮箱。 后续 经过了多年对这项行业顶级调查问卷和报告的追逐。今年的报告内容量大，新发现多，而且引入了新的研究模型。我会从内容和模型层面做更多的总结和研究。后续用一系列的文章进行报道。请关注“DevOps教练”微信号的更新文章和本网址的更新。\n","date":"2019-08-22T07:27:16+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/abstract-4.jpg","permalink":"https://martinliu.cn/blog/2019-state-devops-survey-report/","title":"2019年加速度DevOps状态调查报告-导读"},{"content":"本文是中文版《2019年加速度DevOps状态调查》问卷。如果你还没有填写该问卷的话，可以在线上填写英文版，点击这个链接 https://bit.ly/2UzLMH2 ，进入问卷调查网站。本文可以作为你的帮助文档。\n译者团队：刘征、张晔、刘頲、朱婷、王英伟、王虹、李建芳、沈越飞、井建宇、申屠欣欣\n本文由以上翻译团队经过两周的时间，在业余时间翻译完成，如果对本文有任何改进建议请发邮件到 martin AT DevOpsCoach.org\n发布本文的另外一个原因：作为历时6年，被称之为DevOps界之科学的调查研究，我们可以透过这套问卷，洞察如何用问卷的方式定量的度量DevOps的现状。对于已经实施了多年DevOps企业，本问卷可谓是一道营养丰富的大餐。\n历年来的DevOps状态报告 如果你需要下载学习的话，请点击下面的链接（扫码二维码），这里还有历年来英文版报告全集和部分中文版本。\n下面是2019年DevOps状态调查问卷的简体中文版译文。\n第一部分 欢迎参加2019年全球DevOps全球行业调查。\n我们有兴趣了解您的工作方式以及工作环境。 答案并没有对错。 如果您不知道答案，可以选择“我不知道或不适用”，您的作答将被忽略。 非常感谢您花时间帮助我们去探索那些能使技术进步的秘密！\n1. 您的组织主要属于哪个行业？ 教育 能源 金融服务 政府 医疗保健和制药 工业与制造业 保险 媒体/娱乐 非盈利 零售/消费品/电子商务 技术 电信 其他。请明确说明： [____] 2. 有多少员工在您的组织里工作？ 1-4 5-9 10-19 20-99 100-499 500-1,999 2,000-4,999 5,000-9,999 10,000+ 我不知道 3. 你们的服务器上都部署了哪些操作系统？ Windows 2003 / 2003R2 Windows 2008 / 2008R2 Windows 2012 / 2012R2 Windows 其他 Linux Debian / Ubuntu变种 Linux Enterprise Linux变体（RHEL，Oracle，CentOS） Linux Fedora Linux SUSE Linux Enterprise Server Linux OpenSUSE Linux Arch Linux其他 其他的UNIX FreeBSD / NetBSD / OpenBSD系统 AIX Solaris 其他 4. 在过去一年中，关于下列绩效指标，您的组织实现的程度如何？ 您组织的整体表现 您组织的整体盈利能力 主要产品的相对市场份额 客户数量增加 （表现远低于目标 表现低于目标 略低于目标 达到了目标 略高于目标 表现高于目标 表现远高于目标 不适用或我不知道）\n5. 我们也有兴趣了解其他一些目标。 选择指示您的组织在过去一年中如何针对以下目标执行的选项 产品或服务的数量 运营效率 消费者满意度 所提供的产品或服务的质量 实现组织的/使命的目标 通过其它的方面向外部各方证明了贵组织实现预期成果 （表现远低于目标 表现低于目标 略低于目标 达到了目标 略高于目标 表现高于目标 表现远高于目标 不适用或我不知道）\n6. 我们有兴趣了解DevOps或敏捷方法是怎样在您组织的各个团队中传播的。 在这里，我们将描述我们看到过的那些常见的模式，并要求您从中选择出哪些在自己的组织中最常见方式（请选择所有适用的选项）\n培训中心（有时也称为DOJO） - 让人们暂时脱离正常的工作惯例，以便在一段时间内学习新的工具或技术、实践甚至文化，然后再回到正常的工作环境中，目标（希望？）是：他们会坚持使用新的工作方式，甚至可能推广给其他的人。\n卓越中心 - 一个所有专业知识都具足，然后为内部各方提供咨询的地方。\n止步于概念证明 - 进行概念证明（PoC）项目，通常执行团队可以突破组织规范（通常是官方的规则）的羁绊，从而自由的按照所认为的最好的方式构建。然而，在PoC之后，那些付出就停滞不前了。\n用概念证明当模板 - 也是从小规模的概念证明（PoC）项目（如上所述）开始，然后开始使用这个最初的模式在组织中的其它团队进行复制。\n用概念证明做种子 - 也是从小规模的概念证明（PoC）开始，然后将PoC知识传播给其他团队。这是通过打散PoC（可以是第一个PoC团队，或是后续/并行的PoC团队）执行团队，并将他们派发到其他团队，去分享他们所学到的知识和实践的方式来完成的。也可以称此为轮岗，那些前PoC团队成员沉浸在其他团队中，发挥着传播新的实践和文化，并兼做导师的职责。他们可能会无限期地留在这个新的群体中，或者只是用足够长的时间来确保，他带来的新的做法是可持续的。\n实践社区 - 在组织内培养对工具、语言或方法有共同兴趣的团体，以便在他们的彼此之间、团队之间，以及在组织内部分享他们的知识和专业技能。\n大爆炸式 - 组织进行整体一次性的DevOps方法（当然他们要选择对其下的定义）转型，通常采用自上而下的指令。\n自下而上或草根方式 - 那些在一线工作的小团队将资源整合在一起，然后在整个组织中，通过非官方的形式分享所取得的成功，并进行推广，而无需任何组织官方的支持或资源。\n混搭型 - 组织实施过了上述的若干种方法，通常由于无法得到成功所需的资源和重视，只能是半途而废了。\n第二部分 这部分涉及您的工作及其成果，以及它对您自身的影响。\n1. 在你工作的过程中，你的感受是怎样的？ 请评价您对以下陈述的同意或不同意程度。\n我经常处于高水平的生产力 我经常能够进入一个良好的“流程”，在那里我可以完成复杂、耗时的任务，同时最大限度地减少干扰和中断。 我对我的工作很满意。 我有足够的工具和资源来完成我的工作。 我的工作很好地利用了我的技能和能力。 （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n2. 对于您工作的主要应用程序或服务，变更前置时间（即：从代码提交到在生产中成功运行的过程需要的时间）是多长？ 超过六个月 一个月到六个月之间 一周到一个月之间 一天到一周之间 不到一天 不到一个小时 我不知道或不适用 3. 对于您工作的主要应用程序或服务，您的组织在生产环境进行代码部署或向最终用户做发布的频率是什么？ 每六个月少于一次 每一到六个月一次 每周到每月一次 每天到每周一次 每小时到每天一次 按需（每天都要进行多次部署） 我不知道或不适用 4. 对于您工作的主要应用程序或服务，当服务中断或出现影响用户Bug时（如：计划外中断、服务受损），恢复服务通常需要多长时间？ 超过六个月 一个月到六个月之间 一周到一个月之间 一天到一周之间 一天之内 一小时之内 我不知道或不适用 5. 对于您所工作的主要应用程序或服务，对于生产变更，或向最终用户发版的变更，百分之多少会导致服务质量下降（如：服务受损或服务中断），并需要进行后续的修复工作（需要热补丁、回滚，前向修复，打补丁修复） 0％-15％ 16％-30％ 31％-45％ 46％-60％ 61％-75％ 76％-100％ 我不知道或不适用 6. 接下来的问题会询问可靠性，以及您和您的团队如何看待它。 请评价您对以下陈述的同意或不同意程度。 对于您所工作的主要应用程序或服务：\n定义了明确的可用性目标（如服务级别协议/服务级别目标），这些目标在团队和客户之间达成了清晰的共识。 我知道最近一段时间实际的可用性。 在最近一段时间内，我的团队达到或超过了可用性目标。 当我们未达成可用性目标时，就会进行改进工作，也或将对调整工作的优先级。 如果使用云服务，我的团队就会借助云计算的高可用性（如：使用多个可用区）来提高可靠性。 （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n7. 工作的可持续性很重要，而职场透支是一个相关的重要度量指标。您能否回答几个问题，让我们知道您的工作对您有何影响？ 请评价您对以下声明的同意或不同意程度：\n我感觉透支很严重。 我感到筋疲力尽。 我对所从事的工作无语或愤世嫉俗。 我觉得工作效率低下。 我觉得工作应对业余的正常生活产生负面影响。 我能够完成工作并保持良好的整体状态。 我能够有效应对与工作有关的压力。 我可以在业余时间中（即，当我选择不工作时）脱离工作。 （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n第三部分 当你回答以下问题的时候，请回想一下你在团队中的经历\n1. 请评价您对以下声明的同意或不同意程度 如果我对我们的团队犯了错误，也不会有不良影响。 我们团队的成员能够发现问题和提出棘手的问题。 我们团队的成员不会因为差异性而互相拒绝。 对我们的团队而言冒风险是安全的。 想让我们团队的其人提供帮助并不困难。 我们团队中没有人会以任何形式故意破坏我的工作成果。 团队非常重视我独特的技术和才能。 我们的团队能够在出现冲突时解决冲突。 我们团队内部有很高的信任度。 （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n2. 当你回答以下问题时，回想你是如何和你的团队合作的 请评价您对以下声明的同意或不同意程度：\n当我的团队成员之间存在相反的意见时，我们会互相尊重。 我可以依靠我的团队来产出高质量的成果。 我的团队提供了一个可以创新的环境。 我的团队有明确的角色和责任。 我的团队所承担的项目对我来说具有个人和专业意义。 我能够获得有效完成工作所需的必要的信息（例如，战略、新产品、组织变革，我们的优先事项和价值观）。 （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n3. 回想一下你的团队是如何工作和组织的 请评价您对以下陈述的同意或不同意程度。\n对于您使用的主要应用程序或服务：\n为了完成我自己的工作，我不需要与团队外的人沟通和协调。 在我的团队中，我们可以对系统的设计进行大规模更改，而无需为其他团队创建重要的工作。 在我的团队中，我们可以对系统的设计进行大规模更改，而不用依赖于其他团队的大量工作。 我的团队可以根据需要独立部署和发布我们的产品或服务，而不依赖于其依赖的其他服务。 我们可以按需的进行大部分的测试，而无需等待一个集成测试环境。 在我的团队中，我们在正常工作指端中执行部署，停机时间可忽略不计。 （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n4. 最后，我们想了解一下您的组织文化 请评价您对以下声明的同意或不同意程度：\n我的组织氛围宜人，重视各种不同的观点。 我的组织是一个所有类型的员工（例如，所有性别，种族，文化背景）都能够完全发挥其能力的地方。 当我在组织中发言时，我的意见很受重视。 （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n第四部分 这部分关于你所处环境中知识是如何供给和获取的。 让我们换个角度，告诉我们您的日常工作。\n1. 当您工作时，您会在哪里寻找信息？ 当我需要相关知识用于解决问题时，我会频繁访问外部信息（如Stack Overflow、百度等）。 当我遇到具有挑战性的问题，需要寻找类似问题的解决方案时，我经常访问外部信息 (如Stack Overflow、百度等)。 当我处理困难的任务时，我经常和可能遇到类似问题的人沟通。 当我需要工作相关主题或问题的知识时，我经常与其他人讨论。 在处理任务时，我经常会参考内部知识库或工具来帮助找到解决方案。 当我处理具有挑战性的问题时，我经常搜索内部工具或代码库以便找到类似问题或示例的解决方案。 当我有疑问或寻找代码示例时，我经常搜索组织的源代码库 当我有疑问或遇到有挑战的问题时，我会搜索内部文档 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n2. 当您遇到问题时，您会定期检查哪些信息来源？请选择所有适用项 内部(组织)知识库、论坛或文档 内部(组织)代码库 Stack Overflow 网站 在线教程和视频 百度、Bing或其它类似的公开搜索引擎 外部(公共)参考文档 当面请教同事 通过电子邮件、文本或聊天工具请教同事 朋友或同行(如微信、网络兴趣组、微博等) 您自己的个人笔记 其它。请填写 以上都不是 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n第五部分 这部分关于你的角色，以及你们团队做变更的特征和模式等。\n1. 现在让我们谈谈您工作时的感受 无论您的正式职位是什么，让我们谈谈您所做的工作。在您的日常工作中，您负责多少个不同的角色（或工作类型）？请选择所有适用项\n软件开发 测试 基础设施/运营 数据库管理 信息/应用安全 人员管理 项目或产品管理 文档 需求分析 用户体验 随时待命/事件响应 其它。请列出您执行的其他角色 2. 您每天在这些角色之间切换多少次？ 不想回应 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20或以上 3. 您现在正工作在多少个项目或产品上？ 不想回应 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20或以上 4. 您通常在一周中工作在多少个项目上？ 不想回应 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20或以上 5. 思考下你过去3个月的工作。 请以这些记忆里的工作对以下陈述进行回应 我遇到过的代码，脚本，配置或系统\u0026hellip;\u0026hellip;\n包含已知的错误，这些错误不支持新功能开发 没有足够的测试或测试覆盖率 与低下的代码质量或设计有关 取消或放弃项目后尚未进行清理 在我所在的团队中没有人有专业知识能够理解 有不完全或不正确的迁移 使用了过时的技术 文档和/或注释存在缺失、不完整或过时的情况 6. 现在思考在你的组织中的进行变更及相应流程是什么样的 在我的组织中\u0026hellip;\u0026hellip;\n在实施或部署之前，必须由外部机构（例如，变更审批委员会，经理等）批准生产变更 我的组织有一个正式的流程来批准在实施或发布之前对应用程序或生产系统进行变更。 我清楚地了解批准实施​​变更的流程 我相信我能够及时通过审批流程来实施变更 对于我通常所做的各类变更，我知道每次从“提交”到“已接受”所需的步骤。 我们依靠同事的同行评审（例如代码审查或结对编程）来管理或批准变更。 我的团队遵循基于风险的政策来批准变更，通过自动化方法推进低风险变更，只有高风险变更才需要人工批准。 所有重大变更必须在实施前由高级经理批准 第6部分 对于此页面上的问题，请思考你为测试生产系统的弹性所做的工作。\n1.以下哪些活动用于测试我们的IT系统/服务的弹性？ 未在真实系统上进行沙盘推演 基础设施（包括数据中心）故障转移 应用程序故障转移 模拟破坏类生产的测试系统（包括故障注入、如降级网络链路、关闭路由器等） 模拟破坏生产系统（包括故障注入，如降级网络链路，关闭路由器等） 创建自动化和系统，定期，持续地破坏生产系统 其他。 请明确说明： 以上都不是 2. 你所在的组织多久执行一次中断生产系统的模拟（包括故障注入，例如降级网络链路、关闭路由器等） 从不 仅在初次部署 按周 按月 按年 少于一年一次 不知道或不适用 3. 你所在的组织多久执行一次基础设施（包括数据中心）故障转移以测试弹性？ 从不 仅在初次部署 按周 按月 按年 少于一年一次 不知道或不适用 4. 你所在的组织多久执行一次应用程序故障转移以测试弹性？ 从不 仅在初次部署 按周 按月 按年 少于一年一次 不知道或不适用 5. 如果我的组织在灾备演习时发现了任何改进的机会，我们会创建行动任务并在下一次演习前修复这些改进项 非常同意 同意 有点同意 既不赞成也不反对 不太同意 不同意 强烈反对 不适用或我不知道 第七部分 此页将会询问您或您的组织关于云应用的一些问题\n1. 我主要负责的产品或服务在哪运行？（请选择所有适用的选项） 公有云（包含多个公有云） 私有云 混合云（将公有云和私有云/数据中心/本地设施结合在一起） 在数据中心或本地（不是云） 我桌面下的一个小服务器 其他 2.采用多个云提供商的驱动因素是什么？（请最多选择3个） 我们只有一个云提供商, 或者我们没有使用公有云 法律合规性 灾备可用性 对一个供应商缺乏信任 利用每个提供商的独特优势 谈判策略或采购要求 其他 3.请评价您对以下陈述同意或不同意的程度 我主要负责的产品或服务最初是设计在云中运行或基于云设计架构的。 对于我主要负责的产品或服务, 环境配置和部署仅使用存储在版本控制库中的脚本和信息, 无需手动步骤 (审批除外)。 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n4.请评价您使用云服务时对以下陈述的同意或不同意程度 一旦我有了访问权限, 我就可以根据需要独立地配置和配置产品或服务所需的云资源和功能, 而无需提高票证或需要人工交互。 我主要负责的服务或产品设计为通过网络从各种设备 (如智能手机、平板电脑、笔记本电脑) 访问, 而不需要专有插件或协议。 我的产品或服务所运行的云，服务于多个团队和应用程序, 并根据需要动态分配和重新分配计算和基础架构资源。 我可以根据需求动态地增加或减少可用于主要支持的服务或产品的云资源。 我可以监视或控制我主要支持的服务或产品所使用的云资源的数量和成本。 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n5.换个主题，在您工作的时候，您是怎样看待成本的？ 我的团队可以准确地估计操作我们软件的成本。 我的团队可以轻松识别我们运营成本最高的应用程序。 我的团队很少超出我们的成本费用或支出预算。 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n第八部分 关于版本控制系统、分支模型、自动化测试、持续集成、持续交付等一直到生产环境的反馈等等实践。 现在让我们谈谈您和您的团队所做的技术工作。\n1.请介绍一下您和您的团队如何开发软件。我的团队 我们的组织将所有代码存储在一个单一庞大的版本控制存储库中 组织中所有工程师都可以查看和搜索组织中所有代码 我可以在自己之外的项目中编辑代码，并适时提交 我们将应用程序的所有依赖项源代码（例如软件库）都存储到版本控制存储库中 我们为发行版本创建的所有包，包括依赖项，都是在单个版本控制中创建的，而不是从多个版本或分支中创建的 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n2.我们关注您工作中使用什么代码，请评价您对以下陈述同意或不同意程度 如果需要，我们很容易更改其他团队维护的代码 我很容易在代码库中找到示例 我经常从团队之外的工程师那里收到项目的更新。 我很容易重新使用别人的代码 我很容易对我的项目增加新的依赖项 我很容易移动新的依赖项版本 我的依赖项是稳定的很少破坏我的代码 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n3.我们关注您在工作中遵循的开发实践和模式 我团队中的所有开发人员至少每天都会将代码推送到trunk / master 应用程序的代码库中不到三个活动分支 我们的应用程序团队从来没有代码锁定期，任何时候没有人可以签入代码或由于合并配置而执行请求。 在合并到master之前，分支和分叉的生命周期非常短（不到一天）。 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n4.下一组问题是关于在工作中提交代码、搭建和部署软件 对于您使用的主要应用程序或服务：\n代码提交会自动生成软件 代码提交会运行一系列自动化测试 每天成功地执行自动化的构建和测试 当构建中断时，它通常在十分钟内修复 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n5.许多团队使用自动化测试来优化他们的软件 请评价您对以下陈述的同意或不同意程度 回答这些问题时，请考虑您自己的测试过程：\n当自动化测试通过时，我确信软件是可发布的 自动测试失败可能表明存在真正的缺陷 开发人员很容易重现和修复验收失败的测试 我们测试必要的数据，以便每一步都能轻松运行自动化测试 我可以在十分钟内从自动测试中得到反馈 我们经常使用之前的测试运行数据来提高自动化测试套件的质量 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n6.请评价您对以下陈述的同意或不同意程度 对于您使用的主要应用程序或服务：\n我们的软件在整个生命周期中都处于可部署状态 我的团队优先考虑保持软件可部署而不是处理新功能 团队中的任何人都可以获得系统在质量和可部署性方面的快速反馈 当人们得到系统不可部署的反馈时（例如构建或测试失败），他们将优先解决这些问题 我们可以根据需要随时将我们的系统部署到生产或最终用户 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n7. 请结合自己的测试过程回答以下问题 当通过自动化测试后，我相信软件是可发布的。 自动化测试失败表明存在真正的缺陷。 开发人员很容易重现并修复验收测试发现的缺陷。 我们有必要的测试数据，用于每个步骤中轻松地运行自动化测试。 我可以在10分钟内收到自动化测试反馈。 我们经常使用以前测试运行的数据来提高自动化测试套件的质量。 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n8. 对于您工作的主要应用或服务 我们的软件始终处于可部署的状态。 在我的团队中，保持软件处于可部署状态的优先级高于实现新需求。 任何团队成员都可以快速反馈系统的质量和可部署性。 团队成员将修复导致系统无法部署的问题（如编译失败、测试失败等）置于最高优先级。 我们可以随时根据需要将系统部署到生产环境或最终用户。 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n9. 对于您工作的主要应用或服务，实现完全自动化部署到生产环境或最终用户的比例是 0%-15% 16%-30% 31%-45% 46%-60% 61%-75% 76%-100% 我不知道或不适用 10. 对于您工作的主要应用或服务，部署过程需要多长时间才能使软件新版本可供用户使用 小于1小时 在1小时和1天之间 在1天和3天之间 在3天和1周之间 在1周和1个月之间 大于1个月 我不知道或不适用 11. 您如何监控和了解正在运行的系统 我的团队有一套技术解决方案用以报告系统的整体健康状况（如系统功能是否正常？系统是否有充足的可用资源等？）。 我的团队有一套技术解决方案用以报告基于用户使用情况的系统状态（如用户是否知道系统已关闭，是否有不良的体验等？）。 我的团队有一套技术解决方案用以监控主要业务和系统参数。 我的团队有工具用于协助我们了解和调试生产环境上的系统。 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n第九部分 这页面询问了一些细节关于您的技术环境和工作\n请选择以下之一\n1. 为了部署我们的软件解决方案，我的团队使用以下CI / CD /测试自动化工具链 主要是内部开发（自研）的，且所有权属于我的组织 混合使用专有工具，开源和商业现成软件 主要是开源和商用现货，高度定制 主要是开源和商用现货，很少定制 主要是商业现成的套装软件 主要是开源的，高度定制 主要是开源的，很少定制 其他 不适用或我不知道 2. 请评价您对以下说法的同意或不同意程度 在我的团队中，与组织中的其他团队相比，我们的CI/CD/自动化测试过程和工具是为我们的需求而定制的 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n3. 请评价您对以下说法的同意或不同意程度。 通过CI / CD工具链部署软件时 使用CI / CD工具链可以提高我的效率在我的工作中 使用CI / CD工具链在我的工作中提高我的生产力 使用Ci/CD工具链提高了我的工作效率 我发现CI / CD工具链在我的工作中很有用。 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n4. 请评价您对以下说法的同意或不同意程度。 通过CI / CD /测试自动化工具链部署软件时 我的交互在工具链是清晰易懂的 与工具链交互并不需要我的大量精力 我发现工具链容易使用 我发现容易让工具链做我想要做的事 (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n5. 选择最能代表谁负责创建和维护CI / CD /测试自动化工具链及其配置的选项 我们的团队有完全自治选择和配置自己的CI / CD /自动化测试的工具链。 我们需要使用一个统一工具链，但是我们为构建/测试/部署过程维护自己的脚本，并且在配置方式上有很多自主权。 我们需要使用一个统一工具链具有预配置脚本和构建步骤，测试和部署过程的步骤，我们可以根据需要重构或自定义。 我们需要使用带有预配置脚本和步骤的统一工具链，而我们几乎没有能力重构它 所有构建，测试和部署软件，都由我们建立的统一团队处理 不适用或我不知道 6. 我的工具链包括以下内容（请选择所有适用的选项） 自动化构建 自动化单元测试 自动化验收测试 自动化性能测试 自动安全测试 自动化配置和部署到测试环境 自动化部署到生产 与chatbots / Slack集成 与生产监控和可视化工具集成 以上都不是 第十部分 最后一页！请花几分钟时间告诉我们你自己。 请注意，此数据仅用于研究目的，此调查是匿名的，仅以匿名方式汇总报告。\n1. 你的性别？ 男 女 非二元 不想回应 2. 在您的团队中工作的女性比例是多少？ 请输入0到100之间的数字。\n女性团队的百分比： [___] 不想回应 3. 您是否认定为少数派群体的成员？ 是 没有 不想回应 4. 你认定是残疾人吗？ 包括与视觉，听觉，步行，记忆/集中，自我保健或沟通相关的残疾\n是 没有 不想回应 5. 哪个最贴切地描述了你的工作角色？ 开发或工程师 DevOps或SRE 信息安全 IT运营或基础设施 网络运营 产品管理 用户体验或软件分析 经理 专业服务 质量工程师或QA 发布工程师 销售工程师 销售或营销 我是顾问、教练或培训师 我是C级高管 我是学生 我不属于任何部门 其他 不想回答 6. 你有多少年的经验？ 0-2 3-5 6-10 11-15 超过16 不想回应 7. ­­­­­请选择您所在的地理区域 非洲 亚洲 中美洲 东欧洲 欧洲联盟 中东 北美 大洋洲 南美洲 加勒比 总结 本文是否帮你解答了这样一个疑问：每年的DevOps状态报告中的参考数据是从哪里来的？是通过什么方式采集的？到目前为止，我们还不清楚这些数据是通过什么打分规则和算法处理的。如果你是这方面的专家，请和我们分享以下你的观点。\n","date":"2019-05-06T12:27:16+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/2019-dora.png","permalink":"https://martinliu.cn/blog/2019-state-devops-survey-chinese-version/","title":"中文版：2019年DevOps状态调查问卷"},{"content":"2019年加速度DevOps状态调查首发，首发的位置在Google Cloud网站上的Blog栏目，发布于产品新闻分类下。\n文章使用的主标签 DevOps 、SRE。 文章地址：https://cloud.google.com/blog/products/devops-sre/make-your-voice-heard-take-the-2019-accelerate-state-of-devops-survey 关于今年的状态调查有什么更新和变化，文章中只给出了一句话的概况：今年会对部署工具链、云计算、灾难恢复和工作方式等主题进行深度调查。更详细的情况，详细你参与完问卷调查只有自由评判。\n如何参与2019年DevOps状态调查 点击这个链接 https://bit.ly/2UzLMH2 ，进入问卷调查网站。\n从围观到参与是一种积极的态度。与其观望这份行业报告的产生过程，倒不如参与其中。由于今年这个问卷调查是Google发起的，可能会有更多的人会参与。\n精通英文的人应该能在半个小时内完成这个调查。如果英文不好的话，最多也用不了2个小时，以上推测，基于我去年的填写经历。\n我还想发起一个基于这个调查的兴趣小组，请符合以下条件之一的人进微信群交流：\n正在认证填写这份问卷，想从群里获得必要的帮助，从而可以能正确的作答。 想研究这份文件的题库，大家共同分析DORA设问的目标和结构。 跟进一步的，交流关于DevOps度量方面的话题 关于2018年的DevOps状态报告 有幸去年策划和参与了这份报告的翻译工作。也算是相对其他人更深入的学习和研究了去年的结果。并对它的总结和推论都有非常深刻的印象，也受益匪浅。\n2018年DevOps状态调查报告的中文版本，在2018年DevOpsDays 深圳大会上做了发布，我也在台上和张乐一起向与会者做了简短的分享。如果你需要下载学习的话，请点击下面的链接（扫码二维码），这里还有历年来英文版报告全集和部分中文版本。\n在2018年里Nicole Forsgren博士发布了《Accelerate》这本书，书里算是对这场从2014年开始的，持续对年的行业专项调查研究的一个总结。书中对度量DevOps这个主题做了详解科学的解读，它是那些需要度量DevOps成果的组织的一本很好的参考书。中文版本据说在翻译的过程中，期待它的出版。等不及的话可以去国外买英文电子版，这本书我是读了不下三遍，也做了相关的分享演讲，确实有很多收获。\n分享几个我观察到的小细节：\nDORA在2018年结束了与Puppet公司的合作调查，因此2018年的报告标题中增加了一个单词“加速度”，即：2018 Acclerate State of DevOps Report； 以前的都叫做 xxxx年 State of DevOps Report。 Puppet公司也没有闲着，Puppet和Splunk公司携手也进行了状态调查和分析，也发布了名为《2018 State of DevOps Report》，问卷的问题肯定和以前无法延续和持续的，但是报告的命名保持下来了。我猜这也是为何DORA的报告需要加一个词的原因， 总结一下，由Nicole Forsgren博士主持进行的DevOps状态调查报告的下载站点都在 https://puppet.com/resources/whitepaper ， 在这里依然可以下载到名为 2018 State of DevOps Report 的报告，但是这一个和Nicole博士无关；所有她主持的报告下载地址在她的DORA网站上 https://devops-research.com/research.html 。 在DORA加入了Google Cloud以后，Nicole博士主持的调查问卷名为“ Accelerate State of DevOps Report” ； 相信我们所期待的最终的分析结果的标题应该是“ 2019 Accelerate State of DevOps Report” ； 而Puppet公司应该还是会持续发布名为“2019 State of DevOps Report”的报告。我相信肯定会有很多人在2018年去年就有点晕了，怎么出来两个名字相似，可是内容大相径庭的DevOps状态报告。\nDevOps背后的科学：访谈Nicole Forsgren 最近在Nicole Forsgren正式发布了2019年的DevOps状态调查报告之后，她接受了RealWorldDevOps电台的访问。Nicole Forsgren保持这一贯的爽朗、认真和理性的特点，与电台主播迈克进行了42分钟的畅谈。\n访谈英文原文：https://www.realworlddevops.com/episodes/the-science-behind-devops-with-dr-nicole-forsgren 在这个页面上还可以收听或者下载这期访谈节目。 英文原文的翻译版本（Google机器翻译，为修订）见下文。 访谈中的几个关键内容（并不是所有观点）： 2014年开始DevOps状态调查分析和报告工作 这项工作前期与Puppet公司合作进行 Nicole和Jez Humble建立了独立的DORA，即DevOps Research \u0026amp; Assessment公司 https://devops-research.com/ 2018年12月DORA被Google收购，Nicole加入Google后，Google将作为DORA的特别调查样本和支持公司，保持DORA持续进行。 Nicole叙述了最有意义的三件事：架构高于技术，云计算很重要，外包是不起作用的。 在这次访谈中，我们也可以听出一点关于这个行业调查的宗旨和调性。紧跟时代发展步伐，每年做一定的突破和更新，保持厂商/工具无关性等等。具体内容详见下面的机器翻译文字。\n访谈笔录 以下为电台网站英文版本的直接机器翻译，未做修订，不保证能够被人正确理解；有疑问的地方请参考英文原文和访谈音频。\n迈克朱利安：这是真实的世界DevOps播客，我是你的主持人迈克朱利安。我正准备在DevOps世界中遇到最有趣的人。从您喜爱的工具的创作者到精彩会议的组织者，以及出色的公共演讲者的伟大着作的作者，我想向您介绍我能找到的最有趣的人。\n迈克朱利安：啊，崩溃报道。经常被遗忘的一块坚实的监控策略。您是否很难复制您从用户那里听到的错误或难以捉摸的性能问题？你应该看看Raygun。无论你是负责网络应用程序还是移动应用程序，Raygun都可以在几分钟内轻松找到并诊断出问题，而不是你通常做的事情，如果你像我一样，请问最近的人，“嘿，是app适合你？“得到一个空白的凝视，因为嘿，这是星巴克，谁是一个奇怪的人提出有关移动应用程序性能的问题？无论如何，Raygun，我个人感谢他们帮助使这个播客成为可能。您可以访问raygun.com查看今天的免费试用版。\n迈克朱利安：嗨伙计们。我是Mike Julian，你是Real World DevOps Podcast的主持人。本周我的客人是Nicole Forsgren博士。您可能知道她是“加速：精益软件和DevOps的科学”一书的作者，或者可能是年度DevOps状态报告背后的研究员。当然，这不是全部。她也是最近被谷歌收购的DevOps研究和评估的创始人，他是管理信息系统和会计教授，同时也是一名性能工程师和系统管理员。说我很高兴与你交谈，这可能是一种轻描淡写。所以，欢迎来到节目。\nNicole Forsgren：谢谢。很高兴来到这里。我很高兴我们终于联系了。我们试图做多久了？\n迈克朱利安：几个月。我想我已经联系过你了，现在已经是三月了。我在11月份到达了，你说，“嗯，你知道，我还有其他的东西在继续，顺便说一句，我的公司被收购了。”\nNicole Forsgren：那么，那时候，我必须狡猾，对吧？我不得不说，“我有一个真正的大项目。我很抱歉。我们以后可以见面吗？”而且，上帝保佑，你是非常仁慈和善良的，你说，“当然 - ”\n迈克朱利安：谢谢你。\nNicole Forsgren：\u0026hellip;\u0026hellip;“我们以后可以聊聊。”然后我想你在说：“哦，恭喜你的\u0026rsquo;大项目\u0026rsquo;\u0026lsquo;之后给我发了一条消息。”我说，“谢谢。”\n迈克朱利安：听起来不错。\nNicole Forsgren：我很感激。是啊。然后，你再次伸出手，我说，“哦，我正在做另一个大项目。但是，这一次\u0026hellip;\u0026hellip;”\n迈克朱利安：这不是收购。\nNicole Forsgren：是的，这不是收购。这一次，这是一个正常的大项目，这是今年的DevOps状态报告。我们刚刚启动了调查，所以我非常兴奋，我们再次收集数据。\n迈克朱利安：所以我们可以解决这个问题，你在哪里可以找到DevOps状态报告？\nNicole Forsgren：所有DevOps状态报告都在DORA网站上发布。我们仍然有网站。我们所参与的所有报道，我想说我们从2014年开始，我已经很老了，我已经忘记了。我们完成的所有报告都是托管的。我们会在演出笔记中发布它们。如果你可以拿自己的健怡可乐或咖啡或茶或水，或者你想要波本威士忌。舒服。坐下来，大约需要25分钟。我知道，对，每个人都喜欢，“女孩，25分钟？”\n迈克朱利安：这是一项重大调查。\n妮可福斯格伦：我知道。它是。但这是因为DevOps状态报告是科学的，对吧？我们研究预测，而不仅仅是相关性。但请坐下来，舒服一点，让我知道做你的工作是什么感觉。因为今年我们正在挖掘其他一些东西;生产力，工具链，关于职业倦怠和幸福的额外事情，以及我们如何进入流动，以及真正的样子。还有一些非常棒的事情是，在以非常深思熟虑的方式进行调查之后，已经有很多人已经准备好了。顺便说一下，如果你有的话，我爱你们所有人。与同事分享，与同行分享。\n但是他们已经说过，仅仅通过参加调查，他们已经离开了，甚至在报告出来之前，他们已经走开了有关如何使他们的工作更好的非常有趣的想法和技巧和见解。\n迈克朱利安：是的，想到这一点很疯狂，参加调查的行为实际上改善了我的工作。因为我采取的大多数调查，我已经完成了，我想，“嗯，这有点浪费时间。”感觉就像我只是放弃了一堆东西而没有得到任何东西。\nNicole Forsgren：是的，我认为这种方式起作用的原因是因为我们对问题的处理方式非常谨慎，有时只是采取调查的行为可以帮助你思考你的工作方式。因此，采取某些问题的行为可以帮助人们思考他们正在做的事情。然后，当然，就像我开玩笑说，这是我的生活圈，调查将持续到5月3日，然后我将进入数据分析和报告撰写。我们预计报告本身将在8月中旬左右公布。\n迈克朱利安：嗯，为什么我们不退后几步说\u0026hellip;每个人都喜欢一个好的起源故事。很多年前，我相信你和我在一次LISA会面。您正在与Carolyn Rowland联合举办研讨会 -\nNicole Forsgren：哦，我喜欢Carolyn。\n迈克朱利安：是的，她也很精彩。我应该让她在这里。\n妮可福斯格伦：我的双胞胎。是。绝对。\n迈克朱利安：所以当我第一次见到你时你就是一名教授。我想，你知道教授在LISA上闲逛，并就如何理解商业价值给出了所有这些很好的建议，我认为这绝对令人着迷。教授，在DevOps世界中闲逛，这是怎么发生的？\nNicole Forsgren：哦，天哪。好的，有趣的是，我实际上是从工业开始的。我的第一份工作是在一个主框架上，编写医疗系统，然后编写财务系统。所以我是一名大型机程序员。然后支持我的主框架系统，对吧？这就是Ops中我们这么多人在Ops中开始的原因，有人说，“好吧，有人必须这样做。”对？我还在学校，然后我最终成为DEV，对吗？我在IBM担任软件工程师已有好几年了，然后转向学术界。我得到了博士学位，在那里我开始询问有关如何分析系统的问题，所以我实际上在做NLP，自然语言处理。\n迈克朱利安：很有意思。\nNicole Forsgren：是的，我在做\u0026hellip;\u0026hellip;\n迈克朱利安：是的，这是一个奇怪的切入点。绝对不是我所期望的。\nNicole Forsgren：是的，所以疯狂的事情，我的第一年实际上是欺骗检测。\n迈克朱利安：我打赌这太棒了。\nNicole Forsgren：这真的很有趣，非常有趣。但是我从系统工作中充分利用了我的背景，对吧？因为我们做什么？我们分析日志系统。\n迈克朱利安：对。\n妮可福斯格伦：对吗？我们习惯于以凌乱的格式分析大量数据，很多时候基于文本，超级嘈杂，不能总是信任它，对吧？现在人们都说，“我不相信调查。人们撒谎。”孩子们，我们的系统也是如此。\n迈克朱利安：一直以来。\n妮可福斯格伦：对吗？所以，他们喜欢我的一大堆这项工作。突然间，我随机对系统管理员进行了可用性研究。我们写了结果，把它们还给了IBM，IBM就像是，“你的意思是什么？我们遵循UCD指南，用户中心设计指南。这应该是适用的。”我就像是，“等等，哇哇哇哇哇哇哇哇哇哇哇哇哇哇\n当时，他们为所有用户提供了一套UCD指南。超级先进，高级别的高级系统管理员，他们正在做备份，灾难恢复，一切。那些买过笔记本电脑并且在生命中第一次使用电子邮件的人。\n迈克朱利安：我确信那个过得很好。\n妮可福斯格伦：什么？我想，“就是这样。改变我的论文。”当然，这让我的顾问惊慌失措。他们就像是，“你会去做什么？”所以我开始做什么，当时是DevOps的基础。那是什么，你如何理解和预测信息系统？通过信息系统，技术，自动化，使用和预测，然后是团队，组织层面的个人团队的结果和影响。\n现在，我说了所有这些，那是大词，这是学术用语，基本上是什么是DevOps。我如何理解人们何时使用自动化和流程以及工具和文化，以及我如何知道它汇总起来以产生影响并增加价值？现在我们就像，“哦，那是DevOps。”\n这是2007年末。\n迈克朱利安：哦，哇。所以你和我们在一起很早。\nNicole Forsgren：是的。这是一个非常有趣的平行轨道，因为现在我们回顾过去，我们就像，大约10年前。这与DevOps同时是新生的起源，对吧？所以，我们这么多人在同一时间偶然发现了它。我不知道这是在工业中发生的事情。我一直在偷偷摸摸，我一直这样做，偶然发现LISA，试图连接数据，当然，就像每个好学者一样。拼命想找到数据。\n偶然发现，撞到了一个收集类似东西但使用不同粗糙方法的小组。一个来自一个可爱的小配置管理创业公司的团队叫做Puppet，对吧？开始与他们合作，邀请自己参与该项目。上帝保佑他们，我对他们有如此多的爱和尊重，因为他们基本上让这个随机的，随机的学术撕裂他们的研究并重做它并亲切地告诉我以前从未见过的这两个家伙，在电话中，名叫Jean和Jez，他们做错了什么，他们使用的这个词不是正确的词。 Redid，在2013年末，DevOps状态报告，使其在学术上严谨，然后，持续了几年，对吗？然后突然间，我们在几年后重新编写了一堆东西。\n我离开学术界，离开即将任职的地方，去另一个可爱的小配置管理创业公司Chef，这很有趣，对吗？因此，我正在与Puppet合作，为Chef工作，并继续研究并与组织和公司合作。我离开了学术界，因为我看到这个疯狂的DevOps事情有所作为。但是在学术界，他们还没有完全掌握它。而且我想确保我可以做出更大的改变，因为我在98,99,2000开始在大学的科技工作;我们举起这个疯狂的网络泡沫破灭。\n它不是一场萧条，因为一切都崩溃了，世界就像人们想象的那样结束了，但公司失败了，它对人们的遭遇产生了巨大的影响和影响。他们失去了工作，打破了家庭，他们感到沮丧，影响了他们的生活，有些人正在自杀。而且我非常担心当我们再次击中这一波时会发生什么，我们又开始看到那次击中。那么，如果公司和组织不了解制造技术的智能方法会发生什么，因为你不能只是让人们不顾问题，或者让同样的人陷入困境。当我说同样的人扔我的意思时，七天强行游行。\n当他们让我们这样做时，我在IBM，对吗？他们陷入集体诉讼，你不能这样做。这不是一种生活方式。\n迈克朱利安：是的，我参与其中很多，他们是残酷的。而且它们没有任何有用的结果。\nNicole Forsgren：这只是破碎的心灵和破碎的生命，对吧？所以，有些人喜欢说，你真的关心这个。我只是这个书呆子的学者，他只关心我做的事情。因此，如果我们真的可以，从根本上改变人们制作软件的方式，因为如果它实际上实际上，从根本上改善了他们的生活\u0026hellip;\u0026hellip;让我们这样做。\n然后，感谢上帝，我们发现它确实存在。当然，它很好地为企业提供价值，但这很重要，因为那时它的作用是帮助他们做出更明智的投资，因为这样可以减少倦怠。它让人们更快乐，让他们的生活更美好，我认为这是重要的部分。\n迈克朱利安：所以你发现的是，一家公司实施所有这些更好的持续部署实践，更快的交付时间，更快的价值实现\u0026hellip;\u0026hellip;它使人们的生活更好地完成了工作？\nNicole Forsgren：是的，John Shook也发现了这一点。对？他在精益中做了这项伟大的工作，为了改变\u0026hellip;有些人说，“你如何改变文化？”让我们找到改变文化的方法。有时，改变文化的最佳方式是改变你的工作方式，我相信我们已经看到了自己，对吗？在我们生活的其他方面。改变我们的感受，改变家庭的工作方式，改变我们的关系工作方式。你实际上改变了你的生活经历，或者你生活经历的某些方面。\n因此，如果我们改变我们制作软件的方式，我们将改变我们团队的运作方式，这正在改变文化的方式。换句话说，如果我们可以告诉我们的组织在技术和流程方面做出哪些明智的投资，那么我们也可以改善文化。我们也可以改变人们的生活吧？微软Bing团队发现了这个，对吧？他们希望在持续交付方面进行明智的投资。\n在一年之内，他们看到了工作生涯的分数，我将其从头脑中拉下来，但我想说它从38％上升到75％。那太大了。\n迈克朱利安：这是一个令人难以置信的跳跃。\n妮可福斯格伦：对。这是因为人们能够在工作中离开工作然后回家。你可以去看你的家人，你可以去看电影，你可以去吃饭，你可以有爱好，或者你可以去狂欢看格雷的解剖。你可以做你想做的。\n迈克朱利安：这对我来说最令人难以置信的事情之一是，为了让公司取得成功，他们必须推动员工，让他们通过振铃器。直观地说，这是永远不会正确的。而你实际上有数据表明这是不对的。做这些事实上让每个人都变得更好。业务得到了显着改善，人们的生活得到了极大的改善，而且一切都很棒。\nNicole Forsgren：是的，如果我们想要推动人们，这是不可持续的。如果有的话，我们希望推动人们做他们擅长的事情，我们希望利用自动化来实现自动化擅长的事情。那是什么意思呢？\n我们希望让人们做有创意，创新，新颖的事情。让我们让人们解决问题，让自动化做我们需要的一致性，可靠性，可重复性，可自动性。让我们不要让人敲打锤子并不断进行手动测试。让我们让人们弄清楚如何解决问题，做一两次以确保这是正确的事情，自动化，将其委托给自动化，机器和工具，交付，完成，然后拉人回到循环中进入循环，找出新的东西。\n我认为是Jesse Purcell说：“我想让自己不断自动化。”对？使自己脱离当前的工作，然后找到一份新工作，让自己再次自动化。我们永远不会失业。\nMike Julian：是的，当我第一次开始使用DevOps时，我常常担心这一点，实际上，当我第一次开始自动化时，当时并不是DevOps，它是在大学中自动化Windows桌面部署。这是在21世纪初。我最大的担忧之一是，因为我花了半个星期的时间来做这件事，如果我要自动化，我会花一个小时做这个，剩下的时间我会做什么呢？他们只是要解雇我，因为他们不再需要我了。\n事实证明，不，这根本不是发生的事情。更高的工作价值变得有效，因为我并没有那么专注于辛劳。\nNicole Forsgren：对，那些类型的东西，机器和电脑都做不到。而另一件事，我曾经告诉我的所有朋友，在工作保障方面不考虑这一点，对吧？不要试图将自己描绘成一个别人无法做到的事情，因为那样你就无法被替换，因为这也意味着你永远无法得到晋升。\n如果我们始终确保工作的某些方面可以实现自动化，以便我们有机会获得新工作，那么这只会为创造更多的事物创造更多机会。总会有问题，我们总有一些问题需要解决。我不想被困在做无聊的工作。\n迈克朱利安：是的，上帝知道这是事实。\n妮可福斯格伦：哦，天哪，我知道。我不想被困在做无聊，重复的工作。这简直令人头痛。如果我们能找到，特别是真正具有挑战性的复杂事物，如果我们能找到自动化的方法，相信我，我们永远不会把自己挖到那个洞的底部。那总是存在的。\nMike Julian：所以我想谈谈DevOps状态报告，我想先问一个你之前提到过的问题。你提到这句话，学术严谨。那是什么意思？\nNicole Forsgren：学术严谨包括一些事情，好吗？因此学术严谨的一部分是研究设计。所以这不只是在回答一堆问题\u0026hellip;\u0026hellip;对不起，yolo是我的简写，“你的方法论是有问题的。”\n迈克朱利安：我最近看到很多调查结果出来了。\nNicole Forsgren：是的。所以一个是研究设计。有人说，“妮可，研究设计是什么意思？”那么研究设计是，您要求的问题类型是否与您用于收集数据的方法相匹配？对？这些东西是否匹配？对于某些事情，调查是恰当的。一次，所以一次是横截面，一个时间跨整个行业的调查。有些事情适合。有些事情不适合。\n一个很好的例子，很多人真的希望我在DevOps状态报告中做开放空间和问题。\n迈克朱利安：这是什么意思？喜欢开放式问题？\nNicole Forsgren：不，开放空间。所以很多人对开放式办公空间有很多感觉。我应该在开放的办公空间工作吗？开放办公空间会影响生产力吗？或配对编程\u0026hellip;\u0026hellip;配对编程会影响生产力吗？配对编程会影响质量吗？人们对这些事情有很多感觉。在DevOps状态报告中使用的研究设计类型是一个完全匿名部署的调查，在整个行业中的单个时间点，并不适合回答其中任何一个问题的研究设计。\n迈克朱利安：那是为什么？\nNicole Forsgren：因为您需要做的是拥有更加可控的研究设计。所以我需要知道，例如，你和谁一起工作。我需要知道，所以让我们继续进行同行评审，我需要知道你正在处理的问题类型，代码问题的类型，我现在需要问题的复杂性，我需要知道它花了多长时间，对吧？如果你现在想要提高生产力，对吧？因为我需要了解一定的生产力。我需要知道结果是什么。因此，如果我的结果是生产力，我需要衡量生产力，因为我需要控制困惑，对吧？因为事情比较复杂，我们希望花更长的时间。那些不那么复杂的东西，我希望不会那么久，对吧？\n然后我需要匹配和控制。对？甚至像开放式办公空间这样的东西，对吧？因为如果你在一个开放的办公空间而不是一个开放的办公空间进行同行编程，如果你在办公室里这样做，我需要知道这个人的资历，或者一些资历代理。我现在需要你如何配对，你是否与你的近似经验水平的人配对，如果不是资历经验水平。我需要知道配对编程是如何工作的，我需要知道所涉及的技术，我需要知道你是否偏远，或者你是否真的坐在一起。我需要知道你是否能够同时输入文本，或者是否有人插入而另一个人没有。\n因此，当我进行比较时，我知道比较是什么样的。\n迈克朱利安：这是一个令人难以置信的信息量。我没想到你必须知道这么多才能从中得到一个好的答案。\nNicole Forsgren：这不是我的头脑。是的，因为你问了我一个很好的问题，我吐了一口气。这只是研究设计，然后你继续分析，对吗？当您继续进行分析时，我们需要了解您提出的问题类型。这些类型的问题，我们是否在考虑相关性？我们在看预测吗？我们在考虑因果关系吗？我们提供哪些类型的数据以及适合哪种类型的分析和问题？\n同样，他们需要以正确的方式匹配。某些类型的数据不适用于某些类型的分析或问题。所以你真的需要确保每一个都适合于正确类型的东西。对？某些类型的分析，如机械，调查问题，永远不适合机械分析，对吧？虽然，老实说，没有人会做机械分析。从来没有，顺便说一句，如果有人来找我并说他们正在做机械分析，我会坐下来非常专心地听你的，非常感兴趣，因为我认为没有人在做机械\u0026hellip;\u0026hellip;这不是一个事情。\n迈克朱利安：所以当你分析调查结果时，我们看到的是一个问题，然后是另一个问题，接下来是另一个问题，你知道数百个问题。当您分析这些内容时，您是在一次查看问题，还是在查看多个问题，然后根据您在几个不同问题中看到的内容来解释答案？\nNicole Forsgren：所以当我写完结果时，当我写这份报告时，我正在写出我的分析结果，而我的分析正在考虑一个非常非常仔细的研究设计。现在意味着什么，我的研究设计经过精心构建，以尽量减少误解。它试图尽量减少答案中的漂移。所以，我们这样做的一种方式，这在加速的第二部分中概述，如果有任何想要阅读的统计数据书呆子，我们做的事情称为潜在结构。\n所以，你问过只有几个问题或几个问题。我提到过，我们这样做的一种方式称为潜在构造。如果我想问你关于文化的话，我可以向10个人询问文化，我会得到15个答案。因为文化可能意味着许多不同的事情，对吗？一般来说，当我们在DevOps环境中谈论文化时，我们倾向于得到一些东西\u0026hellip;\u0026hellip;人们会说非常常见的事情，如打破孤岛，拥有良好的信任，拥有新奇，对吧？\n因此，我们所做的是从定义开始，然后我们将提出几个项目，问题，捕获每个维度。所以你可能想要考虑一个涂料维恩图，其中每个问题都被覆盖，然后是所有他们拥有最大或完美覆盖的东西，它们是中心，那个小坚果，这就是构造是什么。这就是文化，即文化所代表的。\n然后每个圈子都是问题。这就是我们在研究设计中所做的。研究设计的一部分。当我进入统计分析模式时，我会考虑所有问题，所有项目，不仅仅是文化，而是我正在考虑的每一件事。因此，在过去的几年里，我已经完成了监视可观察性，我已经完成了CI，我已经完成了自动化测试，我已经完成了版本控制，我已经完成了所有这些工作，并且我将所有这些都扔进了漏斗，对？\n迈克朱利安：我敢肯定，这可能是你庞大的Excel电子表格。\nNicole Forsgren：不，这是SPSS。我使用SPSS但您可以使用几种不同的统计工具。我们做主成分分析。而我们所做的就是它们如何加载？基本上，他们如何组合在一起，我们是否具有收敛有效性？它们会聚合吗？他们只测量他们应该测量的东西吗？我们是否有判别有效性？他们不衡量他们不应该衡量的东西吗？我们有可靠性吗？每个阅读这些问题的人都会以非常相似的方式阅读吗？\n一旦我们掌握了所有这些，并且对所有这些事情进行了几次统计测试，那么我说，“好的，这些项目，通常是三到五项，所有这些项目都是文化，”或“所有这些项目一起是CI，“或”所有这些，正确的这些项目分组，代表了这一点。“好的，现在，现在，我可以开始查看关联，预测或其他内容，然后我会看到报告，现在我只想谈谈文化。\n所以我把它作为一件事情谈论，但实际上是几件事，然后当我谈到文化时，我可以说，“这就是文化是什么”，我可以用这种细微的，多维的方式谈论它，我知道那些维度是什么，因为它由三到五，六到七个问题组成，顺便说一下，如果其中一个问题不合适，因为我从统计分析中知道，我可以抛弃它，我知道为什么。我总是有几件事。如果您只有一个问题或者您只有两个问题，那就是风险。如果其中一个不起作用，哪一个是错误的？你不知道。对？因为，是A还是B？我不知道。\n至少如果我从三开始，一个失败，那么它可能是好的两个。\n迈克朱利安：是的。这里的许多听众已经采取了很多由营销组织进行的调查，除了调查也是由营销人员设计的\u0026hellip;\nNicole Forsgren：他们是由想要特定答案的人设计的。\n迈克朱利安：没错。\nNicole Forsgren：这就是挑战。\n迈克朱利安：是的，然而，为了清楚地说明，DevOps状态报告根本就不是这样。正如你所说，有很多东西都是严格的。\nNicole Forsgren：好的一点是，我们一直是供应商和工具无关的。\n迈克朱利安：你不是在寻找一个非常特别的答案，你想知道实际上是什么。\nNicole Forsgren：我们并不是在寻找产品的答案。那么，在CI的例子中，什么是CI？我不关心工具。我说，如果你正在做CI，如果你正在进行CI，持续集成，以一种预测智能结果的方式，你将拥有这四样东西。其中的力量是，任何人都可以回过头来看待这个评估工具。如果您是经理，领导者或开发人员，您可以说，“我使用的任何工具，世界上的任何工具，我应该寻找这四件事”，或“我自己构建的任何工具，或者如果我正在做CI，我应该有这四件事。“\n如果你是一个供应商，你应该说，“如果我认为我正在建立或销售CI，我最好有这四件事。对吗？这就是伟大的事情，我必须说，上帝保佑我的新团队。他们让我以同样的方式运行它。它仍然是相同的。它仍然是供应商和工具无关，它仍然是能力集中。你寻找的每一件事，无论是自动化或流程，文化或结果，它的供应商和工具不可知，它的能力集中，再次，权力是你可以用它作为一个评估工具。\n我的团队是这样做的吗？我的工具是这样做的吗？我的技术是这样做的吗？我能做到吗？如果我不是，我的弱点是什么？我的约束是什么？因为如果我把我们带回到开头，是什么驱使我和DORA团队，那么我们想要摆脱这一点是什么？我们想让事情变得更好。我们该怎么做？我们可以为人们提供简单的评估标准。而且我并不是说这很容易，因为所有这些都很简单，需要工作。但如果有明确的评估标准，我们就有了可以去的地方。\nMike Julian：因为我知道你喜欢谈论你几年来所做的事情。您提出了哪些最有趣的结果？\nNicole Forsgren：哦，有很多好的。\n迈克朱利安：让我们选择你的前三名。\nNicole Forsgren：好的，我认为我的最爱之一是，我会用俗气的营销方式来做\u0026hellip;\n迈克朱利安：请接受。我们已经做好了准备。\nNicole Forsgren：有一个小创业公司并且不得不假装它作为营销人员一分钟的人，我们将看到我在这方面做了什么。\n架构很重要，而不是技术没有。第一。好的。那是什么意思呢？这意味着，我们发现如果您以正确的方式构建它，您的架构结果会比您的技术堆栈产生更大的影响。所以架构成果，一些关键问题是：我可以测试吗？我可以部署吗？我可以建立没有细粒度的沟通和协调吗？\n迈克朱利安：细粒度意味着什么？\nNicole Forsgren：我是否必须与他人见面并一起工作并征用一些东西，我是否需要开辟一些疯狂的新测试环境，还是必须获得17个不同团队的批准？请注意，我刚刚提到过团队。沟通和协调可能是技术限制，也可能是人的限制。这让人很难回到康威定律。\n迈克朱利安：我最喜欢的法律之一。\n妮可福斯格伦：对吗？这是一个DevOp的事情。但是，这是真的。无论我们的沟通模式如何，我们通常最终会融入我们的技术。现在，我将说这在云和云原生环境中通常更容易实现，但它也可以在Legacy和Mainframe环境中完全实现。我们没有看到前几年布朗菲尔德和格林菲尔德受访者之间存在统计学上的显着差异。\n迈克朱利安：很高兴知道。\nNicole Forsgren：是的，我喜欢那个。那个人很有趣。\n好的，第二个。云很重要，但只有你做得对。\n迈克朱利安：噢，这意味着什么？\nNicole Forsgren：Dun dun duh。所以，这是我最喜欢的统计数据之一。我们发现，如果您正在执行所有五个重要的云特征，那么您成为精英表演者的可能性要高23倍。根据美国国家标准技术研究院（NIST）的说法，我想你可以说你是否正在完成云计算的所有五个基本特征。所以我没有提出这个，这来自NIST，好吗？\n所以它很有趣，因为我们询问了很多人是否在云端。他们就像，当然我们在云端，我们完全在云端，对吗？但只有22％的人正在做五件事。那这五个是什么？所以这五个是按需自助服务。您可以在没有人工干预的情况下配置资源，如果您必须填写一张票并等待一个人办票，这不算数。没有积分。\n另一个是广泛的网络访问。因此，您可以通过任何类型的平台访问您的云端内容;手机，平板电脑，笔记本电脑，工作站。大多数人都非常擅长这一点。另一个是资源池，因此可以根据需要动态分配和重新分配资源。另一个是快速弹性，对，爆裂魔法。我们通常都知道这个。\n现在最后一个是测量服务。所以我们只支付我们使用的费用。因此，最常查看的通常是广泛的网络访问和按需自助服务。\n迈克朱利安：是的，有趣的是，对我来说，那里没有任何东西阻止，比如说，从排位赛开始的内部开放堆栈集群。\nNicole Forsgren：没错，对。所以这可能是私有云。我爱你指出了这一点。之所以如此重要的原因是，它只是归结为执行。它可以完成，另一个挑战是组织，管理人员或董事会经常说你必须去云，所以有人说，“哦，是的，我们要去云端。”但后来有人重新定义了云中的意义。对？所以，你到达那里，有人检查他们的小盒子，把金星放在某人的图表上，他们走开了，他们就像是，“好吧，我们没有看到任何好处。”好吧，是的，因为你没有这样做。\n迈克朱利安：对。是的。\nNicole Forsgren：就像是，“我买了一个健身房会员，我已经完成了。”不，再说一遍，我不是说这很容易，对吧？有一些工作涉及。现在我喜欢的另一件事是，让我们说你不在云端，由于某种原因你必须留在Legacy环境中，你可以看看这五件事你可以尽可能多地实现，你仍然可以实现利益。\n迈克朱利安：对。这不是一个全有或全无的方法。你可以做其中的一些，并从中获得很多好处。\nNicole Forsgren：这几乎就像一个骗子回到了第一，这是建筑问题，技术没有。我怎么能做一个备忘单，看看如何到达那里的一些非常好的技巧？\n迈克朱利安：那你的三号是什么？\nNicole Forsgren：我的第三个可能是，外包不起作用。\n迈克朱利安：是的。\nNicole Forsgren：有些人讨厌我，他们从他们的眼睛射出激光束。所以我们说外包不起作用*。\n迈克朱利安：好的，什么是星号？\nNicole Forsgren：Asterisk，星号将是功能性外包不起作用。\n迈克朱利安：好的，所以说外包我的待命职责，可能不会那么好用。\nNicole Forsgren：拿走所有的DEV，把它运走。全部采用TEST，将其运走。拿走所有OPS，运送它。现在，为什么呢？因为那样，你们所做的一切都是另一套交接，你们创造了另一个孤岛。你还批量完成了大量的工作，而你却让每个人都等待这种情况发生。目标是创造价值而不是让人们等待。如果现在每个人都必须等待所有东西回来，如果你正在做高价值的工作等待低价值的工作，因为它必须回到一起，这通常是它的工作方式，你是骨头。\n现在，功能外包。如果您有一个与您合作并与您协调并以相同的节奏交付的外包合作伙伴，那么这不是功能性外包。那是星号。\n迈克朱利安：好的，有问题。\nNicole Forsgren：另外，如果他们是你的团队的一部分，他们是你公司的一部分，但他们基本上一次消失了三个月。对不起孩子，这是功能外包。我没有任何积分，愿上帝怜悯你的灵魂。这没用。\n迈克朱利安：对。在我看来，你怎么知道你是否处于这种困境中，如果你的团队和你给这些项目的人之间有明显的交接，你就有功能外包。那会是对的吗？\nNicole Forsgren：是的，特别是如果有一个明显的手，然后是一个黑盒子的神秘。\n迈克朱利安：就像，工作是如何完成的？\nNicole Forsgren：第一步，第二步，问号，第三步：获利。\n迈克朱利安：也许吧。所以前两个，这一切都很好，因为我们可以看到从哪里去，但第三个实际上看起来有点困难，因为如果我是一个系统管理员，我完全无法控制这个功能外包。我可能也讨厌它，我可能自己讨厌它，但我对它没有任何控制权。我可以做什么作为系统管理员，或操作员，开发人员，我该如何改善这种情况？\n妮可福斯格伦：所以一些想法可能包括一些事情，看看是否有任何方法可以改善过渡期间的沟通或节奏。对？您可能仍然拥有该外包合作伙伴，因为这就是它的方式。但是，假设您已经以三个月的增量进行了工作，有没有办法将切换增加到每月一次？有没有什么方法可以让我们知道我们知道我们导入的功能，小批量工作，只是增加切换？有什么方法可以将它们整合到我们的节奏中，融入我们的团队吗？\n现在我意识到这里有一些挑战，因为从法律的角度来看，我们不能像我们的团队那样对待他们，因为那时，至少从美国的角度来看，一旦我们像对待员工那样对待他们，那么我们就要对就业税负责以及所有其他合法的东西。但是，如果我们能够将它们整合到我们的工作节奏中，或者更接近我们的工作节奏，那么我们的结果就会得到改善。\n迈克朱利安：好的，很酷。这更有意义。这听起来并不像我担心的那么难。\nNicole Forsgren：所以它可以开始减少节奏的延迟，要求稍微更清楚地了解正在发生的事情，如果它是一个完整的黑盒子，那就是寻找它。\n迈克朱利安：妮可，这绝对是太棒了。非常感谢你加入我。我有两个最后的问题。人们在哪里可以找到这个DevOps状态报告来进行调查？调查在哪里？\nNicole Forsgren：哦，我们已经发布了调查结果。我可以将它包含在演出笔记中吗？\n迈克朱利安：当然。好的，大家，查看链接的节目说明。我的最后一个问题是除了这项调查之外，人们可以在哪里找到更多关于你和你的工作的信息？\nNicole Forsgren：我有几个地方。所以我自己的网站是在nicolefv.com，我总是在Twitter上，通常谈论冰淇淋和健怡可乐，那是@nicolefv。\n迈克朱利安：我确实爱你Twitter推特。这是我的最爱之一。\nNicole Forsgren：是的，每个人都来打个招呼。我的DM是开放的。\n迈克朱利安：我最喜欢你的Twitter提要大概是在你写报告的时候，说：“天哪，我为什么要这样做？”\nNicole Forsgren：是的，我试着把它锁起来，但每隔一段时间就会有什么东西会滑落，比如“哦，我的天哪，一件好事正在发生”，或者“哦，我忘记了这一件事”，或“那么多好事正在发生。“\n迈克朱利安：是的，我记得去年就像，“哦，我的上帝，这太酷了，但我无法告诉你。”\n","date":"2019-04-20T22:27:16+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/abstract-4.jpg","permalink":"https://martinliu.cn/blog/2019-state-devops-survey-open/","title":"2019年DevOps状态调查问卷开放中"},{"content":"本文汇聚了来自3个网站的预测文章，他们分别是XebiaLabs、G20Group和Veritis。在总共22项预测中，个别预测是相同的。DevOps是一个持续进化和发展的过程，同时也受到目前各种新技术的影响。\nXebiaLabs的7个预测 英文原文： https://blog.xebialabs.com/2019/01/10/7-predictions-for-devops-in-2019/\n1. 持续集将成作为流水线的重要代办事项 如果企业希望提高团队用在功能开发上的可用时间，从而加速向生产环境中交付的话，那么在整个DevOps流水线中，引进持续集成CI部分将成为高优先级且重要的事项。监控CI流水线相关的数据、活动和流程的能力将变得非常重要，这样可以使发布流程中的所有人都能看到最新的流程状态，从而减少开发人员花费在无关任务上的时间。 【来自：XebiaLabs产品开发副总裁Andreas Prins】\n2. 价值流映射将被广泛使用 目前，随着软件交付的速度和质量正成为大型企业的巨大竞争优势，越来越多的组织将会探索价值流映射（Value stream mapping）的使用方式，从而确保他们的软件开发是和整体业务价值保持一致的。这种转变将会减少软件发布流水线中的浪费，并创建出更强大的跨职能团队协作。【来自：Lisa Wells，XebiaLabs产品营销副总裁】\n3. 实时挖掘软件交付流水线所产生的数据 在2019年，IT部门通过软件持续不断创造业务价值的压力将会越来越高。因此，组织将用各种方法挖掘在软件交付流程中大量的由机器所生成的数据，而不只是在事后才进行分析，甚至还包括DevOps的可预测性。这样才能够更好地预测软件交付流程和基础架构中所发生的问题，而这些问题可能对应用程序的质量和安全性产生负面影响，可能会使产品上市时间延期。【来自： Lisa Wells，XebiaLabs产品营销副总裁】\n4. 在人和流程中培养责任共但文化 DevOps同时关乎于人、流程和工具。对于任何DevOps实施计划而言，需要将人和流程视为首要的交付价值的因素。在2019年，我们将看到企业会越来越重视培养承担责任的文化，团队在复杂的应用程序交付流水线中共同承担质量和效率的责任。各个团队需要及时了解协作和进度。关键是在项目的进展过程中，及时的与整个公司分享那些取得了成功的措施和及其成果。除了证明他们的努力能够带来重大成果之外，毕竟，也没有什么比这种方式更能激励团队的了。【来自：T.J. Randall，客户成功副总裁，XebiaLabs】\n5. 自服务部署将成为主流 随着自动化部署已经成为企业的标准实践，随着组织逐渐地意识到可以将信息安全和合规性也融入到他们的交付流程中，在2019年，自助服务式部署会成为主流的工作实践。【来自：T.J. Randall，客户成功副总裁，XebiaLabs】\n6. 建立自己的DevOps能力度量组合 随着DevOps的投资增加，管理层将需要更多的投资回报率证据。团队需要建立他们基于全局测量（不仅仅是单个团队或个人）和结果（具有速度和稳定性的软件交付）的组合来测量DevOps（DevOps Intelligence）的能力。【来自：Vincent Lussenburg，DevOps战略总监，XebiaLabs】\n7. DevSecOps融入到DevOps流程中 对信息安全“前置（左移）”的需求将会在DevOps实践中得到更好的理解和更有效的应用。在2018年，“前置（左移）”经常被滥用，被误以为会把软件的安全性责任推给开发人员。在2019年，DevSecOps将成为DevOps的另一个自然的选择，将安全性融入到流程中的每个阶段，并且所有人都对安全性有责任。【来自：Vincent Lussenburg, Director of DevOps Strategy, XebiaLabs】\nG20Group的5个预测 原文：https://www.go2group.com/blog/devops-trends-2019-our-top-five-predictions-for-the-year/\n由于文章比较长，下面是核心观点的概述。\n使用AI加速/优化的DevOps将开始被逐渐应用。基于AI的预测性可以被用在CI或者CD栋流水线过程中，确保交付流程的有效性。这个趋势将加速应用开发者和数据科学家之间的协作。 容器化应用不在是新鲜事物了。DevOps和多云架构加速了容器相关的技术在大型企业中国的使用。越来越巨大的软件开发和部署规模也进一步提高了容器生产环境集群的规模和复杂性。Kubernets的广泛使用也进一步加速了应用容器化的进程。 Functions-as-a-Service (FaaS) 将会崭露头角。随着越来越多的专业人士在生产环境中广泛的使用容器技术。相信FaaS也会逐渐被应用起来，它也比称之为无服务器计算。这种技术的实现包括：AWS Lambda、Google Cloud Functions, Microsoft Azure Functions, IBM 等。 DevSecOps会变得更加重要。随着企业应用DevOps的范围逐渐扩大化，将安全性和合规性无缝的集成到DevOps转型过程中也得到了广泛的接受。主流的DevOps实践者会把安全性视为代码，安全团队会在DevOps工作流中和各种团队携手打造安全性。 自动化将会依然非常重要。企业越来越意识到在软件开发周中提高响应速度、运维的可恢复性、更快的上市时间的重要性；这需要将软件开发和运维工作通过自动化更好的链接起来。组织在复杂的生态系统中扩大自动化的应用还是有些难度。 来自Veritis的10个预测 原文： https://www.veritis.com/blog/devops-trends-top-10-predictions-for-devops-in-2019/\n","date":"2019-03-09T22:27:16+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/15218597150085.jpg","permalink":"https://martinliu.cn/blog/2019%E5%B9%B4%E5%85%B3%E4%BA%8Edevops%E7%9A%84%E5%87%A0%E4%B8%AA%E9%A2%84%E6%B5%8B/","title":"2019年关于DevOps的几个预测"},{"content":"DevOps企业峰会是历史悠久的DevOps主题企业级峰会，近年来在北美的拉斯维加斯和欧洲的伦敦每年各举办一次。 这个大会的官网：https://events.itrevolution.com/ 2019年的会议时间已经发布，感兴趣的可以参加。\nCSG公司连续多年参加DevOps企业峰会，本分享主题是CSG在2018年美国拉斯维加斯的峰会上的主旨演讲之一。本文是对这个演讲的视频回放的整理，该视频已经上传到了腾讯视频。\nCSG International公司简介 CSG是一个基于SaaS的客户支持和计费公司。CSG是美国最大的账单打印和呼叫中心公司。帮助他们的合作伙伴公司完成水电费、宽带费、通信费等相关业务的收款工作，并为最终客户提供热线电话支持。\nCSG的技术堆栈范围广泛，从Mainframe主机到Linux开放系统到AWS云服务，CSG认为如果正确的运用DevOps技术的话，技术堆栈并不是阻力和限制。\nCSG的DevOps旅程经历了如下几个阶段。\n2012年 敏捷转型 敏捷转型历经四年，进行了组织结构调整，在这个过程中关注点和亮点如下：\n应用精益思想消除了各种等待队列 应用康威定律重组重组了团队 重组团队之后形成跨职能团队，将设计团队，开发和测试团队融为一体 实施持续集成技术，落地持续部署流水线作为业务开发的基础设施 实施了测试自动化 实施了共享的遥测数据，这就是今天所热议的可观察性 将作业批量尺寸缩减为以前的一半 成立了多个独立于研发团队的共享的运维团队【注意：运维还没有和研发团队融为一体，共享运维团队管理所有IT环境并和所有产品团队协作】 敏捷转型的效果：\n发布影响业务的事件数量下降（在固定的时间周期里统计由于发布导致的影响客户服务的事件数量） 变更失败率下降 2012-2015 敏捷转型和DevOps早期 在敏捷转型的持续集成的基础上，CSG实施了持续部署实践，持续部署被视为应用DevOps实践的标志性动作，将所有部署转为为可重复执行的自动化部署。\n上图是运维工程师们在工作时段里进行日间部署的场景，但是平均每天进行15.1个部署，71个面向最终用户的特性发布。在部署期间，运维工程师们在信心满满的打着电动。由于每一个生产环境的部署都已经做过了大量的自动化测试，且在其它环境中至少部署过7遍了。\n2016 反作用力和挣扎期 上图的情形应该很常见，CSG也经历了这个阶段。\n开发团队追逐：\n交付速度 更好、更快的环境 更好的服务请求工具 憎恨变更请求队列（流程） 运维团队追逐：\n稳定性！ 高质量代码 更敏捷的工具 憎恨变更请求队列（流程） 开发和运维团队都厌恶的：\n变更管理流程 发布管理流程 生产环境的运维部门 PMO项目经理 客户想要的是：“更快得到高质量的特性！”\n2016 DevOps团队融合阶段 大家一起反思这个问题：“我们为何不站在同一条战线上，一起追逐相同的目标？”\n设置共同（共享）目标：更快、更稳定和更安全！融为同一个团队，为了更好的服务客户而努力奋斗。\n2016~2018 后DevOps时代 为了化解在的研发和运维之间的依然持续存的矛盾现象，在大家反思之后；进行了再次的团队组织结构调整，消除了所有共享的运维团队，将运维团队的工程师融入了各个研发团队。\nCSG的DevOps转型阶段的重点：\n运用了不同于双模IT的模型，即”统模IT“，在DevOps实践面前，各种类型的IT架构都一视同仁 转型后的开发团队统一负责产品的构建、测试、运行和服务质量 下放变更管理委员会（CAB）职责到各个开发团队，成立本地化的CAB（详见ITIL的术语表） 建立了群策群力的服务支持响应机制（参考精益思想的安灯拉绳），因此大幅度缩短了MTTR时间 实施了反向布兰特操作，消除大量普遍存在的布兰特（这是一个比喻，详见《凤凰项目》的人物布兰特） 建立整合的Backlog，将开发、测试和运维的工作统筹管理 实施基础设施自动化 将运维问题（目标不一致、反作用力、部门墙）视为工程实践问题：更好的工程实践，更少的苦活累活！ 【注意】如上图所示，新增了一个度量指标：Inc/Mo 每月的事件数量（ITIL的术语），这是生产环境中每月发生的事件单的数量，数量的降低说明了生产环境的稳定性的提高。\nCSG在这个阶段中所引入的DevOps实践参考指南书籍是《DevOps Handbook》，中文版封面如下图所示：\nhttps://book.douban.com/subject/30186150/\n在始于2016年的DevOps旅程中，CSG从改善负面指标阶段，步入了追逐正向业务价值目标的阶段。\nCSG通过打敏捷开发、精益思想和DevOps实践的组合拳，实现了稳定性和业务的同步增长。\n从2012年到2018年业务订阅用户数增长了27%。 生产系统的交易吞吐量（TPS每秒的交易数），增长了433% 产品管理遇上DevOps的主旋律 产品管理和DevOps之间的关系该如何协调和处理，在这个阶段里得到了定义。\n整个集体应该遵从的三大主旋律：\n将策略连接落实到人，从而改善了产品管理和DevOp的关系，基于相同的业务诉求：实现了更好的价值产出 IT不是是独立于业务之外：管理的应该是产品价值流，而非项目。 运维问题是一个同时于与工程和产品都相关的问题 见上图，寻找划出的重点和关键词。\n出现了新的度量指标：\nImpact minutes ：业务恢复时间 MTRR Release on demand ： 特性按需发布比率 eNPS ：员工对企业的点赞比率 以上数据的度量周期是从2017年至今的，影响这些指标的内因包括：\n精益领导力组合 产品经理遇上DevOps 产品管理为何要遇上DevOps？ 在CSG工作了19年之久，经历和目睹敏捷和DevOps转型全过程的项目经理，Brian Clark（VP Product management）的简单版答案：“业务成果”。\nCSG的处于一个非常稳定的成熟市场，而且是市场的领导者；上游的电信运营商公司和宽带网络公司的业务都已经很难成长了。\nCSG所在行业的复合年均增长率约等于2%，CSG公司的复合年均增长率是3.92%。他们面临着如何保留高级技术人才的挑战。而在实施了DevOps实践之后，业务成果好转，新增了两个BBS企业客户。雇员的eNPS增长了400%，人员保有率大于95%，目标市场的业务占用率提高了。\n从2015开始产品经理和DevOps团队开始讨论“团队的精益领导力组合”，定义了组织级别的愿景：“将工作可视化，把我们的人员和策略链接在一起，驱动参与度、价值和兴奋度。”\n所谓的精益领导力组合如下图所示：\n主要有三部分组成：\n组合管理 发布管理 转型赋能 回顾一下CSG过去的三年，主要经历了6里程碑。 1 服务请求管理 从梳理服务目录开始，将100多种IT服务梳理在一个服务目录中，需要这些服务的人通过服务请求并获得服务。以前这些服务工作交付所付出的大量运维性劳动是无法可视化和计量的。通过服务目录的不断完善，以前不可见的运维工作都可以察觉到，并可以计量和统计。\n到2018年为止，统计数据表明：\n服务目录管理的服务条目数量是 620 个 从服务目录创建并完成的服务请求单数量是 53000+ 个 使用同一个服务目录增加了工作的可视化程度，并且还具有潜在的成长空间 服务目录请求站点的访问量达到了 75000+ 次 服务目录的实施结果是可以被统计的，将这些数据呈现给了领导层团队；领导层随后决定增加了这些方面的投资，从而优化和消除了大量可重复的工作。这个阶段的成果也是非常突出的。举两个简单的例子如下：\n自动化了一个非常耗时的服务，该项服务每年需要消耗5000+人工时，这几乎是3个专职工程师一年的工作量。 优化了一个通常需要耗时10天才能完成的服务，后来该项服务现可以在请求的当天就得以满足。 随着以上成果的逐渐扩大化，服务请求方和交付方都更加愿意和领导团队接触，并参与到等多的提议和计划中。这些成果足以值得让团队兴奋起来，下图是史诗一号团队在举行团建活动，以此来庆祝第一步的成功。【注：想获取兴奋度就喝起来！】\n2 建立技术和产品组合规划室 - TAM Room 为了让项目执行过程和项目中的工作内容都更加可视化，建立了“技术和产品组合规划室”。在这个房间的墙上设立大型工作看板，将不同类型的工作用不同的颜色表示。这面墙展示了所有团队当前的工作内容，是产品和项目级别管理的全貌，任何事情如果不在这面墙上，团队不会对它耗费一秒钟。\n蓝色： 安全相关 红色：客户相关 黄色：云计算相关 绿色：技术相关 橙色：项目管理 这些是史诗级别的工作，是经过客户优先级排序的工作。 接下来构建了十六个团队的团队级别看板，团队会把这些实施工作拿走到他们自己的看板上。\n当团队工作在这个看板上之后，团队可以很好的处理计划外工作。如果有什么经理人员向团队提出其它工作的时候，团队可以回答“Yes”；然后请他看看当前的工作状态，说出可能的选项是什么？【注：讨论的结果很可能是，用Yes婉拒了计划外工作，或者请工作提出者交换他的进行中的工作。】\nTAP Room还是每个一个项目周期结束时，大家一起做回顾的场所，房间里提供了汉堡和热狗等午餐，团队成员用午餐会的形式交流各自的收获和想法。\n3 向全员推广，并提升参与度 - 各种坛子 如何将以上的成功经验传播到整个组织里，如何让更多的人参与其中，并提升全员的参与度。CSG创建了各种坛子的想法。\n每个坛子都有各自的负责人和执行周期。如Shark Tank是两周进行一次，如果任何人对产品和技术有谏言建议都会发到这里，负责人会统一收集和用不同的优先级排序。\nShark Tank 组织战略级别的，由VP们管理 Think Tank 产品组合级别的，由产品经理/负责人管理 DO Tank Scrum团队级别，由团队的负责人管理 上面一行的三个坛子是把组织级别的业务战略直接贯彻和对齐到底（Engineer）方式，当然任何人也可以在各个层面上提出反馈建议，并实现了每个人的参与度的从下而上的反馈回路。\n下面一行的三个坛子和他们的组织架构相关，也分别有各种独立的定义和用法，所有坛子都是两周执行一次回顾和处理。\n4 倡导价值驱动和交付 在这个阶段中，CSG不想仅仅止步于成功经验的传播和反馈，希望让更多人知道能从哪里，获得他们需要的信息和帮助，从而复制那些在组织级别已经取得成功的套路。\nCSG制作了视频短片，用阶段性回顾的方式，总结了他们所谓的参与度、有趣、有价值和有意义等概念，希望人多人能加入到史诗团队中。让人们觉得是和公司息息相关的。\n这个短片用产品周报发布的全公司，根据数据统计显示，有大约500人在发布的当天从头看到尾。使所有人都参与到价值交付中，并感受到激动。\n5 产能洞察管理 - Capacity Insights CSG也和其它所有公司一样，每个团队都很忙，项目经理和交付的工程师团队也存在在感受不一致的情况。如下高压力对话也很常见。\n你们能做更多工作么？ 不能！ 怎么会啊！ 我们很忙！ 给我一个忙的证据！ 产能管理工具（Capacity Insights）的出现缓解了这个问题，首先，CSG把计划内的工作输入到这个工具里，并进行工作量的跟踪和记录。同时还把计划外的工作也纳入这个系统，进行统一的跟踪和记录。这里的数据在项目、产品和团队级别上被透明的分享和沟通，从此团队的高压力对话现象得到了大幅度的缓解，大家更有意愿进行合作了。\n这些数据可以按照各种价值流的维度将耗费的工作时间（计划和实用）统计出来，并按照产品、团队和技术技能等各种维度进行钻去和统计。这样就可以把宝贵的产能合理的使用，实现了好钢用在刀刃上。\n6 生活和工作平衡 CSG不希望工程师团队周末加班，当然一周工作时间超长的情况也很常见，CSG希望他们能过上正常人的生活。领导层关注到这个问题后，开始实施一些措施。建立了产品迭代回顾的画廊，如下图所示。\n在这个画廊上关注着一些数据的状态。\n31个团队的总工作时间是15000小时 削减了25%的值守加班时间 削减了100%的测试数据配置工作，用自动化的方法削减了相当于3个全职工程师的工作量 用自动化的方式消除了某个业务流程确认环节90%的时间 CSG的成功秘诀是人，这都仰仗于赋能的员工：开放、分享、参与和兴奋。\n产品和项目的PK 对于这个话题的总结如下。\n部门墙（Queue）有碍于学习进步 基于项目的团队管理有碍于学习进步 基于产品的团队才可以精进成长 CSG公司在2017年以前的工作模式，产品和项目并存。\n开发团队 - 产品工作\n基于业务需求的史诗 （最左侧的） 基于发布节奏的工作 管理产品代办工作\u0026amp;排序 交付工作完成的解决方案 运维团队 - 项目工作\n处理临时、非计划的发布工作 被各种会议驱动和中断 接受研发发布过来的解决方案（临时和计划的） 同时处理各种基础设施的IT项目（最右侧的） 当两者的工作节奏交织在一起的时候，就会产生各种冲突。\n出现了各种明显的问题：\n双向的依赖关系 多个任务工作时间计划相互撞车 缺乏统一的依赖管理和产能规划，这进一步产生了大量进行中工作（WIP） 项目制的工作模式导致研发在迫于发布周期的情况下，交付了质量很低的解决方案 CSG随后进行了基于价值流的产品条线的聚焦，将开发和运维团队的代办工作事项都整合到了统一的单独入口，从而进行统一的管理。\n单一的工作入口管理可以更好的在统一的时间轴上进行优先级排序管理，并且能够实现所有工作的可视化和排序。 设置不同的发布节奏，从2周到12周不等，还有特性的按需发布 根据完成度、业务需求和耦合程度，不同工作任务选取不同的发布节奏 进行工程上的重构：自动化、架构和运维即服务模式 完全参考和接受了ThoughtWorks技术雷达提出的：应用产品管理的方式到内部平台。\n运维团队的人也将IT工作转为产品交付的方式，指定专人专家管理内部的平台。安全运维被视为工程和产品问题，通过重构的工程方法优化平台。\n基于产品/服务价值流交付的管理方式是多个迭代，往复循环的迭代，而不会是简单的停止于测试完毕的验收发布。\n配置管理、服务请求变更管理、遥测、监控管理、安全、事件问题管理和相应都是产品管理的一部分，这些运行态的工作是产品生命周期中不可或缺的。也不应该被其它孤立的外部团操作。\n因此服务持续性管理也变成为一种内置的持续的动作，而不是这个流程之外的独立事件。\nCSG提倡：运维是工程和产品的问题，在本图中也得到体现，运维工作是产品的运行时管理工作，也是包括在持续的产品开发迭代中，最好有一个统一的持久的团队负责。\nCSG举例说明了”运维是工程和产品的问题“；CSG的业务系统需要处理信用卡信息，因此需要满足PCI的合规需求。在这个业务需求的驱动下，运维团队花费了无数的安全审计时间（20000+小时）去满足合规的标准。在产品驱动的思维下，运维团队和安全专家合作开发了，实现PCI合规的配置管理工具。这些安全管理工具是基于Chef开发的，也在Chef的开发者大会上分享过，而且现在是一个开源的产品，任何人都可以下载使用。\n通过以下的对比发现CSG在这个思维转型了以后所得到的收益。\nCSG在跨价值流的工作可视化管理方面也取得了一定的收益。\n以前各种不同工作分类的工作内容，上图每种颜色的方框就是一个分类，每个分类的工作都有各自不同的跟踪管理系统（工单系统）。在这种情况下如果跨价值流分析相关的工作内容，则非常困难，要依赖大量的手工统计和集成工作。统一的工作可视化无法实现。因此CSG使用Jira来统一管理和跟踪以上各种工作，从而得到准确和实时的视图。\n2019年的目标 CSG的2019年DevOps的发展目标和举措也很值得参考。\nImpact Minutes 服务受影响的时间 ： 4700分钟，实现年同步增长50%；计划实施系统的强壮性工程，落实人的可恢复性 Release on Demond 按需发布 ： 希望最终是消除发布这个环节，或者是高于70%的按需发布比例；计划实施的举措是重构架构、自动化、解耦。 eNPS 员工推荐率 ： 提升这个比例；计划实施的举措有精益领导力组合，链接到每个人，工作生活平衡。 ","date":"2019-03-07T12:27:16+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/v1551950710/bjxysnye.png","permalink":"https://martinliu.cn/blog/csg-product-meet-devops/","title":"产品管理遇上Devops"},{"content":"上一篇文章重要观点回顾：\n应用DevOps的企业不应该使用成熟度模型度量 应用DevOps的不同企业/部门不会参考某个所谓标准 应用DevOps的不同企业/部门应该参考5大类24项的能力成长模型，来度量其发展进度，在磨练这些能力的过程中，选择符合自身业务需求的，且优先级别高能力先发展。 成熟度模型已死 这个模型在各行各业都可能存在，而且可能是最容易被人接受的模型之一。对于很多新生的领域，如法炮制的套用这个模型合适么？无论合适与否，它还是会出现在DevOps的领域中。为了避免实践者试错，我们不得来分析一下这种模型的特点。\n特征1 它总是阶梯式的，而且从来都是5个等级，人们经常戏称为Golden 5。常见的5级成熟度模型有下列几种。\nCMMI 能力成熟度模型集成\nITIL/ITSM的成熟度模型\nIT与业务融合的成熟度 http://www.cio.com.cn/eyan/1431.html\n德勤网络安全合规成熟度示意图\n持续交付流程成熟度\n如果你百度“成熟度模型”，还可以轻易地找到很多类似模型。客观的讲，这个模型是被广泛应用的神五级。\n这个模型对于任何使用的组织来说都是统一的，不会说对于有些企业是8级的，对于另外一些企业是10级的。\n这种模型的另外一个代名词是“XXX标准”，或者“XX行业标准”。\n特征2 通常对于每个等级上还可以定义出3到7个不同的维度。维度的数量少则3个级别，多字7到10个维度；可以要在每一个级别的不同维度上进行评价。这些维度一旦确定下来，也通常是十年如一日的静止不变。\n只是一种纵横交叉的矩阵的模式，如以上的持续交付流程成熟度、德勤网络安全合规成熟度示意图和IT与业务融合的成熟度都是这样。\n维度和等级往往都是静态的，通常模型发布之后，在很长一段时间里，不会发生改变。\n特征3 这些模型对于不同的组织而言，组织的目标都是一致而单纯的，即“通过/到达”某个级别。请你回忆一下以前的经历。一个软件开发组织经过一年的奋斗，他们通过了CMMI3级认证；第二年的时候，项目组一狠心，一跺脚一次性通过了5级认证。请问他们为什么一定要在第二年通过5级？在第三年里，相比以前，软件开发的质量提高了么？在第四年，有没有可能出现倒退的现象？如果你回答不了这些问题的话，可以尝试请教一个更资深一些的，工作10年以上的朋友或者同事。\n成熟度模型的局限性 根据以上的三个主要特征，这种模型的局限性大概有以下几个方面：\n每一个企业的自身条件、业务环境、资源约束都是不同的。让他们都对标一个统一的静态成熟度模型是不合适的。这就像是目前某些国家的教育体制一样。\nIT行业每天都在发生着巨大的变化，这就是我么经常提到的乌卡时代，今年流行的技术，很快就会过时，明年也将出现新的、未知的技术领域。很多行业的特点就是，在不断反复的被颠覆。而这些成熟度模型通常是永恒不变的。\n成熟度模型通常是在微观上进行考察，对很多考察点做孤立的分析和评测。这样做只能度量到技术、工具或者流程本身的一些方面。而忽视了组织通过它们所获得的总体成果产出。举个例子一个企业在通过了CMMI5级之后，发现收入/利润比以前还下降了；解释CMMI到达顶级的企业，业务收入还退步了，这本来就是一件比较尴尬的事情。\n如果一个集团企业，在所有IT组织/部门中强推某种成熟度模型的话，还有可能出现停滞不前的博弈现象。某些组织可能会宁愿待在中间的某个不成熟等级，并不愿意快速的提升到最高等级。那样的话，他们将失去每年一定数量的，用于提高成熟度等级的资源和预算。从最大化局部利益的角度考虑，最高级的成熟度可能等于最低级的资源支持。\n最后，无论到达了那个等级的成熟度，这种明确而清晰的满足感，滋生出了锚定效应。这其实阻碍了组织持续的探索和尝试未知领域，组织因此学习的知识就会越来越少。甚至于出现能力的下滑和倒退。\n综上所述，在DevOps的领域里，成熟度模型和统一标准已经过时了，它不适合用于DevOps的度量；而且，纵观整个行业，国际上目前还没有那一个适用的DevOps成熟度模型被应用于任何组织。那么还有什么其他DevOps适用的模型？\nDevOps能力成长模型 这个模型是在《Accelerate-加速器》这本书里被提出的。相信大家对Nicole博士联合Puppet Lab发起的DevOps状态调查和年度报告并不陌生。这本书分析了DevOps状态报告四年的历史数据，书里所展示的内容，其实也正好是作者Nicole Forsgren博士对DevOps现状调研的第一个迭代的阶段性成果。\n这本书的目标是解密高效能组织的高明之处，以及背后的原因。从探寻影响组织绩效的因素为起点，经过了四年的不断调研，Nicole博士向我们展示了一个相对比较完整的，各种影响因素的关系网。特别说明的是：下图来自于《加速器》这本书，这个形态是经过4年演进出来的，我们无法猜测2018年Nicole博士究竟怎样地拓展了调研的范围；更无法猜测的是：在2018年的状态报告结果中，这幅图会变成什么样子？\nNicole博士总结出了DevOps能力的5大分类，包含的能力点有24项。\n第一类：持续交付 对生产环境的所有工件进行版本控制 运用自动化部署流程 实施持续集成 运用基于主干的开发方法 实施测试自动化 进行测试数据管理 前置信息安全管理 实施持续交付 第二类：系统架构 应用松耦合的架构设计 授权团队进行架构重构的决策 第三类：产品和流程 收集和实施客户反馈 运用价值流模式可视化工作流 运用小批量的工作模式 培养和赋能团队进行试验 第四类：精益管理和监控 应用轻量变更审批流程 业务决策得到从应用到基础架构的全堆栈支持 前瞻性地监控系统的状况 应用WIP来进行价值流的工作管理 通过可视化来监控团队工作质量和进行沟通 第五类：企业文化 发展并支持生机型企业文化 鼓励和支持学习 支持和辅助团队间的协作 提供工作所需要的资源和工具 支持和落实领导力转型 DevOps能力成长模型的特点 首先，这个模型是基于4年以上的、科学的调查分析而来的。Nicole博士和全球最顶尖的DevOps公司，以及各种业内大咖，历经了多年的协作。其次，此模型是演变出来的，而且一定会持续更新。最后，分析一下这个模型的特点。\n它目标是适用于能力和起点本来就参差不齐的不同的组织/团队。 它适用于每个团队在能力上优劣各不相同的情况。而且每个团队的业务使命和向下文也不相同。 它使每个团队聚焦在各自不同的能力点上，发展和解决各不相同的约束点/弱点。 以上能力模型来上游调查数据就是一个行业基线（基线也在不断变化中），不同的团队参考每一项能力的行业基线定义各自的下一步的发展目标。 建议的度量套路 可以将DevOps能力成长模型作为企业应用DevOps的一个有效的度量工具。通过持续的度量，现状分析和改进，让DevOps的优化全局价值产出的特性加速企业客户价值的增长。这里简单描述一下建议的套路\n度量关键产出：这些指标是衡量你的团队软件交付的好坏与否的一个高阶的度量。相关指标有：IT效能、前置时间、部署频率、MTTR、变更失败率、加班程度和部署痛点。 能力驱动的改进：这些能力是你提升关键产出的抓手。由于你提高了一些能力，你在这些能力得到提升的同时，还能更快且可靠的交付软件。 按优先级改进：通过能力模型的评估，你识别出了那些能力约束点/瓶颈，是它们在阻止你达到更高的技术阶段，然后确定那些能力需要先优先发展。 ","date":"2018-06-27T21:34:04+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/v1549271017/Anubis-Background-Download-Free.jpg","permalink":"https://martinliu.cn/blog/maturity-is-dead/","title":"成熟度模型已死"},{"content":"听说这里有一个15分钟就能完成的DevOps调查问卷，有25位参与者或将得到总值为3200美元的亚马逊购物券。一年也就是这一次机会。问卷调查将在10天后就关闭。\n这是DevOps状态报告调查问卷的第七年。在过去的6年里，已经有两万七千多人参与了这项调查。这项调查已经获得了丰硕的成果，主要是帮助你了解在DevOps之旅上当前的进展。今年又扩展了调查的范围，再度加深了对DevOps之旅的调研。\n我已经帮你把问题的套路摸清楚了，其实问题都很清晰直白，很容易和你所在企业的DevOps状态做匹配。填写问卷调查也是一个学习的过程，可以用开放的心态去了解一下，调查报告对DevOps的观察角度都有哪些？\n对其中的部分问题做出了简要的说明，预祝你在参加这项全球性著名调查的过程中，有一个愉快的体验。\n今年的看点 据说DevOps状态调查报告的一个最大的价值就是：在你的组织中，你可以用这些数据展示出DevOps的价值，从而取得管理层的支持，并启动DevOps项目。\n在今年的调查研究工作中，新加入的，对在企业中应用和推广DevOps有深度洞察的专家包括：\nAndi Mann, the chief technology advocate at Splunk and co-author of Visible Ops – Private Cloud and and The Innovative CIO. Michael Stahnke, a director of engineering at Puppet and the author of Pro OpenSSH. Alanna Brown, the director of product marketing at Puppet and creator of the first State of DevOps Report in 2013. 参加这项问卷调查将有25人会得到亚马逊购物券，价值 $100, $200 或 $500 ； 抽奖说明：\n$500 2 人 $200 8 人 $100 15 人 注：规则完整版 https://puppet.com/2018-devops-survey-contest-rules\n参与此项调研报告 每道问题选择了答案之后，会影响到后续所出现的问题，我选择了金融（含保险）行业的DevOps软件工程师的路径。\n这个调查的问题库非常强大，每一个问题的回答都在影响下一个问题的范围。有些问题是情景设定和分析题，会预设一个阶段（有可能是你还未达到的），在这种情况里作出你的判断和选择。\n翻墙之后网页刷新速度会更快一些。\n第一部分 Where do you work? / 你在那个大洲工作？ In which country do you work? / 在那个国家工作？ What is the principal industry of your organization? / 你的组织是什么行业的？ Which of the following best describes your title or role in your company? / 下面的各种头衔/角色那个和你最匹配？ What department do you work in? / 你什么部门工作？ And what team do you work on? / 你在什么团队工作？ Which of the following describes your level of knowledge regarding your organization’s IT operations and software delivery? / 下面那一项最准确地描述了你的组织在IT运维和软件交付方面的知识程度？ 第二部分 Many people say that there are four elements of DevOps that work together as enterprises evolve. They are:\nCulture 文化 Automation 自动化 Measurement 度量 Sharing 分享 The next few questions will ask about each of these elements.\n这部分是对企业的CAMS调查的。\nWhere would you say you are at culture-wise, on your DevOps journey so far? / 在你目前的DevOps旅程中，DevOps文化存在于怎样的范围里？\nWhere would you say you are at automation-wise, on your DevOps journey so far? / 在你目前的DevOps旅程中，自动化的程度是怎样的？\nWhere would you say you are at measurement-wise, on your DevOps journey so far? Please select all that apply. / 在你目前的DevOps旅程中，在那些方面实施了度量？- 多选\nWhere would you say you are at sharing-wise, on your DevOps journey so far? / 在你目前的DevOps旅程中，在分享方面是怎么做的？\nHow frequently do each of these practices occur in your organization? / 下列实践在你的组织中发生的频率？从来没用过 ~ 总是在用 5级\nWe balance lowering technical debt, with new feature work Configurations are managed by a configuration management tool A cross-functional review is done before implementation of a project Teams use continuous delivery Before starting a project, we establish concrete success criteria We create learning opportunities across teams (e.g., training, internal DevOps workshops, etc.) We expose data and services via APIs Success metrics for projects are visible DevOps initiatives are supported by senior leadership Teams use agile approaches across development and operations Developers are on-call for production issues Teams use continuous integration Source code is made available to other teams Experiences and lessons are shared externally (e.g., meetups / conferences, blog posts, etc.) How frequently were each of these practices used when you were first starting out with DevOps? / 在你的DevOps刚刚起步的阶段，下列实践的使用频率是怎样的？从来没用过 ~ 总是在用 5级\nApplication configurations are in version control Infrastructure teams use version control Automate system configurations (e.g. operating system baselines) System configurations are in version control Automate provisioning (e.g. server, VM, cloud instances, etc.) Application development teams use version control Automate security policy configurations How frequently were these practices used after you started to see some traction with DevOps? / 在你开始感受到DevOps的优势以后，下列实践的使用频率是怎样的？从来没用过 ~ 总是在用\nWe reuse deployment patterns for building applications or services Monitoring and alerting are configurable by the team operating the service We deploy on a single standardized operating system We deploy on a set of standardized operating systems We build on a standardized set of technologies Configurations are managed by a configuration management tool We reuse testing patterns for building applications or services How frequently were the following used while you were expanding DevOps practices? / 在你推广DevOps实践的过程中，下列实践的使用频率是怎样的？从来没用过 ~ 总是在用 5级\nWe have post-incident reviews and share results Security teams are involved in technology design and deployment Teams contribute improvements to tooling provided by other teams We reuse testing patterns for building applications or services Individuals can do their work without manual approval from outside of their team We reuse deployment patterns for building applications or services Monitoring and alerting are configurable by team operating service How frequently were these practices used while you were optimizing your DevOps practices? / 当你在优化DevOps实践的过程中，下列实践的使用频率是怎样的？从来没用过 ~ 总是在用 5级\nInfrastructure changes are tested before deploying to production Rearchitect applications based on business needs (e.g., reducing operational costs, ease of deployment, etc.) Individuals accomplish changes without significant wait times Monitoring and alerting are configurable by team operating service Teams contribute improvements to tooling provided by other teams Service changes can be made during business hours Incident responses are automated How frequently were these practices used while you were enabling self-service? / 在你管理自助服务的情况下，下列实践的使用频率是怎样的？从来没用过 ~ 总是在用 5级\nTeams contribute improvements to tooling provided by other teams Resources (e.g., accounts, infrastructure, etc.) made available via self-service Logging configuration is deployed with the application or service Monitoring and alerting are configurable by team operating service App developers deploy testing environments on their own Which, if any, of the following processes or tools are “self-service” in your DevOps approach? Please select all that apply. / 在你的DevOps计划中，下列哪些流程或者工具会做成自助服务？\nWhich of the following organizational structures have you used in your DevOps journey? / 在你DevOps的旅程中，你曾经用过下列哪些组织结构？\nCross-functional teams that are responsible for specific services or applications A centralized IT team and multiple application development teams A Site Reliability Engineering (SRE) team A service provider that provides DevOps capabilities (e.g. builds test environments, provides monitoring, etc.) A dedicated DevOps team Please tell us what kind of development your organization does. / 你的组织开发各种类型软件的比例是多少？5个问题填写百分比，凑够100\nWe do custom development for internal users We do custom development for COTS (commercial off-the-shelf software) We manage COTS (commercial off-the-shelf software (e.g., upgrades) We do in-house development of custom applications for external users If you could move the needle on one metric related to DevOps, what would it be? / 如果让你仅仅选择一个度量DevOps的指标，这个指标是什么？ - 描述题\nJust a few more questions to help us categorize your answers. / 下列问题帮助我们对你的组织进行分类。\nWhat figure best describes your company’s annual revenue in US$ equivalent? / 你们公司的年营业额是多少美元？\nWhat is the proportion of genders working on your team? / 你所在的团队男女比例？\nPlease tell us how you identify. / 请问告诉我们你认为自己是什么性别。\nWhat is your current annual salary in US dollars? / 你的年薪是多少美元？\nDo you consider yourself to be part of a visible or invisible minority where you work? / 你认为自己工作是显耀的还是无足轻重（少数派）的？\nPlease tell us of what minority(ies) you consider yourself to be a member. Please select all that apply. / 请告诉我们你的这种无足轻重是指哪方面？-多选\nWould you like to receive an email with the report link when it is available? / 你是否希望收到这份报告的下载链接？\n完毕 本文来源：https://puppet.com/blog/introducing-2018-state-devops-survey-new-research-focus\n调查问卷网址：https://polls.onresearch.net/DevOps/blog\n后记 DevOps圈子里的人都知道，这项问卷调查在IT行业里的知名度和权威性。它的目的在于：通过持续的研究DevOps在各个企业中应用的状态特征，定量的收集大量行业基础分析数据，这样所有的企业就有了一个可以参照的基线数据。更重要的是，它还将企业的绩效分成了高中低三个等级；对这些数据，用科学的分析方法，总结出了高绩效企业之所以高明的原因，将这些结论/假设/原因还在逐年推演和求证中。因此它形成了最具说服力的一些列结论。这些结论都展示在了历年来的DevOps状态报告中。\n今年 Nicole Forsgren博士，《Accelerate》一书的主要作者，用此书对多年来的DevOps状态分析做了一个总结。此书一出版就高居亚马逊畅销榜榜首，还被誉为DevOps界的科学。这本书为你展示了历年来的状态分析报告是怎么来的？调查的范围和方向是如何演进的？为什么会得出这样的分析结果？\n调查报告的分析结果是客观而科学的。而这本书向你展示了这些报告数据背后的How和Why。它提出了一个全新的主题“DevOps能力发展模型”；该书的一些结论也是非常具有颠覆性：\n应用DevOps的企业不应该使用成熟度模型度量 应用DevOps的不同企业/部门不会参考某个共同标准 应用DevOps的不同企业/部门应该参考5大类24项的能力成长模型，来度量其发展进度，在磨练这些能力的过程中，选择符合自身业务需求的，且优先级别高能力先发展。 下图是24项能力的分解表：\n我在这本刚发布的时候购买了电子版。在参加5月份的DevOpsDays大会北京站的深度培训“持续交付”课上，遇到了这个培训老师的Jez Humble先生，他也是本书的合著者之一。意外地获赠了一本他的签名实体书。\n在学习了一段时间以后，我总结和归纳了一些内容：关于对DevOps能力发展模型的详细剖析，对24项DevOps主要发展能力之间的关联关系的解读；这些内容将会在8月份上海的DevOpsDays大会上呈现。\n","date":"2018-06-27T00:09:21+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/abstract-6.jpg","permalink":"https://martinliu.cn/blog/2018-devops-survey/","title":"参与2018年DevOps状态调查报告"},{"content":"各种大会、各种喧嚣，你都看够了么？免费的，收费的，都与你有何相干？哪里是你自己的社区，哪里可以找到同类和导师？本文是我对社区的一点个人的思考，感兴趣的读一下。\n本文的标题图片是中国DevOpsDays社区志愿者招募的标题图片，这是NASA的一张完美风暴的航拍图片，暂时不欣赏这幅图的完美之处。让我来先讲讲它的出处，这幅图来自于樊登读书会App，源于他最近读到的一本书《谢谢你迟到》。\n我觉得书名和DevOps有些相关性，DevOps在IT行业中的兴起是最近9年的事，说来这是一段不长不短的时间。纵观最近几年的IT行业，这是一个从业人员的幸福感和优越感急剧下降的过程，是敏捷、精益、CMM和ITSM等管理等套路，在逐渐被人质疑的过程，是IT行业内的大厂纷纷走向没落的9年。DevOps并不是从无到有蹦出来的，它的姗姗来迟也并不具有任何的偶然性，相反它是各种管理实践分久必合的必然结果，它是一个各种最佳实践的聚合体，它是从敏捷社区发源，然后逐步融入了各种必要的元素，而且各种元素之间产生了化学反应后的化合物。\n我对社区的认识源于很久以前在大学中对Linux的喜爱，从哪里听说了开源社区这种事物。对开源软件社区的深刻理解是在加入Red Hat公司期间形成的。Red Hat公司创造了一种神奇的开放文化（见CEO Jim出版的Open Orgnazation一书），让曾经在哪里工作过的员工可以将自己的职业生涯清晰的化为：Red Hat阶段和非Red Hat两个阶段（所有其它公司都是和Red Hat迥异的，都是雷同的）。这不是我自己总结的，是今天早晨和一个公司同事聊出来的，我们都曾经在Red Hat工作过，不过在那段时间里我们并不认识。\n在Red Hat的时候，当你加入到某个开源项目的邮件讨论组的时候，你会很自豪的有一等公民的感觉。由于你发现你的同事在各种项目的讨论中频繁出现，他们的日常工作就是在开源社区中修复bug，提交feature。虽然我并不贡献代码，不过还是觉得占了“Red Hat是个活雷锋”的形象的光。Red Hat公司的工程师在开源社区中的贡献，是这种项目的助推剂和催化剂。\n当然也有人觉得Red Hat是商业开源而已，少了早年开源社区的那种乌托邦式的纯粹感，并不是一种无欲无求的奉献。但是时代还是要继续，而且是不断的变迁的。开源软件社区就是这样轻易的颠覆了软件世界的格局，纷纷倒闭和没落的昔日贵族们，他们不都是巨无霸级别的闭源殿堂么？\n开源软件的开放性和分享精神给了我非常大的影响，这加深了我对社区的认识。DevOpsDays社区是不同于开源软件社区的，我对他的感受和理解基于软件开源社区，但隐约感觉到它们是两种社区，应该是不同的类型，但是目前还说不清楚。\n用台风眼作为DevOpsDays社区的比喻是在我听樊登讲《谢谢你迟到》时想到的。听完之后，看了一下App里的此书的图文描述，发现这的确是我所需要的寓意，下面直接转述，不做解释。\n2.台风眼\n在台风来袭时，位于台风中心的台风眼反而是最安全、最风平浪静的。回到社区，找到自己熟悉的中心，就像是台风中的“台风眼”。\n台风眼也不是固定不动的，它能保持安稳的一大原因就是，它会应时而动。台风持续不断地移动，就像这个时代的脉搏，台风眼也随着它移动，保持自己始终处在有利的位置。\n台风眼就是我们每个人最好的老师。\n我现在所深度参与的是“DevOpsDays社区”，它的历史可以追溯到 #DevOps 这个词的诞生，它的全球广泛程度可以参考官网 https://DevOpsDays.org ； 这也是我喜爱这个社区的两个原因。\n另外，我觉得DevOps本身对这个时代应该是很有价值的；此时此刻的深夜，我扫了一眼微信朋友圈，还是能看到“深夜、聚众、上线加夜班的团队”在上演着这不断重复的人间悲喜剧，看到他们相互的点赞、加油和鼓励；可是从DevOps的观点出发，我们其实可以冒出这样一句话：“其实还有一条更好的路”。\n虽然，有时候你觉得DevOps无处不在；但是，我个人深刻的意识到，其实IT行业中还有巨大数量的人，他们并不知道DevOps的存在。还有大量的人，个人掌握了DevOps的知识和实践，但是还是无法影响和改变周遭的人。还有大量的团队在迷迷糊糊地实施着DevOps。更有大量的公司在观望着DevOps。\n很显然，DevOps的推广和传播还是不够的，这是我觉得各种DevOps社区都应该意识到的一个事实。我们都有责任传播正确的理念和信息，切勿蹭着这个热点，而有不负责的传播着错误和误导的信息。所有博主、微信号和公司都应该自省。纷繁复杂的DevOps实践之间本来就已经存在着千丝万缕的联系，而它们的落地无不挑战和考验着所有的DevOps实践者们；只有在各自公司的业务场景里，运用科学系统的思维方式，经历相当长一段时间的实验阶段，才可能感知和捕捉到DevOps的好处和优势。在这个过程中，和同行的实践者坐而论道或将是一种很好的学习和提升的方式。而这也是DevOpsDays社区期望能为实践者们提供的。为此DevOpsDays社区需要做如下的工作，才能提供出以上的学习环境：\n线上线下的分享会 线下的城市聚会 举办区域的大会 这些活动的发生时需要一定数量的人力、物力和财力。如果我们想在国内覆盖更大数量的群体，必然需要更多数量的志愿者。如果没有坚实的志愿者群体，没有志愿者群体的奉献，任何社区可能都是难于发展和存在的。\n总结 本文其实是写给我自己的和整个国内DevOps社区的，仅仅是简单地回顾了一下我个人的社区经历而已。不是想引导任何人来加入我们所发起的这个志愿者群体的。原因很简单：不到24小时，我们收到了近百人的报名申请。这让我们核心组织者措手不及。之前是发愁没有志愿者分担我们的劳动，而现在发愁的是如何与已经报名的人联系起来，我个人也没有管理如此数量志愿者群体的经验。最后希望我们可以快速的度过这个幸福难题；使志愿者们可以自组织地运作起来，让DevOpsDays社区为这个行业传播价值，让它在人和人之间创建有意义的链接。\n参与中国DevOpsDays社区的三种姿势：\n关注，从中学习所需要的知识；就这样静静的看着挺好。 加入，分担一些志愿者工作，结交新朋友。 分享，为这个社区注入新鲜的知识和经验，社区需要更多这样的人，需要有更多的人可以成长为分享者，分享也是一种更高阶的学习。 中国DevOpsDays社区的官网是： http://ChinaDevOpsDays.org\n.\n","date":"2018-05-20T10:54:51+08:00","image":"http://res.cloudinary.com/martinliu/image/upload/v1526781579/Eye_Of_The_Storm_Hurricane_From_Space_freecomputerdesktopwallpaper_1600x900.jpg","permalink":"https://martinliu.cn/blog/perfect-storm-devops-days/","title":"从完美风暴说开去，直到DevOpsDays社区"},{"content":"kops这种方式是我找到的最佳的，最适合于培训课堂需要的安装方式，当然对有类似需求的人有帮助。\nRoute53 DNS配置 kops需要使用DNS服务，用主机名提供k8s的相关服务访问。配置的注意点：\n域名还是有必要有一个的，没有的话注册一个也不贵，以后用着也方便 建议在aws的Route53里做一个二级域名，例如：k8s.devopscoach.org 这个二级域名最好是能被正常公网解析的，为了便于直接访问集群里的服务 用 dig NS k8s.devopscoach.org 可以能正常解析（Mac上是这个命令） 由于全球的域名同步会需要一些时间，因此可以先做这一步，用到的时候，可能就已经同步好了。\nkops会将所有主机的域名解析都自动化的添加A记录到这里。\n安装工具准备 需要安装的工具包括 kubectl, kops 和 AWS CLI 工具。kops需要调用 AWS CLI来创建所需要的资源。我觉得简单的方法是：在目标的Region里创建一台Amazon AMI的虚拟机，这样AWS CLI就不用装了，而且在云里的话，执行kops的时候，由于有一大堆资源创建更新的api调用，感觉速度比在本机快很多，而且还用担心断网。\n可以启动一台t2.micro规格的Amazon AMI即可，另外需要给这个实例配置如下IAM用户权限，在启动的时候选择合适的IAM Role。\nAmazonEC2FullAccess AmazonRoute53FullAccess AmazonS3FullAccess IAMFullAccess AmazonVPCFullAccess 这台虚拟机启动之后，安装kubectl和kops。\n1 2 3 4 5 6 7 8 curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl sudo chmod +x kubectl sudo mv kubectl /usr/local/bin/kubectl wget https://github.com/kubernetes/kops/releases/download/1.8.0/kops-linux-amd64 sudo chmod +x kops-linux-amd64 sudo mv kops-linux-amd64 /usr/local/bin/kops 准备ssh登陆秘钥，用户ssh登录各个ec2实例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [ec2-user@ip-172-31-27-182 ~]$ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/ec2-user/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/ec2-user/.ssh/id_rsa. Your public key has been saved in /home/ec2-user/.ssh/id_rsa.pub. The key fingerprint is: SHA256:oSPZf85vNsC7l9z24umLJs4tQ6qDMCrWfqAVXGYoA34 ec2-user@ip-172-31-27-182 The key\u0026#39;s randomart image is: +---[RSA 2048]----+ |o . | |.o . + | | .+E+ . | | .o o . . | | + + S. | | oo . o + | | .+o.. .o.+ o | |oo .... .==.O.+. | |o ... .o .*@+==+.| +----[SHA256]-----+ [ec2-user@ip-172-31-27-182 ~]$ 创建S3 bucket 这是用来存储Kubernetes群集的配置信息的，kops在创建、运行、更新和管理它创建的群集过程中，没个Cluster的信息可以保存在bucket的一个目录中。\n1 2 3 [ec2-user@ip-172-31-27-182 ~]$ aws s3 mb s3://clusters.k8s.devopscoach.org make_bucket: clusters.k8s.devopscoach.org [ec2-user@ip-172-31-27-182 ~]$ export KOPS_STATE_STORE=s3://clusters.k8s.devopscoach.org 创建完成后，将其放入环境变量中待用。\n在集群安装完成之后，bucket里面的文件如下：\n创建Kubernetes Cluster 命令行参数如下：\nkops create cluster //创建集群 \u0026ndash;cloud=aws //使用aws \u0026ndash;zones=ap-northeast-1a //使用这个指定的zone \u0026ndash;name=dev.k8s.devopscoach.org //集群的名字 \u0026ndash;dns-zone=k8s.devopscoach.org //集群所使用的DNS解析区 \u0026ndash;dns public //对公可访问 命令的执行结果如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 [ec2-user@ip-172-31-27-182 ~]$ kops create cluster --cloud=aws --zones=ap-northeast-1a --name=dev.k8s.devopscoach.org --dns-zone=k8s.devopscoach.org --dns public I0401 17:05:06.003257 30031 create_cluster.go:971] Using SSH public key: /home/ec2-user/.ssh/id_rsa.pub I0401 17:05:07.132058 30031 subnets.go:184] Assigned CIDR 172.20.32.0/19 to subnet ap-northeast-1a Previewing changes that will be made: ********************************************************************************* A new kops version is available: 1.8.1 Upgrading is recommended More information: https://github.com/kubernetes/kops/blob/master/permalinks/upgrade_kops.md#1.8.1 ********************************************************************************* I0401 17:05:12.605297 30031 executor.go:91] Tasks: 0 done / 73 total; 31 can run I0401 17:05:13.546597 30031 executor.go:91] Tasks: 31 done / 73 total; 24 can run -----此处删除了n个字符------ VPC/dev.k8s.devopscoach.org CIDR 172.20.0.0/16 EnableDNSHostnames true EnableDNSSupport true Shared false Tags {Name: dev.k8s.devopscoach.org, KubernetesCluster: dev.k8s.devopscoach.org, kubernetes.io/cluster/dev.k8s.devopscoach.org: owned} VPCDHCPOptionsAssociation/dev.k8s.devopscoach.org VPC name:dev.k8s.devopscoach.org DHCPOptions name:dev.k8s.devopscoach.org Must specify --yes to apply changes Cluster configuration has been created. Suggestions: * list clusters with: kops get cluster * edit this cluster with: kops edit cluster dev.k8s.devopscoach.org * edit your node instance group: kops edit ig --name=dev.k8s.devopscoach.org nodes * edit your master instance group: kops edit ig --name=dev.k8s.devopscoach.org master-ap-northeast-1a Finally configure your cluster with: kops update cluster dev.k8s.devopscoach.org --yes [ec2-user@ip-172-31-27-182 ~]$ kops命令列出了所有需要建立的资源清单。而真实的开始资源创建，并搭建和配置Kubernetes集群还需要执行，以上输出中提示的最后一条命令: kops update cluster dev.k8s.devopscoach.org --yes 执行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 [ec2-user@ip-172-31-27-182 ~]$ kops update cluster dev.k8s.devopscoach.org --yes ********************************************************************************* A new kops version is available: 1.8.1 Upgrading is recommended More information: https://github.com/kubernetes/kops/blob/master/permalinks/upgrade_kops.md#1.8.1 ********************************************************************************* I0401 17:13:02.482203 30077 executor.go:91] Tasks: 0 done / 73 total; 31 can run I0401 17:13:04.389402 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;apiserver-aggregator-ca\u0026#34; I0401 17:13:04.628667 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;ca\u0026#34; I0401 17:13:07.291294 30077 executor.go:91] Tasks: 31 done / 73 total; 24 can run I0401 17:13:09.273293 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;kubelet-api\u0026#34; I0401 17:13:09.803612 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;kubelet\u0026#34; I0401 17:13:09.809131 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;kube-scheduler\u0026#34; I0401 17:13:09.973826 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;apiserver-proxy-client\u0026#34; I0401 17:13:10.317412 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;kops\u0026#34; I0401 17:13:10.321177 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;apiserver-aggregator\u0026#34; I0401 17:13:10.440919 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;kube-controller-manager\u0026#34; I0401 17:13:10.630182 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;kubecfg\u0026#34; I0401 17:13:11.020560 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;master\u0026#34; I0401 17:13:11.040010 30077 vfs_castore.go:430] Issuing new certificate: \u0026#34;kube-proxy\u0026#34; I0401 17:13:12.698208 30077 executor.go:91] Tasks: 55 done / 73 total; 16 can run I0401 17:13:13.609559 30077 launchconfiguration.go:333] waiting for IAM instance profile \u0026#34;nodes.dev.k8s.devopscoach.org\u0026#34; to be ready I0401 17:13:13.656221 30077 launchconfiguration.go:333] waiting for IAM instance profile \u0026#34;masters.dev.k8s.devopscoach.org\u0026#34; to be ready I0401 17:13:24.156701 30077 executor.go:91] Tasks: 71 done / 73 total; 2 can run I0401 17:13:24.864262 30077 executor.go:91] Tasks: 73 done / 73 total; 0 can run I0401 17:13:24.864379 30077 dns.go:153] Pre-creating DNS records I0401 17:13:26.454177 30077 update_cluster.go:248] Exporting kubecfg for cluster kops has set your kubectl context to dev.k8s.devopscoach.org Cluster is starting. It should be ready in a few minutes. Suggestions: * validate cluster: kops validate cluster * list nodes: kubectl get nodes --show-labels * ssh to the master: ssh -i ~/.ssh/id_rsa admin@api.dev.k8s.devopscoach.org The admin user is specific to Debian. If not using Debian please use the appropriate user based on your OS. * read about installing addons: https://github.com/kubernetes/kops/blob/master/docs/addons.md 以上这套组合拳打出去之后，需要等几分钟才能完成Kubernetes集群的部署。\n在以上实例中创建的Ec2实例如下：\nmaster-ap-northeast-1a.masters.dev.k8s.devopscoach.org //m3.medium nodes.dev.k8s.devopscoach.org //t2.medium nodes.dev.k8s.devopscoach.org //t2.medium 也创建了两个ASG：\n一个是针对master的扩容规则 另外一个是针对worker node的扩容规则 从扩容规则为空可以看出，它主要是用于定义集群规格的，而非自动化扩容的。\n在安装完成之后，用一下命令确认集群状态如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [ec2-user@ip-172-31-27-182 ~]$ kops validate cluster Using cluster from kubectl context: dev.k8s.devopscoach.org Validating cluster dev.k8s.devopscoach.org INSTANCE GROUPS NAME ROLE MACHINETYPE MIN MAX SUBNETS master-ap-northeast-1a Master m3.medium 1 1 ap-northeast-1a nodes Node t2.medium 2 2 ap-northeast-1a NODE STATUS NAME ROLE READY ip-172-20-38-48.ap-northeast-1.compute.internal master True ip-172-20-45-235.ap-northeast-1.compute.internal node True ip-172-20-63-157.ap-northeast-1.compute.internal node True Your cluster dev.k8s.devopscoach.org is ready [ec2-user@ip-172-31-27-182 ~]$ kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS ip-172-20-38-48.ap-northeast-1.compute.internal Ready master 5m v1.8.7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m3.medium,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=ap-northeast-1,failure-domain.beta.kubernetes.io/zone=ap-northeast-1a,kops.k8s.io/instancegroup=master-ap-northeast-1a,kubernetes.io/hostname=ip-172-20-38-48.ap-northeast-1.compute.internal,kubernetes.io/role=master,node-role.kubernetes.io/master= ip-172-20-45-235.ap-northeast-1.compute.internal Ready node 4m v1.8.7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.medium,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=ap-northeast-1,failure-domain.beta.kubernetes.io/zone=ap-northeast-1a,kops.k8s.io/instancegroup=nodes,kubernetes.io/hostname=ip-172-20-45-235.ap-northeast-1.compute.internal,kubernetes.io/role=node,node-role.kubernetes.io/node= ip-172-20-63-157.ap-northeast-1.compute.internal Ready node 4m v1.8.7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.medium,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=ap-northeast-1,failure-domain.beta.kubernetes.io/zone=ap-northeast-1a,kops.k8s.io/instancegroup=nodes,kubernetes.io/hostname=ip-172-20-63-157.ap-northeast-1.compute.internal,kubernetes.io/role=node,node-role.kubernetes.io/node= [ec2-user@ip-172-31-27-182 ~]$ 创建并访问服务 如下所示的创建两副本的nginx部署，部署的命令 sample-nginx。\n1 2 3 4 5 6 7 8 9 [ec2-user@ip-172-31-27-182 ~]$ kubectl run sample-nginx --image=nginx --replicas=2 --port=80 deployment.apps \u0026#34;sample-nginx\u0026#34; created [ec2-user@ip-172-31-27-182 ~]$ kubectl get pods NAME READY STATUS RESTARTS AGE sample-nginx-7588757c8f-jvkjt 1/1 Running 0 5s sample-nginx-7588757c8f-zq8tj 1/1 Running 0 5s [ec2-user@ip-172-31-27-182 ~]$ kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE sample-nginx 2 2 2 2 13s 然后将这个部署暴露为服务，使用到Kubernetes的命令如下：\n1 2 3 4 5 6 [ec2-user@ip-172-31-27-182 ~]$ kubectl expose deployment sample-nginx --port=80 --type=LoadBalancer service \u0026#34;sample-nginx\u0026#34; exposed [ec2-user@ip-172-31-27-182 ~]$ kubectl get services -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR kubernetes ClusterIP 100.64.0.1 \u0026lt;none\u0026gt; 443/TCP 10m \u0026lt;none\u0026gt; sample-nginx LoadBalancer 100.64.127.19 ae3a1ca9235d111e890d706038dd676b-392190656.ap-northeast-1.elb.amazonaws.com 80:30363/TCP 25s run=sample-nginx 这条命令 ubectl expose deployment sample-nginx --port=80 --type=LoadBalancer 会创建一个ELB并将，集群里容正在运行的 sample—nginx 服务注册到这个ELB，然后就可以访问浏览到Nginx的默认页面了。\n删除集群 用一条命令就能删除以上所建立的Kubernetes集群。\n1 kops delete cluster --name=dev.k8s.devopscoach.org --yes ","date":"2018-04-02T00:22:44+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/BingWallpaper-2018-03-17.jpg","permalink":"https://martinliu.cn/blog/kops-on-aws/","title":"Kops on Aws"},{"content":"本文来自于Red Hat咨询顾问Bilgin Ibryam所编写的一篇白皮书，名为《PRINCIPLES OF CONTAINER-BASED APPLICATION DESIGN》。这篇文章在作者的Blog上发表后，作者的twitter被Kubernetes官方twitter转发。白皮书在Red Hat官网的下载地址：https://www.redhat.com/en/resources/cloud-native-container-design-whitepaper 文本是对这篇文章的学习和整理。\n先回顾经典的软件设计原则：\n保持简单，愚蠢（KISS） 不要重复自己（DRY） 你不会需要它 （YAGNI） 关注点分离（SoC） Single responsibility, Open/closed, Liskov substitution, Interface segregation, Dependency inversion （SOLID） 然后是Red Hat的云原生容器设计原则：\n唯一关注性原则（SCP） 高度可观测性原则（HOP） 生命周期一致性原则（LCP） 镜像不可变性原则（IIP） 进程可处置性原则（PDP） 自包含性原则（S-CP） 运行时约束性原则（RCP） 很多组织都理解云原生的重要性和必要性，但是并不知道从哪里开始。那么请确保：云原生平台和容器化应用能无缝的运行在一起，并且具备抵御故障的能力，甚至在底层的基础架构出现宕机的时候，也能通过过弹性扩展的方式表现出可靠性。本文描述了容器化应用时需要遵循的基本准则，实施这些原则有助于使之与云原生平台Kubernetes更加适配。\n唯一关注性原则 SINGLE CONCERN PRINCIPLE（SCP） 在许多方面，唯一关注性原则与来自SOLID的SRP是类似的，它建议一个类应该只有一个责任。SRP背后的动机是每个责任是变更的一个轴心，一个类应该有，且也只有一个需要改变的理由。SCP原则中的“关注”一词强调关注是一种更高层次的抽象的责任，而且它更好地将范围描述为一个容器而不是一个类。虽然SRP的主要动机是变化原因的唯一性，而SCP的主要动机是容器镜像重用和可替换性。如果你创建一个解决单个问题的容器，并且以功能完整的方式来实现，不同应用程序中的容器镜像重用的可能性就会更高。\n因此，SCP原则规定每个集容器都应该解决一个问题，并做得很好。 实现这一点，通常比在面向对象的世界中实现SRP更容易，容器通常管理的一个单一的进程，大多数情况下一个进程解决一个问题。\n如果你的容器化微服务需要解决多个问题，它可以使用这样的模式，将多个容器用sidecar和init-containers的模式合并成一个部署单元（pod），这样每个容器仍然是处理单个问题。同样，您可以替换处理同样问题的容器。 例如，将Web服务器容器或队列实现容器，更新为更具可扩展性的容器。\n高度可观测性原则 HIGH OBSERVABILITY PRINCIPLE（HOP） 容器提供了一种统一的方式来打包和运行应用程序，将它们视为一个黑盒子对象。 但任何旨在成为云原生公民的容器都必须提供API支持，要为运行时环境编写接口（API），以观察容器的健康状况和行为。 这是自动化容器更新和生命周期回收的基本先决条件和统一的方式，从而提高系统的弹性和用户体验。\n实际上，您的容器化应用程序必须至少为其提供不同类型的健康检查的API\u0026ndash;活动和就绪等状态。更好的应用程序的行为则必须提供其他手段来观察容器化应用程序的状态。应用程序应该将重要事件记录到标准错误（STDERR）和标准输出（STDOUT）中，从而通过统一的日志聚合工具（诸如Fluentd和Logstash之类的工具）进行分析，并与跟踪和指标收集库相结合，例如OpenTracing，Prometheus等。\n将您的应用程序视为黑盒子，但实施所有必要的API以帮助平台对其进行观测，并以最佳方式管理您的应用程序。\n生命周期一致性原则 LIFE-CYCLE CONFORMANCE PRINCIPLE（LCP） HOP规定了你的容器提供供平台观测的API。 LCP则规定：您的应用程序有办法读取来自平台的事件。 此外，除了获得事件以外，容器还应该对这些事件相应地作出反应。这就是此原则名字由来。这几乎就像在应用程序通过一个“写入API”与平台进行交互。\n来自管理平台的各种事件都是为了帮助您管理您的容器的生命周期的。决定处理哪些事件取决于您的应用程序 以及是否对这些事件做出反应。\n但有些事件比其他事件更重要。例如，任何需要一个干净的关闭进程，这就需要捕获信号：终止（SIGTERM）消息，并尽可能迅速关闭。 这是为了避免通过强制关闭信号：kill（SIGKILL），之后跟随一个SIGTERM。\n还有其他事件，例如PostStart和PreStop，可能对您的应用程序生命周期管理也非常重要。 例如，某些应用程序需要在服务之前进行预热请求和一些需要在关闭干净之前释放资源。\n镜像不可变性原则 IMAGE IMMUTABILITY PRINCIPLE（IIP） IMAGE IMMUTABILITY PRINCIPLE（IIP）容器化的应用程序是不可变更的，镜像一旦完成了构建，预计在不同的环境中运行都不会改变。这意味着在因外部环境的不同，在需要的时候需要使用外部手法处理所依赖的外部配置数据，而不是每个环境修改或者构建不同的容器。而容器应用程序中的任何变更，都应该因此触发构建新的容器映像，并在所有环境中重用它。相同于这个原理的，不可变服务器和不可变基础架构的概念也很受欢迎，并且对于服务器/主机管理也是如此。\n在遵循IIP原则的情况下，应该防止为不同的环境创建相似的容器镜像，要始终坚持为所有环境只配置一个容器映像。 这个原则允许在应用程序更新期间，采用自动回滚和前滚等做法，这是云原生自动化的重要方面。\n进程可处置性原则 PROCESS DISPOSABILITY PRINCIPLE（PDP） 迁移到容器应用程序的主要动机之一是：容器需要尽可能做到临时性，并做好在任何时候被另一个容器实例替换的准备。需要更换容器的原因有很多，比如：健康检查失败、缩容、应用程序将容器迁移到不同的主机，平台资源匮乏或其它的问题。\n这意味着容器化的应用程序必须保持其状态为向外扩展的或分布式和冗余的。这也意味着应用程序应该快速启动和关闭，甚至为彻底的硬件故障做好准备。 实施这一原则的另一个有用的做法是创建小容器。 容器在云原生环境可以自动调度并在不同的主机上启动。较小的容器可以实现更快启动时间，因为在重新启动之前容器镜像需要被物理地复制到主机系统。\n自包含性原则 SELF-CONTAINMENT PRINCIPLE（S-CP） 这个原则规定一个容器应该在构建时包含所有需要的东西。容器的存在应该仅仅依赖于Linux®内核，在并添加相关额外的库，在容器构建时加入它们。除了库之外，它还应该包含语言运行时，应用程序平台（如果需要），以及运行所需的其他依赖关系，等运行容器化应用所需要的诸如此类的东西。\n唯一的例外是：由于不同环境之间差异，并且只能在运行时提供的配置; 例如，通过Kubernetes提供的ConfigMap。\n某些应用程序由多个容器组件组成。 例如，容器化的Web应用程序也可能需要数据库容器。 根据这个原则，并不建议合并两个容器。相反，它建议的是数据库容器只包含运行数据库所需的所有内容，Web应用程序容器只包含运行Web应用程序所需的所有内容，如Web服务器。 在运行时，Web应用程序容器将根据需要依赖于并访问数据库容器。\n运行时约束性原则 RUNTIME CONFINEMENT PRINCIPLE（RCP） S-CP从构建时的角度查看容器，并关注于生成的二进制文件及其内容。但是容器不仅仅是磁盘上一个只有尺寸大小的单一维度的黑盒子。 容器运行时有多个维度，例如内存使用维度，CPU使用维度等资源消耗维度。\n这个RCP原则建议每个容器申报资源需求，并发送信息到平台。它应该分享容器的资源配置文件，从CPU，内存，网络，磁盘的角度声明。这影响到平台如何执行调度，自动扩展，容量 管理以及容器常规的服务级别协议（SLA）等。\n除了向平台声明容器的资源需求之外，还有一点也很重要， 应用被约束在使用所声明的资源需求内。如果应用程序对资源的使用保持在约束的范围内，则当资源匮乏发生时，平台不太可能将其终止和迁移。\n结论 云原生不仅仅是一种最终状态 - 它也是一种工作方式。 本份白皮书描述了一系列容器应用的基本原则，必须遵守才能成为优秀的云原生公民。\n除了这些原则之外，创建良好的容器应用程序还需要熟悉其他容器相关的最佳实践和技术。 尽管上述原则非常根本，适用于大多数用例，下面列出的最佳实践在应用和不应用的时候，则需要判断力。以下是一些与容器相关的更常见的最佳实践：\n镜像要尽可能的小。 通过清理临时文件，并避免安装不必要的软件包来构建小尺寸镜像。 这减少了容器的尺寸，构建时间和复制容器镜像的网络传输时间。 支持任意用户ID。 避免使用sudo命令或要求特定用户名运行你的容器。 标记重要的端口。 虽然可以在运行时指定端口号，然而使用EXPOSE命令在运行的时候指定，则可以让镜像的使用者更轻松。 为持久数据使用卷。 在容器摧毁之后还需要保存的容器数据的，必须将数据写入一个数据卷。 设置镜像元数据。 以标签和注释形式存在的镜像元数据可以使您的容器镜像更加实用，从而为使用您的容器的开发人员提供了更好的体验。 使主机和镜像同步。 一些容器应用需要容器在某些属性（如时间和机器ID）上与主机同步。 这里是指向各种模式和最佳实践的资源的链接，以帮助您能有效地实现上述目标：\n• https://www.slideshare.net/luebken/container-patterns • https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices • http://docs.projectatomic.io/container-best-practices • https://docs.openshift.com/enterprise/3.0/creating_images/guidelines.html • https://www.usenix.org/system/files/conference/hotcloud16/hotcloud16_burns.pdf • https://leanpub.com/k8spatterns/ • https://12factor.net ","date":"2018-03-24T20:51:01+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/BingWallpaper-2018-03-20.jpg","permalink":"https://martinliu.cn/blog/cloud-native-container-design/","title":"容器化应用的设计原则"},{"content":"使用DevOps的目的是改变和改善开发与IT运营之间的关系，倡导两个部门之间更好的沟通与协作。虽然这看起来有些简单，然后，DevOps工程师还需要做更多的工作，才能成功部署代码，并将Dev和Ops两个部分成功地绑定在一起。\n从应付DevOps压力的角度出发，DevOps工程师除了需要日常技能的基础，每个工程师都必须具备多种技能。DevOps工程师除了要对脚本和编码有着强烈的热情之外，还必须具有开放的思想和协作精神，才能成功地执行该过程。\n“DevOps教练”参考一些文献，已经为你设计了一个清单，列出了下面的7种必备技能，公司的DevOps工程师的招聘需求里，应该明确提出下列所有品质。\n1. 灵活性 编码是一个持续的过程，不断变化，总是需要更新。要成为一个成功而有效的DevOps工程师，理想的候选人必须有能力不断地开发新的系统，并将其集成到主干代码中。DevOps工程师必须具有灵活的工作技能并适应不断变化的代码。\n无论是集成、测试、发布还是部署，工程师都必须能够轻松地从一个软件构建领域迁移到另一个领域。例如，持续集成需要具备快速有效地管理变更的技术技能，并且能够在团队中协作，以保证每个人都朝着共同的目标努力。\n2. 安全技能 与许多其他所熟练的领域一样，安全始终是最重要的，尤其是在编码方面。黑客进入系统的一个简单方法是利用漏洞，破坏现有的系统并获取数据。 DevOps带来了更快的代码开发和部署周期，这意味着漏洞也比以前更容易引入代码。因此，工程师必须具备编写安全代码的技能，以保护应用程序免受不期望的攻击，此外还要确保系统针对常见的网络安全漏洞建立防御机制。\nDevOps工程师在受雇时必须具备安全技能，因为软件从部署一开始就内置了安全性(而不是在以后添加)是至关重要。如果从一开始就没有安全措施，那么黑客就有更多的机会通过网络注入破坏性代码。因此，在招聘下一位DevOps工程师时，确保安全性是技能列表中最重要的一项。\n3. 协作 对于一个成功的DevOps工程师来说，不具备八面玲珑的和周围打成一片的能力是不行的——协作实际上是DevOps概念的核心，它将软件开发和软件运维结合在一起。DevOps工程师必须具备团队合作的能力，在DevOps流程中协作提供了更多的跨职能的联动。\n4. 脚本编写技巧 尽管这一点听起来很显然，但任何开发人员都必须具备编写代码的高超技能。无论是JavaScript、Python、Perl还是Ruby，一个成功的开发工程师都必须能够编写代码。\n从编写手动代码到替换手动操作流程(如分配IP地址或DNS代码)，必须团队里必须具有能够编写这些代码的人员，这是完美的候选人应该能够做到的。\n5. 决策 一个优柔寡断的候选人不是你想要的业务开发工程师。一个成功DevOps工程师候选人将有能力自信而迅速地作出决定，即使是在繁忙的环境工作。\n代码不断变化的特性使得必须快速决定如何修复代码中任何不连贯的元素。果断性必须是雇用DevOps工程师时要考虑的一个因素，因为快速决策允许工程师保持快速开发和部署新编码更改的能力。\n6. 基础架构知识 脚本编写只是开发人员应具备的关键技能之一，仅次于云和基础架构的经验。工程师应该对基于数据中心和云基础架构的各种组件的工作方式有一定了解。这包括软件如何联网、并运行在虚拟网络上等要素。\n如果没有理解基础架构的能力，要成为全栈软件开发工程师可能会有些困难。整合基础架构技能将使有效的DevOps工程师能够使用最佳的平台，有效地设计和部署应用程序。还能提出优化建议。\n7. 软技能 如上所述，当一名DevOps工程师不是一个人在工作，所以在这种情况下，任何未来的员工必须具备软技能和技术。在信任的前提下，DevOps文化使所有员工能够与流程进行沟通和理解，在需要的时候作出变化。\n当开发人员有效地相互沟通时，应用程序可以在比某些工作人员不在上下文中的情况里要短得多的时间内交付。以及更快的进入市场，良好的通信将导致更少的错误，从而降低成本并提高代码质量。\n","date":"2018-03-24T00:00:00Z","image":"https://res.cloudinary.com/martinliu/image/upload/Nyala_ZH-CN13349334824_1920x1080.jpg","permalink":"https://martinliu.cn/blog/7-skills-devops-engineer/","title":"7种DevOps工程师必备技能"},{"content":"DevOps已经出现了很长时间，我们中的很多人都认为它只是一个时髦词。现在我们知道这并不是一个神话。DevOps已经成为一个IT主流的焦点，并且在过去的几年里一直在重塑着软件世界。专家表示，DevOps将成为主流，2018年DevOps的人气将达到顶峰。\n下面是术语“DevOps”在Google趋势里的现状，以及对2018年预计增长的假设。 谈到统计数据，从2015年到2016年，DevOps的应用企业数增加了约8%，预计2018年这一数字将大幅增长，如上所示。\n你可以阅读RightScale的整个报告。甚至Forrester的报告也明确提到2018年将是DevOps的一年。\n最近发表的关于DevOps的事实和统计数据的文章得到了DevOps爱好者的热烈响应，它只是表明许多技术布道者者对了解更多DevOps并在他们的组织中实施DevOps很感兴趣。\n今天，我们将看到以下事实将塑造DevOps的未来。\n1 将重心从CI流水线移到DevOps装配线 通过CI流水线可以显示应用程序从源代码管理到生产的完整可视化。你可以在一个统一的视图上看到一切。它不仅仅只关于CI，它更多是作为CD (连续交付)的基础；组织正在投入时间和精力来进一步了解自动化其完整的软件开发流程。2018年，第一大DevOps转变将是从单纯的CI流水线转变为DevOps的装配线链接是Shippable关于装配线的描述。\n2 自动化将成为主要关注点 在DevOps中，我们经常谈论自动化。如果可能，对服务器的零接触自动化将是未来的趋势。这并不意味着你必须自动化一切，但如果你必须这样做，那么你应该能够做到。了解DevOps循环的6个C，并确保在这些阶段之间应用自动化是关键，这将是2018年的主要目标。\n3 测试人员需要学会编写代码 在DevOps中，需要测试人员知道如何编写自动化脚本来测试各种情况。如果您是一名测试人员，如果在是否学习编码的问题上进退两难，那么我建议您学习编码。了解不同的DevOps工具和自动化脚本，在当今的软件开发中起着至关重要的作用，这将在2018年占据主导地位。\n如果测试人员不学习自己编写自动化测试脚本，他们将会灭亡。手动测试将在2018年过时，它将占用大量时间。自动化测试不仅可以提高效率，还可以确保功能更快地交付给市场。\n4 微服务体系结构应用的增加 DevOps和微服务最近正是天作之合。微服务是独立的实体，因此不会在出现问题时由于任何依赖关系而中断其他系统。微服务体系结构可帮助公司轻松进行部署和添加新功能。预计公司将转向微服务体系结构，以提高其运行时间和效率。不要因为别人采用了微服务体系结构就跟着他们走，点这个文章：了解自己并理解为什么应该采用微服务体系结构。\n5 预计将有更多的公司选择企业版DevOps工具 目前有许多公司仍然处于建造还是购买的两难境地。但是，我们建议您做您最擅长的事情，并根据您的要求购买工具。这不仅有助于您专注于自己的目标，而且通过完全依赖第三方平台来提高工作效率。许多公司现在都在寻求企业版本，以获得自己的DevOps基础架构，并确保安全性尽可能掌握在最佳人员手中。\n6 KUBERNETES将会大行其道 Kubernetes因其优异的功能性和易用性，从而成为增长最快的容器技术。kubernetes围绕它建立了一个伟大的开源社区。在全球范围内，许多首席信息官和技术人员都采用了Kubernetes，采用比例预计将在2018年进一步提升。\n最近，在KubeCon + CloudberNativeCon北美( 2017年12月6日至8日)之前，云计算基金会进行了一项调查，并分享了容器编排环境正在发生的变化和向Kubernetes的转变。\n来源:容器业务流程环境正在更改。\n以上是将在2018年复现的DevOps的6个趋势。\n","date":"2018-03-23T17:50:25+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/Decaying_Startrails_nimiaRM_165652_1080_HD_ZH-CN1933491271.jpg","permalink":"https://martinliu.cn/blog/6-devops-trends-aware/","title":"2018年必须认识到的6个DevOps趋势"},{"content":"本文向你简要介绍2018年DevOps界的15大最重要的大会活动。DevOps的一个方面就是持续\u0026hellip;\u0026hellip;.参加大会学习！全球范围内看，基本上每个月都至少有一个我们值得重点关注的大会。我们不能奢望都你有机会参加，但是作为DevOps业内人士，如果你不了解这个大会的情况，你就Out了。\n这些大会中有些社偏技术的、有些是注重社交和体验；根据你的业务需求和学习目标，今年走出去参加最高端DevOps盛会的奢望可以有。不提前做功课，怎么能说服领导支持你呢？万一领导批准了呢？\n1. Cloud \u0026amp; DevOps World June 12-14, London\ncloud\u0026amp;DevOps World是techxl 8的一部分，是一系列各种技术会议、网络机会和博览会的一部分。cloud\u0026amp;DevOps World涵盖云创新和管理微服务、DevOps、容器、无服务器体系结构和监管实践。云与云世界的一大亮点是，您可以通过展览的其他部分(如物联网和虚拟现实会议)看到云概念和云概念在发挥作用。\n与会者还可以向观众演示他们的云解决方案，并享受联网、交互式会话和讨论面板。在去年的展会上，有300多家参展商和15000多名与会者参加，使这成为业界最大的展会之一。\n2. DevOps Enterprise Summit (DOES) June 25-26, London\nDevOps企业峰会针对的是参与DevOps革命的主要企业的高级经理。该大会深入探讨了各种重要的主题，一方面涉及技术和架构问题，另一方面涉及领导力挑战。DevOps Enterprise Summit的主题演讲、专题小组讨论、聊天室、社交圈区和展览大厅。\n伦敦活动的讲演者包括来自IBM、Puppet、微软和各行各业的资深人士。DOES是一项每年举办两次的活动，地点在美国和欧洲之间变化。上一次在旧金山举行的展览有1400多人参加。\n3. O’Reilly Velocity Conference June 11-14, San Jose\nVelocity会议是本列表上排名第三的活动，由O’Reilly Media欧莱利媒体公司举办，该公司是一家技术媒体公司，在各种技术领域举办了无数的展览。Velocity会议在讨论站点可靠性工程、基础架构(如代码)、混沌工程、自动化、连续交付、恢复能力和安全性时，吸引了web ops、系统工程师和开发专家。圣何塞展览(今年在不同城市实际上有三个Velocity会议)的演讲者包括来自微软、Netflix、亚马逊和谷歌的代表。\n4. ChefConf May 22-25, Chicago\nChefConf面向开发、自动化和法规遵从性感兴趣的管理员和开发人员。ChefConf关注处理整个应用程序开发和管理生命周期所需的策略和技能。本次活动侧重于实践和经验，以涵盖构建云应用程序、持续法规遵从性和广泛的自动化等活动。去年的ChefConf吸引了大约1，500名与会者，来自Chef和其他重要科技公司的演讲者。\n5. Continuous Lifecycle May 15-18, London\nContinuous Lifecycle每年在伦敦举行，主要集中在开发、容器化、连续交付和敏捷方面。这是一个为期三天的活动，包括会议和研讨会，与会者包括开发负责人、架构师、开发人员、CTO、工程师和工具/基础架构专家。每一个行业都有代表，从高技术的最高水平到制造企业。\n6. DevOps Con May 28-31, Berlin\n你是德国人吗？就算你只能说有点德文，DevOps Con也是值得一游的。它可能被认为是一年中最重要的持续交付会议，在微服务、Docker、云计算和精益业务方面进行了出色的讨论。今年的演讲者包括优步、红帽和西门子的高级职员。DevOps Con演讲者使用德语和英语，让与会者忙于实际的研讨会、会议和主旨演讲。\n7. DevOps Days 今年DevOpsDays在国内举办三场：北京-5月，上海-8月，深圳-11月。\n如果你还不能参加一个DevOps Days会议，那你肯定是住在了月球上。从亚特兰大到苏黎世，DevOps日一年四季都在不断发生，一个月内有多达几十个大会活动，遍布全球。DevOps Days活动关注软件开发和IT基础架构运营，重点关注自动化、测试、安全性和组织文化。\n每场大会的地点都不尽相同，因此如果您有特定的感兴趣区域，请确保您注册了最感兴趣的城市，以便充分利用2018年DevOps的重大活动。DevOps Days甚至鼓励专业人士在大会上组织自己的日程。\n8. DockerCon June 11-15, San Francisco\nDocker大会的演讲者人大多来Docker本身，这并不奇怪。然而，在过去的几年里，来自AWS、Puppet、Cisco和cloudBee的演讲者也逐渐加入。为期三天的会议探讨了分布式、基于容器的应用程序的未来，并提供了一个引人入胜的视角，看看领先公司目前是如何开发Docker平台和容器的。\n与会者将有机会参加技术演示、实验教程和主题演讲。上一届会议有5 000多人出席。\n9. Gartner IT Operations Strategies and Solutions May 15-17, Orlando\n由于Gartner分析师的数量超过了您的能力范围，因此IT运营战略和解决方案展览是向真正了解DevOps行业全局的专家学习的绝佳途径。\n该活动非常适合IT运营管理、云运营和IT服务支持专业人员。今年展会的主题包括IT运营优化、开发与敏捷、云与自动化、新兴IT运营趋势和战略。\n10. IT/Dev Connections Oct 15-18, Dallas\nIT/Dev Connections将自己描述为“反基调”会议。这意味着它集中于实践科目和培训，避免了供应商过多的营销。说到实际，IT/Dev Connections的组织者甚至有一个“出勤证明中心”。\n除了各种讲习班、小组讨论和网络活动外，该会议还值得一提的是其妇女参与技术午餐会。IT/Dev Connections分为五个方面，涉及云和数据中心、数据平台、业务智能、企业协作、管理、移动性、安全性和DevOps的会话超过250个。\n11. Jenkins World September 16-19, San Francisco\nDevOps只是Jenkins World涵盖的主题之一，它还涉及社区、CloudBee和生态系统等不同领域。虽然这一活动更倾向于一个特定的工具集，但它仍然非常受欢迎，2017年的活动约有2，000人参加。过去的讲演者代表了诸如Docker、Red Hat和亚马逊网络服务等公司。\n12. Large Installation System Administration Conference (LISA) October 29–31, Nashville\nLISA会议将自己标榜为“供应商中立”，以便将市场营销保持在最低限度。LISA由美国先进计算系统协会Usenix组织，每年在美国不同的城市举办。本次大会吸引了大量供应商和系统管理员，重点关注关键系统的设计、构建和维护，以及围绕体系结构、文化和工程的实际考虑。讲演者包括戴尔、Netflix、Facebook和fasty等公司的高级代表。\n13. Microsoft Ignite September 24-28, Orlando\n这将是2018年DevOps所有活动的母亲，因为这个大会看起来将超过2017年的人数，将有超过24000人参加。事实上，微软于2014年开始将Ignite作为合并多个会议的一种方式，数字反映了这一点。预计Ignite将非常繁忙，因为它涉及700多个演讲。然而，并不是所有的事情都与微软有关，因为展会包括100多家供应商，他们都是展会和会议演示的一部分。\n14. Monitorama June 4-6, Portland\nMonitorama是另一个特别的大会，它只限于关于软件和基础架构监控工具和技术的主题。它还主办了一次黑客马拉松活动。Monitorama是为数不多的只有一个主题的大会之一，这样与会者就可以专注于一个问题，避免FOMO体验。该大会自2013年以来一直在进行，观众人数限制在600人左右，因此尽早预订是个好主意。\n15. PuppetConf 2018 October 9-11, San Francisco\nPuppet是一种开源配置管理工具，它对DevOps、云管理、下一代基础架构、应用程序交付、安全性、法规遵从性和持续交付的影响非常重要。\nPuppetConf由100多位专家提供了80多个课程，是一个非常棒的学习体验，无论是初学者还是老兵。PuppetConf由IT主管参加，他们希望获得有关DevOps转换、云迁移和持续交付的建议。2017年活动的讲演者包括来自Twitter、Yelp、谷歌、销售人员和Slack的Puppet员工和专业人士。\n后记 本文的清单是15个比较出名的大会，我发起并动态更新的全球DevOps重要大会的日历，访问的地址在这里：https://teamup.com/ks5kh2kcca4w6xva4y\n目前整理的全球大会日程表见下图（持续更新中，请直接查看线上版本）：\n最后一招：参加大会是为了学习先进思想和实践，这些大会是货真价实的真理发源地，在诸位参会学会了以后，回到公司，万一领导还是不理解，不支持怎么办？而且领导也不感冒参加这些大会。那么你可以在公司内部举办类似的大会，可以请外部的和尚来自己的庙里念经。这也是我们中国DevOpsDays核心组织者的一个想法，希望能够提供协助和支持，帮助所有传统企业早上走上上下一心的DevOps转型之旅。\n","date":"2018-03-22T08:30:13+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/carauari-brazil.png","permalink":"https://martinliu.cn/blog/2018-best-devops-event/","title":"2018值得关注的15个DevOps大会"},{"content":"持续集成通常是针对应用而言的，可是基础架构的持续集成应该怎么做？基础架构的持续集成应该属于持续交付/部署的基础。贯串本文的一个问题，或者在阅读本文时，您应该不断地问自己这个问题：我们的应用部署流程是怎样的？\n在回答这个问题之前，我们先来回顾一下，目前几乎所有人正在使用的手工环境和资源交付流程。在源码被编译打包了以后，安装包文件被上传保存到了内部的某个文件服务器上。Ops团队的某个组/人被分配到工单，根据工单描述的需求，它在测试或者生产环境中开始工作：\n用图形界面进行虚拟机模板的手工克隆工作，或者由于没有相应的权限或者自助服务，不得不给虚拟化管理员发任务单，然后等待回复。 获取用户名和密码手工登录服务器，有些企业还要是等待领导的审批，才能得到密码信封和所需要的访问密码。 根据工单（变更单）里的描述和自己的经验对虚拟机的操作系统进行配置，在这个过程中，Ops往往可能还需和需求方进行不止一次的沟通，确认相关参数。 手工的下载应用安装包，然后分别手工上传到目标的服务器，凭经验和工单信息部署应用，然后测试部署结果，可能是看下页面有没有正常显示，或者服务起没起. 手工测试和确认这些虚拟机的服务和状态，凭经验觉得OK了以后，回复工单，关闭工单。 以上的工作场景，可能是Ops人员很常规的一天，或者是几天内的工作，当然在这个过程中，他们还需要参与一些救火行动；他们在这个过程中也可能会有疑问，也可能会对此工作结果不确定；但是，日常的工作经验告诉他，差不多了，关闭任务单要紧，还有好多项目催活呢！就这样，配置并不精确的虚拟机环境就交给了下游的需求方。\n以上工作过程的问题如下：\n工作周期长，速度慢。实际上工作周期拖延的越久，工作结果的质量就越差，而并不是我们想想中的慢工出细活。 所有步骤都是纯手工操作，不仅费事费力，而且出错几率高，也几乎不可能无痛的回退。可能有人会说了，我们不需要那么快，我们也不是互联网公司；可是从精益思想的角度看，以上这些工作都属于对业务价值的交付贡献为零的工作；你可能是由于公司给你发着工资，才错误的感觉到，这项工作活动应该有它的价值。 上游传递来的信息可能不全面，不准确，因此Ops很有可能造成错误配置，因此会返工。 传递给下游的虚拟机很可能会在后续的部署过程中，由于应用需求的变化，而需要下游的人员对其重新配置，产生重复的劳动。 手工部署的时间和代价 = 应的数量 X 应用版本数量 X 环境数量\n对以上工作系统进行优化的原则：如果某一项活动的重复频率越高，那么对它进行优化，所产生的回报也会越明显；这里还要参考限制理论，优化的顺序要正确。\n我们从这个角度出发，就可以来设定基础架构持续集成和应用部署流程的改进目标了：\n减少总体人工工作时间和代价 提高交付的速度、可靠性和频率 能进行应用部署，能进行数据库Schema的更新 能够实现部署流程的自服务，让任何需要部署应用的人能一键式部署任何版本 到了这里我们就必须将上述手工劳动，变为自动化的过程。因此，基础架构即代码IaC （Infrastructure as code）和相关的配置管理工具就会用到。\n上图是一个典型的持续交付流水线模型，在此我们对它的关注点如下：\n代码的变更被Jenkins自动化的构建（CI是基础），打包后的安装包被存储在Artifactory里，Artifactory里面还可以存储应用包的其它相关元数据，如测试结果，能否可以用于下一步部署的标签等等。 Jenkins自动化的搭建所需要的环境，调用虚拟化或者公有云资源池的API，制备虚拟机资源，然后调用Chef完成对虚拟机的配置，完成应用包部署所需要的所有层次的配置。 环境配置完成后，应用正常运行了，在相关的测试工具对部署后的环境做验收测试，Chef具有支持测试驱动的相关工具。 基础架构的持续集成 为了实现完整的基础架构持续集成流程，以上持续交付流水线必须具备的能力和概念包括：分层的系统管理、基础架构即代码IaC、配置管理、Chef工具等。下面详细对它们进行描述。\n分层的系统管理 系统管理的层次涉及到OS相关的三个层次。下面自下而上地简单描述一下。\n制备管理：涉及到虚拟化层，这一层是资源表达层，目前所有主流的虚拟化都支持标准的Rest API，包括VMWare、EC2和Nuanix等。大多数主流配置管理工具都具备用于虚拟机生命周期管理（从生成、到开机、到删除等）的API功能，能按需的获得任何数量、规模、网络和操作系统类型的部署环境。 配置管理：在任何类型的操作系统里自动化的安装和配置软件包，将所有配置参数配置好以后，持续保持这些配置点的状态。对于简单应用，来说按配置参数启动服务即任务完成。 应用编排管理：对于复杂的分布式系统，由于各个自服务之间存在着依赖关系，所有自服务之前需要互通一些配置参数才能实现，应用程序整体的正常运行，配置应用服务器的odbc数据库连接，配置web前端的ldap认证服务器等等。目前微服务所涉及的服务发现和路由，是应用编排必备的配套设施。 不同的DevOps配置管理工具也都力求能覆盖以上三个层次，但是他们所追求的方向，或者想解决的主要问题并不相同。因此各个工具之间功能上有重叠。\n因此在运用这些工具的时候，不仅要追求其卓越的功能，还要能意识到，并有意的在不同层面上做取舍。\n基础架构即代码 IaC这个概念最早是被Chef这类工具提出并实现，它的基本想法就是让Ops人员象开发人员一样的，工作在基础架构的代码上，而不是面对着数十个图形和文字终端界面。使用类似于开发应用程序的方式，开发和管理基础架构环境，因此基础架构能通过API访问和操控是基础，目前所有主流的虚拟化/云计算平台都具备很好的API接口；可惜的是在传统的企业环境中，这些资源池的API功能几乎没有被用到。\n像开发应用代码一样的管理IT基础架构，基础架构的开发和管理也需要遵循与应用开发类似的原则，这些原则包括：\n一切从源代码开始:并对其进行严格的版本管理，要对基础架构变更，就需要对相应的代码进行变更和测试，最后发布这些代码。从而力求做到服务器的无人登录运维。 模块化设计:不同应用底层所使用的基础架构有着大量的相似之处，模块化的设计不仅意味着标准化，也意味着更少的重复代码。我所用过的Terraform、Chef和Puppet这三种工具，都具有高度的模块化特性。 抽象能力：能够使用不同的模块和参数对任何特征的应用进行建模，用IaC代码进行表达，基础架构的代码开发也就是借助这种抽象能力，将所有管理对象（配置管理项）具体化地描述为应用服务模型。编写出来的基础架构代码，不仅包含了所有对应用配置描述性的语义，而且还是能够被执行的代码，在IaC代码执行之后，你就得到了所期望的虚拟机、应用配置和应用服务。 可测试性：这是一个经常忽略的能力，而在了解之后，你会发现IaC也是编程语言，就是对基础架构进行高级的编程，而且IaC代码本身和它的运行结果都是可以测试的。在执行前对其语义语法测试，在运行以后对其运行结果测试。Chef在这方面表现的尤为突出。 配置管理 我可能是最早的一批进行ITIL配置管理实践，CMDB建设的这批人；我以前和甲方客户有着大量的关于配置管理和CMDB的对话，所经历过的项目也非常煎熬。而在DevOps场景下，感觉以前的经历也是很有意思的，只是我现在说到的CI，在没有特指的情况下，是持续集成的概念，还不是配置项了。\nProcess for establishing and maintaining consistency of a product’s performance, functional and physical attributes with its requirements, design and operational information throughout its life。\n以上是配置管理在维基百科里的定义，它所表达的含义还是值得借鉴的；而如今很多人对DevOps的认识，还有人是建立在DevOps配置管理相关的工具上的。为了纠正这个错误观点，我们经常说：“天文学并不只是关于望远镜的。”\n配置管理工具中有很多是基于主机（OS）的管理工具，包括：CFEngine、Puppet、Chef、Salt和Ansible等。它们都具有基础架构即代码的相关原则和特征。都能实现：定义服务器的目标期望状态的能力，在每一次执行周期里，它们都进行状态检查，汇报当前状态和目标状态的偏差，在必要的时候也可以自动的执行必要的状态修复操作。\nChef这种配置管理工具，使用了Ruby风格的DSL语言，使用者只需要用Chef代码表达”What“即可，而不需要明白”How“；”What“既是对目标配置状态的描述，使用者只需要将需求转换为Chef代码，然后用Chef客户端工具运行它即可。Chef的代码清晰，描述能力强大。在编码的时候遵循DSL规则，如果有必要的话也可以调用Ruby。\nChef是客户端服务器的架构，安装了Chef-client程序的节点可以注册到一个Chef管理服务器里。\nChef的开发人员（IaC编码者），在安装了用于和Chef服务器交互的名为knife的工具，称之为工作站的系统上开发基础架构代码。Chef使用大量内置的DSL资源（例如：package，service，file，directory等操作系统资源分类）对目标节点的配置进行建模，代码可以映射到内部的用来执行这些代码的各种提供者上。\n所能实现的示例代码如下所示，下面是配置Linux操作系统中的Apache服务器。\n1 2 3 4 5 6 7 8 package \u0026#39;httpd\u0026#39; do action :install end service \u0026#39;httpd\u0026#39; do action [ :enable, :start ] end 下面是在Linux操作系统里配置 /a/b/c 目录\n1 2 3 4 5 6 7 8 directory \u0026#39;/a/b/c\u0026#39; do owner \u0026#39;admin\u0026#39; group \u0026#39;admin\u0026#39; mode \u0026#39;0755\u0026#39; action :create recursive true end 以下面就是 /a/b/c 目录的配置结果状态：\n1 2 $ls ‐ld /a/b/c drwxr-­‐xr-­‐x. 5 admin admin 4096 Feb 14 11:22 /a/b/c Chef其它的重要术语：\nrecipe ：包含了一个或者对个资源描述定义（Chef预定义了文件、用户、软件包、服务等等资源，可以扩展开发自定义资源类） cookbook ：包含了一个或多个recipe配方 data bag ：包含了一个或多个配置数据点(data bag item)，是JSON格式，一个cookbook食谱可以包含一个或者多个数据袋 run list ：包含了一个或者多个cookbook食谱，可将其部署在被管理的node节点上 role ：一组特定内容的run list运行清单构成了一个角色 environments：同我们现在对环境的定义，并可以一一对应起来 Chef是偏主机配置管理的非常的Iac语言，它具有很丰富的扩展能力和生态系统。它有很好的扩展能力，很强的逻辑性，能够进行深度的表达和锻造。它和Terraform和Ansible都有较大差异。\n部署流程设计 将以上手工处理过程转换为自动化执行的、一键式触发或者自动触发的流程需要关注很多个要点。\n使用Chef部署自开发的应用程序，包括配置所依赖的操作系统配置和软件，以及自身所需的应用配置。可以使用Liquibase进行数据库的schema部署和更新。可以用Jenkins协调和组织所有工序的执行。使用Jenkins管理部署流程的感觉和用它执行CI是类似。\n从简单开始，尽量将一组彼此相关的、版本化的可部署物组织在一起发布，例如在一个发布集合中可以包含：UI、REST服务器、消息服务和数据库。尽量使用一条命令构建，使用一条命令部署。\nCookbook设计类型 Library Cookbook 库食谱 ：这种类型的食谱涵盖了通用的、可重用的逻辑。例如所有配置基线，也可以是安全基线。例如：dns、ntp、主机登录提示、用户和组、禁用服务清单等等。开发扩展的自定义chef资源，用来部署自开发应用。\nApplication Cookbook 应用系统食谱 ：在以上库食谱的基础上，为一个套应用系统开发一个Cookbook食谱，每个应用可是一个recipe配方，recipe配方使用自定义开发的Chef资源。这样就形成了非常轻量的代码库。\nData Bag 数据袋：包含了各种应用配置，例如：服务端口、JAVA_OPTS等等。一个应用系统Cookbook食谱对应一个数据袋，袋子里面包含了该应用在每一套环境里的相关所有配置点。\n上线一个应用的新版本意味着新版本IaC代码的更新和部署，大致的流程是：编辑Chef代码、推送到Chef管理服务器、在节点上运行Chef客户端程序执行部署动作。Chef服务器的版本始终和版本控制库里的Master主干保持一致，这同样意味着环境配置和Master主干代码保持一致。\n用Chef开发自定义应用资源的实例代码如下，这段代码表示了一个Java应用war包的部署。\n基于类似于以上的自定义资源类型，在必要的情况下，还可以对其开发Action（chef资源的操作），可能的操作定义有：\n从Artifactory服务器下载Java、Tomcat和WAR包。 在标准的路径安装Java和Tomcat。 创建和配置Tomcat容器 在特定的容器里安装WAR包 在主机上开防火墙端口 生成应用属性文件 启动Tomcat容器 Data Bag数据袋的实例代码结构如下：\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;version\u0026#34;: \u0026#34;1.4.9\u0026#34;, \u0026#34;runtime\u0026#34;:{ \u0026#34;my-­app-­ui\u0026#34;:{ \u0026#34;java_opts\u0026#34;: \u0026#34;-­‐Xmx2G -­‐XX:MaxPermSize=1024m\u0026#34; } }, \u0026#34;app_config\u0026#34;:{ \u0026#34;db.url\u0026#34;: \u0026#34;jdbc:postgresql://devdb:5432/myapp\u0026#34;, \u0026#34;svc.foo.url\u0026#34;: \u0026#34;http://devsvc:9000/foo\u0026#34; } 以上是data_bags/my_app/DEV.json的定义，还可以有其它环境的定义data_bags/my_app/TEST.json和data_bags/my_app/PROD.json等。\n人员角色 基础架构的持续集成需要Dev和Ops的相互协作，才能做通，才能全面覆盖应用所需要的技术栈。\n部署人员 更data_bag新数据袋和环境定义文件，触发生产环境部署的动作，调度chef-client客户端的运行，或者推送新版本的Chef代码更新。\n技术负责人 维护应用系统Cookbook食谱。\n框架开发人员 维护库Cookbook食谱，维护框架，持续改进流程。\n以上这三种角色，从上到下是从Ops到Dev的过渡。对于传统IT组织的架构，部署人员是Ops团队的，框架开发人员是Dev团队的。\n这三种角色都凑齐了，才能起到全套应用系统的整体建模和编码，而且每个角色都有负责的部分。技术负责人可能是来自Ops和Dev团队的技术大拿。他们对整体的正确性和完整性负责。\n目前也有Dev团队在其内部招聘运维研发的角色。这三种角色是基础架构即代码的层次结构和人员团队架构的对应，在实际工作中可以灵活应用；一方面覆盖所有技术层次，另外一方面引入所有必要的人员，是团队形成合力。\n如果不是本着将全套应用系统做全量的部署，以上任何角色做自己职责范围内的IaC自动化实践，其实效果是事倍功半的，或者机会只有技术学习和探索的价值。\n构建Cookbook 在开发了各种Cookbook之后，我们就需要对其进行持续测试，因此就需要使用Cookbook的持续构建流程。这个步骤就如同我们对应用程序的代码做CI一样。\n开发人员（程序员不是业务应用开发者的专业名词，这里指IaC开发者，可能来自任何团队）在Workstations工作站上开发Chef的Cookbook代码，将代码提交到GitHub上的Chef代码仓库。\nJenkins的Master服务器会触发CI Job，调用Ruby Slave对Cookbook代码进行集成和测试，然后触发EC2临时实例的创建，将Cookbook在EC2实例中进行测试，使用Artifactory中存储的应用软件包部署应用。如果测试都通过了，就触发Release Job，它将Cookbook代码上传到Chef服务器，供所各种环境中的被管理节点使用。\n上图用EC2作为Chef代码的CI环境，可以替代的方案有Vagrant+虚拟化（Virtual Box或者kvm），或者使用其它虚拟机资源池，如Ovirt KVM、Xen、Nutanix。我实际测试过使用Terraform对接Nutanix资源池，虚拟机创建超级快，几乎是秒得的速度。现有的虚拟化资源池就是最方便的对接对象，需要了解一下API和对接工具即可。\n对于Jenkins构建服务器而言，每一套应用系统对应的Cookbook组/集合的测试和发布都会在同一个构建服务器上发生，一般情况下这个服务器也是这些应用的CI服务器；这个Jenkins服务器也是相关Cookbook的CI作业和发布作业的运行地点。这个服务器上会安装所需要的Ruby gem包，应该能访问到与Chef服务器链接所需要的秘钥；应该可以使用到创建EC2测试节点虚拟机的秘钥，或者说访问其他类型虚拟机资源池的用户名和密码。\nCookbook CI Job Cookbook CI作业的触发条件是：当有新Chef代码被合并的时候。它会进静态代码扫码和测试工作，包括如下内容：\n使用json和gem的相关工具分析JSON的句法 使用Tailor做Ruby的句法和风格扫描 使用Knife做Chef代码的句法分析 使用Foodctritic做Che代码的句法分析和正确性分析 Chef代码在测试虚拟机里的集成测试是本文的重点，集成测试工具使用Test Kitchen，这个工具有一系列和虚拟化/云环境对接的插件，如 kitchen-ec2插件等。能按需临时的创建用于集成测试的虚拟机，在测试完毕，得出了测试结果之后，就删除本作业所创建的临时虚拟机。\n在集成测试的生命周期过程中也可能创建多个测试虚拟机/EC2实例，这个过程使对应用系统里的所有组件进行仿真的、实际的安装包和服务部署，进行单节点或者多节点的全量应用系统部署。在每个节点上都执行Chef代码，在Chef对应用系统的配置和部署完成之后，在对运行中的应用进行验证测试，测试包括测试相关的服务端口是否能访问，返回结果是否正常等等，Chef是可以进行测试驱动开发的，因此可以写出较细致的测试代码，从而分析本Cookbook集成测试通过与否。在测试结束了以后（最好是10分钟左右或更短），删除所有测试的虚拟机资源。\n应该尽可能的优化这个集成测试，尽量缩短它的执行时间。可以创建专用的EC2-AMI/Nutanix/Kvm/VMWare操作系统镜像，预装所需要的Ruby环境和Chef工具。\n使用Chef Solo（不依赖chef服务器）执行Chef代码的测试，以免将临时节点也添加到了Chef服务器，同时也消除了Chef的客户端和服务器架构之间相互通讯的消耗，这个场景里其实没有使用Chef服务器的必要。使用一个名为CHEFDEV的伪环境来测试代码，而JSON文件里定义的真实环境则被保留用于正式生产环境。在创建EC2虚拟机的时候，给它们打上特定的标签，从而保持一定的可追踪性和环境的可维护性。\nCookbook Release Job 这个作业的运行内容和CI Job基本一致的，而它是靠人为手工触发的，从Chef角度看，可以说：本文上述的所有描述，属于Chef风格的基础架构即代码程序的持续交付。本作业将测试成功的代码在GitHub/GitLab里打上标签，并且上传Cookbook的新版本到正式的Chef生产服务器上。\n可以想象经过多个Cookbook的build job之后，Cookbook的某个版本被发布到了生产环境中，用于环境的配置和应用的部署。本Job作业交付了IaC的开发结果到生产环境中的Chef管理服务器。\n其它IaC的基础架构持续及集成与本文描述的也应该是类似流程。\n应用部署流程 Cookbook的开发和集成完毕了以后，它的结果产物是一些列新版本的Cookbook代码，它们最终上传到Chef服务器。支持生产环境应用部署的Chef服务器与各种环境保持连接，包括测试、预发布和生产等等。\n在发布过程中所使用到的制品是从Artifactory中拉取的。下面简单说下这个架构中的关键点。\nJenkins部署服务器 这是专门用于各种部署工作的Jenkins Master服务器，它和上一个步骤里Cookbook的Build服务器是不同的。它的Slave应该满足这些需求：安装了所需要Ruby环境和gem包。安装了Chef工具，并且具有能更新Chef服务器的秘钥。具有能访问各种虚拟化环境中节点的SSH秘钥。\n部署作业的类型 可以对于每一个应用组（一套应用系统）设置两个部署作业：在开发环境中的，用于开发人员使用的DEV部署作业；另外是运维人员所使用的Non-Dev部署作业。在实践过程中也能发展出其他类型。\n部署人员的工作流程：\n变更Chef相关代码和配置，包括：编辑应用的data bag配置数据点，有必要的话编辑环境文件，合并代码。 然后在Jenkins部署服务器上执行作业。 通过以上的流程和工具，开发、测试和运维的相关人员，如果需要部署应用了，就可以用一键式的、自助式的部署模式，将任何应用应用系统通过一键式的方式自动化的部署到各种应用环境中。\n这样我们将大量各种角色人员都从事的、没有附加值的应用部署工作，彻底的消灭掉了，节省的时间可以用来做更多有意义的工作，Dev人员有更多时间编码、测试人员不需要等待时间、运维人员也降低的工作压力。\n总结 关于基础架构的持续集成，还有下列值得参考的原则：\n尽可能的标准化：包括技术、设计和流程等方面；要能够支持环境的规模化扩展，例外是可以的，但是要尽量避免。 所有工具最好有API：避免在某个工具，在工具链上的任何环节的脱节。 使用多种形式的沟通路径：这个实践需要用各种方式进行宣传和推广，包括：全员大会的主题分享、每个团队的启动会议、与开发人员的随时沟通，使用文档进行知识传播和沟通。 保持乐观，尽量发现和找到那些志同道合的早期响应者，让他们和你站在一条战线上。 引用 参考视频 https://www.youtube.com/watch?v=PQ6KTRgAeMU 参考书籍 ","date":"2018-03-17T10:50:57+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/coding-snippet.jpg","permalink":"https://martinliu.cn/blog/devops-infrastructure-ci-app-deployment/","title":"基础架构的持续集成和应用部署"},{"content":"Nutanix是什么？中文名字是路坦力，是我目前所在的公司；我负责运营商行业以及与云服务商的合作业务，解决客户在售前、架构和DevOps等方面的问题，我是Nutanix Calm产品的专家。\n之前也发过一些介绍Nutanix和超融合技术的文章，本文会是一篇持续更新的文章，我会把在Nutanix上开展超融合的方法，持续的更新在这里。\n本文上属于Beta版本，会持续更新，欢迎各种类型的反馈信息，发邮件到： martin.liu@nutanix.com\n变更日志：\n2018-2-26，发表了相关概况介绍性内容 什么是DevOps？ 我的定义：DevOps是为了将软件开发、运维和质量保证等部门紧密地协作和集成在一起，而运用的一组成熟的、相互融合在一起的最佳实践。它使人们能准时/及时地生产软件产品或服务，从而满足企业的某个业务目标，开发与运维工作将在一个统一的目标之下协同工作，它是对IT组织内部各个角色之间的相互依存关系的一种新的理解。这个实践集合主要包含了四种最佳实践，如下图所示：\n注意：上图里Nutanix的定位在持续交付，超融合平台能高速平滑的交付IT服务。\n来自网络的其它定义还有如下。\n定义2：You cannot buy DevOps and install it. DevOps is not just automation or infrastructure as code. DevOps is people following a process enabled by products to deliver value to end users. \u0026ndash; Donovan Brown, Microsoft DevOps Program Manager\n以上出自：Donovan\u0026rsquo;s blog post on \u0026ldquo;What is DevOps\u0026rdquo;.\n定义3：DevOps（Development和Operations的组合词）是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。\n以上出自：维基百科 Wikipedia - DevOps\n什么是HCI-超融合基础架构 我对超融合的定义：将计算、存储和网络这三种资源的至少两种融合在一起的技术就可以称之为超融合技术。Nutanix是将计算和存储融合在了一个系统只能，这里说的系统可以理解一个物理的机箱，并且在这个机箱里搭载了目前业内最通用的KVM虚拟化功能。Nutanix的超融合系统是开箱即用的IaaS平台，可以无节点数限制的水平扩展，能够支持服务器虚拟化、VDI、Oracle RAC等关键性数据库、企业核心业务系统、大数据和私有云等工作负载。在性能和功能上是专门为HCI而打造的。HCI技术正在颠覆着传统的三层架构技术堆栈（指的是：服务器-存储网络-集中存储）。\nNutanix在2018年Gartner融合基础架构分析报告中，Nutanix在领导象限里遥遥领先。\n2018 年 2 月 9 日，北京 ——企业云计算领域的领先企业 Nutanix（纳斯达克：NTNX）今天宣布， Gartner 将 Nutanix 评为 2018 年 Gartner 超融合基础架构（HCI）魔力象限领导者。Nutanix 认为，此次跻身“领导者”象限有力印证了 Nutanix 在其率先开拓的市场上的领导地位，也充分彰显了公司致力于提供下一代企业云操作系统的愿景。\n随着越来越多的企业机构认识到超融合基础架构（HCI）的优势，企业基础设施正在经历根本性的转变。这些企业机构采用了一种新的架构设计，将网络规模技术和消费级设计相融合，实现“隐形基础设施”，从而使 IT 团队能将更多的时间投入到业务应用中。同时，这些企业机构还纷纷采取了能够利用多云基础设施和云服务的 IT 战略。\nNutanix 认为，利用其企业云操作系统软件，用户不但能实现公有云的精简性、敏捷性以及部分 IT 消费收益，还能保障企业数据中心的高可控性与安全性。在融合了私有云、公有云和分布式云的统一 IT 操作环境下，Nutanix 企业云操作系统软件提供单点控制来管理任何云的基础设施与应用，从而为云运营商和采用云交付式服务及应用的用户提供统一、高性能、无缝的使用体验。\n关于Nutanix的更多视频，请访问Youku的频道。\n学习Nutanix核心技术 关于Nutanix超融合系统的核心技术特性请访问：Nutanix 圣经，圣经网站上有中文版本pdf下载，最近会有一次中文版的修订请关注。\n试用Nutanix产品 Nutanix提供免费的社区版本，对此感兴趣的人都可以下载和使用。使用这个版本，你能够在几个小时内，搭建起数量为1、3或者4个的物理服务器组成的Nutanix集群。\n关于如何安装和试用Nutanix CE版本的技术文档，访问我的Nutanix实验室文档站点：https://nutanix.martinliu.cn/\n使用Nutanix Calm实现DevOps持续交付 Nutanix是一种开箱即用的高性价比的虚拟化资源池，你可以用最小的时间成本完成大规模资源池的搭建和部署。而现实情况下：所有企业的虚拟化管理员的工作模式还是基于工单的手工VM模板克隆的方式。还没有人能将基于vm的业务系统做到自动化的持续交付。Nutanix Calm就是一项解决这个问题的技术。它是Nutanix超融合系统内置的一个功能，可以一键式的开启这项功能。\nNutanix Calm的主要功能如下所示：\n应用生命周期管理：利用预定义的应用蓝图，全面地实现了传统型多层应用和流行的分布式服务的自动化运维，包括系统制备、扩缩容和资源释放等操作。应用蓝图将极大地简化了私有云和公有云的应用管理和运维。 应用蓝图管理：将应用系统的所有组成部分（包括相关的虚拟机、配置和可执行程序）融入到了一个可视化的、操作直观的蓝图里，从而简化了企业应用的配置管理和日常运维。应用蓝图提升了基础架构团队的管理效率。IT团队再也不用像以前那样，在应用管理的日常工作上花费大量时间。 Nutanix应用市场：应用蓝图可以在Nutanix 应用市场（Marketplace）里把应用直接发布给最终用户，使产品经理和开发人员能够持续交付产品，快速地供给应用，及时地满足IT服务请求。 应用治理：Calm基于角色的访问控制机制可以限制用户的操作权限。此外，系统会集中地记录所有操作活动和变更，可以实现端到端的可追溯性，这些信息可以提供给安全团队，用来配合相关合规审核工作。 混合云管理：能在混合云的架构里，自动化地制备应用，包括AWS公有云环境，能实现多层应用和分布式应用的弹性扩缩容。Calm能全局统计资源用量，让您对公有云的实际消费成本一目了然，方便您按照业需求和预算做出合理的决策。 Nutanix Calm的蓝图编辑器如下所示。\n在我的Nutanix实验室：文档站点里已经写了一些操作使用的方法和产品截图。如果您已经是Nutanix用户了，请参考和使用这些文档。如果你还不是的话，可以联系Nutanix试用这个产品。\n后续会持续更新这一部分，会根据DevOps的逻辑将Nutanix Calm的能力全面的展示出来，敬请期待。\n使用Nutanix实现完美的Docker Datacenter体验 CaaS on IaaS的简洁实现方式莫过于在Nutanix超融合平台上部署Docker Datacenter产品。其实Docker Datacenter还是一个很容易使用的Docker平台，易用性非常好，入门级Docker用户建议走这条路试试，毕竟K8s的学习曲线目前还比较陡峭。\n这个组合的免费试用方法：\n安装部署Nutanix CE（文档见Nutanix实验室） 申请和下载Docker Datacenter的安装包和许可证文件（10个节点免费试用，30天到期了还可以无限次延续） 在Nutanix上创建10个虚拟机用于部署Docker Datacenter 安装部署Docker Datacenter （文档见Nutanix实验室） Enjoy it forever! 如果你使用4台物理服务器安装Nutanix CE，建议的服务器配置：2路20核 Intel XeonCPU，内存256，SSD 512GB一块，SAS HDD 4TB两块；这样形成的群集的总资源量：\n160个物理CPU核，一个物理核跑两个虚拟机的话，你可以跑320个虚拟机；当然内存够的情况下，你还可以尝试更高的整合比，如1个物理的核带5到10个虚拟机 总存储空间为18TB，使用两副本存数据，你有9TB可用空间，打开去重压缩等功能的话你可以拥有更多的存储空间。 2TB的SSD存储可以让你应付大量的热数据，所有热数据相当于使用了全闪存储一般。 建议这些服务器使用10GB或更高速的以太网，以保证更优雅的性能 不建议这个环境跑生产负载，记住不要把研发环境不算生产负载。 如果需要生产级别的保障，请考虑使用费CE版本的正式Nutanix产品。 使用Nutanix ACS2.0实现完美的K8s体验 此产品预计18年发布，敬请期待。\n","date":"2018-02-26T11:08:53+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/testdrive_background.jpg","permalink":"https://martinliu.cn/blog/devops-on-nutanix/","title":"DevOps on Nutanix[Beta]"},{"content":"\n企业如何通过DevOps实践提高盈利能力，改善工作文化，实现卓越的生产力目标。如今这些高绩效管理技术比以往的任何时候都要更加重要，由于这对于企业的商业竞争力而言是至关重的，数十年以来，技术组织的领导者们始终在努力地维持这IT系统的敏捷性、可靠性和安全性。然后惨痛的案例依然比比皆是\u0026ndash;不论是healthcare.gov的崩溃，持卡人数据的泄露；还是在云计算环境中大数据的丢失。\n然而，那些运用DevOps原则的高绩效企业（例如Google，Amazon，Facebook，Etsy和Netflix）则每天都可以在生产环境中成百上千次频繁地部署代码。那么DevOps理论、原则和实践到底是何等的殊胜呢？相信所有人在看了本书之后一定会得到答案。\n通过数字看这本书 基础数据 原作者4人 Jene Kim是这本书的主要作者，他在出版了《凤凰项目》之后，开始与其他三位作者编写本书的。Jez Humble是《持续交付》的作者，是持续交付实践和概念的重要发起人。Patrick Debios是DevOpsDays大会的发起人，是他最早在Twiter是用 #DevOps 这个短标签的，是DevOps运动和社区的重要人物。John Willis是DevOps社区早期的推动者之一，曾任Docker公司生态系统发展总监。\n译者4人 在我和人民邮电出版社联系并进行试译之后，组织了翻译小组。王磊和马博文是我这几年结识的DevOps圈内的技术大拿；曾朝京是IT管理领域的资深专家，是我的前同事。王磊的著作有《微服务架构与实践》；马博文翻译的书籍有《DevOps 实践》\n刘征，Nutanix路坦力资深架构师。Exin首批国内DevOps Master和DevOps Professional认证讲师。持有红帽RHCA认证和AWS高级架构师认证。谙熟企业数据中心的IT服务管理。目前致力于推广DevOps相关的理念和实践，在DevOps社区中积极地参与培训和研讨会等活动，DevOpsDays大会活动在中国的核心组织者。\n王磊，前ThoughtWorks首席咨询师，EXIN首批国内DevOps Master认证教练。较早倡导和实践微服务的先行者，著有国内首本微服务架构相关书籍《微服务架构与实践》一书。超过10年以上的软件行业经验，对服务化架构、持续交付以及DevOps转型等有丰富的实践经验，同时他也是西安DevOpsMeetup联合发起人，西安GDCR组织者，并译有《Ruby Gems开发实战》一书。\n马博文, 前ThoughtWorks 高级咨询师，AWS助理架构师。曾从事多年web开发和DevOps，熟悉持续交付，微服务。参与翻译《Scala编程实战》、《DevOps实践》等书，是西安DevOps Meetup活动的发起人。\n曾朝京，Micro Focus资深解决方案顾问，参加Exin首批国内Devops Master讲师认证培训。长期从事IT运维管理领域咨询工作，曾为能源、金融、航空运输、政府行业中的多个大型企业提供 IT 运维管理规划。目前致力于探索Devops理念在企业IT部门的实践。\n翻译小组完成翻译，并提交给出版社的日期是2017年12月8日。\n目录提前曝光 本书目前（本文的发布日期）正处于出版社编辑阶段。预计在五月份左右正式出版。下面是本书的目录。\n序言 前言 导言：展望DevOps新世界 第一部分 三步工作法 第1章 敏捷、持续交付和三步法 第2章 第一步，流动原则 第3章 第二步，反馈原则 第4章 第三步，持续学习与实验原则 第二部分 从何处开始 第5章 选择合适的价值流作为切入点 第6章 理解、可视化和运用价值流 第7章 参考康威定律设计组织结构 第8章 将运维融入日常开发工作 第三部分 第一步：流的技术实践 第9章 为部署流水线奠定基础 第10章 实现快速可靠的自动化测试 第11章 应用和实践持续集成 第12章 自动化和低风险发布 第13章 降低发布风险的架构 第四部分 第二步：反馈的技术实践 第14章 建立能发现并解决问题的遥测系统 第15章 分析遥测数据以更好地预测故障和实现目标 第16章 应用反馈实现安全部署 第17章 将假设驱动的开发和A/B测试融入日常工作 第18章 建立评审和协作流程以提升当前工作的质量 第五部分 第三步：持续学习与实验的技术实践 第19章 将学习融入每天的工作中 第20章 将局部经验转化为全局改进 第21章 预留组织学习和改进的时间 第六部分 集成信息安全、变更管理和合规性的技术实践 第22章 将信息安全融入每个人的日常工作 第23章 保护部署流水线 行动起来 - DevOps手册总结 附录 附加资源 以上目录标题有可能在出版社的编辑过程中会有所调整。不过已经可以看出其主要内容。\n来自出版社-IT Revolution Press (October 6, 2016) IT Revolution Press是 DevOps Handbook 一书的的出版社，位于美国的波特兰市。这本书的简体中文版的书名是《DevOps实践指南》，它是作者继《凤凰项目》之后的一个重大作品，它向你展示了如何将产品经理、开发、质量保证、IT运维和信息安全集成在一起，从而帮助你提升企业的竞争力并赢得市场；如何复制前人那些惊人的DevOps经验成果。\n那么《DevOps实践指南》是否适合你？本书的作者Gene Kim、Jez Humble、Patrick Debois和John Willis为那些希望对IT组织进行转型的人共同编写了此书；特别是为那些想通过DevOps实际进行重大的变革，从而提高生产力、盈利能力并赢得市场的人。这本书涉及DevOps转型的很多方面，是一本从规划到实操的全方位指南，同时它还介绍了DevOps的历史背景，支撑DevOps的各种原则，以及数十个DevOps案例研究。它还提供了各种最佳实践，能有助于组织团结团队一心，使他们实现共同目标，同时获得高层领导支持。\n《DevOps实践指南》深入地研究了DevOps的三个基本原则，现在我们称其为“DevOps工作三步法”，它们是流动、反馈、持续学习与实验”。 《DevOps实践指南》是Gene Kim继《凤凰项目》一书之后编写的，在那本书里也对“三步法”作了概括的描述，后来发展成为本书第一部分的重要内容。\n随着本书循序渐进地揭示DevOps工作三步法，读者将能够清晰的了解到，那些高绩效公司是如何利用这些原则取得成功的。希望任何大型组织也能够复制这些高绩效企业所使用过的成功经验，从而指导他们自己也进行一场成功的DevOps转型。本书用六个部分描述了详实的内容，其中包括：\n在五年时间里，4位合著者为本书投入了2000多小时的工作时间 40多个DevOps案例研究，包括亚马逊，Etsy，Capital One，Google，Facebook，Intuit，Nationwide保险等等 编写了长达400多页的DevOps实践指南、经验总结和工作指导。 参考和使用来来自25,000多个数据收集点的DevOps相关数据。 《Phoenix项目》（英文版）已经售出35万本，2018年2月进行了第五次印刷。《DevOps实践指南》从DevOps的历史开始讲起，解释了它是怎样从数十年的相关联的知识体系中发展出来的，以及由此应运而生的相关技术、架构和文化实践。在为读者奠定了这些历史基础后，读者就能够深入了解三步工作法的原则了。读者将逐步对当今的DevOps相关理论和原则有更深入的理解。在本书的相关章节里介绍了各种具体原则和模式，以及如何将它们应用在实际的技术价值流中。\n我们很自豪的宣布 DevOps Handbook - 《DevOps实践指南》获得了2016年，年度DevOps最佳图书奖，详见：https://devops.com/the-2016-devops-dozen-winners-announced/\n在亚马逊书网上书店 本书的英文版本在亚马逊有三种格式：Kindle、纸质印刷版和有声书版本。这本书的排名和评价如下，下图的抓取时间是：2018-2-25。\n在信息管理分类里排名：7 在流程和基础架构里排名：107 在管理书籍里排名：111 有85%的读者给本书了5星的评价。关于这本书在亚马逊的最新状态，请点这里。\n本书的日文版是在2017年6月在日本发布的，详情见日本亚马逊网站。\n本书的使用方式 在上一篇文章《DevOps登山指南》里我分析和介绍了美国金融行业Nationwide保险公司的DevOps案例，原文点这里。这家公司在实施DevOps的过程中将本书做为参考指南，所有DevOps团队通过每周一次的读书会的方式，持续地对照和改进自己的DevOps实践状态。他们总结出来的DevOps项目实施指南如下图所示：\n本图在Nationwide公司内部的使用场景如下：\n本图将DevOps实施核心团对指导产品开发团队（也可以说是业务团队、服务团队、这样的团队他们有200多个）取得的经验总结在一张纸上，供其它有实施DevOps想法的团队参考。 该登山指南简化了对其它非DevOps团队的教育和指引。 他们将DevOps的实施分成三个阶段，分别用大本营、北坡营地和顶峰作比喻。 这三个阶段里的技术实践都来自于DevOps Handbook，通过他们的筛选和整理，并根据自己的经验做了分阶段的规划。 ","date":"2018-02-25T22:27:16+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/IT_Revolution_press.png","permalink":"https://martinliu.cn/blog/devops-handbook/","title":"Devops Handbook《DevOps实践指南》简介"},{"content":"\n本文内容主要来源于《DevOps Handbook》-DevOps实践指南，本文概述的原则是DevOps工作三步法的第一步，它的目标是先建立最底层的基础，即：DevOps技术实践和合理的应用架构；只有这样才能使工作快速而稳定地从开发端流动到运维端；与此同时还能保证不会给生产环境带来混乱，不会中断客户的服务。这就意味着需要降低在生产环境中部署和发布变更的风险。可以通过 持续交付 的技术实践来实现这个目标。\n持续交付基于稳定的自动化部署流水线，团队能够使用自动化测试持续验证代码，确保代码始终处于可部署的状态，开发人员要保证每天都向主干提交代码，以及设计和实现有利于实施低发布风险的环境和软件架构。\n在流动原则的指导下，需要开展的重要的工作内容如下：\n奠定部署流水线的基础 实现快速、可靠的自动化测试 实现并实践持续集成和持续测试 通过自动化、架构解耦等方式实现低风险发布 以上技术实践能够有效地缩短创建类生产环境的前置时间。同时，持续测试可以为所有团队成员提供快速的反馈，使小型团队能够安全、独立地开发、测试和向生产环境部署代码，从而将生产环境的部署和发布作为日常工作的一部分。\n此外，通过将QA人员和运维人员的任务集成到DevOps实施团队的日常工作中，能够减少救火、困境以及繁琐的重复劳动的发生，使团队成员的工作高效且充满乐趣。这不仅能提升团队的工作质量，还能提高组织的竞争力。\n流动原则相关的详细技术实践请参考请《DevOps实践指南》一书的第三部分，这部分包含第10章到第13章，一共描述了5个技术实践。\n在流动原则里我们强调的而是全局的目标而不是局部的目标，局部目标的例子如下所示：\n特性开发完成率 测试发现/修复缺陷的比例 运维的可用性指标 我们需要减少价值流中的工作交接的次数，由于当交接次数多到一定程度时，所有人就会彻底的迷失，无法回答工作的上下文联系是什么？也不清楚我们要解决的是什么问题？或者组织的全局目标是什么？\n价值流的应用实例 如果我们选择做DevOps转型的项目是棕地项目，我们就需要对当前的工作，进行细致的值流研讨和分析；需要画出当前的状态。如下图的示例所示（注：这是一个示例，你的棕地项目分析完之后并非如此）。\n为了在实施DevOps的过程中持续的度量和改进，我们需要分析出当前价值流的核心定量指标：\n总计前置时间 = 求和价值流中每个工作步骤里的LT 【这个指标是DevOps项目的北极星】 总计增值时间 = 求和值流中每个工作步骤里的VA 完成且精确百分比 = 连乘值流中每个工作步骤的%C/A 如果是绿地项目，我们在第一个工作周里，价值流图是没有这些数值的。我们需要每天都在CI/CD流水线工具中采集相关数据，在每个人的日常工作中关注和记录相关数据，在第二周和后续的每一周里度量和分析以上指标，最好用仪表板展示工具，将这些数据实时地显示在所有项目组成员都可以轻松看到的位置。\n对这个价值流进行持续的优化，使它更高效的工作，并不断的进化和改进。如果是棕地项目，那么在分析完以上的机制流之后，可以定制新的进化版的价值流图，并按照新版本的价值流图重新开始项目的执行。如下图的示例所示（注：这是一个示例，你的棕地项目改进优化完之后并非如此）。\n优化和改进日常工作 Goldratt博士的约束理论(TOC) 在实践运用流动原则的技术实践时，可以使用Goldratt博士给出的方法，随时识别并解决价值流中的约束点，这个五步法如下：\n识别系统的约束点。 决定如何利用这个系统约束点。 基于上述决定，考虑全局工作。 改善系统的约束点。 如果约束点已经突破了，请回到第一步，但要杜绝惯性导致的系统约束。 以上五步法是DevOps实施项目组日常工作的必备流程优化工具。\n常见的4个约束点 传统企业或者团队里最容易发生的约束点有一定的共性，一般可能会按照以下顺序逐个攻克和优化：\n环境搭建 代码部署 测试的准备和执行 紧密耦合的架构 可以清楚的看到大多数约束点比较偏Ops这一侧，而攻克所有这些约束点需要Dev和Ops一起协作完成。\n常见的9中浪费 在DevOps工作团队里需要尽快能地避免以下浪费现象的发生：\n半成品 额外/多余工序 额外/多余功能 任务切换 等待 移动 缺陷 非标准或手工操作 填坑侠 以上浪费现象最早是从制造行业的精益管理中总结出来的，这些也是完全可以应用到技术价值流中，IT相关的工作能对每一条有很多痛点清晰的解读，你可以尝试在自己的工作环境中寻找以上所有浪费现象。\nDevOps工作三步工作法 in《凤凰项目》 在本书中，我们阐述了这一基础原理，即所有开发运维模式都来自“三步工作法”，它旨在阐明指导开发运维的流程与实践的价值观与理念。\n第一工作法是关于从开发到IT运维再到客户的整个自左向右的工作流。为了使流量最大化，我们需要小的批量规模和工作间隔，绝不让缺陷流向下游工作中心，并且不断为了整体目标（相对于开发功能完成率、测试发现/修复比率或运维有效性指标等局部目标）进行优化。\n必要的做法包括持续构建、集成以及部署，按需创建环境，严控半成品，以及构建起能够顺利变更的安全系统和组织。\n第二工作法是关于价值流各阶段自右向左的快速持续反馈流，放大其效益以确保防止问题再次发生，或者更快地发现和修复问题。这样，我们就能在所需之处获取或嵌入知识，从源头上保证质量。\n“必要的做法包括：在部署管道中的构建和测试失败时“停止生产线”；日复一日地持续改进日常工作；创建快速的自动化测试套装软件，以确保代码总是处于可部署的状态；在开发和IT运维之间建立共同的目标和共同解决问题的机制；建立普遍的产品遥测技术，让每个人都能知道，代码和环境是否在按照设定的运行，以及是否达到了客户的目标。\n第三工作法 是关于创造公司文化，该文化可带动两种风气的形成：不断尝试，这需要承担风险并从成功和失败中吸取经验教训；理解重复和练习是熟练掌握的前提。”\n“尝试和承担风险让我们能够不懈地改进工作系统，这经常要求我们去做一些与几十年来的做法大不相同的事。一旦出了问题，不断重复的日常操练赋予我们的技能和经验，令我们可以撤回至安全区域并恢复正常运作。\n必要的做法包括营造一种勇于创新、敢于冒险（相对于畏惧或盲目服从命令）以及高信任度（相对于低信任度和命令控制）的文化，把至少20%的开发和IT运维周期划拨给非功能性需求，并且不断鼓励进行改进。”\nFrom: [美] 金（Gene Kim ），[美] 贝尔（Kevin Behr），[美] 斯帕福德（George Spafford）. “凤凰项目一个IT运维的传奇故事.”。\n","date":"2018-02-21T23:10:01+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/IT_Revolution_press.png","permalink":"https://martinliu.cn/blog/devops-first-way-flow/","title":"DevOps工作三步法：第一步流动原则"},{"content":"美国金融行业Nationwide保险公司DevOps案例研究，来源DOES17 San Francisco，主题-DevOps Handbook Experiments in Accelerating Delivery\n全美互惠保险公司(Nationwide)美国公司。在2017年6月7日，《财富》2017年美国500强排行榜发布，全美互惠保险公司排名第68位。营业收入40074.1百万美元。\n这家公司是DevOps Handbook（DevOps实践指南）书中的案例研究之一。这是一家DevOps水平较高的企业，是DevOpsDays大会上分享嘉宾的常客，也是各个DevOps工具厂商（New Relic）经常邀请的案例分享嘉宾。他们也经常参加DevOps企业峰会，曾多次做过自己的DevOps应用状况案例分享。\n本文分析和整理了他们在2017年11月旧金山站DevOps企业峰会上他们的演讲，主题为《DevOps Handbook Experiments in Accelerating Delivery - Nationwide》（翻译：使用DevOps Handbook在加速开发交付的过程中的实验）\n本文根据这个演讲的YouTube视频整理而成。视频已经上传到腾讯视频，点这里观看该视频。\nDevOps登山指南手册 我在翻译DevOps Handbook的过程中，感觉书中所描述的这家公司的案例研究，并不像本演讲里所说的这样的精彩。\n而时光已经很快的流转到了将近2018年，他们的DevOps也经过了几年的发展，本文案例向我们展示了一个金融行业（我们往往认为不太容易实施DevOps的行业）企业，在很大的企业规模了，所取得的令人敬佩的成就。\n下面这张图是本文的精华，先给各位呈现出来。他们使用攀登珠穆朗玛峰做为比喻，对DevOps的实施做了生动的诠释。\n本图在Nationwide公司内部的使用场景如下：\n本图将DevOps实施核心团对指导产品开发团队（也可以说是业务团队、服务团队、这样的团队他们有200多个）取得的经验总结在一张纸上，供其它有实施DevOps想法的团队参考。 该登山指南简化了对其它非DevOps团队的教育和指引。 他们将DevOps的实施分成三个阶段，分别用大本营、北坡营地和顶峰作比喻。 这三个阶段里的技术实践都来自于DevOps Handbook，通过他们的筛选和整理，并根据自己的经验做了分阶段的规划。 为了知其所以然，我们将继续向下发掘，详细了解这个案例分享所讲的主要内容。下面的内容也包含了我对他们的分析和评论，欲了解原始资料，请请参看我上传到腾讯的视频。\n主题：DevOps Handbook-在加速交付中的各种实验 分享者介绍。\n这个演讲距2018年2月也就是三个月，还算是很新鲜的一个案例。Cindy是DevOps团队中的核心人员之一，她的头衔是Director，角色是夏尔巴人（后面会详细解释这个比喻的含义），为业务产品组提供内部的DevOps咨询和辅导。Jim属于业务条线/BU的Dev这一侧，他是业务部门的解决方案架构师。\nNationwide的核心价值：保护对你最有价值的 公司简介和状况。\n在很多险种上Nationwide都在业内排名第一名，包括：宠物保险、农场保险、公司寿险等等。 这是一家有90年历史的老店 汽车保险也行业排名第八（后面就是用这个业务为例，来佐证DevOps实施的效果） 不光在财富500强企业排名68，还是财富所评选的前100个最佳的工作企业。 Nationwide IT的规模很大 IT组织的特点和相关数据。\nIT组织庞大，结构复杂，业务条线众多 在选择应用某个DevOps实践的时候，总是要考虑到规模因素，需要评估该实践是否能在200多个业务开发团队的规模上全面地推广和实施 IT人员总数超过5100人，其中程序员和测试人员的数量超过2600人；在电脑世界的IT最佳工作地点的排行帮上位居第51名 该公司有用200多个产品开发团队，他们服务于23个业务部门BU Nationwide IT的组织结构 典型、复杂和庞大的组织结构\nI\u0026amp;O是基础架构和操作运维团队，该组织不仅运维了所有的IT服务，还服务于所有的业务开发团队。 多个共享服务团队提供企业级的共享服务，包括Scrum测试等传统开发服务，同时也为企业内部的DevOps实践提供技术咨询，他们支持所有类型的企业应用堆栈 业务部门如前所述有23个，有200多个开发团队，Jim服务于金融业务BU 该公司的架构模型近似于典型的Dev、QA和Ops架构；他们的Ops组织也是集中式的；如此复杂的架构带来了DevOps流水线的复杂度方面的挑战，为某个业务BU实施的持续交付流水线会横跨多个BU，有时候甚至需要三个BU的CIO级别领导一起来参与决策，这里也会出现项目投资方和项目决策方不统一的难题。 从哪里开始 应用DevOps的企业环境背景和定位。\nIT组织十年以来追求的战略目标：构建具有全球竞争力的内包式软件开发能力；为此而采用了不同的管理框架和实践，应用和开始的时间点也不同 Agile：敏捷软件开发是10年前就开始的，定位和目标是通过敏捷软件开发交付高质量的软件 DevOps：今年加入了DevOps实践，定位是如何实现速度、效率和降低风险。 Lean IT：定位是确保将IT管理的各种实践（包括以上的敏捷和DevOps）提升和推广到企业级规模。（他们认为在团队级别上任何敏捷和DevOps相关的实践都是很容易实现的，而企业级规模的推广是更高等级的管理，是不容易达到的） CMMI：使用行业规范的软件开发成熟度标准评价和考量自身的软件开发能力，为自身的不断提高提供标准参考。 该公司DevOps实践是最晚开始应用的，其它的三个方面使用的历史比较长了，为了达成一个战略目标，需要4个战术层面实践的支持，这些战术的采用时期和定位不同；4个战术从不同的侧面支持了战略目标的实现。该企业也在Lean IT的论坛上分享和演讲过。 从哪里开始（续） 应用DevOps的时间轨迹和历程，各个时期的关键词。\n2015-简化：DevOps小屋是入手DevOps实践时，最早使用过的参考框架；他们分析梳理了所有相关的方法论；工具方面专注在部署工具的改进上，所有产品线采用了IBM UrbanCode作为统一的部署工具；可是这个阶段接触的实践还是比较庞杂。 2016-组织：在获得了高层领导的支持以后，他们同时在三个方向出击：软件开发模型、精益IT管理和供应链管理；在三个方面都直接提高和优化了DevOps的速度。 2017-实验：在取得了天时地利人和之后，他们展开了所谓的“双模实验”的实践道路；从业务需求入手（规划了使用了MMP最小化可市场产品的概念），逐渐抛开了纷繁复杂的实践和方法论，他们开始聚焦在了“程序员体验”上，通过各种实验验证DevOps Handbook中描述的实践是如何影响并提升他们的。孵化和实验各种DevOps Handbook书里的实践。 2018-促动：如何把相关的工具推广到200多个开发团队，如何引入Google的SRE模型，将交付流水线作为产品对待，在复杂的组织中，实施跨部门的流水线的挑战依旧不轻。 该公司的DevOps实践道路是一步一个台阶的持续改进过程，经历了三年多时间，每个阶段的关键词代表了他们的成果和挑战。 DevOps团队间的交互模型 【重点】团队组织结构和交互方式。\n这是实验各种DevOps实践的团队组织模型，开展每项DevOps实践都遵循PDCA的持续改进方法。 所有团队遵循着三个基础原则：1速度，江湖武功唯快不破，这是他们清醒而简单的唯一追求目标，成为检验所有优化改进的唯一验收标准和条件。2实践者之成功，他们做的并不是自顶向下的、政令式的强推，而是让参与DevOps实践的团队自己提出工作想法，自己来决定在哪里尝试改进能提升速度。3范围，从端到端的价值流全局看，既不推崇极左的做法，也不推崇极右的做法，他们将范围限定在，从一张工作卡片进入DevOps产品代办工作（Backlog）开始，直至将它的成果发布到生产环境中。 实施“双模实验”团队的模型，两个团队都提出自己想做的实验想法，双方的工作内容都汇总到一个集中的DevOps产品代办工作队列中，每一项工作/卡片都是一项实验，每一项实验都由两个团队分别完成，A/B团队的做法和实现结果可能不同，这样也自然地应用到了A/B测试的模型。 DevOps Leadership Team团队里是Cindy和Jim所在的团队（应该是一个虚拟团队组织），他们确保所有代办工作都遵循以上的三个基础原则，另外使用系统性思考来确保每种实验如果取得了成功，在推敲是否它能推广并应用到其它的200多个开发团队。 DevOps平台团队辅助和优化双模实验团队的工作，例如双模团队可能都需要自动化变更流程（ITSM的管理范畴）的API，而这些工作就可以踢给平台团队做，平台团队负责设计实现这个API，并且保证它具有企业级规模的能力，然后交付双模团队使用即可。 治理团队是由该公司的各个CIO级别的利益干系人组成的，上文说过某些复杂的DevOps持续交付流水线会跨三个以上的部门，这些BU的大佬会在这个团队中；他们在每个迭代都会出现在双模团队的工作现场，一起现场查看状况，现场解决问题。Jim认为他们亲自临场观察和了解实验工作的效果，远远比将实验成果作出PPT后再给他们去汇报的效果要好。 EPIC史诗 【重点】DevOps团队根据Handbook为基础，提出了所有想实验的工作内容。\n开发团队从寻找什么拖慢了速度出发，寻找优化和改进工作内容的方法，在渐梳理和过滤以后，发现最后确定要做的工作都可以在Handbook中得到确认。甚至有些人在讨论某个工作条目的时候，能清晰的告诉大家可以参考Handbook书中的章节和页数。 DevOps产品代办工作里的EPIC史诗工作必须是在Handbook书中能够出现和参考到的，如果不是的话，团队可能会对它表示质疑。 这里Cindy简述了自动化测试这项工作的实验，故事是这样的：开发团队自己描述到，当前的Test Bed已经大到不可管理的程度，测试运行的时间太长了，因此不能保持测试的精简和有效性，这样的情况持续了一段时间以后，大家就失去了对自动化测试的信心。而且由于开发和测试人员不在同一个组织/团队里，团队之间必须进行工作交接（部门墙），导致了大量复测试案例的存在。他们的解决方法是，让开发和测试人员结对子，这样就减少了重复测试。当测试套件又变得精简和绿色了以后，大家又开始相信这些自动化测试了，之后大家对自动化测试的文化转变为：将自动化测试案例失败视为零容忍事件（失败的测试会导致全team的人停下来，并在1天内解决）。另外一个故事关于性能测试，性能测试是通过一个位于俄亥俄州的集中式性能测试团队做的，任何开发团队的申请时间是90天（被识别为最长时间的约束点），他们认为这个前置时间是无法接受的。解决方法是，将性测试脚本和运行权限交还给了开发团队，最后90天的性能周期被缩短为了2小时。 DevOps团队和管理层对Handbook书里的实践内容达成了共识和一致，上下一致的参考书中这些业界已经验证过的实践，节省了决策和探索DevOps做法和套路的时间。 开发者/程序员体验：十八般神兵利器，大量的上下文切换 【重点】2017年的实践核心是“开发者/程序员体验”（程序员要“富养”）\n在专注于开发者体验优化的过程中，应用了大量DevOps工具，最后发现如果开发者把它们都用一遍的话，要花好几个小时的时间。为了解决这个问题，他们体验了Rocket.Chat工具，开发者们对此工具提出了一致好评。\n为了让公司领导层支持增加这个工具，他们请领导们到现场亲自视察观看开发人员在使用了Rocket.Chat之后，优化的体验。领导们就这样决策增加的这个工具。\n开发者/程序员体验：拥抱聊天机器人，减少上下文切换 优化后的开发者工具集如下所示。\n开发者直接面对的工具精简了很多，他们几乎只需要专注于写代码和处理代码的提交和PR即可。 之前开发者如果需要部署代码，就需要手工的在UrbanCode里点击十几二十次鼠标，才能完成一次部署操作。 在使用了聊天机器人之后，他们只需要对聊天机器人说：deploy；即可 DevOps登山指南 通过这一页纸的手册，为新来的DevOps实践者提供了清晰的指导。\n攀登高山隐喻了这是一个艰难的旅程。\n北极星 - 前置时间 【重点】各项DevOps工作的唯一参考指标是“前置时间”（指南针）\n选用这个指标的三个原因：\n这个指标可以在横向的200多个敏捷开发团队里实施；在纵向的组织级、部门级和团队级上，大家都能理解和认可这一指标，都能够掌握前置时间的计算和测量方法。缩短前置时间的目标是清晰的：及时要加快交付速度。 各个开发团队可以自行选择优化前置时间的方法和路径，其实这鼓励了团队的创造性。 对此指标的度量和持续改进，是可以按天实时进行的，同时还要保证实现部署的零宕机时间。 DevOps登山用品：地图和装备 DevOps实践者基础的精神和物质需求。\n工具和DevOps实践直接相关 每个工具都有其价值和应用场景（例如Rocket.Chat） DevOps Handbook（中文书名：DevOp实践指南）的作用是地图，每个DevOps实践团队都进行至少每周一次的读书俱乐部活动，每次都对书中具体的章节进行团队讨论和学习。 DevOps的支持模型 DevOps支持团队的作用。\n为了满足企业级的支持规模，让水平参差不齐的200多个开发团队都能顺利应用DevOps实践，没有这个支持模型是不可能走远的。\n夏尔巴人团队的作用是支持和辅导DevOps实践团队，提升团队的思想意识观念和技能，帮助它们构建某些特定领域的工作能力。 参与DevOps实践的开发团队必须自己登上山顶，哪怕是爬也是自己爬上去。绝不勉强，不想进步的团队就不要参与了。 逐渐开展了沉浸式配对的支持模式，让低水平团队的人员在DevOps高水平团队中进行交叉培训，让他们现场看到相同的工作确实可以有不同的、更好的做法。 他们进行每月一次的DevOps道场，在道场里DevOps技术顾问现场指导和帮助前来提高的团队。 将流水线视为产品，流水线的管理确实也是他们的痛点之一。 DevOps成功的那一刻 DevOps对业务有毛用？！\n这个故事是该公司刚开始品尝DevOps成功硕果的那一刻。飓风哈维（是2017年大西洋飓风季中的一个热带气旋。2017年8月25日，登陆美国德克萨斯州沿岸，时速130英里）导致车辆涉水险的申报数量剧增。业务部门的人处理这些车险事件的过程中意识到，他们的业务流程对这个险种的索赔并不友好，于是就来找到了IT部门，提出想要优化这个险种报案和索赔处理。\n这是第一次业务部门找上门来提出的业务需求，IT部门在当天就搞定的经历。业务人员和IT部门的人用了一个小时的时间讨论优化方案，决定去掉索赔流程里40%的多余步骤。IT部门开始设计和实施这个想法，决定需要变更多个应用，他们在当天里，在剩下的7个小时内就完成了这些业务需求的开发和测试，这些业务变更的生产环境部署工作是在工作时段进行的，变更在当天的营业时间结束前就上线了。他们始终以速度为先的实践原则在一年后，在这一天里得到了回报。以前需要至少90天的周期才能完成这样的变更，性能测试会就会占用一半以上的前置时间。而他们觉得这次在整个的设计、实施和部署过程中，其实并没有感到什么压力和风险。\n后记 本文的价值在于，向你展示一个有参考价值的DevOps案例。它的很多特征和成功之处都值得借鉴和思考。本文的文字主要来源于对视频中的叙述，其中也包含了大量我个人的观点和分析；欢迎读者在观看本案例视频后，与我分享和讨论以上内容。\n","date":"2018-02-20T00:34:09+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/q_auto:eco/Evest.jpg","permalink":"https://martinliu.cn/blog/devops-climbing-guide/","title":"DevOps登山指南"},{"content":"农历年才是中国人意识里的年，狗年不到来，鸡年绝对还没有过完。在这几天里总有一些想要总结和展望的。一年的时间过的犹如白骥过隙一般，愈来愈加明显的感觉到各种岁月的痕迹。此刻所想到的一切只有缓慢和宁静，能否让这个世界缓慢和宁静下来。\n盘点 想想去年这一年都做了什么事？都去过哪些地方？有哪些值得回忆的经历？\n旅行 回顾一下才发现这一年去过不少地方，很多地方是第一次去。\n1-日本（春节） 去年的第一个旅行是在过年期间去日本的东京大阪之旅。首次去日本的总体感觉还是不错的，住的是Airbnb的家庭房间，位置和环境都非常好。游玩了福建狐狸大社、在奈良的东大寺喂小鹿、游玩了大阪的迪士尼，日本好玩好逛的地方真多。\n不过印象最深的还是两件事：1）京都的鸭川河边跑步十公里；2）在大阪的烧肉店和朋友一起和热清酒。\n2-吉隆坡（三月） 这次是出差，公司在吉隆坡开会，顺便带了小孩一起去玩，赶在上小学之前能玩的机会不能放过。在这一周的行程里，不仅游览了市区主要的地方，还去珍拉丁湾的CloudMed故地重游了一下。\n3-普吉岛的泼水节（四月） 去普吉岛开会期间，碰巧赶上了泼水节。除了一头一尾的两天休闲时光之外，其它的三天会议时间，非常消耗精力和体力；完全是三天的黑客马拉松式的比赛式培训。代表中国团队上台做了项目汇报演讲，虽然有些超时，虽然没有拿到第一名，不过整个竞赛的体验还是很不错的。\n4-拉斯维加斯和大峡谷之旅（八月） 这是出差去美国参加公司的年度启动大会。这是一次极致的旅行，在拉斯维加斯的几天会议过程中，和同事一起各种的购物和游览，给我的赌场之旅画上了圆满的句号。而精彩的部分在开完会之后，和同事们一起去大峡谷的游览。\n我们住在大峡谷南缘的威廉姆斯小镇上，来过的人应该都知道这个小镇，对大峡谷南缘的主要景区进行了两进两出的深度游览。希望下次来的时候，可以从东部的羚羊峡谷北上，再次访问我的第一个美国旅行目的地：盐湖城（2006年）。\n5-台北深度一周游（8月） 从美帝回来之后，接着去台北参加了DevOpsDays台北站的大会。趁着开会之余的时间和随行的朋友们一起游览了台北市和附近的不少地方。第一次去宝岛台湾，第一次在国外的城市参加DevOpsDays大会；参加这次大会有两项任务：1）作为国内专家团的邀请人，邀请了多位业内的DevOps大拿同去台北演讲；2）我的专题演讲是在第二天；真是圆满的一次旅行。台北的101大厦、故宫和诚品书店给我留下了深刻的印象。\nDevOps 这一年中除了工作之外，我主要的研究方向是在DevOps上。参加了两次DevOpsDays大会，完成了DevOps Handbook的翻译。\n1-DevOpsDays北京 大会在三月十八日召开，这是在我拿到Exin DevOps Master自由讲师资质以后，所参加的最重要的一个DevOps大会。我也是很积极的参与在这次大会活动里，主持了OpenSpack开放空间环节。这个大会是DevOps社区比较正宗和原生的社区大会，我也是第一次见到了DevOps之父Patric先生。\n在这两天的大会活动中，我们都可以感觉到DevOps社区的火热，由于是DevOpsDays大会的首次来华；它的象征性更大于其它的任何意义。\n通过这次参与首届DevOpsDays大会活动，我感觉找到从技术和社区这两个方面而言，找到了和我匹配最佳的社区。我的工作经历是ITIL相关的IT管理背景的，技术方面接从事最多的是IT管理工具和云计算；而我也是开源技术社区的超级粉丝。\n2-翻译 DevOps Handbook 这是2017年内我投入巨大的一项工作，从来没有想到工作量是如此的惊人，即使是和其它三个朋友一起做；最后回顾一下，觉得工作量还是远远超出了我的想想。\n出版社的线上书稿编辑系统里，有大部分工作时间的统计，经过了不计其数的起早贪黑以后，我的线上系统内工作时间定格在了：278小时44分钟；这份工作让我记忆犹新的是：周末送孩子去上课以后，我在星巴克度过的n多个上午；在交稿前的最后几次令人抓狂的集中修订。出版社审稿通过，编辑开始编辑审稿之后，看着三审作完之后的结果还是觉得分外激动的。\n这本书的中文书名为《DevOps实践指南》，为这本书我建立了一个独立的推广站点：https://handbook.martinliu.cn/，站点里的术语表非常欢迎大家的引用和协作修订。\n3-DevOps培训课 由于这一年中我几乎所有的业余时间和精力都花在Handbook的翻译上，因此接的课很少，甚至于还推掉了不少的课；在翻译完成之后，应该有时间在周末做这方面的培训了。\n培训课对我而言是我进行社区分享的一种形式，觉得很多知识和经验的体会，如果不通过什么渠道分享出来的话，始终会就觉得不尽兴，觉得白学了这些知识。也有可能是开源社区 开放和分享 的毒中的太深了，哈哈！\n展望 虽然在感觉上2017年一晃就过去了，但是盘点之后发现，过得还是极度的充实和饱满的。觉得我的付出和辛苦还是很值得。\n在元旦之后我就确定了今年的总基调：停止开始，开始完成，继往开来，全面开挂。\n我在DevOps方面的经验完全能够利用到公司的产品和工作中，这一点实在是可遇而不可求的。随着公司对Nutanix Calm的重视，基于蓝图的应用全生命周期自动化运维，正渐渐的成为很多项目的需求。为此我也建了一个文档分享站点：https://nutanix.martinliu.cn/；希望在新的一年里继续丰富和优化这些文档。在客户项目和合作伙伴培训的过程中能和更多人碰出DevOps火花。\n在旅行方面，18年可能会去欧洲，还没具体的计划。\n在新领域探索方面，18年已经开始了对区块链的了解和参与。\n在18年里作为中国DevOpsDays大会的核心组织者，希望在5月北京站的大会上，和Handbook的作者一起发布中文版Handbook图书，并在DevOps社区里做更多的分享和贡献。\n","date":"2018-02-12T13:04:30+08:00","image":"https://res.cloudinary.com/martinliu/image/upload/q_auto:eco/HongKongEye_ZH-CN12285832688_1920x1080.jpg","permalink":"https://martinliu.cn/blog/2017%E5%B9%B4%E5%BA%95%E7%9A%84%E5%9B%9E%E9%A1%BE%E5%92%8C%E5%B1%95%E6%9C%9B/","title":"2017年底的回顾和展望"},{"content":"K8s在2017年底为这场速战速决的站点话上了句号，结果是所有竞争对手都选择了增加对K8s的支持。在各自的编排器框架里内置了K8s。本文是根据Mesosphere公司的大拿Karl KARL ISENBERG在各种大会上分享过多次的一份演讲稿改版的。\nKARL ISENBERG 是谁？ 所在公司?\nMesosphere（当前） Pivotal 做过的产品?\nDC/OS opensource CloudFoundry BOSH 联络信息：\ngithub.com/karlkfi twitter.com/karlkfi linkedin.com/in/karlkfi karl.isenberg.us 基础架构的进化 传统的应用架构在逐渐向下面两种架构演变。\n可扩展的单体应用架构 关键词：\nOnline 基于互联网 Latency Routed 用户访问基于延迟路由 Multi-Region 多区部署 Load Balanced 负载均衡接入 Multi-Zone 多个Zone Replicated 应用实例多副本 Auto-Scaled 容量自动化收缩 Data Replication 区内数据多副本 Data Synchronization 跨区数据同步 可扩展的微服务架构 上图出处：Wheel of Doom ，来自A Journey into Microservices by Hailo\n应用+裸金属服务器 APPLICATION PROVISIONING ON BARE METAL\n应用+IaaS APPLICATION PROVISIONING ON VIRTUAL INFRASTRUCTURE PLATFORM (IaaS)\n“Ultimately, utility cloud providers have exposed how difficult it is to properly operate data centers — and reminded all of us that the ability to expertly operate infrastructure is what really fuels the consumption of open source infrastructure.” \u0026ndash;Brian Stein (Rackspace VP - 2017)\n应用+PaaS/aPaaS+IaaS APPLICATION PLATFORM (PaaS / aPaaS) ON INFRASTRUCTURE PLATFORM (IaaS)\n“The goal of Cloud Foundry is to put more of the controls back in the hands of developers so they can self-provision, so there aren’t a lot of roadblocks in their way. But it gives a lot of guardrails.” \u0026ndash; Chip Childers (Cloud Foundry Foundation CTO - 2017) 容器编排器+IaaS CONTAINER ORCHESTRATION ON INFRASTRUCTURE PLATFORM (IaaS)\n“\u0026hellip;traditional “PaaS” roles have now been taken over by containers… The piece that is left for PaaS is the part that was always the most important part of PaaS in the first place, and that’s the opinionated developer experience.” \u0026ndash;Brendan Burns (Kubernetes Cofounder - 2017)\nCaaS+IaaS CONTAINER PLATFORM (CaaS) ON INFRASTRUCTURE PLATFORM (IaaS) CaaS+裸金属服务器 CONTAINER PLATFORM (CaaS) ON BARE METAL\nFaaS+IaaS FUNCTION PLATFORM (FaaS) ON INFRASTRUCTURE PLATFORM (IaaS)\n“If your PaaS can efficiently start instances in 20ms that run for half a second, then call it serverless.” \u0026ndash;Adrian Cockcroft-(AWS VP - 2016)\nFaaS+CaaS FUNCTION PLATFORM (FaaS) ON CONTAINER PLATFORM (CaaS) FaaS+CaaS+IaaS FUNCTION PLATFORM (FaaS) ON CONTAINER PLATFORM (CaaS) ON INFRASTRUCTURE PLATFORM (IaaS)\n平台频谱 - PLATFORM SPECTRUM 从左到右，资源的抽象程度不断提高；最左侧的弹性最高，最右侧的速率最高。 下图是不同类型里的厂商和软件。 容器平台层次 容器编排器的层次如下： User workloads 用户工作负载 Distributed container management 分布式容器管理 Local container management 本地容器管理 Container agnostic infrastructure 容器无关性基础架构 容器平台的层次如下： CONTAINER PLATFORM\nUser workloads 用户工作负载 System management \u0026amp; service enablement 系统管理和服务管理 Distributed container management 分布式容器管理 Local container management 本地容器管理 Container aware infrastructure 容器感知的基础架构 Container agnostic infrastructure 容器无关的基础架构 分布式操作系统的层次如下： 容器平台功能点 CONTAINER PLATFORM CAPABILITIES\n运行态的能力 1 容器\nResource Isolation Resource Constraints Process Tree Environment Isolation Shell / Exec 2 镜像\nBuild Layers Download Cache Publish Prune 3 网络\nContainer Bridge Host Virtual Overlay Remote User-defined Port Mapping 4 数据卷\nEphemeral Host Backup / Restore Copy In / Out Shared 编排器的能力 调度\nPlacement Replication/Scaling Readiness Checking Resurrection Rescheduling Rolling Updates Collocation Daemons Cron Jobs 资源管理\nMemory CPU GPU Ephemeral Volumes Remote Persistent Volumes Local Persistent Volumes Ports IPs (per container) 服务管理\nLabels Groups/Namespaces Dependencies Load Balancing (L7) VIPs (L3/L4 LB) DNS DNS Proxy Secrets Config Mgmt 运维方面的能力 管理\nGUI CLI Metrics API Logs API Events API Rolling Upgrades Backups \u0026amp; Restores MULTI-INFRASTRUCTURE\nMulti-cloud Multi-zone Multi-region Hybrid-cloud Federation 系统服务\nAuto-Scaling Package Management Service Catalog Service Brokers Admin Proxy API Gateway 平台的能力 容器网络\nOverlay Routing Network Address Translation (NAT) Firewalls Access Control Lists Quality of Service 容器存储\nLocal Volumes Remote Volumes Block Storage File System Storage Object Storage 平台数据库\nLock Service Key-Value Database Relational Database Time Series Database 安全\nUser Accounts Service Accounts System/User Space E2E Encryption Non-root User Workloads Audit Logging Public Key Infrastructure Certifications 多租户\nUser Groups Permissions RBAC ABAC Resource Sharing FIFO Fair Quotas Branding Quality of Service 非功能需求\n稳定性\nPerformance Responsiveness Efficiency 可用性\nFault Tolerance Robustness, Reliability, Resilience, Disaster Recovery 灵活性\nFormat Support, Interoperability, Extensibility, Container Runtimes 可用度\nFamiliarity, Maintainability, Compatibility, Debuggability 可移植性\nHost OS, Cloud, Bare-Metal, Hybrid 安全性\nEncryption Quality, Vulnerability Process, Fast Patching, Backporting 容器平台对比 市场里的主要技术厂商如下。 其它值得考虑的厂商如下。\n下面的能力对比的时间点是 06/2017，这个时候K8s是否能胜出还是个悬念。\n调度 图示说明：\n绿勾：包含此能力 横杠：New/External/Partial/Experimental 资源管理 服务管理 如何选择 第一阵营：重量级 KUBERNETES\nHuge community Solid API Some assembly required Multitude of vendors/installers OPENSHIFT\nApplication platform based on Kubernetes Always trailing Kubernetes releases No assembly required Open core, enterprise platform DC/OS\nRuns native applications (non-Docker) Specialized in data services Ambitious scope (on-prem AWS) No assembly required Open core, enterprise platform DOCKER\nHuge community Fast moving API Integrated orchestration and runtime Recent pivot from runtime to orchestration Open core, enterprise platform 第二阵营：轻量级 EC2 CONTAINER SERVICE (ECS)\nHosted-only solution Tight integration with AWS services Closed platform RANCHER CATTLE\nGateway to Kubernetes, Mesos, and Docker Open platform, enterprise support NOMAD\nProvisioner with orchestration features Runs native applications (non-Docker) Tight integration with Vault and Consul Some assembly required Open platform, enterprise support KONTENA\nSimple to set up No assembly required Open core, enterprise platform Karl个人的考察点？ Which is more important to you: velocity or flexibility? Do you want an opinionated application platform? Do you need to support Big Data initiatives and pipelines? Do you want a hosted solution? Are you willing to build out your own integrations? Do you need on-prem \u0026amp; hybrid capabilities? Do you want to avoid infrastructure lock-in? Are you already invested in a specific infrastructure? Are you already invested in a specific operating system? Do you need federation and multi-regionsupport? Do you want multi-tenancy or is multi-instance good enough? How important are seamless automated rolling upgrades? How many nines do your customers need? How important is reverse compatibility \u0026amp; API stability? Do you need to support non-Docker workloads? ","date":"2018-01-12T23:33:32+08:00","image":"https://martinliu.cn/images/abstract-11.jpg","permalink":"https://martinliu.cn/blog/container-orchestration-wars/","title":"容器编排器之战"},{"content":"我的笔记本上有好几个 Hugo 做的静态的站点，有自己的个人 Blog，有公司产品的培训文档；其中的有些站点内容，有可能是不方便发布到 Internet 上，有可能是你的观众并没有条件访问 Internet，但是使大家同在一个局域网里是一个很现实很方便的做法。那么怎样以最小的代价实现这个需求呢？\n选择 Hugo 服务器启动参数 为了满足以上需求，在启动 Hugo 服务器的时候需要增加两个参数，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 martin@bogon:source/martinliu-hugo ‹master*›$ hugo server --bind 192.168.1.107 --baseURL http://192.168.1.107/ Started building sites ... Built site for language en: 0 draft content 0 future content 0 expired content 387 regular pages created 1100 other pages created 0 non-page files copied 668 paginator pages created 509 tags created 37 categories created total in 922 ms Watching for changes in /Users/martin/source/martinliu-hugo/{content,static,themes} Serving pages from memory Web Server is available at http://192.168.1.107:1313/ (bind address 192.168.1.107) Press Ctrl+C to stop 对以上参数的解释：\n\u0026ndash;bind 192.168.1.107 ：这个 192 的 IP 地址是笔记本目前局域网（Wifi）的地址，其他人需要和你同在这个局域网里，或者能够访问到这个网段的地址 \u0026ndash;baseURL http://192.168.1.107/ ： 这会覆盖 Hugo 站点里根目录下配置文件里的 baseURL 参数，有可能配置文件中这个参数是类似于 http://martinliu.cn/ ，如果不加这个参数的话网站上的相关图片会显示不出来。 配置笔记本电脑的防火墙 以 macOS 为例，当你启动了这个 Hugo 服务器的时候，你访问 Security \u0026amp; Privacy 配置的时候，选择 Firewall 标签的时候，会自动弹出一个对话框，询问是否允许 incoming 的网络连接到 hugo 的应用服务。点击允许即可，这样防火墙配置里就多了一条配置，如下图所示：\n总结 Hugo 可以很方便的将本地站点分享给局域网里的其它人，只需要在启动的时候加上适当的参数，配置好本机的防火墙策略即可。\n","date":"2018-01-04T07:33:32+08:00","image":"https://martinliu.cn/images/abstract-12.jpg","permalink":"https://martinliu.cn/blog/share-hugo-site-to-lan/","title":"将笔记本上的Hugo站点分享给局域网里的其他人"},{"content":"Kubernetes 无疑当下最火热的技术之一，Google 公司围绕着它下了更大的一盘棋 CNCF。这是在国际寡头 IT 软件公司的统治局面渐渐退去之后，各种新鲜技术百花齐放了一段时间以后，再通过 CNCF 的形式又逐渐集中化起来的趋势。KubeCon 的人气很旺，演讲分享的人很多。\n最近一次的 KubeCon，2017 年在奥斯汀站的演讲稿和视频下载的清单已经发布出来了：\nhttps://github.com/cloudyuga/kubecon17\n我在 YouTube 里听了一部分视频，感觉确实有很多新鲜的工程实践经验的分享。下面分享一个觉得不错的实战案例分享。\nBox 公司分享持续交付实战经验 关于这个分享的看点：\nBox 公司全面实施 Kubernetes 的案例，涵盖了所有的环境：Dev、Staging 和 Prod 遇到的挑战和问题共性强 Jenkins 流水线+金丝雀部署+持续交付的组合 解决问题的模式值得借鉴 工具集里开发出来的核心组件已经开业分享在 Github 上 分享者经典语录：\n我们是软件工程师，我们不是坐在那按按钮的猴子！\n以上分享的持续交付方案里 kube-applier 的源代码分享：\nhttps://github.com/box/kube-applier\nPS：非常敬佩这种开放和分享的工程式文化。很符合开源的精神，爱分享的人，不把东西分享出来的话可能会不爽。\n延伸阅读：\nhttps://blog.box.com/blog/introducing-kube-applier-declarative-configuration-for-kubernetes/ https://blog.box.com/blog/kubernetes-box-microservices-maximum-velocity/ 观看以上演讲视频 ","date":"2018-01-03T00:00:00Z","image":"https://martinliu.cn/images/abstract-10.jpg","permalink":"https://martinliu.cn/blog/kubecon17/","title":"Kubecon 2017演讲稿和视频下载"},{"content":"用跑步的方式启动2018年 元旦这天早晨送女儿去中国儿童艺术剧院看剧，这正好是我跑步的大好时机。正好是一个大晴天，这样的蓝天岂能辜负。环绕故宫的路线是一根长了很久的草，今天总算可以拔除了。于是我从东华门开始往北，沿着逆时针方向开始跑。下面是这次的跑步路线图。\n跑步路线评价 东华门一侧向北的路上，直到故宫西北角的角楼；刚开始游客和行人还不是很多，但是到了故宫博物院的北门，哪里的游客非常多，需要躲开行人往前跑；在10点以后的时间里，保证你想跑也跑不快，人确实是比较多的，而且正好赶上了元旦这一天。听说有9万人在天安门广场观看了升旗仪式。\n故宫的西侧南长街这条路是很窄的人行道，由于也是有不少游客，我后半程是机动车上和机动车流逆行了一段跑的，虽然有点危险，不过机动车开得都不快，也在明显的躲让这行人，跑后还是感觉还是不建议这么跑。\n到了长安街以后，我想从天安门广场门口跑过，也就是从天安门的西边跑到东边，结果发现其实西边和东边以及广场周边都是设置了安检，如果没有带身份证的话根本就走不过去。在天安门站西的安检门口排了5分钟队以后放弃了。接着过马路到路西想往东跑，结果也比警察截住赶走了。无奈只能继续往南跑，从人民大会堂西路，途径前门大街和正义路，又回到了长安街。还不死心，企图混过东侧的安检抵达天安门城楼下，未果。然后继续沿着南池子大街跑到了起点。\n如果没有带身份证，根本无法接近天安门城楼下和进入天安门广场以内 如果在节假日里，安检排队的等候时间应该是是10到30分钟以上，根本不适合在跑步的过程中有安检的环节，不是么？ 整个一圈下来，觉得道路上主要是游客居多，如果是跑步圈地，圈名胜地标的想法，还可以跑，不是的话，还是去其它的跑步地点吧 最后 在东华门终点附近，排了两张故宫外侧的图片。\n2018年必须是一个不平凡的一年，我将这一年的基调定义为：停止开始，开始结束，全面开挂！\n","date":"2018-01-02T15:57:54+08:00","image":"https://martinliu.cn/images/abstract-11.jpg","permalink":"https://martinliu.cn/blog/2018-1-kickoff/","title":"用跑步的方式启动2018年"},{"content":"DevOps Enterprise Summit由美国的Gene Kim发起并举办的，他是两本流行书籍的作者：《凤凰项目》和《DevOps Handbook》（中文书名《DevOps实践指南》预计于2018年春季出版）。\n大会简介 下面是来自这个大会官网的简单介绍：\nDevOps Enterprise Summit is a conference for the leaders of large, complex organizations implementing DevOps principles and practices. The event programming emphasizes both evolving technical and architectural practices and the methods needed to lead widespread change efforts in large organizations. The goal is to give leaders the tools and practices they need to develop and deploy software faster and to win in the marketplace.\nFrom:https://events.itrevolution.com/us/\n推荐视频 最近我通过微信公众号分享过关于Seek公司DevOps转型的精彩视频。\n演讲稿目录 星期 场次 名称 Monday Electric Cloud Track Rocha, Aloisio, Betting on DevOps- How NetEnt Transforms Online Gaming Delivery.pdf Monday Electric Cloud Track Wallgren, Andres, Architecting Your App and Your Pipeline for Continuous Delivery - 10 DO\u0026rsquo;s for Successful DevOps.pdf Monday Electric Cloud Track Mckay, Gary, From Mainframe to Microservices- How Somos Keeps Telcos and Us All Connected.pdf Monday Electric Cloud Track Pullen, Wesley, DevOps from Grassroots to Mainstream.pdf Monday Electric Cloud Track Esser, John, DevOps Transformation 2.0- From Ancestry.com to AdvancedMD - applying strategies for leading DevOps innovation.pdf Monday Breakout Session Comtois, Pauly, Bringing DevOps to Product.pdf Monday Breakout Session Raia, Alice, Overcoming 75 years of inertia in healthcare; a Top-down + bottoms-up DevOps Transformation.pdf Monday Breakout Session Perret, Jennifer, Guckenheimer, Sam, The Skype Journey to 1ES and Cloud.pdf Monday Breakout Session Grafmeyer, Jim, Payne, Cindy, DevOps Handbook Experiments in Accelerating Delivery.pdf Monday Breakout Session Hering, Micro, What got you here, wont get you there - A story of transformations.pdf Monday Breakout Session Dominica DeGrandis - DeGrandis_Nov 12.2017.pdf Monday Breakout Session Olivier, Dawie, Agile:Dawie ruined my life.pdf Monday Breakout Session Thrasher, Paula, Scaling DevOps Talent in a Large Enterprise.pdf Monday Breakout Session Daththreya, Gnani, Shunmugasundaram, Sathiya, Continuous Chaos in DevOps.pdf Monday Breakout Session Hockaday, Kurt, Turning the Battleship A Principled Approach to Driving Change in DoD IT.pdf Monday General Session Mayner, Steve, Transformational Leadership and DevOps - Beyond the Research.pdf Monday General Session Johnson, Suzette, Yeman, Robin, What Legacy government organizations need to advance the state of DevOps.pdf Monday General Session Nassello, Scott, Using DevOps to build your learning organization.pdf Monday General Session Morrison, Erica, Prugh, Scott, More Culture, More Engineering, Less Duct-Tape.pdf Tuesday Electric Cloud Track Aggarwal, Manish, Intel\u0026rsquo;s Journey to Build Quality In How QA and Test Automation Drive DevOps Transformation.pdf Tuesday Electric Cloud Track Priolo, Marc, Mastering the Three S’s for a Successful Pipeline-as-a-Service Strategy Standardization, Self-service, Scale.pdf Tuesday Electric Cloud Track Stroud, Robert, DevOps From Analyst Inquiry to Organizational Action.pdf Tuesday Electric Cloud Track Gruver, Gary, Starting and Scaling DevOps in the Enterprise.pdf Tuesday Electric Cloud Track Reed, J. Paul, Navigating the Software Delivery Minefield DevOps and the Art of Release Engineering.pdf Tuesday Breakout Session Blank-Edelman, David, SRE For Enterprises.pdf Tuesday Breakout Session Lackey, Zane, DevSecOps How to use DevOps to make you more secure.pdf Tuesday Breakout Session Burgin, Andy Devops in a Data Warehouse Inside Out.pdf Tuesday Breakout Session Nowak, Chris, Alliances, Data and Startup Mentality – How we Led Three Banks through DevOps Transformations.pdf Tuesday Breakout Session Rinehart, Aaron, Wickett, James, DevOps and the Healthcare Giant.pdf Tuesday Breakout Session Kolli, Rama, Supercharging PayPal’s application development to help democratize financial services.pdf Tuesday Breakout Session Fong, Richard, Nir, Erez, From Dev Opps to DevOps.pdf Tuesday Breakout Session Nielsen, Suzanne, Shewell, Sarah, Transformation at Scale, One Cup at a Time.pdf Tuesday Breakout Session Finster, Bryan, Pendergraft, Brent, CD Solving the talent problem.pdf Tuesday Breakout Session Edmundson, Jill, Musil, Jill, Service Request Management CSG\u0026rsquo;s Journey from Chaos to Clarity.pdf Tuesday Breakout Session Magennis, Troy, Prioritization – 10 different techniques for choosing what to start next.pdf Tuesday Breakout Session Owczarek, David, Best Practices for Availability.pdf Tuesday General Session Forsgren, Nicole, The key to high performance What the data says.pdf Tuesday General Session Matthew, Tisson, The Making of Amazon Prime Now.pdf Tuesday General Session Allspaw, John, How Your Systems Keep Running Day After Day - Resilience Engineering as DevOps.pdf Tuesday General Session Brady, Jennifer, Pal, Tapabrata, Better Governance – Banking on Continuous Delivery.pdf Wednesday Electric Cloud Track Morales, Marco, Process-as-Code Real-World Examples that Scale.pdf Wednesday Electric Cloud Track Lynn, Angelo, Best Practices for DevOps-Ready Infrastructure Management and Automation.pdf Wednesday Electric Cloud Track McKnight, Ken,Data-Driven DevOps Taking Action!.pdf Wednesday Electric Cloud Track Doucet, Chris, Best Practices for Model Driven Approach to Application Release.pdf Wednesday Electric Cloud Track Sutton, Mark, BizDevOps Using KPIs to Unlock a Common Language.pdf Wednesday Electric Cloud Track Schuller, Manuel, How Financial Services are Leveraging Legacy IT Investments When Transitioning to DevOps.pdf Wednesday Breakout Session England, Rob, Surviving DevOps.pdf Wednesday Breakout Session Konno, Miki, Marks, Justin, User Feedback at the Speed of DevOps.pdf Wednesday Breakout Session Finn, Ray, Singh, Aru, Service Ownership - Devops for Salesforce.pdf Wednesday Breakout Session Hill, Chris, Context Switches in Software Engineering.pdf Wednesday Breakout Session Wester, Julia, Taming the Chaos- Beyond the Quick Wins.pdf Wednesday Breakout Session Kernaghan, Chris, Can you do Devops in SAP DOES.pdf Wednesday Breakout Session Jelleda, Kishore, DevOps at Scale is a Hard Problem- Challenges, Insights and Lessons Learned.pdf Wednesday Breakout Session Radcliffe, Rosalind, Two Amazing Mainframe DevOps Transformation Case Studies.pdf Wednesday Breakout Session Shoup, Randy, Scaling Personalization- DevOps at Stitch Fix.pdf Wednesday Breakout Session DeArdo, Carmen, Kersten, Mik, The Case for Value Stream Architecture.pdf Wednesday Breakout Session Rizzo, David, Two Amazing Mainframe DevOps Transformation Case Studies.pdf Wednesday General Session Boecker, Scott, Forrester, Ron There is No Finish Line.pdf Wednesday General Session Clanton, Ross, Kumar, Nanda, Fear does not exist in the dojo - a devops journey with a competitive twist.pdf Wednesday General Session Smart, Jonathan, The Yin and Yang of Speed and Control.pdf Wednesday General Session Hendrickson, Elisabeth, Data and DevOps Breaking Down the Silos.pdf Wednesday General Session Dekker, Sindey, The human factor Inspiring the pursuit of success and averting drift into failure.pdf 演讲稿下载 我从官网的Dropbox网盘里下载了所有演讲稿，分享到了微云的网盘里。\n点这里下载 以上文件压缩包大将近700MB。\n也可以从GitHub看到这些分享的文件：https://github.com/devopsenterprise/2017-San-Francisco\n同样的今年6月份在伦敦举行的欧洲场次的DevOps企业峰会的演讲稿下载地址在：https://github.com/devopsenterprise/2017-london\n","date":"2017-12-28T00:00:00Z","image":"https://martinliu.cn/images/abstract-7.jpg","permalink":"https://martinliu.cn/blog/2017-does-sfo/","title":"2017DevOps企业峰会旧金山站"},{"content":"本文介绍如何用Docker卷插件的方式，给Docker Swarm的群集挂载Nutanix存储。Nutanix Container Volume Plug-in简称DVP，可以给容器提供数据持久化的功能。\n本文使用ownCloud网盘应用做功能测试。测试的过程如下，安装部署Docker Datacenter，配置好群集，在UCP的界面里调用DVP插件建持久的数据卷，建立ownCloud服务，部署和测试该服务。\nNutanix DVP (Docker Volume Plug-in)安装和配置 这一部分描述DVP的安装部署过程，需要连接互联网；安装调试完毕之后，作虚拟机的镜像模板使用。这样Docker Swarm的其它节点也都不需要重复这个步骤了。\n本文使用的是Docker社区文档稳定版 17.03.1-ce ；本文使用的OS是CentOS 7.3。所Docker安装的版本如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@centos7-temp]# docker version Client: Version: 17.03.1-ce API version: 1.27 Go version: go1.7.5 Git commit: c6d412e Built: Mon Mar 27 17:05:44 2017 OS/Arch: linux/amd64 Server: Version: 17.03.1-ce API version: 1.27 (minimum version 1.12) Go version: go1.7.5 Git commit: c6d412e Built: Mon Mar 27 17:05:44 2017 OS/Arch: linux/amd64 Experimental: false [root@centos7-temp]# rpm -qa|grep docker docker-ce-17.03.1.ce-1.el7.centos.x86_64 docker-ce-selinux-17.03.1.ce-1.el7.centos.noarch 本文使用的Docker 安装yum源如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 [root@centos7-temp]# cat /etc/yum.repos.d/docker-ce.repo [docker-ce-stable] name=Docker CE Stable - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/stable enabled=1 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-stable-debuginfo] name=Docker CE Stable - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/stable enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-stable-source] name=Docker CE Stable - Sources baseurl=https://download.docker.com/linux/centos/7/source/stable enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge] name=Docker CE Edge - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge-debuginfo] name=Docker CE Edge - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge-source] name=Docker CE Edge - Sources baseurl=https://download.docker.com/linux/centos/7/source/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test] name=Docker CE Test - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test-debuginfo] name=Docker CE Test - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test-source] name=Docker CE Test - Sources baseurl=https://download.docker.com/linux/centos/7/source/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg 本机所使用的所有安装源如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@centos7-temp]# yum repolist Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com repo id repo name status base/7/x86_64 CentOS-7 - Base - mirrors.aliyun.com 9,363 docker-ce-stable/x86_64 Docker CE Stable - x86_64 4 epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 11,808 extras/7/x86_64 CentOS-7 - Extras - mirrors.aliyun.com 381 updates/7/x86_64 CentOS-7 - Updates - mirrors.aliyun.com 1,859 repolist: 23,415 安装docker引擎，并启动服务，并校验服务状态。安装过程参考如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@centos7-temp]# yum install -y docker-ce [root@centos7-temp]# systemctl enable docker [root@centos7-temp]# systemctl start docker [root@centos7-temp]# systemctl status docker ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2017-06-20 20:30:49 CST; 19min ago Docs: https://docs.docker.com Main PID: 875 (dockerd) CGroup: /system.slice/docker.service ├─ 875 /usr/bin/dockerd ├─ 942 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-in... ├─2008 docker-containerd-shim 0ca2346b6126de702fb4dda5f807c0a69a402eb643f15c142730277d0eb7bbcb /var/... └─0ca2346b6126de702fb4dda5f807c0a69a402eb643f15c142730277d0eb7bbcb └─2038 /usr/bin/python /code/main.py --prism-ip 10.68.69.22 --dataservices-ip 10.68.69.23 --prism-... 到目前为止，Docker安装配置完成。\n下面开始安装DVP，安装和配置过程参考页面。\nhttps://store.docker.com/plugins/nutanix-dvp-docker-volume-plug-in\n下面是给操作系统安装iscsi initiator服务的参考步骤：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 yum install -y iscsi-initiator-utils systemd-tmpfiles --create systemctl start iscsid systemctl enable iscsid systemctl status iscsid ● iscsid.service - Open-iSCSI Loaded: loaded (/usr/lib/systemd/system/iscsid.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2017-06-20 20:30:46 CST; 24min ago Docs: man:iscsid(8) man:iscsiadm(8) Main PID: 888 (iscsid) CGroup: /system.slice/iscsid.service ├─882 /usr/sbin/iscsid └─888 /usr/sbin/iscsid Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Starting Open-iSCSI... Jun 20 20:30:46 centos7-temp.zenlab.local iscsid[878]: iSCSI logger with pid=882 started! Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Failed to read PID from file /var/run/iscsid.pid: Inva...ent Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Started Open-iSCSI. Jun 20 20:30:47 centos7-temp.zenlab.local iscsid[882]: iSCSI daemon with pid=888 started! Hint: Some lines were ellipsized, use -l to show in full. 解释一下DVP的工作原理是，它是让Docker主机通过iSCSI协议连接Nutanix的存储服务。DVP插件的配置里包含了连接存储服务和存储容器（这个容器是Nutanix的存储术语，非Docker说的容器）的相关信息。这样Docker主机上用该卷插件建立的数据卷都会指向Nutanix后台的存储容器中；数据通过iSCSI协议连接Nutanix存储服务的时候，就可以利用到Nutanix群集提供的负载均衡能力；当数据块写入Nutanix存储池的过程中和之后，就可以利用到到Nutanix存储容器所具备的其它重要特性：数据块2~3副本的高可靠性、冷热数据分成、压缩、去重、纠删码等；而且存储空间对于容器或者Docker Swarm里的服务都是透明和无限容量的。\n现在做一些安装DVP的准备工作，询问Nutanix系统管理员下面信息：\n获得Prism 的IP 获得Nutanix群集数据服务的IP，这个IP是群集上的虚拟服务IP 获得群集的用户名和密码 新建一个测试存储容器，获得容器名 参考下面的DVP安装命令：\n1 docker plugin install ntnx/nutanix_volume_plugin PRISM_IP=\u0026#34;10.68.69.22\u0026#34; DATASERVICES_IP=\u0026#34;10.68.69.23\u0026#34; PRISM_PASSWORD=\u0026#34;nutanix/4u\u0026#34; PRISM_USERNAME=\u0026#34;admin\u0026#34; DEFAULT_CONTAINER=\u0026#34;ddc-sc1\u0026#34; --alias nutanix 以上的命令执行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@centos7-temp]# docker plugin install ntnx/nutanix_volume_plugin PRISM_IP=\u0026#34;10.68.69.22\u0026#34; DATASERVICES_IP=\u0026#34;10.68.69.23\u0026#34; PRISM_PASSWORD=\u0026#34;nutanix/4u\u0026#34; PRISM_USERNAME=\u0026#34;admin\u0026#34; DEFAULT_CONTAINER=\u0026#34;ddc-sc1\u0026#34; --alias nutanix Plugin \u0026#34;ntnx/nutanix_volume_plugin\u0026#34; is requesting the following privileges: - network: [host] - mount: [/dev] - mount: [/lib/modules] - mount: [/etc/iscsi] - mount: [/var/lock/iscsi] - mount: [/proc] - allow-all-devices: [true] - capabilities: [CAP_SYS_ADMIN CAP_SYS_PTRACE CAP_IPC_LOCK CAP_IPC_OWNER CAP_NET_ADMIN CAP_MKNOD CAP_SYS_MODULE] Do you grant the above permissions? [y/N] y （输入y，按回车） latest: Pulling from ntnx/nutanix_volume_plugin be892c8cb64d: Download complete Digest: sha256:5a3730ffae077eb6ddc0c125620283d56852528b686cbe42f2f58696eab82c0d Status: Downloaded newer image for ntnx/nutanix_volume_plugin:latest Installed plugin ntnx/nutanix_volume_plugin 确认VDP安装结果，这个插件应该是最新版、启动的状态，如下：\n1 2 3 [root@centos7-temp]# docker plugin ls ID NAME DESCRIPTION ENABLED f0e38fbc11b3 nutanix:latest Nutanix volume plugin for docker true 执行下面的测试，确认DVP工作正常。\n1 2 3 4 5 6 [root@centos7-temp]# docker volume create testvol -d nutanix:latest testvol [root@centos7-temp]# docker volume ls DRIVER VOLUME NAME nutanix:latest testvol [root@centos7-temp]# 回到Nutanix的Prisum界面（主要的群集管理图形化界面）中查看Storage \u0026ndash;\u0026gt; table \u0026ndash;\u0026gt; Volume Group，应该能看到这个命令所创建的名为testvol的数据卷。如下图所示：\n在命令行删除这个测试的卷。\n1 2 3 4 5 [root@centos7-temp]# docker volume rm testvol testvol [root@centos7-temp]# docker volume ls DRIVER VOLUME NAME [root@centos7-temp]# 在回到Prisum界面中查看刚才看到的那个卷应该就消失了。到此为止所有节点的DVP部署配置工作就完毕了，并且确认docker服务和DVP功能都很正常。用 sys-unconfig 命令关机，把这个虚拟机在Prisum里面做一个快照备用，也可以在Nutanix的acli命令行里面把它做成一个基础镜像。\n我们已经理解和熟悉了DVP的基本操作，配置和部署，下面开始安装Docker Datacenter；Docker Datacenter的架构图如下所示： 本文安装的架构是：\n一个 UCP manager 节点 一个 DTR 节点 两个 worker node 节点 在Nutanix的Prisum中用刚才制作的那个快照或者镜像模板，克隆/新建4个虚拟机。虚拟机的参考配置如下：\n2 vCPU 4GB RAM 50GB Disk 安装UCP（Docker Universal Control Plane）节点 在Nutanix的Prisum中从刚才新建的四个虚拟机中选择一个，Power on开机；ssh登录到操作系统内之后，设定主机名和IP地址。\n安装配置参考文档：https://docs.docker.com/datacenter/ucp/2.1/guides/admin/install/install-offline/#download-the-offline-package\n注意事项，提前下载好安装包，这个tar包里面包含了UCP需要的所有镜像，可以一次性导入到UCP的节点上。\n1 2 3 wget https://packages.docker.com/caas/ucp_images_2.1.4.tar.gz -O docker-datacenter.tar.gz docker load \u0026lt; docker-datacenter.tar.gz 载入完毕后，可以看到如下镜像。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@ucp-master ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker/ucp-metrics 2.1.4 e3e24ef156bd 3 weeks ago 92.2 MB docker/ucp-swarm 2.1.4 d8b51d6801e5 3 weeks ago 21 MB docker/ucp-hrm 2.1.4 38a19323327d 3 weeks ago 14.8 MB docker/ucp-etcd 2.1.4 9aa382502e19 3 weeks ago 38.5 MB docker/ucp-controller 2.1.4 5a852aa3039e 3 weeks ago 28 MB docker/ucp-dsinfo 2.1.4 66ee9368796a 3 weeks ago 159 MB docker/ucp 2.1.4 7a28dbfc44e4 3 weeks ago 19.1 MB docker/ucp latest 7a28dbfc44e4 3 weeks ago 19.1 MB docker/ucp-cfssl 2.1.4 acdc1f147711 3 weeks ago 15.1 MB docker/ucp-compose 2.1.4 25775e989077 3 weeks ago 32.9 MB docker/ucp-auth-store 2.1.4 f27ad13dee6c 3 weeks ago 58.7 MB docker/ucp-agent 2.1.4 d716a096c331 3 weeks ago 22.5 MB docker/ucp-auth 2.1.4 1f4739cd3c08 3 weeks ago 25.1 MB [root@ucp-master ~]# 安装UCP的命令参考如下：\n1 2 3 4 5 docker run --rm -it --name ucp \\ -v /var/run/docker.sock:/var/run/docker.sock \\ docker/ucp:2.1.4 install \\ --host-address 10.68.69.12 \\ --interactive 以上命令中10.68.69.12是UCP主机的ip地址，建议UCP使用固定IP。以上命令完毕后用浏览器访问这个IP。\n参考以下文档，完成UCP的安装步骤，其中需要到Docker网站获得30天的试用版许可证文件。\nhttps://docs.docker.com/datacenter/ucp/2.1/guides/admin/install/\n能够正常登陆访问UCP之后，在首页下方点击 【Add Node】按钮，获得加其它节点到群集里的命令，参考命令如下：\n1 2 3 docker swarm join \\ --token SWMTKN-1-1310ah7gzj9e7bk6a5yobo2qyiwf93ybrd29flkved1zqydd6i-7pir0884sag5pjofwzjq5o1um \\ 10.68.69.12:2377 把以上命令记录在写字板中备用。\n加3个节点到群集里 把剩下的三个虚拟机开机，进入操作系统后设定主机名和IP。其中的一个安装DTR（Docker镜像仓库）的节点建议使用固定IP。\n在每个操作系统里面用docker命令确认DVP是否正常。\ndocker plugin ls docker volume ls systemctl status iscsid 下面就可以把上一步所记录命令在命令行里面执行以下，完毕之后回到UCP的界面中查看是否它们已经添加成功。如下图所示： 安装DTR-Docker镜像仓库 在UCP首页的下方，找到并点击 【Install DTR】的按钮，取得安装命令（记得从清单中选择固定IP地址的DTR主机）；在登录DTR主机的控制台里面输入这个命令，命令如下：\n1 2 3 4 docker run -it --rm \\ docker/dtr:2.2.5 install \\ --ucp-node 10.68.69.12 \\ --ucp-insecure-tls DTR节点没有离线安装的整合包，它需要联网下载很多相关镜像，如果网络速度不是很快的话，下载和安装的过程需要至少半个小时，过程中还需要输入UCP的管理员，用户名和密码。\n参考文档如： https://docs.docker.com/datacenter/dtr/2.2/guides/admin/install/#step-3-install-dtr\nDTR正常工作了以后，登录建立一个名为owncloud的镜像库，点击【New Rrepository】输入owncloud。 在一个节点上下载owncloud镜像，添加新的tag，上传到这个镜像到镜像库里备用。参考命令如下：\n1 2 3 4 docker login dtr.zenlab.local docker pull owncloud docker tag owncloud:latest dtr.zenlab.local/admin/owncloud:latest docker push dtr.zenlab.local/admin/owncloud:latest 注意：如果你的环境中没有DNS，就把dtr.zenlab.local换成DTR的IP地址。\n以上这个步骤主要是方便以后，反复使用和测试这个镜像的可能性，如果所有的节点都有高速的互联网链接，可以忽略以上步骤。\nDocker Swarm群集中使用DVP 这里使用UCP的图形化界面，在一个所有节点都配置和部署了VDP的群集上，给群集挂载外部Nutanix的数据卷。\n登录UCP主页，点击Resource，点击Volumes，点击 【Create Volume】，输入相关参数，如下图所示。图中的sizeMb=500000这个参数是制定VolumeGroup的大小，不设定这个参数的话，默认是10GB。 在到Nutanix的Prism里面查看这个Volume Group是否存在。应该如下图所示：\n部署OwnCloud网盘服务 登录UCP主页，点击 Service ， 点击 【Create a Service】按钮；开始建立这个服务。输入服务名，镜像名；点击 【Next】按钮。\n点击 【Next】按钮。进入 Resource页面，这里需要配置端口和数据卷。 最后点击【Deploy Now】按钮。 部署完毕之后，显示这个服务的状态为正常。 点击这个服务，到这个页面的最下方，找到右下角的发布端口的链接，点击后，就可以看到ownCloud的初始化配置页面了。 输入管理员的用户名和密码，进入之后，上传一些图片，测试一下功能是否正常。\n尝试一些Docker Datacenter的高级功能，如服务的高可用性；同时Nutanix的DVP在底层保障了数据的持久性和完全性。测试步骤如下：\n找到运行owncloud的容器，删除这个容器 在服务页面查看owncloud服务的状态变化 等ownCloud的状态恢复正常之后 再次登录ownCloud页面 查看和确认刚才上传的文件是否还在 总结 Nutanix是一种融合和了计算、存储和虚拟化（内置KVM）的超融合平台。Nutanix DVP (Docker Volume Plug-in)可以让平台里的容器用上持久化存储服务。DVP不仅可以给单独虚拟机里的容器提供持久卷服务，还能给类似于Docker Swarm的其它容器编排平台提供持久化数据服务功能。我后续的文章还会分享路测试Kubernetes等其它平台。\n","date":"2017-11-02T00:00:00Z","image":"https://martinliu.cn/images/abstract-4.jpg","permalink":"https://martinliu.cn/blog/nutanix-dvp/","title":"为Docker Swarm群集配置Nutanix持久存储"},{"content":"Tips for Docker on Mac 在macOS上使用Docker很长时间了，本文总结一些我不想忘记的tips，方便自己反复使用的同时，也顺便总结分享一下，留下本文作为长期更新的备忘录。\n搭建私有镜像库 运行一个本地镜像库\n1 docker run -d -p 5000:5000 --restart=always --name registry registry:2 这条命令会从docker hub 下载 registry:2 镜像，在本机运行一个镜像库服务。\n下载一个测试用的镜像。\n1 docker pull ubuntu:16.04 给这个镜像打上私有镜像库的标签\n1 docker tag ubuntu:16.04 localhost:5000/ubuntu:16.04 push这个测试镜像到本地的镜像库\n1 docker push localhost:5000/ubuntu:16.04 这时候你会发现我的本地这样岂不是有了两份相同的镜像了，有这个必要么？是不是多余了？下面几个场景中会用到：\n当你用docker-machine在本机启动1个vm的时候，你运行任何docker run或者docker-compose up的时候你可能需要一个之前在本地就有的image，这是一种分享本机image给docker-machine vm的一种方式。\n当你用docker-machine在本机启动多个个vm的时候，你可能会把它们作出docker Swarm群集，当你在这个群集上启动一个服务的时候，docker compose文件中的镜像地址可以引用这个本地地址，引用地址类似这样 image: 192.168.99.1:5000/influxdb\n当你用 minikube start启动了一个minikube的vm的时候，你可能也需要本机的docker镜像，尤其是在你做demo的时候，这是最快的下载途径。 需要注意的是，以上三种情况都需要指定一下\u0026ndash;engine-insecure-registry 192.168.99.1:5000 这个参数。\n自动化创建Docker Swarm群集 在我的文件目录中存放着这个脚本\n1 2 3 4 5 6 7 8 9 10 11 cat create-swarm.sh docker-machine create manager --engine-insecure-registry 192.168.99.1:5000 docker-machine create agent1 --engine-insecure-registry 192.168.99.1:5000 docker-machine create agent2 --engine-insecure-registry 192.168.99.1:5000 docker-machine create agent3 --engine-insecure-registry 192.168.99.1:5000 eval `docker-machine env manager` docker swarm init --advertise-addr `docker-machine ip manager` docker-machine ssh agent1 docker swarm join --token `docker swarm join-token -q worker` `docker-machine ip manager`:2377 docker-machine ssh agent2 docker swarm join --token `docker swarm join-token -q worker` `docker-machine ip manager`:2377 docker-machine ssh agent3 docker swarm join --token `docker swarm join-token -q worker` `docker-machine ip manager`:2377 docker node ls 解释一下上面的代码：创建四个docker-machine vm，初始化swarm群集，把三个worker节点加入群集。这样四节点的群集就up and running了。\n清除以上群集虚拟机的命令如下：\n1 docker-machine rm -y manager agent1 agent2 agent3 ","date":"2017-09-26T00:00:00Z","image":"https://martinliu.cn/images/sandrali-3.JPG","permalink":"https://martinliu.cn/blog/tips-for-docker-on-mac/","title":"Tips for Docker on Mac"},{"content":"DevOps是孕育于敏捷社区，又反哺给整个IT技术行业的，是一次彻底而全面的技术和文化运动。本文从它的出处谈起，一直描述到当前国内的现状。最后总结了相关的核心技术和主要实践。\nDevOps简史 在2008年多伦多举办的敏捷大会（Velocity Conf 2008 ）上，Patrick DeBois 和AndrewClay Shafer 先生首次提议讨论“敏捷基础架构”这个话题。在第二年的敏捷大会上有一个具有里程碑的意义技术分享，来自Flickr公司《每天部署10次》的分享，它激发了随后Patrick DeBios在同年十月，在比利时的根特市举办的首届DevOpsDays活动，这个活动是两天的日程，为了大家方便在twitter上的传播，人们把DevOpsDays这个词简写为 “#DevOps” 。 此后，“DevOps”一词问世了，这个词所包含的理念和实践一时在越来越广大的人群中产生了共鸣，随后成为全球IT界在各种大会和论坛里热议和讨论的焦点话题，很多大型IT论坛也都开设出了DevOps专题讨论。这就是DevOps这个词的由来。DevOpsDays活动随后在Patrick DeBios等相关核心发起人的推动下，在全球范围内蓬勃发展了起来。2010年在美国山景城(Mountain View) 举办的DevOpsDays 活动中，Damon Edwards先生使用“CAMS”这个缩写，高度概括和诠释了DevOps，即文化（Culture）、自动化（Automation）、度量（Measurement or Metrics）和分享（Sharing）。随后Jez Humble先生将“L”精益 (Lean) 原则也加入其中，最终变成了CALMS。\nCulture（文化）- 是指拥抱变革，促进协作和沟通 Automation（自动化）- 是指将人为干预的环节从价值链中消除 Lean（精益）- 是指通过使用精益原则促使高频率循环周期 Metrics（指标）- 是指衡量每一个环节，并通过数据来改进循环周期 Sharing（分享）- 是指与他人开放分享成功与失败的经验，并在错误中不断学习改进 “CALMS”完全吻合Patrick DeBois先生所一向倡导的“DevOps is a human problem” (DevOps 是关于人的问题) 的理念 。\nDevOpsDays活动的现状 从DevOps概念的产生，到如今它在全球范围内的蔓延和认同，已经经历了9个年头的时间。它的火爆推广也伴随着IT行业的迅速变迁和发展，现在已经到了移动互联网时代的后半场，国内的信息化建设已经完成了很多年；如今各行各业的企业也都亟待完成全方位的数字化转型。IT信息技术的先进程度标志着一个企业的核心能力，任何一个成功的企业，敏捷高效的软件开发创新实力和IT管理综合能力不只是门面而已，而是实实在在的市场竞争能力。DevOps倡导打敏捷、持续交付和ITIL三种实践的组合拳，同时应用精益生产理念为基础的管理思想，这正在逐渐地被广泛的接受和认可。\n在过去的几年中，国内的各种IT大会也蓬勃发展，其中DevOps相关的专题和分会场也颇受人们的关注。各种云计算、运维等IT技术的社交媒体也都非常重视DevOps这个话题的分享。一个专属于DevOps社群的、国际性的、有影响力的DevOps大会正呼之欲出。在这样的时代背景下DevOpsDays大会北京站在2017年的3月18日来到中国，在同年的8月18日上海，还要举办DevOpsDays Shanghai站的大会。\n下面列举一些DevOpsDays大会的相关数据，数据来源于DevOpsDays.org 网站。从2009年到2016年，已经在全球的61个城市/国家成功地举办了117场。\n在谈这个话题前先看一下DevOps相关工具集的全貌，如下图所示：\n（上图来源于：Exin DevOps白皮书）\n","date":"2017-09-23T00:00:00Z","image":"https://martinliu.cn/images/tf_5.jpg","permalink":"https://martinliu.cn/blog/about-devops-china/","title":"关于DevOps 的那些事"},{"content":"在经历了一个很长的周期之后，我的blog又回到了最原始的状态。很早以前学习网页开发的时候，用写字板编写html代码，后来是Asp，工作以后是用Blogspot，之后是WordPress，然后是Jekyll+github，现在是Ghost+七牛。\n4个拐点\n我的blog经历了四个转折点，下面稍微说下，为啥选择了某个平台，为啥后来又放弃了。\n免费博客平台：最初我试用了几个国内外免费的服务，最后发现Blogspot的体验要优于其他所有平台，而且具备一定的定制能力，还没有广告。然后就一直用到了Blogspot被墙的时候，那时候我还没有买域名。记得MSN的Space也用过，如果你没有用过MSN的话，当我没说这句话。总之免费blog空间的弊端就是，你码的字和图片是给别人的，不属于你自己，没有延续性。 WordPress：是我用的时间最长的平台，它的好处是可以host在任何php虚拟空间和云主机上；优势就是功能强。曾经浪花费了大量的时间，在测试和感受各种插件和皮肤上。而且WP的搬家工作也容易，因此换了很多个空间，一共有多少个主机空间现在已经都忘了。放弃WP的原因：维护LAMP堆栈的工作量还是有的，即使在PHP的虚拟空间里，这个系统的优化工作还是持续不断的要做的，否则网站速度会很慢，而且时快时慢，网站的访问性能其实无法保证。因此在这个过程中必须使用CDN服务，七牛的wp插件是我用的最长时间的，因此我早期的blog的图片都在七牛上，它给我了一个备份和加速图片的福利。性能不稳定，页面打开速度慢是放弃它的主要原因。 Jekyll+GitHub：选择这个组合，开始于我重度使用Github的时候。而且macOS上安装Jekyll这种静态blog程序很方便，捣鼓起来之后，就感觉比WP方便简单直接多了。发现这个方式非常轻量和简洁。而且Github.io的免费静态网站host服务还支持自定义域名。因此，我做了把之前所有WP的文章导出为MD格式文档的数据迁移工作。由于之前WP文章里的图，已近都存放在七牛里了，因此这次我做了一个出乎意料敏捷轻松的转身。使用过程中，逐渐发现了Jekyll的各种不足，界面和格式的定制工作还是有的，即使用几十刀买的皮肤都会让你用到难以忍受，毕竟不是想developer那样天天写代码，也逐渐感到Jekyll的简洁变成了简陋。代码定制的工作量和难度大是放弃它的主要原因。 Ghost+七牛：其实早就瞄上Ghost了，可是一种没有下决心换。直到最近我开始把Ghost安装在Mac OS的笔记本电脑上，发现在本机编辑和维护文章资料，速度飞快，和以前WP在线编辑简直是天壤之别。如果Ghost应用跑在自己的笔记本电脑上的话，既可以离线工作，像之前用Jekyll+Github组合一样，也更可以不需要购买任何虚拟主机和空间了，在本机离线工作的速度和效率好，而且稳定太多了。 buster这个程序是这次切换到Ghost的催化剂，它可以把Ghost网站的全站导出成静态文件，线上就只需要一个CDN空间了。七牛的qshell工具可以方便地把本地的静态网站文件夹，同步到CDN的buckte存储中。切换到这个方案的原因是：网站变为纯静态网页，全站html/css和图片全面上CDN，配置全球加速网站域名，享用七牛的免费套餐。 下面花一点篇幅介绍一下目前的blog环境细节。简单地说：目前是在笔记本上跑Ghost服务器，这样就省去了云主机和虚拟主机空间的需求，把ghost的站点导出为静态网页和图片，然后增量地上传到七牛的CDN上去。 Ghost本地安装\n我的操作系统是MacOS，用的是2017款MBP。\n先安装node.js，进入https://nodejs.org/en/ 在网站的首页上就可以下载到安装包，下载安装即可。也可以用 brew 安装。安装完了以后就获得了 npm 包管理程序。\n之后参考https://docs.ghost.org/v1.0.0/docs/install#pre-requisites 的文档安装 ghost-cli ； 然后用ghost的命令行来实现ghost程序的安装和升级。\n用ghost-cli安装ghost服务器的时候，要选择local的方式，它会使用sqllite作为数据库，这样做管理和维护Ghost应用栈的工作就都在本地了。\nghost服务器的初始化 ghost install local 这个命令会问你几个问题，全都用默认即可。安装完之后就可以看到服务器运行的状态了。\n1 2 3 4 5 6 martin@mbp ghost status Process manager \u0026#39;systemd\u0026#39; will not run on this system, defaulting to \u0026#39;local\u0026#39; │ Name │ Location │ Version │ Status │ URL │ Port │ Process Manager │ │ localhost │ ~/source/ghost │ 1.8.7 │ running (production) │ http://martinliu.cn/ │ 2368 │ systemd │ 这样就表明本地安装成功，访问 http://martinliu.cn/ghost 建立管理员账户，登录以后，就可以在本地编辑和维护blog文章了。 Buster安装和使用\nBuster的安装也很简单，网上有很多安装使用攻略，此处忽略。我用下面的命令来把Ghost网站做导出：\n1 buster generate --new-domain=martinliu.cn 在ghost的根目录下运行这个命令，就可以把本地的ghost网站都导出到一个名为static的目录里。可以直接在这个目录里打开这些html纯静态的网页，可以浏览和验证格式是否正常，一般不需要这样做，格式一般不会出错的。 配置七牛CDN\n七牛提供了本地的qshell，用于上传和同步文件到云端的存储里。安装过程文档见 https://github.com/qiniu/qshell\n我在ghost的根目录下，编辑了一个上传网站的配置文件upload.conf，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { \u0026#34;src_dir\u0026#34; : \u0026#34;/Users/martin/source/ghost/static\u0026#34;, \u0026#34;access_key\u0026#34; : \u0026#34;XXXXXXXkAA9TYrcDmQPBAAcB7\u0026#34;, \u0026#34;secret_key\u0026#34; : \u0026#34;XXXXXXXXXXXXXXXXXXXXXndwt\u0026#34;, \u0026#34;bucket\u0026#34; : \u0026#34;martinliu-cn\u0026#34;， \u0026#34;ignore_dir\u0026#34; : false, \u0026#34;overwrite\u0026#34; : true, \u0026#34;check_exists\u0026#34; : true, \u0026#34;check_hash\u0026#34; : true, \u0026#34;rescan_local\u0026#34; : true, \u0026#34;log_file\u0026#34; : \u0026#34;./upload.log\u0026#34;, \u0026#34;log_level\u0026#34; : \u0026#34;info\u0026#34;, \u0026#34;log_rotate\u0026#34; : 1, \u0026#34;log_stdout\u0026#34; : true, \u0026#34;file_type\u0026#34; : 0 } 以上这个配置很重要，它的目的是实现：\n增量上传 修改的文件覆盖上传 感谢七牛的工程师茅工，在我调试以上需求的时候，给我提供了及时的帮助。而且七牛的免费账户也可以开工单获取技术支持，支持的响应速度还不错。\n这样执行 qshell qupload 10 upload.conf 既可以完成一次上传同步工作，这个步骤是唯一需要在线操作的步骤。这条命令的输出结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 2017/09/25 00:00:21 [I] File `tag/cloud/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/coding/index.html =\u0026gt; tag/coding/index.html [113/119, 95.0%] ... 2017/09/25 00:00:21 [I] File `tag/coding/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/devops/index.html =\u0026gt; tag/devops/index.html [114/119, 95.8%] ... 2017/09/25 00:00:21 [I] File `tag/devops/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/getting-started/index.html =\u0026gt; tag/getting-started/index.html [115/119, 96.6%] ... 2017/09/25 00:00:21 [I] File `tag/getting-started/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/journey/index.html =\u0026gt; tag/journey/index.html [116/119, 97.5%] ... 2017/09/25 00:00:21 [I] File `tag/journey/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/opensource/index.html =\u0026gt; tag/opensource/index.html [117/119, 98.3%] ... 2017/09/25 00:00:21 [I] File `tag/opensource/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/running/index.html =\u0026gt; tag/running/index.html [118/119, 99.2%] ... 2017/09/25 00:00:22 [I] File `tag/running/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/test.html =\u0026gt; test.html [119/119, 100.0%] ... 2017/09/25 00:00:22 [I] File `test.html` exists in bucket, hash match, ignore this upload 2017/09/25 00:00:22 [I] -------------Upload Result-------------- 2017/09/25 00:00:22 [I] Total: 119 2017/09/25 00:00:22 [I] Success: 0 2017/09/25 00:00:22 [I] Failure: 0 2017/09/25 00:00:22 [I] NotOverwrite: 0 2017/09/25 00:00:22 [I] Skipped: 119 2017/09/25 00:00:22 [I] Duration: 36.533056019s 2017/09/25 00:00:22 [I] ---------------------------------------- See upload log at path ./upload.log 七牛的域名配置如下图所示： Blog工作流 下面就是我目前的blog工作流程说明。\n启动本地的ghost服务器，开始编辑和维护blog文章，如新写一篇blog；其实我也根本就不关这个服务器，感觉它也没有什么消耗。这样的话飞机上的无聊时间，可以彻底得到充分利用了。 在本地发布和预览blog文章和内容，修订并定稿。 运行Buster命令导出全站文章到本地。 在想更新上线新内容的时候，在联网的情况下，运行qshell上传同步命令，把本地static文件夹和七牛上的存储bucket同步一下。 至此我完成了从动态blog到纯静态blog的转型，现在网页html和图片文件全都在七牛的CDN里，而且域名 martinliu.cn 的访问配置成了全球加速。\n目前使用的是七牛的免费流量和空间套餐，套餐内的各种数量限制如下。\n目前的疑问是这个免费套餐是否够用，不知道这个羊毛多久会被我薅完。我会定期在本文跟新以上解决方案，在使用期间的各种配置细节变更，或者遇到的问题和解决方法。\nTO-Do\n把static变成一个git库，以后配置Jenkins，基于它的变化，自动化触发后续的更新和上传动作 在上传前运行htlm和css文件的压缩工具（命令行执行），优化页面尺寸 在上传前运行图片的压缩工具（命令行执行），优化图片尺寸 在Ghost里加入评论功能 加入Google网站统计代码 测试Ghost网站备份和迁移过程，保证当前的ghost服务器崩溃了，数据不会丢失 ","date":"2017-09-21T00:00:00Z","image":"https://martinliu.cn/images/abstract-12.jpg","permalink":"https://martinliu.cn/blog/welcome-to-ghost/","title":"切换到Ghost+七牛"},{"content":" Usage: minikube [command]\nAvailable Commands: addons Modify minikube\u0026rsquo;s kubernetes addons completion Outputs minikube shell completion for the given shell (bash) config Modify minikube config dashboard Opens/displays the kubernetes dashboard URL for your local cluster delete Deletes a local kubernetes cluster docker-env Sets up docker env variables; similar to \u0026lsquo;$(docker-machine env)\u0026rsquo; get-k8s-versions Gets the list of available kubernetes versions available for minikube ip Retrieves the IP address of the running cluster logs Gets the logs of the running localkube instance, used for debugging minikube, not user code mount Mounts the specified directory into minikube profile Profile sets the current minikube profile service Gets the kubernetes URL(s) for the specified service in your local cluster ssh Log into or run a command on a machine with SSH; similar to \u0026lsquo;docker-machine ssh\u0026rsquo; ssh-key Retrieve the ssh identity key path of the specified cluster start Starts a local kubernetes cluster status Gets the status of a local kubernetes cluster stop Stops a running local kubernetes cluster update-context Verify the IP address of the running cluster in kubeconfig. version Print the version of minikube\nFlags: \u0026ndash;alsologtostderr log to standard error as well as files -b, \u0026ndash;bootstrapper string The name of the cluster bootstrapper that will set up the kubernetes cluster. (default \u0026ldquo;localkube\u0026rdquo;) -h, \u0026ndash;help help for minikube \u0026ndash;log_backtrace_at traceLocation when logging hits line file:N, emit a stack trace (default :0) \u0026ndash;log_dir string If non-empty, write log files in this directory \u0026ndash;loglevel int Log level (0 = DEBUG, 5 = FATAL) (default 1) \u0026ndash;logtostderr log to standard error instead of files -p, \u0026ndash;profile string The name of the minikube VM being used. This can be modified to allow for multiple minikube instances to be run independently (default \u0026ldquo;minikube\u0026rdquo;) \u0026ndash;stderrthreshold severity logs at or above this threshold go to stderr (default 2) -v, \u0026ndash;v Level log level for V logs \u0026ndash;vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging\nUse \u0026ldquo;minikube [command] \u0026ndash;help\u0026rdquo; for more information about a command. Starting local Kubernetes v1.7.5 cluster\u0026hellip; Starting VM\u0026hellip; Getting VM IP address\u0026hellip; Moving files into cluster\u0026hellip; Setting up certs\u0026hellip; Connecting to cluster\u0026hellip; Setting up kubeconfig\u0026hellip; Starting cluster components\u0026hellip; Kubectl is now configured to use the cluster. We have now launched an echoserver pod but we have to wait until the pod is up before curling/accessing it via the exposed service To check whether the pod is up and running we can use the following $ kubectl get pod NAME READY STATUS RESTARTS AGE hello-minikube-3383150820-vctvh 1/1 ContainerCreating 0 3s\nWe can see that the pod is still being created from the ContainerCreating status $ kubectl get pod NAME READY STATUS RESTARTS AGE hello-minikube-3383150820-vctvh 1/1 Running 0 13s\nWe can see that the pod is now Running and we will now be able to curl it $ curl $(minikube service hello-minikube \u0026ndash;url) CLIENT VALUES: client_address=172.17.0.2 command=GET real path=/ query=nil request_version=1.1 request_uri=http://192.168.99.100:8080/\nSERVER VALUES: server_version=nginx: 1.10.0 - lua: 10001\nHEADERS RECEIVED: accept=/ host=192.168.99.100:31721 user-agent=curl/7.54.0 BODY: -no body in request-% $ APISERVER=$(kubectl config view | grep https | cut -f 2- -d \u0026ldquo;:\u0026rdquo; | tr -d \u0026quot; \u0026ldquo;)\n$ curl $APISERVER \u0026ndash;header \u0026ldquo;Authorization: Bearer $TOKEN\u0026rdquo; \u0026ndash;insecure { \u0026ldquo;paths\u0026rdquo;: [ \u0026ldquo;/api\u0026rdquo;, \u0026ldquo;/api/v1\u0026rdquo;, \u0026ldquo;/apis\u0026rdquo;, \u0026ldquo;/apis/\u0026rdquo;, \u0026ldquo;/apis/admissionregistration.k8s.io\u0026rdquo;, \u0026ldquo;/apis/admissionregistration.k8s.io/v1alpha1\u0026rdquo;, \u0026ldquo;/apis/apiextensions.k8s.io\u0026rdquo;, \u0026ldquo;/apis/apiextensions.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/apiregistration.k8s.io\u0026rdquo;, \u0026ldquo;/apis/apiregistration.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/apps\u0026rdquo;, \u0026ldquo;/apis/apps/v1beta1\u0026rdquo;, \u0026ldquo;/apis/authentication.k8s.io\u0026rdquo;, \u0026ldquo;/apis/authentication.k8s.io/v1\u0026rdquo;, \u0026ldquo;/apis/authentication.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/authorization.k8s.io\u0026rdquo;, \u0026ldquo;/apis/authorization.k8s.io/v1\u0026rdquo;, \u0026ldquo;/apis/authorization.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/autoscaling\u0026rdquo;, \u0026ldquo;/apis/autoscaling/v1\u0026rdquo;, \u0026ldquo;/apis/autoscaling/v2alpha1\u0026rdquo;, \u0026ldquo;/apis/batch\u0026rdquo;, \u0026ldquo;/apis/batch/v1\u0026rdquo;, \u0026ldquo;/apis/batch/v2alpha1\u0026rdquo;, \u0026ldquo;/apis/certificates.k8s.io\u0026rdquo;, \u0026ldquo;/apis/certificates.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/extensions\u0026rdquo;, \u0026ldquo;/apis/extensions/v1beta1\u0026rdquo;, \u0026ldquo;/apis/networking.k8s.io\u0026rdquo;, \u0026ldquo;/apis/networking.k8s.io/v1\u0026rdquo;, \u0026ldquo;/apis/policy\u0026rdquo;, \u0026ldquo;/apis/policy/v1beta1\u0026rdquo;, \u0026ldquo;/apis/rbac.authorization.k8s.io\u0026rdquo;, \u0026ldquo;/apis/rbac.authorization.k8s.io/v1alpha1\u0026rdquo;, \u0026ldquo;/apis/rbac.authorization.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/settings.k8s.io\u0026rdquo;, \u0026ldquo;/apis/settings.k8s.io/v1alpha1\u0026rdquo;, \u0026ldquo;/apis/storage.k8s.io\u0026rdquo;, \u0026ldquo;/apis/storage.k8s.io/v1\u0026rdquo;, \u0026ldquo;/apis/storage.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/healthz\u0026rdquo;, \u0026ldquo;/healthz/autoregister-completion\u0026rdquo;, \u0026ldquo;/healthz/ping\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/apiservice-registration-controller\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/apiservice-status-available-controller\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/bootstrap-controller\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/ca-registration\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/extensions/third-party-resources\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/generic-apiserver-start-informers\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/kube-apiserver-autoregistration\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/start-apiextensions-controllers\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/start-apiextensions-informers\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/start-kube-aggregator-informers\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/start-kube-apiserver-informers\u0026rdquo;, \u0026ldquo;/logs\u0026rdquo;, \u0026ldquo;/metrics\u0026rdquo;, \u0026ldquo;/swagger-2.0.0.json\u0026rdquo;, \u0026ldquo;/swagger-2.0.0.pb-v1\u0026rdquo;, \u0026ldquo;/swagger-2.0.0.pb-v1.gz\u0026rdquo;, \u0026ldquo;/swagger.json\u0026rdquo;, \u0026ldquo;/swaggerapi\u0026rdquo;, \u0026ldquo;/ui\u0026rdquo;, \u0026ldquo;/ui/\u0026rdquo;, \u0026ldquo;/version\u0026rdquo; ] }%\n","date":"2017-09-21T00:00:00Z","image":"https://martinliu.cn/images/abstract-1.jpg","permalink":"https://martinliu.cn/blog/install-minikube-k8s/","title":"用Minikube体验单节点K8S"},{"content":"来西安出差很多次了，每次都想绕城墙跑一圈，后来也不止一次看到其他朋友，要么绕城跑，要么在城墙上跑过；因此这根草也就越长越高，这次跑步的动力主要是拔草。\n从上图可以看出，绕城一周的距离是13.49公里，西安的城墙东西方向长，所以是一个比较扁的长方形。我是下午7点钟开始跑的，如果稍微晚几分钟到西门的话，售票处就会关门，我就错过了此次城墙上奔跑的机会，门票是45元，可一天中多次上下城墙使用。幸亏我从酒店（城西的老喜来登酒店）骑着摩拜及时赶到。\n城墙上的地砖较硬度比较大，建议穿缓冲好的鞋。7点半以后，天就彻底黑了，城墙上没有路灯，我有四分之三的距离感觉是摸黑跑，虽然路面是清晰可见的，不过在路过上下斜坡和台阶的时候，还是要加倍小心，毕竟安全第一。\n上图除了中间一张城墙砖的图片以外，其余的8张都是我用手机拍的。我想留下真实的时空的记忆。从左中的西门开始，我的路线是顺时针跑的，跑到北门，也就是上中的那张图，天就黑彻底了，完全失去了自然光。我在东南西北的城门都拍照了。在四个角楼也拍了。\n下图是在南门城墙上，往北拍的鼓楼，这个方向的路是西安城的中轴线，这个距离是城墙上离鼓楼最短的距离。也就是800左右的距离。\n总结 这次跑步并非是纯粹的拔草之旅，城墙给我们的历史感和沧桑感是非常强烈的。在这个城墙上跑一圈，你大概能够回想起秦黄汉武的盛世，能够想到玄奘西天取经等经典历史片段。感觉朝拜华夏文明历史的意义大于跑步健身。不过也要感谢跑步的习惯，否则没有这么强烈的仪式感，自己的身体和精神也就不会有这么强烈的冲击。这样的文化之旅，的确值得强烈推荐给所有跑友。\n","date":"2017-09-12T00:00:00Z","image":"https://martinliu.cn/images/city-wall_Fotor.jpg","permalink":"https://martinliu.cn/blog/%E5%A5%94%E8%B7%91%E5%9C%A8%E8%A5%BF%E5%AE%89%E7%9A%84%E5%9F%8E%E5%A2%99%E4%B8%8A/","title":"奔跑在西安的城墙上"},{"content":"趁着参加DevOpsDays Taipei的机会晨跑台大校园。在台北的这几天总体感觉是非常好的，和很多大陆来的好朋友一起，愉快地玩耍了几天。只跑了这一次，算是前往台大打卡留念吧！\n下图算是台大的东门，校门并不是很大，可是进去之后，看到了纵贯南北的校内大路的时候，才会有豁然开朗的感觉。\n下图就是中午的校园大道，两边高大的棕榈树凸显了亚热带海洋性气候的感觉。 下图是清晨的校园大道，时间大概是7点半左右，可以看到太阳已经很高了。 下图是这条大道的尽头，也就是台北国立大学的主教学楼。 下图是一栋比较新的教学楼，路两边依然是这种热带的树种 下图是这次的跑步地图，从Garmin网站上导出的数据文件，用过Google Earth查看截屏得到的图。 从上图中可以看出我几乎走遍了这个学校的所有主干道，有些地方是教职工宿舍区，有些地方是施工封闭的路段，还由于太阳太晒了，所以并没有凑够10公里整数。 总结 台大校园是台湾的最高学府之一，地位堪比国内的北大、清华和复旦，是台湾学术和科技交流活跃的地点，校内的免费wifi，无墙，而且下载速度在10m左右，网速比大陆快n倍。校园里路面平整，软硬适中，很适合跑步。校内的风景独特而优美，值得来游走一番。如果是北方的人，而且向我一样不是很耐热的，建议早点来，温度和日照强度都低一些。我跑的虽然不远，可是一路上一直是汗流浃背，建议带瓶水。本次跑步是我在台湾的首次跑步，台大校园路线已经进入了我的个人路线集。\n","date":"2017-09-09T00:00:00Z","image":"https://martinliu.cn/images/abstract-2.jpg","permalink":"https://martinliu.cn/blog/ntu-running/","title":"台大校园游览跑"},{"content":"在全球范围内，公有云发展的正如火如荼，对IT行业技术的发展产生了很大的影响，从私有云到公有云，到混合云，再到云原生应用和DevOps。这一连串的连锁，也反映出了最近10年来IT行业发展的主流趋势。\n各种味道的云计算 参考来源：Battle of the clouds: Amazon Web Services vs. Microsoft Azure vs. Google Cloud Platform 作者 Brandon Butler, Senior Editor, Network World ，FEB 22, 2017 12:42 PM PT Which flavor of IaaS public cloud has what you need?\n对于行业观察者而言Amazon AWS是IaaS公有云市场里，不容争辩的领导者。而Azure正在逐渐缩小与AWS之间的差距，后来者GCP正大踏步的走来。\n根据Gartner对云厂商的深度评估，它分析了云厂商对企业工作负载的满足情况，AWS在最近的三年里，在234项功能对比中，保持着92%的满足度，Azure从75%上升到了88%。GCP也进入到了70%的程度。如下图所示：\nGartner对IaaS厂商的评估 重点看Required这一列的百分比。这些企业级功能被分类为三个级别：\nRequired 必须具备的； Preferred 最好能具备的； Optional：推荐具备的。 Amazon Web Services AWS是IaaS公有云市场的缔造者，它在2006年发布了第一项云服务Simple Storage Service - S3；Gartner认为它是最成熟的公有云服务提供商，它的功能从广度和深度上，都能最广泛的，能覆盖各种使用场景。它的优缺点如下图所示：\nAWS的优缺点 优点 缺点 最大和最成熟的公有云IaaS厂商，具有最强大和多样性的功能集合，被Garter称为：最广泛使用场景里的”安全之选“ 尽管AWS的入门和上手是容易的，它还是需要专业人士的管理和驾驭。由于它的功能性的宽广，这会让用老用于也难于面对多种的实施方案，需要第三方的专业顾问帮忙。 市场里的思想领袖和创新者，不断推出各种IaaS的新特性，例如Lambda无服务计算平台 对于用户的时间和实施能力而言，AWS有时候创新速度太快了，用户的知识很快就会过时，需要他们持续地更新AWS功能和平台的知识。 AWS的云市场具有最广泛的第三方工具的选择。而且它的顾问和专家的人数也是最多的，他们可以帮助到AWS的用户。 AWS一直以来都不是追求高价格。用户在每次购买服务的时候都有不同折扣，有时候需要使用第三方的工具帮忙管理成本。\n从技术的角度看，AWS持续创新的速度和动力都是非常强大的，服务更新的频率和速度非常快，在某种程度上超过了客户的适应和学习的速度，增加了客户的学习成本。它的SLA的规定有时候过于繁琐的，例如：需要客户的工作负载必须跨两个AZ部署，这会增加客户的成本。刨除以上所有对于客户的挑战，Gartner依然称之为云计算使用的“安全之选”。\nMicrosoft Azure 微软Azure逐渐变成了//Application development platform as a service (PaaS)的PaaS平台，其实它可以提供包括IaaS、PaaS和SaaS等广泛的服务。微软Azure最大的优势可能是他广大的企业客户基础。很多客户已经把Office系统迁移到了Office 365 SaaS服务上了，微软继续给用户提供大量的IaaS使用折扣（点卡），鼓励用户上云。\nAzure从功能角度看不管是计算、存储，还是数据库和IoT等方面，都与AWS非常的接近和匹配。微软试图通过混合云的策略区别于AWS。因此它提供了Azure Stack私有云方案。\nMicrosoft Azure的优势和劣势 优点 缺点 微软在构建Azure全球的数据中心基础设施方面和云功能开发上已经做出了巨大的投资。Gatner说Azure在IaaS公有云方面是”足够好了” 尽管Aure具有了大多数Gartner企业工作负载所需的功能，这些产品和API在某些情况下还不像它的友商AWS那样的成熟。 微软和几乎所有的大型企业具有长期和稳定的关系，在现有的企业协议EA里提供了非常具有吸引力的Azure的供给。 与Azure云集成的第三方公司的产品数量有限，相对于AWS，它的专家顾问社区也比较小。 微软Azure提供集成化的IaaS、PaaS和SaaS（Office 365）。Azure是已经多年投资于微软系列产品者的理想的选择。它的混合云的方案是很有吸引力的，包括Hyper-V，Windows Server，Active Direcitory， Visual Studio 和最近的Azure Stack。 在区域的设计中，Azure和AWS不同，它的Zone的概念和AWS不同，这会让工作负载的备份相对的稍微有点难。尽管在支持开源和非微软技术方面花费了大量的精力，微软公司任然不算是一个开源的领导者，而AWS和Google的云则是开源技术工作负载的一个更中立的选择。\n显然Azure最适合运行的是微软类型的工作负载，或者最适用于把已有的微软平台应用跑在公有云中。对于那些企业客户的EA，其中会包含一定数目的Azure点卡，不用可惜，用起来的话，Azure的使用还是比较经济的。\nAzure没有AZ的概念可谓是技术上的硬伤，比起AWS，这会导致跨区的备份略显麻烦一点。 业内Azure的专家和顾问还是相对较少。Gartner IaaS Magic Quadrant认为Azure对于大多数企业工作负载而言，已经是 足够用了“good enough”。\nGoogle Cloud Platform GCP与Azure类似，开始于PaaS，然后扩展到IaaS。分析师认为它特别适合跑某些使用场景，包括容器、大数据和机器学习。GCP在全球范围的数据中心相对较少。\nGoogle也有类似于Office 365 的办公套件SaaS服务，是G Suite，它的价格策略是，用的人越多，单价越便宜。\nGCP还是在发展中的云计算，从功能上讲，根据Gartner的年度评估，GCP仅满足70%的必选功能。技术上的优势在于：Google是开源的大数据（Hadoop、 Spark 等）技术、机器学习技术（Tensorflow）和容器编排技术（Kubernetes），它在开发者社区里从来没有缺少过粉丝，它对技术发展的影响不可小觑，这些影响最终都可以通过吸引用户使用GCP来使Google收益，并把这些技术变现。\nGoogle Cloud Platform\n在2016年Google招聘了VMWare的联合创始人Diane Greene，这标志着它计划向企业级能力和市场挺进。 Game of Cloud 公有云的游戏\n分析师认为对于大多数云的用户来说，并不是做的“零和游戏”的选择，很多人使用多云的策略。多云管理平台厂商RightScale，对1000个用户的调查分析 可以看出，用户57%的应用在AWS上，34%的应用在Azure上，15%跑在GCP上。85%的 RightScale的用户使用多云的策略，可能是：公有云+私有云；或者公有云A+公有云B+？？。\n硬碰硬功能对比 计算 AWS Azure GCP EC2 云中的虚拟服务器 Virtual Machines 在几秒钟内预配好 Windows 和 Linux 虚拟机 Compute Engine: Run VMs on Google\u0026rsquo;s infrastructure EC2 Container Service/Registry 运行和管理 Docker 容器，容器镜像仓库服务。 Service Fabric 在 Windows 或 Linux 上开发微服务和安排容器 Container Engineer: Container cluster, Workloads, Discovery\u0026amp;load balancing, Configuration, storage Lightsail 启动和管理虚拟专有服务器 App Service 快速创建适用于 Web 和移动的强大云应用 Cloud Launcher: Cloud Launcher lets you quickly deploy software on Google Cloud Platform Elastic Beanstalk 运行和管理 Web 应用 Cloud Services 创建高度可用且可无限缩放的云应用程序和 API App Engine: PaaS for apps and backends Lambda 运行您的代码以响应事件 Functions 使用无服务器代码处理事件 Cloud Functions : Serverless Applications on Google’s Infrastructure Batch 运行任意规模的批处理作业 Batch 云规模的作业计划和计算管理 无专门的服务，Google App Engine provides a Cron service. Using this service for scheduling and Google Cloud Pub/Sub for distributed messaging, you can build an application to reliably schedule tasks across a fleet of Compute Engine instances. Auto Scaling 自动化弹性扩展 Virtual Machine Scale Sets 管理并扩展到数千台 Linux 和 Windows 虚拟机 Instance Groups: managed instance groups can automatically scale the number of instances in the group.\n从概念上讲，提供的虚拟机功能是没什么差别的，包括虚拟机的自动化扩容和缩容功能都是类似的。区别在于其他的相关功能上。\nAWS在Serverlesss架构方面的Lambda是最领先的，它有最丰富的云市场，能提供最丰富的第三方应用服务，通过Lightsail和云市场都可以一键式启动特定配置的预装应用虚拟机/虚拟机集合。\nAzure在发布Winddows客户端应用上是有优势的。在其它功能上基本上可以和AWS对齐。\nGCP的明显优势是GEK，K8S如日中天的热度刺激人么对其GKE和GCE的关注和使用。\n全世界数据中心覆盖 AWS Location 数据中心在全球的覆盖 AWS Regions and Availability Zones\nhttps://aws.amazon.com/about-aws/global-infrastructure/\n已经开放的区和AZ： US East N. Virginia (6), Ohio (3)\nUS West N. California (3), Oregon (3)\nAsia Pacific Mumbai (2), Seoul (2), Singapore (2), Sydney (3), Tokyo (3)\nCanada Central (2)\nChina Beijing (2)\nEurope Frankfurt (3), Ireland (3), London (2)\nSouth America São Paulo (3)\nAWS GovCloud (US-West) (2)\n绿色的圈是要开放的区。\nChina\nFrance\nHong Kong\nSweden\nAWS GovCloud (US-East)\nAzure Region https://azure.microsoft.com/en-us/regions/\n蓝色三角的是要开放的区。\nGCP 的 Cloud Locations https://cloud.google.com/about/locations/ 蓝色的是要开放的区。\nGCP的另外一个卖点是它的全球高速光缆链接的网络。 存储服务 参考来源： https://www.networkworld.com/article/3191520/cloud-computing/deep-dive-on-aws-vs-azure-vs-google-cloud-storage-options.html\n块存储对比 对象存储 文件存储 Game of Clouds AWS 2017 云市场应用排名\nFrom: https://www.cloudendure.com/blog/aws-cloud-computing-map-game-of-clouds-2017\nAWS的云市场反映出它强大的第三方伙伴和生态系统。\nAzure Stack\n这是它区别于其它云的功能点，是可以在企业数据中心里部署的私有云IaaS平台。它与Azure公有云遥相呼应，为客户提供了混合云方案。\n本地运行 Azure 服务 根据你的需求正确组合云和本地部署来满足业务和技术要求。Azure 基础结构即服务 (IaaS) 传输远优于传统虚拟化。借助虚拟机规模集，新式工作负荷的真正自动扩展可实现快速部署。一致的 Azure 平台即服务 (PaaS) 功能将混合部署选择和可移植性引入云应用程序。因此，可在本地运行完全托管的 PaaS、无服务器计算、分布式微服务体系结构和容器管理。\n生成跨混合云环境的新式应用程序 Azure Stack 是 Azure 的扩展，将云计算的敏捷性和快节奏创新引入到本地环境。只有 Azure Stack 才能让你从组织的数据中心提供 Azure 服务，同时适度平衡灵活性和控制程度，实现真正一致性的混合云部署。\n利用一致的环境加速开发 无论应用是在 Azure 还是在 Azure Stack 上运行，开发人员都能以相同的方式生成和部署应用程序，从而实现工作效率最大化。一套工具 - 使用相同的应用程序模块、自助服务门户和由 Azure Resource Manager 启用的 API。常规 DevOps — 通过 Jenkins 和 Visual Studio Team Services 体验持续部署和集成，通过 Chef 和 Azure PowerShell DSC 扩展体验自动化。 开源 — 使用 Java、Python、Node.js、PHP、Docker 集成式容器、Mesosphere DC/OS 和 Cloud Foundry 等众多开源技术。\n","date":"2017-09-07T00:00:00Z","image":"https://martinliu.cn/images/abstract-10.jpg","permalink":"https://martinliu.cn/blog/game-of-cloud/","title":"Game of Cloud 对比三大主流公有云厂商"},{"content":" ","date":"2017-09-07T00:00:00Z","image":"https://martinliu.cn/images/abstract-11.jpg","permalink":"https://martinliu.cn/blog/taipei/","title":"不一样的台北，不一样的感受"},{"content":"Las Vegas到大峡谷（Grand Canyon National Park）的距离并不遥远，但是离最佳风景观看点南峡（South RIM）还有大半天的路程。很值得去，绝对不会后悔。 行程\n我们走的路线和预先计划的稍微有些差异，主要是受了同时Danny的影响，他曾经自驾车在大峡谷玩过。根据他的建议，我们设计了大峡谷南峡的两日游。路线如下：\n从拉斯维加斯出发–93号公路–40号公里–住在威廉斯小镇–64号公路–大峡谷国家公园（南峡）。本来计划先去游玩胡夫大坝、西峡（Eagle Point和Guano Point），之后晚上住在威廉斯小镇，第二天再去南峡一日游。西峡被Danny果断的否定了，他建议我们要在南峡的主景点多花时间；现在看来这个决定是对的。\n我们在10号早晨4点起床，出发前往大峡谷。在出门的第一个小时，里别导航搞得几乎是崩溃的。出现了几个状况：\n用iPad上的Google Map下载了三个州的离线地图是不好用的，甚至让iPad链接上国内手机热点的型号后，GPS定位还是不正常工作的（不知道是否是我的iPad的问题待查）。 用国内iPhone手机做以上相同的操作，问题是一样的。 用iPhone手机自带的苹果地图，能工作，可是由于没有离线地图，使用的时候略感延迟，也害怕使用过多的流量，因此还是放弃了。 大家各自用手机导航，有人的路线是南峡方向，有人是走北峡方向。在经过路口时大家意见不统一了，才意识到问题，大家都有中枪的感觉。 最后发现用国内手机，在来之前，在家下载好的三个州的Google Map离线地图是唯一好使的方案，在使用过程中可以完全不需要开数据网络，可以用飞行模式。 从拉斯维加斯市区到威廉斯小镇的酒店的路程大约是350公里，整个行程差不多花了5个小时左右（第一个小时忽略不计呵呵）。\n在酒店放下行李，checkin了以后，我们就奔向了大峡谷南峡的南门（东门才是正门），大约从酒店出发，又走了一个小时多才进入公园，车停在了Bright Angle附近的停车场。接着开始了一天的大峡谷之旅。 大峡谷-Day1\n我们按照Danny的建议先乘坐西线（橙色）的Bus，到达了西峡的最远端（Herimt Point），在哪里稍微观赏了一下后，正好是午餐实践，在哪里的零食店一人买了一个三明治吃。然后回程的Bus在第一个停靠点下车，开始了徒步5.9公里的观赏，也就是从第一个停车点走到第二个停车点，回程总共三个停车点。\n这一段路在大峡谷当中，景色算不上是最好的，可是这段路包括了Green Road这一段路。这一段路里包括了大峡谷里的所有主要种类的树木和植物。大量的信息展示牌上介绍着各种动植物的信息，在途中前后碰到了三只鹿，可以算是给徒步者的一个奖励，这几只鹿貌似并不把人类放在眼里，它们各自闲散地吃着树叶，只有在人特别靠近的时候，才不耐烦的走开。\n在路上碰见了不少骑自行车的人，他们很多是以家庭为单位了，三五成群的前后照应着向前行驶而去，有些人的车是自己带的，有些人是在公园里面租车骑行的。\n我们的徒步的路段是：Pima Point到Mojave Point。在Mojave Point看到了著名的、教科书般的、明显的6层、分层地质峡壁和讲解的展板。\n在我们正要回去的时候，我们眼睁睁的错过了一辆Bus。在等下一辆Bus到来的时候遭遇到突如其来的阵雨的袭击。这里的天气很多变，雨滴打在身上特别凉。不一会就把我的上身都打湿了，我只穿了短袖和短裤，所以很快就迫使我我不得不躲到了树下。第二辆Bus在20多分钟之后，终于来了，上车之后，在回程的路上，阵雨下的更大了，能挤上车，顿时感觉自己很幸运。\n在回到了Right Angel Lodge的停车场之后，想着Gary应该在温暖的车里等着我们呢！可是没想到车里没有人，此时从车站冒雨跑过来的三个人鞋子都湿透了，冷风嗖嗖的刮着。大家躲在一个酒店房间的屋檐下，打着哆嗦的等了几分钟，后来觉得这样不行，就各自四处寻找拿着车钥匙的Gary去了。\n我在Lookout Studio附近和Bright Angle Lodge的商店里面寻找Gary的同时，倒也算是另外一番游览；找了30分钟以后，觉得应该回车子看下了，回去后发现Gary已经和曾旭在车里了，赶紧上车喝水休息。等了一会吴东也回来了。这时候雨还在下，时间大约是下午3点多，我们大家一致觉得回酒店休息了，结束了第一天新的游玩。 晚餐\n回到了酒店之后，我们进了房间，我赶紧脱下深山湿漉漉的衣服和鞋子，洗了个热水澡，换上干净温暖的衣服，直接钻进了被窝，昏昏沉沉的休息了大约一个多小时，也正好到了饭点了，外面的雨星星点点的没有停。我们就开车去往镇上吃饭了。\n我们先走进了一家美式当地的餐厅，发现菜单基本看不懂，就走人了。然后打算去吃一家意大利餐厅，发现等座位的人还是很多。后来我建议来这家 Cafe 66 Bar and Grill。这家是一家很地道的美式烧烤餐厅。\n我点的是上图的烤牛肉，其它人主要点的是下图的烤猪排。肉都烤的很嫩很香，几乎都吃不完就吃到顶了，大家饱餐一顿之后，回去妥妥的休息了。\n大峡谷-Day2\n第二天早晨起来大约是7点多，我睡的还行。大家去吃早餐，我泡了碗麦片牛奶、烤了两片土司、烤了一个圈圈面包、乘了一些炒鸡蛋和小香肠、倒了一杯橙汁，吃完了这些后吃了两个苹果。在这温暖的小店里，在一个没有任何赶路压力的行程上，我在这一周的行程当中，在此刻才算是真真的满血复活了。\n早餐后，我们就继续上路了。\n我们先把车停在了Visitor Center的停车场，然后从Mather Point走到了Yavapai Point and Geology Museum。一路上才发现好多大峡谷的明信片照片都是从这里取景拍摄的，这一段是大峡谷游览的必经之旅。\n然后我们驱车前往大峡谷南峡的最东头，也就是Desert View观景点，其实这个景点并不是东边的最后一个景点。我们在哪里看完之后，想一直往东开，看看到底还有什么景点。其实看到了不少的观景台，甚至于在密林中的头角硕大的鹿。最后走出了公园的东门，在往外开，才来到了公园的标识牌设立处。在往外开了几英里之后，就返回了。其实大家想起了再继续往北走180多公里就是著名的羚羊峡谷，Windows7桌面图片中出现过这个景点。可是行程来回要大约4个小时（370公里以上），在我的建议下大家还是忍痛放弃了这个景点。否则今天早晨应该还需要4点出发，回程晚上11点的飞机，想想当天还要赶飞机回家，其实压力还是有的。\n我们从公园外又兜了一圈回来之后，我们中途停在了Tusyan小镇上吃了午餐麦当劳，休息片刻之后继续上路了。路上我们加满油一下跑到了胡佛水坝，到了才知道最后一个游览是5点钟，虽然我已经尽力开快车赶路了，可是还是错过了。稍微浏览一下之后，接着回机场还车。然后座免费bus去机场了。晚上饭是吴东请客。大家在机场踏实的等了2个多小时就登机了。 小节\n这次出行美中不足的是：没有把徒步的装备带好，包括防晒、防雨措施；各种长短方便更换的速干衣裤，帽子等。还很重要的户外徒步的鞋子。\n在开车方面，三个司机的好处非常明显，这样大家分担着开非常有乐趣和安全。\n有可能的话大峡谷南峡的游览方向可以调整为，从东北方向南下过来，也就是羚羊峡谷的方向过来。这样的好处是，从公园东门进来之后，其实在Desert view之前有很多不错的路边的观景点，而且停车特别方便和顺手，这样的方式可以更充分的利用汽车的便利程度，多看了景点，还不累。\nHoover Dam错过了，我还是觉得有些小小的遗憾的。因为这个地方就在路上，时间安排的合理的话，能够参加上他们的水坝游览，里里外外都看一遍，应该还是很不错的。毕竟很多影视剧都到此取过景。\n总之这次拉斯维加斯之旅还是很棒的，除了去打枪射击的这一项没有Checked之外，其它的都算是完美收官了。这次入手了美国国家公园的Passport，用它来记录和收集所到过的国家公园的印章，以后可以统计一下，一共可以去几个了。\n","date":"2017-08-13T00:00:00Z","image":"https://martinliu.cn/images/abstract-11.jpg","permalink":"https://martinliu.cn/blog/las-vegas-p2/","title":"Las Vegas流水账-大峡谷篇"},{"content":"Las Vegas-拉斯维加斯，国人简称拉丝，美国人简称Vegas/威嘎斯。来过很多次美国，可是这个城市还是第一次造访，写个流水账记录一下。 航班\n这次来回都是韩国航空。从北京飞首尔转机直飞美国。这也是第一次乘坐韩国航空公司的飞机，第一次入境韩国。\n中午从北京出发的飞机晚点了30分钟后起飞了，在3点左右达到首尔机场，沿着指示标记，走向国际转机通道，经过安检后就进入了下图的首尔国际机场航站楼。\n这个航站楼还是很大的，里面有各种免税商店，包括化妆品、烟酒、食品和各种奢侈品。为了到此一游我也买了一副墨镜（Rudy意大利产），在此留个纪念；价格上比美亚可能要便宜20刀左右，而且还免税。基本上觉得还是划算的。\n与其它城市的几位同事及其家属碰头以后，我们四处转了转，由于转机的时间比较长，大家相谈甚欢，还是相当的休闲和愉快的。在那一刻也非常同情另外一波从北京出发的同事们，他们的飞机出现了机械故障。\n大约七点多大家想找个地方吃点饭，结果由于机场的人超级多，想找个吃饭的地方，居然不能找到一个能让我们四五个人一起坐下的饭馆，随即放弃吃饭的想法，买了杯星巴克了事。在夕阳的余晖下，大家津津有味地听宇宙同学普及各种会员身份使用攻略和褥羊毛秘籍，不知不觉也到了登机时间了。登机后吃了两顿饭，看了一部电影，快到的时候睡了大约2小时，然后就准时的在当地时间周日下午5点到达了。然后大家商量之后，果断的打了一辆Uber，直奔拉丝的北奥特莱斯去也。 进城\n汽车载着我们穿过市区的主街道，往北走直奔奥特莱斯。 这个奥特莱斯还是蛮大的，在8点下班前，我不紧不慢的买了两双鞋和一件T恤，之后和同事们一起打出租车会到酒店。 到 Aria酒店 Checkin了之后，进房间放下行李箱，同事们一起去酒店的Pool Bar吃晚饭，具体说是一个欢迎酒会。其实也吃不上什么正式的晚餐。当天晚上还是有时差的感觉，到晚上3点才昏昏睡去，睡了4个小时。早晨起来感觉还行，起床后完成了会议登记，接着去吃早餐，早餐是我吃过的所有会务餐中最差的，不提了略过。接着进入开会的节奏。 大会开始\n开场主持人是加拿大的一个Sales，他的气势和技巧还是很专业的，据说粗口的风格是与HR和公司的VP们请示过的，不过的确达到了逗乐和暖场的目的。随着“镜子”舞团的暖场舞，视频上播放了公司大佬们录制的视频，hipop风格的逗乐视频。由于印度裔大佬们较多，我看下来有点宝莱坞的感觉，哈哈！ 公司的大佬们悉数登场，各尽其职的讲述自己的部分。讲解了公司的市场前进和进入4B公司的计划。下午的各种session完了之后，晚餐也还是社交为主的，去了一个高尔夫训练场，大家基本也以聊天为主，至于晚餐么，我忽略不写了。 Night walk 晚餐之后和同事们一起来夜游Vegas的主大街夜景。从美高梅酒店走路到埃菲尔铁塔酒店，最后回房间休息。 横穿美高梅酒店赌场，感觉MGM的人气确实很旺，比其它酒店生意好。 经过自由女神像的纽约酒店赌场。 走到埃菲尔铁塔附近 看完百樂宮酒店（Bellagio）的音乐喷泉后，走路回到酒店。\n考虑到最后两天去大峡谷的路程比较远，希望能早走，我取消了之前的租车订单后，又下单订车，提前了一天取车，而且取车的地方就选择了酒店楼下。这样时间就不紧张，而且取车更方便了。\n这就是此次拉斯维加斯之行的第一部分，航班安全顺利到达，进城后参加了一天平淡无奇的公司大会。大概领略了一下这个极致的城市。\n","date":"2017-08-08T00:00:00Z","image":"https://martinliu.cn/images/las-vegas-strip-at-night.jpg","permalink":"https://martinliu.cn/blog/las-vegas-p1/","title":"Las Vegas流水账-进城篇"},{"content":"nu.shool 牛学院系列以视频加文字的形式，向您展示Nutanix云平台的技术特性和细节。\n本期视频是由《Nutanix圣经》的作者Steven Poitras，向您介绍Nutanix超融合系统架构。\n《Nutanix圣经》章节推荐。\n","date":"2017-02-20T00:00:00Z","image":"https://martinliu.cn/images/abstract-3.jpg","permalink":"https://martinliu.cn/blog/nu-school-converged-platform/","title":"互联网规模的超融合平台"},{"content":"\n在过去的一两年里DevOps持续升温，逐渐成为一场IT行业内的谁不可回避的运动。\nDevOps 定义 我个人是一直以来反对给DevOps做一个名词解释样式的定义的。不过这种需求实在强大，摘抄几条供大家参考，上图是一种定义。\n定义2：You cannot buy DevOps and install it. DevOps is not just automation or infrastructure as code. DevOps is people following a process enabled by products to deliver value to end users. \u0026ndash; Donovan Brown, Microsoft DevOps Program Manager\n以上出自：Donovan\u0026rsquo;s blog post on \u0026ldquo;What is DevOps\u0026rdquo;.\n定义3：DevOps（Development和Operations的组合词）是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。\n以上出自：维基百科 Wikipedia - DevOps\n兴趣和搜索量 以上结果来自Google趋势，上图是从2004年到现在，一共13年的趋势图。下面再看一下最近五年的趋势详情。\n最近5年的搜索趋势 国际关注度 相关话题和查询 关注者年龄和性别 上图年龄分布情况。\n上图是性别分布情况。\nDevOps应用状态 正在应用的:从66%上升到74% 没有应用的:从19%下降到16% 不知道的：从15%下降到6% DevOps Checklist 不管你做不做DevOps？不管你知不知道你是不是DevOps？不管你从哪个角度入手DevOps？看看这个清单中有几项和您相关，就知道你和DevOps的关系是否密切。 检查清单如下：\n基础架构即代码 每天多次部署 研发人员直接部署都生产环境 研发和运维共同奋战在支持的一线 消除研发和运维的部门墙 DevOps流程 下面看看两种相关流程图。 持续业务计划 协作型软件开发 持续测试 持续发布和部署 持续监控 协作式客户反馈和优化 上图来源于《Exin DevOps Master 白皮书 - 企业DevOps的成功之路》 作者：Koichiro(Luke) Toda、Nobuyuki Mitsui、译者：刘颋，史鹏程；审校：EXIN，刘征\n计划 需求 设计 开发 部署 运营 终止 7大DevOps 趋势 DevOps将进入主流，并产生大量关注；因此2017年将成为“DevOps之年”。 随着DevOps的推广，三个C：持续集成、持续部署和持续交付，将形成巨大的势头。 即将产生越来越多新的DevOps自动化工具，这些工具改变了我们软件开发的方式。 “容器化”也将引人注目（例如使用Docker容器）。 许多软件公司将转向微服务架构。 自动化测试和持续测试将变得更加普遍，且更加重要。 必须拥有的工具和平台，包括Docker、AWS、GitHub和JIRA将在开发者社区更受欢迎。 本文参考来源：\nhttp://www.rightscale.com/blog/cloud-industry-insights/new-devops-trends-2016-state-cloud-survey https://www.storybase.com http://pt.slideshare.net/johnpviner/devops-be-careful-what-you-wish-for https://en.wikipedia.org/wiki/DevOps http://www.Google.com ","date":"2017-02-11T00:00:00Z","image":"https://martinliu.cn/images/BingWallpaper-2017-02-10_Fotor.jpg","permalink":"https://martinliu.cn/blog/state-devops-adoption-trends-2017/","title":"2017年DevOps采用和趋势现状-信息图"},{"content":"Nutanix AHV（KVM）Windows虚拟机安装全攻略 Windows 虚拟机安装 Nutanix的AHV虚拟机是基于KVM的。本文件假设您使用和安装的是Nutanix社区版本的群集。在上面安装Windows虚拟机的步骤如下：\n下载操作系统安装光盘 上传操作系统安装光盘到Nutanix群集 （安装Windows虚拟机需要 Fedora virtio 驱动） 新建和配置虚拟机 安装OS 安装Nutanix Guest Tools （NGT） 下面用安装Windows 10举例，说明详细的安装步骤。\n第一步：下载操作系统 ISO 如果你需要下载 Ubuntu Desktop 点这里。\n从微软的TechNet Evaluation Center下载 Microsoft ISO 注意，评估的服务器版只能使用180天，桌面版能使用90天。\n第二步：上传ISO文件到Nutanix群集 Nutanix群集上提供了镜像服务，可以存储几种格式的镜像：ISO格式的操作系统安装镜像，虚拟机的磁盘(如KVM格式等)。这些镜像文件可以被虚拟机通过挂载CD-ROM设备使用，或者直接克隆出虚拟机的磁盘。操作步骤如下。\n点击右上角的齿轮图标，选择image configuration 点击 upload image按钮\n界面字段解释：\nName: 镜像文件的名字（用ISO来与磁盘镜像区分一下） Image Type: 选择 ISO Container: 选择用来存储ISO文件的容器 Image Source: 选择上传文件作为镜像来源 Save: 点击Save按钮可以看到上传的进度条。 在上传成功之后，镜像清单中显示刚才的镜像为 Active 状态。\n由于Nutanix的hypervisor是基于Linux KVM技术，它需要附加的Windows驱动，需要下载 Fedora Windows virtio 驱动。 下载地址如下：\nhttps://fedoraproject.org/wiki/Windows_Virtio_Drivers\n点击第三条 Direct download\n点击 “Stable virtio-win iso” 下载最新的驱动 ISO 文件。\n下载到的文件名如：virtio-win-0.1.126.iso；重复上述Windows IOS文件上传的步骤，把这个文件上传到镜像服务中。\nFedora 的开源版 VirtIO驱动和Nutanix的版本稍微有些不同。Nutanix的 VirtioIO驱动是经过数字签名的，能从Nutanix客户门户下载。由于Nutanix CE社区版是提供给所有人做体验测试的，因此这里使用的是开源版本的VirtioIO驱动，而不是Nutanix的官方版本的驱动。\n第三步：创建和配置虚拟机 我们已经准备好了Windows 10 ISO文件和 Fedora VirtIO驱动IOS文件，现在可以安装虚拟机了。步骤如下：\n点击 Home\u0026ndash;VM\n点击右侧的 Create VM 按钮。\n在下面的页面中输入虚拟机的配置。\n主要配置介绍如下： Name: Win10Desktop 虚拟机的名称 vCPUs: 2 两颗虚拟CPU Number of Cores per vCPU: 1 Memory: 2GB (只是做测试的话，2GB可以了) 下面添加用于虚拟机挂载Windows 10 安装盘的 CDROM设备。删除默认的CDROM设备。 由于偶尔安装Windows 10的时候默认的CDROM驱动器中Fedora Virtio驱动会显示不出来，因此删除默认的CDROM设备。\n添加vm系统安装的磁盘。点击添加磁盘，输入如下实例信息，得到一块40GB的SCSI磁盘用来安装Window 10操作系统。\n添加一个新的CDROM驱动盘，用来挂载 Windows 10 的ISO镜像文件，如下图所示。\nType: CDROM 类型 Operation: Clone from Image Service Bus Type: IDE 类型的应该是默认类型 Image: 选择刚才上传的 Win10ISO 添加一个新的CDROM设备，用来挂载 Fedora Virtio驱动IOS文件，如下图所示。\nType: CDROM 类型 Operation: Clone from Image Service Bus Type: IDE Image: 选择 FedoraVirtISO 配置完成之后的磁盘配置布局如下。\n现在来添加网卡，点击下面的按钮。\n使用默认的ID为0的网络，如下图所示。（此VLAN时之前建立好的）\n现在所有配置都已经完成，点击 Save 保存按钮。\n页面的状态栏会出现一个绿色的执行的提示，表示后天虚拟机正在创建中。\n第四步：运行并安装虚拟机 做如下操作来开启并运行虚拟机，进入Windows操作系统的安装过程。\n点击到 VM 视图 点击 Table 点击 Win10Desktop VM 刚才创建的虚拟机 点击 Power on 当 VM 启动了, 点击 Launch Console 进入控制台页面。 在Windows安装的界面，选择Custom ：高级安装选项。\n由于我们使用的 AHV 是KVM虚拟化，所以需要加载Virtio驱动。点击 Load Driver 按钮。\n点击 Browse 浏览。\n点击并浏览驱动器 E： （这是之前我们挂载 Fedora Virtio ISO文件的CDROM）\n浏览驱动盘到目录 vioscsi\n选择 w10 目录\n选择 amd64 目录，点击 ok\n选择所显示出来的 Red Hat VirtIO SCSI 驱动，点击 Next\n这样刚才创建的 40GB的磁盘就可以看到了，选择 Next\n点击了 Next 按钮之后， Windows 10 开始安装，这个过程大约是3~10分钟不等。最后就到了Windows的账户创建的环节。虽然现在Windows已经安装完成了，还需要进入Windows的设备管理器中查看一下，设备的状态。\n右击Windows的图标 选择 Device Manager 在设备官开启中，我们需要更新一下网卡设备的驱动。\n右击网卡设备，选择 Update Driver Software\u0026hellip;\n点击 Browse，选择当前的 virtio-win-0.11 ，也就是 Fedora VirtIO 驱动的光驱设备，点击 Next\n选中了合适的目录后，网卡设备的驱动安装正常了显示如下：\n到目前为止，我们的Windows 10 虚拟机安装完毕了。\n第五步： 安装Nutanix Guest Tools （NGT） Nutanix Guest Tools 可以实现自服务恢复和应用一致性快照功能，它需要Microsoft Volume Shadow Copy Services (VSS)服务的配合。下面来安装它。\n进入虚拟机的清单视图 点击 Table 点击选中刚才安装的Windows 10 虚拟机 点击 Enable NGT （这个操作需要有一个空闲的CDROM设备，可以点击虚拟机的编辑，把之前的两个光驱中挂载的ISO盘退出一个） 在后续的窗口中点击 Yes 在网页上成功启用了NGT之后，进入Windows 10桌面的控制台页面。打开Windows的资源管理器，双击带有Nutanix图标的CDROM设备，进入该设备安装NGT软件。\n点击 Install 按钮。\n跟随安装向导完成NGT的安装。安装完成之后，在Windows10中关机，在网页上编辑这个虚拟机的配置，删除多余的CDROM设备，之后在开机。至此Windows10虚拟机的安装过程全部完毕。\n扩展阅读：Nutanix AHV 虚拟机模板制作\n","date":"2017-01-29T00:00:00Z","image":"https://martinliu.cn/images/abstract-5.jpg","permalink":"https://martinliu.cn/blog/install-vms-on-nutanix/","title":"Nutanix AHV（KVM）Windows虚拟机安装全攻略"},{"content":"这次并不是刻意安排来日本，为了和同学凑行程，意外来日本国一游。行程稍微有点周折，从北京\u0026ndash;威海\u0026ndash;大板西关\u0026ndash;京都\u0026ndash;大板\u0026ndash;大板西关\u0026ndash;北京。这个行程的缺点在于选择了同一个城市进出日本。本文讲讲京都的几天。\n新京极 在京都期间都住在了锦市场北边的一个市场附近的一家Airbnb。其实从锦市场到新京极的几个街区中间是京都市中心附近。从住所往北一站就是京都市的市政厅。往北一站就是鸭川，这是一条从北到南穿过京都市区的河流，冬季河水特别浅。\n住所在市场旁边吃喝玩逛都非常方便。属于在居民楼中的一个商住楼。\n由于这个区域靠近商业中心，因此楼下临街商业也很发达，大街小巷遍布着各种饭馆和小店，买什么的都有。各种类型的各式各样的小店。\n伏见稻荷 这里是一座山伏见稻荷山所在，山上的这个神庙以它的狐狸大神最为有名。从下图可以看出，这座香火旺盛的主庙的屋脊还是有唐朝的感觉。即使是工作日也有很多人专门来这里朝拜。\n除了在正门的主殿有人朝拜，还有山上的其它地方，凡是有人供奉的地方的石台上，都是有人书有供奉者的名字，或者是毛笔写的或者是石刻的。\nFrom wiki\n伏见稻荷大社位于稻荷山的山麓，在传统上整个稻荷山的范围都被视为是神域（圣地）的范围。伏见稻荷大社主要是祀奉以宇迦之御魂大神为首的诸位稻荷神，自古以来就是农业与商业的神明，除此之外也配祀包括佐田彦大神、大宫能卖大神、田中大神与四大神等其他的神明。由于每年都有大量的香客前来神社祭拜求取农作丰收、生意兴隆、交通安全，使得该神社成为京都地区香火最盛的神社之一。另外，起源于江户时代的习俗，前来此地许愿的人们往往会捐款在神社境内竖立一座鸟居来表达对神明的敬意，使得伏见稻荷大社的范围内竖有数量惊人的大小鸟居，而以“千本鸟居”之名闻名日本全国乃至于海外。捐款竖立鸟居的单位包含个人、公司行号乃至于各地的商会组织，目前现存的鸟居，最早可以追溯到明治年间。 在神社的\n从右侧上山，到山顶后从左侧下山，如果走的快的话，两个小时左右可以玩完。这里可以看到日本所信奉的神的多样性。各种植物、动物和农业相关的东西比较多。\n我们走到半山腰的一个桔园时，有些迷路的感觉，觉得找不到路了。有一个出租车司机回家，把车停到了路边换鞋回家；看到我们似乎找不到路了，他回家后拿来一张地图给我们指路。由于日本的英语真的不通，他所以回家那地图来，大约至少用了他四十分钟的时间，拿着地图来告诉我们继续向前走就可以到山顶了。他说的所有话里面，就两个词可以听懂“Top”和“thirty minutes”；很感谢这个指路人。\n上顶上有一个能够俯瞰市区景色的地方，几排长椅上，人们一边看风景，一遍晒太阳，还是很休闲的。\n奈良 奈良到京都不远。来这里大部分时间都放在了，带孩子喂鹿上了，基本没有怎么逛著名的东大寺。\n我们在路上换车的时候，做错了车，做了一辆特急的快车，结果需要补票花了1千多。\n出了地铁站不远，就可以看到奈良公园的小鹿，一波一波的喂鹿，孩子总是能想出各种奇思妙想的喂法，基本一天没干别的。\nFrom Wiki\n东大寺（日语：東大寺），位于日本奈良县奈良市杂司町，是华严宗大本山，南都七大寺之一，距今约有一千二百余年的历史。1998年作为“古都奈良的文化财”的一部分被列为世界文化遗产。 佛寺是728年由信奉佛教的圣武天皇建立的。东大寺是全国68所国分寺的总寺院。因为建在首都平城京以东，所以被称作东大寺。另外有西大寺。\n最后到寺院里面转了一圈依然下班了。发现日本的景点都是在寺庙附近的；和各种大寺相关的公园非常多，有寺庙，就有公园，就有风景。\n二条城 这个城是一个将军府，距离天皇住所不远。麻雀虽小五脏俱全，它内城和外城，有两层的护城河，城墙是很低的。\nFrom wiki\n二条城是一座位于日本京都府京都市中京区二条城町的城堡，建设于江户时代初期（1603年）。曾经是德川家康的寓所。位于京都市街的一座平城。1994年，被联合国教育科学文化组织列入世界遗产中的古都京都的文化财之一。狭义上，二条城，就是江户时代筑起的城池，但是在广义上，是指第十三代室町幕府将军足利义辉的居城、织田信长为十五代将军足利义昭建造的城池，1573年织田信长举兵将足利义昭放逐河内，此城便被焚毁，在其它地方另筑二条御所，之后献给皇太子。但是一般所提及的二条城，是德川家康筑城的二条城（朝廷则称之为二条亭）。1867年（庆应3年）第十五代将军德川庆喜，在二条城举行“大政奉还”仪式，将政权归还给了天皇，二条城因而闻名。1871年（明治4年） 二之丸御殿作为京都府厅舍。1873年（明治6年）除二之丸外归陆军省。1885年（明治18年）京都府的新厅舍完成移转新址后，二之丸御殿开始修理直到1892年（明治25年）。1893年（明治26年）到1894年（明治27年）将桂宫邸本丸移筑，始有本丸御殿。1915年（大正4年）大正天皇即位仪式大典于二之丸御殿举行，并开始增建南门二之丸御殿的附属建物。1939年，天皇又将之赐给宫内省，并于隔年更名为“元离宫二条城”，正式对外开放参观。\n这是一个比较小规模的景点，出了地铁站，东门正在维修，绕到北门，顺序参观完了外城、内层和各种建筑。这座建筑也是重建的，大约有80多年的历史，曾经被焚毁；最近一次好像是被雷击失火。\n鸭川 我下图的跑步路线大约就是鸭川的主要部分。其中三条到5条的河岸左侧就是京都旧市井的所在，感觉像是北京的南锣鼓巷，不过原貌保护的更好一些。 炸猪排饭 日餐里面的食物和中餐是非常相似的，随便进一个店，都不用为吃啥发愁；有些饭馆是有日文、英语和中文菜单的。下图是一家专门做炸猪排饭的饭馆。这家饭馆主要做三总餐：炸猪排饭、红烧猪排饭和炸大虾饭。套餐的价格在900日元左右，量还是比较多的。我点了一杯扎啤配炸猪排饭味道非常好。\n这家餐厅吃了两次，感觉非常好，年长的老人在店里带领几个非常年轻的孩子们，把这家店搭理的井井有条。看着食物制作的每一个工序，感觉还是不错的。\n","date":"2017-01-27T00:00:00Z","image":"https://martinliu.cn/images/p014h7g3.jpg","permalink":"https://martinliu.cn/blog/kyoto/","title":"日本旅行-第一部分京都休闲游"},{"content":"本文描述了AHV虚拟化的虚拟机模板的制作过程。首先使用ssh登录cvm，进入acropolis命令行。\n找出模板对应的虚拟机 使用 vm.disk_get 命令，按多次tab，显示虚拟机清单，复制模板机名称\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;acropolis\u0026gt; vm.disk_get vm-fedora25 ide.0 { addr { bus: \u0026#34;ide\u0026#34; index: 0 } cdrom: True empty: True } scsi.0 { addr { bus: \u0026#34;scsi\u0026#34; index: 0 } container_id: 4427 container_uuid: \u0026#34;9279ba2c-8e8d-4aea-b00f-410df5a18a23\u0026#34; vmdisk_size: 10737418240 vmdisk_uuid: \u0026#34;7476458e-7917-4df8-b830-a0df5a95dae9\u0026#34; } 创建模板镜像 使用从虚拟机磁盘克隆出镜像的命令。\n1 2 3 \u0026lt;acropolis\u0026gt; image.create fedora25-Template clone_from_vmdisk=7476458e-7917-4df8-b830-a0df5a95dae9 image_type=kDiskImage annotation=\u0026#39;Fedora 25 Server Template\u0026#39; fedora25-Template: complete 模板测试 登录Prism界面，点击镜像服务，确认清单中刚才创建的虚拟机模板镜像；进入vm页面，创建虚拟机，使用 fedora25-Template 镜像做磁盘\n","date":"2017-01-10T00:00:00Z","image":"https://martinliu.cn/images/abstract-10.jpg","permalink":"https://martinliu.cn/blog/clone-ahv-vm-template/","title":"Nutanix AHV 虚拟机模板制作"},{"content":"简介 这份术语表的旨在为DevOps实践者提供参考，在重要的专业术语上保持一致。最初的来源是《DevOps Handbook》英文版。译者在翻译的过程中，梳理和总结了一部分。Exin的DOP认证考试基于此书，考试样题也影响和参考了本术语表。本术语表是开放的，欢迎各界业内人士对其修订和增补。目标是形成一份较为完整和准确的参考资料。参与修订的方式见页脚。欢迎但不限于以下方面的专家参与评审和修订：\n敏捷开发 精益/精益UX/精益创业 丰田生产系统 ITIL 互联网公司 传统企业 这个页面的另外一个存在：https://handbook.martinliu.cn/glossary/\n变更日志 2017年1月7日，在Martin‘s Blog和Github上发布了第一个版本。有几个人在Github上参与了修订（请参与者通过邮件或者其他方式告诉我，这里希望再次申明致谢。） 2017年12月27日，参与修订的人包括卢梦纯（Exin）、刘征、张乐、Wang Jun和许峰。 本网页当前接受繁体中文的增补，所有参与者名单 术语表 英文 中文 A/B Testing A/B测试 Acceptance Stage 验收阶段 Acceptance Test-Driven Development (Atdd) 验收测试驱动开发 Acceptance Tests 验收测试 Accident 事故 Affinity 亲和 Agile 敏捷 Andon Cord 安灯拉绳 Anomaly Detection Techniques 异常探测技术 Antifragility 抗脆弱性 Application Deployment 应用部署 Artifact Management 构件制品库管理 Artifacts 制品 Automated Tests 自动化测试 Automation 自动化 Backlog 待办事项列表 Bad Apple Theory 坏苹果理论 Bad Paths 失败路径 Batch Sizes 批次尺寸、批量大小 Blame 责备 Blameless Post Mortem 免责事后分析 Blamelessness 免责 Blue-Green Deployment 蓝绿部署 Blue-Green Deployment Pattern 蓝绿部署模式 Branching Strategy 分支策略 Brownfield 棕地 Build 构建 Business Value 业务价值 Canary Release 金丝雀发布 Canary Release Pattern 金丝雀发布模式 Card 卡片 Change Categories 变更类别 Change Schedules 变更计划 Cloud Computing 云计算 Cloud Configuration Files 云配置文件 Cluster Immune System Release Pattern 集群免疫系统发布模式 Code Branch 代码分支 Code Review Forms 代码审查表 Codified Nfr 成文的非功能需求 Collaboration 协作 Commit Stage 提交阶段 Commit Code 提交代码 Compliance Requirement 合规性要求 Compliance Checking 合规性检查 Compliancy Officer 合规检测官 Configuration Management 配置管理 Container(S) 容器 Continuous Deployment 持续部署 Continuous Integration 持续集成(CI) Continuous Delivery 持续交付(CD) Conways Law 康威定律 Cycle Time 周期时间 Defect Tracking 缺陷跟踪 Definition Of Done (Dod) 完成的定义 Dev Rituals 开发仪式 Developer 开发人员 Development 开发 Devops Transformation DevOps转型 Downstream/Upstream 下游/上游 Downwards Spiral 恶性循环 E-Mail Pass-Around 电子邮件轮查 Expand/Contract Pattern 扩张/收缩模式 Exploratory Test 探索性测试 Fast Feedback 快速反馈 Feature 特性 Feature Flag 特性标志 Feature Toggles 特性开关 Feedback/Feedback Loop 反馈/反馈回路 Feedforward/Feedforward Loop 前馈/前馈回路 Flow 流 Gated Commit 门控提交 Gaussian Distribution 高斯分布 Green Build 绿色构建 Greenfield 绿地 Handoff 交接 Hand-Off Readiness Review 交接就绪评审 Happy Paths 快乐路径 Hypothesis-Driven Development 假设驱动开发 Incident 事件 Information Radiators 信息辐射器 Infosec 信息安全 Infrastructure Automation 基础架构自动化 Infrastructure As Code 基础设施即代码 Integration Tests 集成测试 I-Shaped, T-Shaped, E-Shaped I型，T型，E型 Iteration 迭代 Itsm (It Service Management) IT服务管理 Ji-Kotei-Kanketsu (Jkk) 质量检查（JKK） Just Culture 公正文化 Just-In-Time (Jit) 准时制 Kaizen (In Lean) 持续改善 Kaizen Blitz (Or Improvement Blitz) 持续改善闪电战 Kanban 看板 Kata Kata Large Batch Size Merge 大批量合并 Latent Defects 潜在缺陷 Lauching Guidance 发布指导 Launch Readiness Review 投产就绪评审 Lead Time 前置时间 Lean 精益 Learning Culture 学习文化 Logging Levels 日志级别 Loosely Coupled Architecture 松耦合架构 Micro-Services 微服务 Minimum Viable Product 最小化可行产品 Monitoring Framework 监控框架 Monolithic Applications 单体应用 Monolytics 单体应用 Mttr 平均恢复时间 Non-Functional Requirement (Nfr) 非功能性需求 Non-Functional Requirement (Nfr) Testing 非功能需求测试 (Non) Ideal Testing Pyramid （非）理想测试金字塔模型 One-Piece-Flow 单件流 Operations 运维 Operations Story 运维故事 Ops Liaison 运维联络人 Organisational Typology Model 组织结构模型 Organization Archetypes 组织原型 Organizational Learning 组织级学习 Over-The-Shoulder 观察者评审 Packages 包 Pair Programming 结对编程 Peer Review 同行评审 Pilot 试点 Pipeline 流水线 Plan-Do-Check-Act Cycle (Pdca Cycle) 计划-实施-检查-改进 （戴明环） Post Mortems 事后回顾 Post-Mortem 事后剖析 Process Time 处理时间 Product Owner 产品负责人 Pull Request Process 拉动请求流程 Qa 质量保证 Reduce Batch Size 降低批次尺寸 Reduce Number Of Handoffs 减少交接次数 Regression Test 回归测试 Release Branch 发布分支 Release Managers 发布经理 Release Patterns 发布模式 Retrospective 回顾 Rhythm 节奏 Roll-Back 回滚 Sad Path 悲伤路径 Safety Culture 安全文化 Safety Conditions 安全条件 Scaling 规模化 Scrum Scrum Scrum Master Scrum Master Security Testing 安全测试 Self Service Capability 自服务能力 Service Deployment 服务部署 Service Level Agreement (Sla) 服务级别协议(SLA) Shared Goals 共享目标 Shared Operations Team (Sot) 共享运维团队 Shared Version Control 共享版本控制 Single Repository 单一存储库 Smoke Testing 冒烟测试 Sprint 冲刺 Staging Staging Staging Environments, Sit 准生产环境 Stakeholder 利益干系人 Standard Deviation 标准差 Standard Operations 标准运维 Static Code Analysis 静态代码分析 Swarm 聚集、聚焦、会诊、围观（动词） Swarming 聚集 System Of Engagement (Soe) 交互系统 System Of Records (Sor) 记录系统 Technical Debt 技术债务 Technology Adaption Curve 技术适应曲线 Technology Executives 技术主管 Telemetry 遥测 Test Coverage Analysis 测试覆盖率分析 Test Story 测试故事 Test-Driven Development 测试驱动开发 The Downward Spiral - Tds 下行螺旋 The Agile Manifesto 敏捷宣言 The Lean Movement 精益运动 The Simian Army: Chaos Gorilla, Chaos Kong, Conformity Monkey, Doctor Monkey, Janitor,Monkey, Latency Monkey, Security Monkey 猿猴军团（可靠性监控服务），Chaos Gorilla（混沌大猩猩）， Chaos Kong（混沌金刚）, Conformity Monkey（一致性猴子）, Doctor Monkey（医生猴子）, Janitor Monkey（看门猴子）, Latency Monkey（延迟猴子）, Security Monkey（安全猴子） The Three Ways 三步工作法 Theory Of Constraints 约束理论 Ticketing System 工单系统 Tightly-Coupled 紧耦合 Tool-Assisted Review 工具辅助评审 Tools 工具 Toyota Production System (Tps) 丰田生产系统 Toyoto Kata 丰田套路 Transformation Team 转型团队 Trunk 主干 User Story 用户故事 Value Stream Mapping 价值流映射 Value Stream 价值流 Velocity 速率 Version Control 版本控制 Virtualized Environment 虚拟化环境 Visible 可视的 Visualisation 可视化 Waste 浪费 Waste Reduction 减少浪费 Waterfall 瀑布式 Wip (Work In Progress / Process) 在制品 Wip Limit 在制品限制 Work Center 工作中心 参与修订说明 请帮忙改进本术语表，请直接Fork本代码库，然后提交PR；或者发邮件到：liuzh66@gmail.com\n建议最好提供修订原文的简要说明和参考依据。\nGitHub操作注意事项：\n建议Fork整个repo做批量更新，小批量可以直接在github网页上提交 请不要完全删除之前的翻译，可以把旧翻译划横线（使用markdown），在右边添加新的中文意思。 ","date":"2017-01-07T00:00:00Z","image":"https://martinliu.cn/images/pexels-photo.jpg","permalink":"https://martinliu.cn/2017/01/07/devops-glossary/","title":"DevOps术语表"},{"content":"做Nutanix的那些不可不知道的资源网站，这里列出了常用的官方和非官方网站。\nNutanix 官方站点 http://portal.nutanix.com/ http://portal.nutanix.com/\n在线文档 在线技术支持，case查看和操作 产品和补丁下载 https://next.nutanix.com/ https://next.nutanix.com/\n产品网上论坛和社区 社区版论坛 博客， Nutanix Connect Blog 技术达人网站和博客 myvirtualcloud.net by Andre Leibovici http://myvirtualcloud.net/nutanix/\nVirtual life style by Joep Piscaer https://www.virtuallifestyle.nl/\nThe Nutanix Bible by Steven Poitras http://nutanixbible.com/\nMark\u0026rsquo;s Blog by Mark Lavi http://mlavi.github.io/\nJeremy Sallee - Nutanix UI/Frontend 设计师 http://salleedesign.com/stuff/sdwip/home/\n想知道Prism是怎么设计出来的：点这里\nVirtual Dennis by Dennis Laube http://www.virtualdennis.com/category/nutanix/\n如何ova格式的虚拟机导入Nutanix AHV 镜像服务能够支持Web界面上传导入的格式包括：raw, vhd, vmdk, vdi, iso 和 qcow2 磁盘，导入为Disk后，即可用做模板 如何在Nutanix中制作AHV虚拟机模板 使用acli命令：vm.disk_get；image.create W2K12R2-Template clone_from_vmdisk=69df5abd-6570-4ce1-ba77-2d117c3df7e5 image_type=kDiskImage 其他资源 Nutanix viso 图标下载 http://www.visiocafe.com/nutanix.htm\n","date":"2017-01-07T00:00:00Z","image":"https://martinliu.cn/images/google-earth-view-6043.jpg","permalink":"https://martinliu.cn/blog/nutanix-resource-sites/","title":"Nutanix资源站点清单"},{"content":"天下事分久必合，合久必分，移动互联网代表了现在的云计算时代，很多企业还正在朝这个方向发展呢！革命还没有成功，怎么这个时代就要结束了。来听听XenSource前CEO怎么给你解读边缘计算时代的到来。\n“I’m going to take you out to the edge to show you what the future looks like.” So begins a16z partner Peter Levine as he takes us on a “crazy” tour of the history and future of cloud computing — from the constant turns between centralized to distributed computing, and even to his “Forrest Gump rule” of investing in these shifts.\nBut… how can we say cloud computing is coming to an “end” when it hasn’t even really started yet?? Because the edge — where self-driving cars and drones are really data centers with wheels or wings — is where it’s at. So where does machine learning in the enterprise come in? How does this change IT? As software programs the world, these are some of the shifts to look at…\n视频在这里 在线观看。\n","date":"2017-01-05T00:00:00Z","image":"https://martinliu.cn/images/MacawFlight_ROW10435257143_1920x1080.jpg","permalink":"https://martinliu.cn/2017/01/05/The-End-of-Cloud-Computing/","title":"云计算时代的终结"},{"content":"Nutanix AOS 5.0 是一个很重要的功能更新大版本，它一气儿带来了46项之多的新功能；在您安装或者测试这个版本\u0026gt; 之前，先通过本文快速了解一下这些更新，可能是更加节省时间的方法。\n主要功能清单 myvirtualcloud.net网站用了4个blog，讲了下面的36项新特性：\nCisco UCS B-Series Blade Servers Support Acropolis Affinity and Anti-affinity Acropolis Dynamic Scheduling (DRS++) REST API 2.0 and 3.0 Support for XenServer TechPreview Network Visualization What-if analysis for New workloads and Allocation-based forecasting Native Self-Service Portal Snapshots – Self Service Restore UI Network Partner Integration Framework Metro Availability Witness VM Flash Mode Improvements Acropolis File Services GA (ESXi and AHV) Acropolis Block Services (CHAP authentication) Oracle VM and Oracle Linux Certified for AHV SAP Netweaver stack Certified for AHV Prism Search Improvements (support for Boolean expressions) I/O Metrics Visualization 1-Click Licensing LCM – Lifecycle Manager Additional Prism Improvements AHV Scale Improvements AHV CPU and Memory Hot Add (Tech Preview) Advanced Compression for Cold Data Acropolis Change Block Tracking (CBT) for Backup Vendors Predictable Performance with Autonomic QoS NCC 3.0 with Prism Integration 1-Node Replication Target Improved Mixed Workload Support with QoS Simplified SATADOM Replacement Workflow Mixed Node Support with Adaptive Replica Selection Dynamically Decreased Erasure Coding Stripes – Node Removals Multi Metadata Disk Support for use available SSDs on the node for metadata Erasure Coding(EC) support for changing the Replication Factor (RF) on containers Inline Compression for OpLog Linux Kernel Upgrade Nutanix 5.0 Features Overview (Beyond Marketing) – Part 1 Nutanix 5.0 Features Overview (Beyond Marketing) – Part 2 Nutanix 5.0 Features Overview (Beyond Marketing) – Part 3 Nutanix 5.0 Features Overview (Beyond Marketing) – Part 4 Nutanix官方Blog新版本介绍 Nutanix 官方Blog的新版本发布帖 The 5.0 Release is Here\nNutanix AOS 5.0 is available now for you to download and will carry a huge payload of innovation across Acropolis – the data plane, Prism – the management plane and AHV – built-in hypervisor. Over the last couple of months we have spoken about different capabilities that will be part of this release. Before we get into details of the release, it is important to take a step back and understand how the core platform is evolving.\nThese services are announced but will be generally available in a subsequent product release To deliver on the vision of Enterprise Cloud and offer public cloud-like services within the datacenter, it is important for us to provide infrastructure services similar to what the public cloud offers. Different workloads have different infrastructure needs and it is important to provide services that can be “turned-on” and “turned-off” based on applications needs – all without having to touch the underlying physical infrastructure. This is exactly what AWS does and that is what we are working towards with our Enterprise Cloud Platform as well.\nHere is a comparison of some of these infrastructure services offered by AWS and Nutanix. The core tenets of the public cloud and the pay-as-you-grow economics are as applicable to Nutanix as it is to the public cloud.\nThe 5.0 release adds new infrastructure services to the platform and enhances the ones that already exist; delivering greater flexibility and potential cost savings for IT organizations of all sizes. With over 45 new capabilities in the software and hundreds of feature enhancements, this release is definitely a huge milestone for us.\nWhile it is impossible for us to cover all the capabilities in detail in one single blog, let me attempt to do a quick walk through of the ones we think you will love!\nAcropolis – Data Plane Enhancements Acropolis File Services (AFS)Generally Available: AFS is a natively built file storage service that eliminates the need for standalone NAS solutions. This capability was in Tech Preview for the past several months and is generally available with the 5.0 release. With AFS, customers can consolidate their virtual machines and the file data they rely on within the same cluster. AFS will work on ESXi and AHV hypervisors for a wide variety of use cases such as user-profiles, home directories, archives and more. You can learn more about this capability in this blog. Here is a quick summary blog on AFS.\nAcropolis Block Services (ABS) Enhancements: ABS, like AFS, is natively built to expose storage to non-virtualized workloads. This capability was introduced in the 4.7 release. We have significantly enhanced ABS in 5.0 with support for dynamic load balancing and flash pinning for better performance, improved security through CHAP for safer client-server conversations and online resizing for higher availability. Additionally, Oracle joins the list of certified workloads on ABS. Here is a quick summary blog on ABS.\nMetro Availability Witness: Metro Availability is Nutanix’s synchronous replication solution for DR. Metro Availability Witness is a light-weight service that will be able to run anywhere to enable automatic failover from one site to another without service disruption by monitoring the status of both sites.\nCompression Enhancements: The compression algorithm used for capacity optimization has significantly improved in the 5.0 release resulting in more efficient data compression. Additionally, on All-flash systems, compression will be turned on by default. With compression, deduplication, erasure coding and other native capacity optimization capabilities, customers can achieve up to 4:1 savings (depending on data type).\nSingle-node Replication Target: One of the common asks from Remote and Branch office/SMB customers was to have a single-node backup/replication target for smaller deployments of Nutanix. This enables customers to use native backup capabilities and replicate data to a storage heavy node of Nutanix that can be on the same site or a different remote site. With 5.0, this is possible with the single Nutanix node having ~40TB of raw capacity and act as a destination for backup/snapshot data.\nAHV – Hypervisor Enhancements AHV, the native hypervisor solution from Nutanix, continues to grow leaps and bounds with several customers standardizing on AHV for all workloads. We have continued to add newer capabilities with every release of the product. 5.0 is no different and adds a couple of very important capabilities.\nAHV Affinity Rules: Workloads such as Microsoft SQL or Oracle are often attached to a specific node for licensing, security or HW configuration related reasons. With affinity rules, virtual machines can now be “pinned” to a specific host or a set of hosts. Additionally AHV will also support VM VM anti-affinity rules to try ensure that specific VMs are never on the same host together.\nAcropolis Dynamic Scheduling (ADS): AHV has supported intelligent initial placement for a while now to make sure VMs are placed on the most optimal hosts when they are initially deployed. With ADS, the hypervisor can detect CPU, memory and storage controller hotspots and can move deployed VMs to a host that is ideal suited. Legacy hypervisor solutions factor in CPU and memory alone while making similar decisions. But with AHV, the VM placement algorithms will also factor in storage resources as well as storage controller bottlenecks before making a decision.\nCPU/Memory Hot Add: With this capability, administrators can add vCPU and memory to a running VM without any service impact. As applications evolve, it is important to dynamically adjust resources assigned to them so that there is no performance impact for the end user. This is what the hot add feature will enable. In the 5.0 release, this feature will be available in Tech preview and is expected to be generally available in a subsequent release.\nWith these capabilities, AHV is ready for all your production workloads and there is very little reason as to why any virtualized workload cannot be run on Nutanix and on AHV. Nutanix customers are already standardizing on AHV and are seeing significant savings in the overall cost of ownership across their entire infrastructure stack.\nPrism – Management Plane Enhancements Over the last year Prism has evolved into a product suite of its own – with Prism Starter and Prism Pro, customers now have an option of choosing a one-click infrastructure management solution or a one-click infra management and operations management solution based on their needs.\nPrism Self-Service: Self-service will bring the goodness of AWS to enterprise datacenters. With this new capability, end-users can login to Prism with their own AD credentials and deploy and monitor applications whenever they want, based on Admin set policies. This removes common friction around developers and end users having to rely on IT admins for common tasks. Instead, administrators just assign resources for specific users or AD groups and end users have complete independence to perform actions that he/she is allowed to do. Here is a quick blog that summarizes this capability.\nNetwork Visualization: This is another key capability that is part of Prism. With Network Visualization, administrators will be able to get an end-to-end operational view of the infrastructure all the way down to the networking layer. With views that provide insight into how virtual machines are connected to the host, NICs, the top of rack switches, the VLANs they are part of as well as the health of these connections, administrators will be able to get all the information they want about their infrastructure in a single screen, without having to rely on separate tools. This will help isolating and fixing common networking issues that result in application downtimes.\nESXi Management: The simplicity of VM management with Prism will extend to ESXi as well with this release – common VM operations that customers relied on vCenter for will be performed from within Prism. One of the common asks from customers was to not go back and forth to vCenter and instead consolidate all operations on Prism. In the first release as part of 5.0, Prism will enable administrators to perform common VM operations such as VM create, update, delete, clone etc. from within Prism. Combining VM operations and the rich monitoring and analytics, vCenter is only needed for less common maintenance and configuration tasks. With the hypervisor becoming commodity, end users get greater simplicity at the management layer.\nJust-in-time Capacity Forecasting (available in Prism Pro): This is probably one of the most important additions to Prism. Just-in-time forecasting will enable IT to stay ahead of the game by modeling and understanding infrastructure needs based on application requirements even before applications are deployed. This way, IT not only understands application-centric capacity usage patterns and what can be done to optimize existing capacity, they can also plan their infrastructure needs for the future and deploy infrastructure if and only when they need them at “byte” sized granularity all based on recommendations from Prism.\nSearch Enhancements (Available in Prism Pro): One of the core aspects to delivering a personalized and consumer-grade management experience is to enable administrators to perform actions the same way they would do it in their personal lives. Prism Search, a Google like search engine, was introduced earlier this year so that administrators can perform all administrative actions through a simple search query. With support for Boolean expressions, saved searches, auto correct, synonyms based search and more, the 5.0 release will take Prism Search to a whole new level. As an example, administrators can type in “vm iops \u0026lt;1500” and quickly see all the VMs across all the sites that have IOPS less than 1500.\n有用链接：\n西瓜哥的微信文章介绍了部分上面的更新 点这里。 Acropolis 5.0 release notes Nutanix Cluster Check 3.0 release notes Nutanix Cluster Check 3.0 download PRISM Central 5.0 release notes ","date":"2017-01-04T00:00:00Z","image":"https://martinliu.cn/images/RoyalBarge_ROW9071716647_1920x1080.jpg","permalink":"https://martinliu.cn/2017/01/04/Nutanix-AOS-5.0/","title":"Nutanix AOS 5.0 新版本新特性"},{"content":"学习DevOps应该会使用到的书籍清单。\n我在豆瓣建立了一个书单，欢迎在豆瓣给我留言，评论和建议。豆瓣书单点这里。\n本清单来自于《DevOps Handbook》书中提到的书，更新到第五本；《看板方法》、《精益思想》、《Implementing Lean Software Development: From Concept to Cash》、《第五项修炼:学习型组织的艺术与实践》、《探索吧!深入理解探索式软件测试》\n《看板方法-科技企業漸進變革成功之道》 转自：Rubbyblog.wordpress.com/images/\n今天要介紹看板方法的由來， 上面這本書是由看板方法之父 David J. Anderson 於: 2010年 4月所著。簡字版是 2014 年2月出版。這篇文章在我上 TechDays 課程時就想登出來了，想把好書介紹給大家。但由於台灣的書商都沒有進口，所以一直等到我拿到第一批書後，肯定大家可以在坊間買到書時才把他登出來。原文書名: Kanban: Successful Evolutionary Change for Your Technology Business.\n看板方法：它是敏捷陣營中實施起來阻力最小，生產力又能大幅提升、前置時間大幅下降，而可預測性又絕佳的敏捷解決方案之一。好神奇喔 … 哈哈! 確實如此，所以我才會這麼急切的推薦給大家。另一個原因是Kanban Method 現在在美國正熱烈風行中，而我們現在開始追正是時候。為此放下了許多手上正在做的工作(包括一本 Scrum的教本)，努力開始推廣希望大家能受用。首先說明: 為何他推廣起來阻力最小?\n※ 實施起來阻力最小:\n因為David J. Anderson 本身是一個微軟的 PM出身，他跟大家一樣知道變革會讓許多人害怕，人們會認為自己的技術是否落伍了，開始擔心害怕變革會對自己的工作事業帶來不利，這種恐懼常常會帶來一種莫名的對立，因此在還沒開始變革之前就已經採取抵制的態度了。所以他創始的看板方法選擇從哪裡開始實施呢? 就從現在既有的流程開始。由工作者本身最熟悉的地方開始。起步的秘訣是甚麼呢? 是精實精神中從豐田系統中學來的原則，先從不浪費開始，作法: 在識別浪費後消除浪費。\n※ 如何能讓生產力大幅提升?\n由審視既有流程，依據 Little’s law的最大產出方法，接著找出阻礙最大產能的瓶頸所在，然後正視這個造成瓶頸的問題，把它顯現在看板上面，讓大家一起站在看板前面討論如何解決它，解決之後再持續進行改善的作業。\n※ 前置時間大幅下降\n過去我們都以為唯有透過良好的規劃及配合才能夠讓前置作業時間下降，但豐田企業的及時(Just In Time)備料讓庫存降至最低，讓半成品減至最少改變了工作流程的前置時間(Lead time)，因此得到大幅下降。\n看板還是看板方法 (Kanban or Kanban Method) 英文叫 Kanban，上網去搜尋會得到一大堆有關製造業的看板資料。所以請使用 Kanban Method去搜尋，因此中文就該叫做「看板方法」。簡體版的作者有用心在翻譯因此翻對了，值得買來閱讀。全書分成四部分:\n※ 第一部分；導讀: 作者說出他的想法，以及創作看板方法的原由。\n※ 第二部分；談使用看板方法的好處: 這裡有他個人做顧問時的經驗談，值得仔細閱讀。\n※ 第三部分；開始談實施看板方法的步驟了。(由六到十五章，好長又夠完整)\n※ 第四部分；談持續改進。在這裡你終於可以感受到精實軟體開發對作者的影響，以及作者由經濟學的角度來看精實軟體開發的第一原則: 消除浪費。\n接下來我就不在多說了，請讀者自己去看吧!(透漏一下，為了共襄盛舉，我正在寫一本有關精實開發的書，內容除了看板方法之外會大幅談到精實軟體開發，在這裡不想打廣告，因此書名就等出版後再說了!)\n精益思想(白金版) 这本书在亚马逊中国有售：https://www.amazon.cn/精益思想-詹姆斯P-沃麦克 简介\n《精益思想》于1996年秋季首次出版，历经20年，畅 销十多个国家，累计销量上百万册。本书的成功在于它对精益生产方式做了最 好的总结，为读者提供了精益的核心原则，实地考察了美国、德国、日本若干具有代表性的大小企业推行精益的实际情况和心得，为准备跨入精益之门和进一步学习、实施精益的人提供了最 好的指南，从而成为精益方面的经典著作。\n基本信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 出版社: 机械工业出版社; 第1版 (2015年8月1日) 外文书名: Lean Thinking ：Banish Waste and Create Wealth in Your Corporation 丛书名: 精益思想丛书 平装: 365页 语种： 简体中文 开本: 16 ISBN: 7111510712, 9787111510710 条形码: 9787111510710 商品尺寸: 24 x 17.4 x 1.8 cm 商品重量: 621 g 品牌: 机械工业出版社 ASIN: B0142EC7AA 用户评分: 平均4.5 星 浏览全部评论 (82 条商品评论) 亚马逊热销商品排名: 图书商品里排第7,694名 Implementing Lean Software Development: From Concept to Cash 基本信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 出版社: Addison-Wesley Professional; 1 (2009年10月31日) 丛书名: Addison-Wesley Signature Series (Beck) 平装: 312页 语种： 英语 ISBN: 0321620704 条形码: 9780321620705 商品尺寸: 17.5 x 1.8 x 22.9 cm 商品重量: 499 g 品牌: Pearson ASIN: 0321620704 用户评分: 分享我的评价 亚马逊热销商品排名: 图书商品里排第1,441,726名 (查看图书商品销售排行榜) 第64位 - 图书 \u0026gt; 进口原版书 \u0026gt; Computers \u0026amp; Technology（计算机与科技） \u0026gt; Business \u0026amp; Management（商业与管理） \u0026gt; Project Management 第393位 - 图书 \u0026gt; 进口原版书 \u0026gt; Computers \u0026amp; Technology（计算机与科技） \u0026gt; Programming（编程） \u0026gt; Software Design, Testing \u0026amp; Engineering \u0026gt; Software Development 作者简介 Mary Poppendieck has led teams implementing various solutions ranging from enterprise supply chain management to digital media. Mary is the president of Poppendieck LLC, which specializes in bringing lean techniques to software development.\nTom Poppendieck, an enterprise analyst, architect, and agile process mentor, currently assists organizations in applying lean principles and tools to software development processes. The Poppendiecks are authors of Lean Software Development, winner of the 2004 Jolt Software Development Productivity Award, and Implementing Lean Software Development (both from Addison-Wesley).\nThe Fifth Discipline: The Art \u0026amp; Practice of The Learning Organization 基本信息 第五项修炼：学习型组织的艺术与实践 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 出版社: 中信出版社; 第1版 (2009年10月1日) 外文书名: The Fifth Discipline:The Art \u0026amp; Practice of The Learning Organization 平装: 455页 语种： 简体中文 开本: 16 ISBN: 7508616820, 9787508616827 条形码: 9787508616827 商品尺寸: 22.8 x 17 x 2.8 cm 商品重量: 739 g 品牌: 中信出版股份有限公司 ASIN: B002QMKJ4C 用户评分: 平均4.5 星 浏览全部评论 (322 条商品评论) 亚马逊热销商品排名: 图书商品里排第1,333名 (查看图书商品销售排行榜) 第6位 - 图书 \u0026gt; 经济管理 \u0026gt; 管理学理论与方法论 \u0026gt; 管理学基础理论 第17位 - 图书 \u0026gt; 经济管理 \u0026gt; 企业经营与管理 \u0026gt; 管理指南 第617位 - 图书 \u0026gt; 在线试读 编辑推荐 《第五项修炼:学习型组织的艺术与实践(新世纪全新扩充修订版)》由当代最杰出的新管理大师彼得•圣吉撰写的著作，被誉为21世纪的管理圣经、20世纪屈指可数的几本管理经典、世界上影响最深远的管理书籍之一，并被《哈佛商业评论》评为过去75年具有影响力的管理类图书，还荣获世界企业学会荣誉的开拓者奖！ 进入21世纪以来，全球经济的迅猛发展，使得全球企业管理趋势、管理理念也顺应发生了巨大的变化，作为新世纪全新扩充修订版，《第五项修炼:学习型组织的艺术与实践(新世纪全新扩充修订版)》其背后是15年来把原书理念付诸实践的经验和案例。圣吉明确指出，从长远来看，你的组织可持续的竞争优势，就是比对手更好更快的学习能力。15年前，许多《第五项修炼》的核心理念都曾显得很激进。但这些理念的许多应用方法，后来已经被融入到人们观察世界的方式中，也被整合到人们的管理实践中；《第五项修炼:学习型组织的艺术与实践(新世纪全新扩充修订版)》对前一版进行了全面修订，新版书中的领导力案例故事揭示了这些经历。并增添了新的内容：实践中的反思，为企业、个人读者更准确理解最新管理理念，对学习型组织进行了有效的反思，对建设学习型组织所面临的新疑惑提供了新的思维。\n名人推荐 流行的管理体系很摧残人……教育界、工商界和政府机构的管理层的任务，应该是使系统最优化……彼得·圣吉的著作《第五项修炼》是帮助开始这项工作的好书，它让我学到了许多东西。 ——爱德华·戴明博士，全面质量管理运动(TQM）的先驱。\n媒体推荐 《第五项修炼》是过去75年来最有影响力的管理学著作之一。 ——《哈佛商业评论》 圣吉的这本著作已经是一本不折不扣的管理学经典。 ——《波士顿环球报》\n作者简介 作者：（美国）彼得•圣吉 译者：张成林\n彼得•圣吉博士（Dr.Peter M. Senge），麻省理工学院斯隆管理学院的高级教授讲师，国际组织学习学会（SoL）和索奥中国（SoL China）的创始主席。除《第五项修炼》之外，他还与人合著了《第五项修炼实践篇》（1994）、《变革之舞》（1999）、《学习型学校》（Schools that Learn, 2000）、《体悟当下》（Presence, 2004），以及最近出版的《必要的革命》（The Necessary Revolution, 2008）等著作。圣吉被誉为最富创新精神的世界级管理学和领导学思想大师之一。他早年毕业于斯坦福大学工程专业，并获得麻省理工社会系统模型硕士和管理学博士，现家居美国马萨诸塞州。\nExplore It!: Reduce Risk and Increase Confidence with Exploratory Testing 探索吧!深入理解探索式软件测试 1 2 3 4 5 6 7 8 9 10 11 12 出版社: 机械工业出版社; 第1版 (2014年1月1日) 外文书名: Explore It! Reduce Risk and Increase Confidence with Exploratory Testing 丛书名: 软件工程技术丛书 平装: 151页 语种： 简体中文 开本: 16 ISBN: 9787111451587 条形码: 9787111451587 商品尺寸: 24.2 x 16.8 x 0.8 cm 商品重量: 281 g 品牌: 机械工业出版社 ASIN: B00IHQBQZC 编辑推荐 《探索吧!深入理解探索式软件测试》给出实用性很强的理念，可用于探索从典型GUI场景到测试软件需求的一切，还包括如何探索低层级代码的建议。此书不只是给软件测试人员看的，对软件管理人员、开发人员也具有重大意义。\n名人推荐 “Elisabeth开创了将探索式测试应用于敏捷开发的先河，并推动它不断演进，使其成为了一种主流实践。” ——Ward Cunnningham wiki概念的发明者 设计模式和敏捷软件方法的先驱之一\n“这是我看到的最佳书籍之一。优良的测试设计源自优良的测试思路，这本书里满是各种优秀的测试思路，辅以故事情节烘托，涎玉沫珠。” ——Alan Page 微软公司Principal SDEI《微软的软件测试之道》作者\nThe Field Guide to Understanding \u0026lsquo;Human Error‘ This latest edition of The Field Guide to Understanding ‘Human Error\u0026rsquo; will help you understand how to move beyond \u0026lsquo;human error\u0026rsquo;; how to understand accidents; how to do better investigations; how to understand and improve your safety work. You will be invited to think creatively and differently about the safety issues you and your organization face. In each, you will find possibilities for a new language, for different concepts, and for new leverage points to influence your own thinking and practice, as well as that of your colleagues and organization.\nProduct Details 1 2 3 4 5 6 7 8 9 10 11 12 File Size: 3149 KB Print Length: 247 pages Publisher: Ashgate; 3 edition (December 28, 2014) Publication Date: December 28, 2014 Sold by: Amazon Digital Services LLC Language: English ASIN: B00Q8XCSFI Text-to-Speech: Enabled X-Ray: Not Enabled Word Wise: Enabled Lending: Not Enabled About the Author Sidney Dekker (PhD Ohio State University, USA, 1996) is currently professor at Griffith University in Brisbane, Australia, where he runs the Safety Science Innovation Lab. He is also Professor (Hon.) of psychology at The University of Queensland, and Professor (Hon.) of human factors and patient safety at the Royal Children\u0026rsquo;s Hospital in Brisbane. Previously, Sidney was Professor of human factors and system safety at Lund University in Sweden. After becoming full professor, he learned to fly the Boeing 737, working part-time as an airline pilot out of Copenhagen. Sidney is the best-selling author of a multitude of human factors and safety books, including, most recently, Safety Differently (2014), Second Victim (2013), Just Culture (2012), Drift into Failure (2011), and Patient Safety (2011).\nLean IT: Enabling and Sustaining Your Lean Transformation Review This book will have a permanent place in my bookshelf. In my ten-year study of high performing IT organizations, I’ve found that businesses rely on IT far more than they think. The impacts of poor flow from application development into IT operations can be devastating: ever increasing cycle times and amounts of rework, and an ever increasing amount of heroics required in IT operations to preserve the illusion of stability and reliability. ―Gene Kim, Chief Technology Officer, Tripwire, Inc.\nThere has never been a more critical time to improve how IT integrates with the global business enterprise. This book provides an unprecedented look at the role that Lean will play in making this revolutionary shift and the critical steps for sustained success. ―Steve Castellanos, Lean Enterprise Director; Nike, Inc.\nTwenty years from now the firms which dominate their industries will have fully embraced lean strategies throughout their IT organizations. Ten years from now those organizations will have started pulling ahead of their competitors as the result of lean IT. Today this book will show those organizations the path they need to start out on. Will your organization be one of them? ―Scott W. Ambler, Chief Methodologist for Agile and Lean, IBM Rational\n\u0026hellip; goes both wide and deep in its exploration of Lean … a great survival manual for those needing nimble and adaptive systems. ―Dr. David Labby, MD, PhD, Medical Director and Director of Clinical Support and Innovation, CareOregon\nThis book makes a major contribution in an often-ignored but much-needed area. It ranges over a huge area – including excellent cases – that will bring IT professionals into the Lean fold but will also enable Lean managers to reach out to IT. ―John Bicheno, Program Director MS in Lean Operations, Cardiff University\n… a comprehensive view into the world of Lean IT, a must read! ―Dave Wilson, Quality Management, Oregon Health \u0026amp; Science University\nAbout the Author Steve Bell, CFPIM brings over twenty years\u0026rsquo; experience in finance, operations management and information systems. He is the author of Lean Enterprise Systems, Using IT for Continuous Improvement. (2006)\nMike Orzen, CMA, CFPIM, PMP delivers a unique blend of IT, operations management, Lean, Six Sigma, and project management. With a BA from Stanford University in economics and an MBA from the University of Oregon, Mike has been consulting, coaching, and teaching for over 20 years.\nSteve and Mike are faculty members of the Lean Enterprise Institute. Together, the authors combine their experience in information systems and process improvement to share their lessons learned.\nProduct Details 1 2 3 4 5 6 7 8 9 Hardcover: 370 pages Publisher: Productivity Press; 1 edition (September 14, 2010) Language: English ISBN-10: 1439817561 ISBN-13: 978-1439817568 Product Dimensions: 6.1 x 1 x 9 inches Shipping Weight: 1.4 pounds (View shipping rates and policies) Average Customer Review: 4.9 out of 5 stars See all reviews (20 customer reviews) Amazon Best Sellers Rank: #129,956 in Books (See Top 100 in Books) True North: Discover Your Authentic Leadership Review \u0026ldquo;With great clarity and insight, Bill George and Peter Sims make a persuasive argument that the journey toward authentic leadership—that finding and pursuing your own True North\u0026ndash;is the key to leadership in all fields, whether in business, government, or the nonprofit arena.\u0026rdquo; —From the Foreword by David Gergen\n\u0026ldquo;In True North, Bill George once again provides a roadmap for leadership in the 21st Century. The future belongs to leaders who want to win, without ever losing track of their own values. We live in a day when the best people can work anywhere. They will follow only authenticity—a person who leads with passion and purpose.\u0026rdquo; —Jeff Immelt, CEO, General Electric\n\u0026ldquo;True North is an awe-inspiring gift to the world. The 125 men and women whose leadership journeys are so beautifully rendered in this book show us that we can have enormous impact without compromising our values—indeed, that we are more successful when we stay true to our ideals. Every aspiring leader (or leader who aspires to become even better) will draw strength and wisdom from this wonderful book.\u0026rdquo; —Rosabeth Moss Kanter, Harvard Business School professor and best-selling author of Confidence: How Winning Streaks \u0026amp; Losing Streaks Begin \u0026amp; End\n\u0026ldquo;True North is about the power of authentic leadership. Great leaders are defined by a sense of passion and purpose and by a profound desire to make a difference. Anyone can find their own True North, if you care deeply and love what you do. This book is a wonderful roadmap for how to get started on the journey.\u0026rdquo; —Andrea Jung, chairman and CEO, Avon Products, Inc.\n\u0026ldquo;If you want to move your leadership in the right direction, read True North. Drawing on the personal stories of some of the world’s most effective leaders, the book shows that you become a successful leader when you stay on course with your highest self.\u0026rdquo; —Ken Blanchard, coauthor of The One Minute Manager® and Leading at a Higher Level\n\u0026ldquo;True North provides a new leadership paradigm and a window into the stories and approaches of dozens of our nation’s best leaders. It is an inspirational, invaluable source of guidance for those who want to make a significant impact.\u0026rdquo; —Wendy Kopp, president and founder of Teach for America\n\u0026ldquo;True North reveals just how powerful authentic leadership can be and, best of all, how to achieve it.\u0026rdquo; —Warren Bennis\nProduct Details 1 2 3 4 5 6 7 8 9 Hardcover: 251 pages Publisher: Jossey-Bass; 1 edition (March 9, 2007) Language: English ISBN-10: 0787987514 ISBN-13: 978-0787987510 Product Dimensions: 6.3 x 1 x 9.4 inches Shipping Weight: 1 pounds Average Customer Review: 4.5 out of 5 stars See all reviews (129 customer reviews) Amazon Best Sellers Rank: #17,250 in Books (See Top 100 in Books) Gemba Walks Editorial Reviews In 12 new essays, ranging from the provocative to the practical and written specially for the second edition of Gemba Walks author and management expert Jim Womack reflects on the past 30 years of lean, and assesses the current state of lean today. He also shares thoughts on how lean thinking and practice can continue to make the world a better place by gaining traction in areas such as government and healthcare, provides practical guidance for how leaders everywhere can realize the full benefits of a lean management system, and shares hope for continued improvement on the path to better work and more value. Over the past 30 years, Womack has developed a method of going to visit the gemba at countless companies and keenly observing how people work together to create value. He has shared his thoughts and discoveries from these visits with the lean community through a monthly letter. With Gemba Walks second edition, Womack has selected and re-organized his key letters, as well as written 12 new essays. Gemba Walks shares his insights on topics ranging from the application of specific tools, to the role of management in sustaining lean, as well as the long-term prospects for this fundamental new way of creating value. Reading this book will reveal to readers a range of lean principles, as well as the basis for the critical lean practice of: go see, ask why, and show respect. Womack explains: • whatever happened to Toyota and what happens next to lean? • how lean got its name 25 years ago; a special essay co-authored by Jim and John Krafcik, president and CEO, Hyundai Motors America • work, management, and leadership \u0026ndash; what is the real work of the lean leader? • don’t offshore or reshore –leanshore • why companies need fewer heroes and more farmers (who work daily to improve the processes and systems needed for perfect work and who take the time and effort to produce long-term improvement) • how “good” people who work in “bad” processes become as “bad” as the process itself • how the real practice of showing respect comes down to helping workers frame and solve their own problems • how the short-term gains from lean tools can be translated to enduring change from lean management. • how the lean manager has a “restless desire to continually rethink the organization’s problems, probe their root causes, and lead experiments to test the best currently known countermeasures” By sharing his personal path of discovery, Womack sheds new light on the continued adoption and development of the most important new business system of the past fifty years. His journey will provide courage and inspiration for every lean practitioner today.\nProduct Details 1 2 3 4 5 6 7 8 9 10 11 Paperback: 311 pages Publisher: Lean Enterprise Institute, Inc.; 2nd ed. edition (January 1, 2013) Language: English ISBN-10: 193410938X ISBN-13: 978-1934109380 Product Dimensions: 6 x 1 x 8.9 inches Shipping Weight: 1.6 pounds Average Customer Review: 3.7 out of 5 stars See all reviews (10 customer reviews) Amazon Best Sellers Rank: #357,633 in Books (See Top 100 in Books) 11799 in Books \u0026gt; Textbooks \u0026gt; Business \u0026amp; Finance 39798 in Books \u0026gt; Business \u0026amp; Money Continuous Delivery: Reliable Software Releases Through Build, Test, and Deployment Automation\n持续交付：发布可靠软件的系统方法\nhttp://item.jd.com/10843669.html\nEric J.Evans在《领域驱动设计》一书中\n**Domain Driven Design by Eric J. Evans.\n《Architecture and Patterns for IT Service Management, Resource Planning, and Governance: Making Shoes for the Cobbler’s Children, observes》\n正如Steven j. Spear在他的书《The High-Velocity Edge》\n1984年由Eliyahu M. Goldratt博士写的《目标：简单而有效的常识管理》。\n2009年，Mike Rother编写了《丰田套路：转变我们对领导力与管理的认知》（Toyota Kata: Managing People for Improvement, Adaptiveness and Superior Results）\nValue Stream Mapping: How to Visualize Work and Align Leadership for Organizational Transformation\n(英语) 精装 – 2013年12月16日 Karen Martin (作者), Mike Osterling (作者)\nhttps://www.amazon.com/dp/B00EHIEJLM/ref=dp-kindle-redirect?_encoding=UTF8\u0026btkr=1\nIn the book Implementing Lean Software Development: From Concept to Cash, Mary and Tom Poppendieck describe waste and hardship in the software development stream as anything that causes delay for the customer, such as activities that can be bypassed without affecting the result.\n“点名、责备和羞辱”模式是Sydney Dekker博士批评的坏苹果理论的一部分，在他的书《The Field Guide to Understanding Human Error》里有深入讨论。\n《Gemba Walks》的作者Jim Womack描述了领导者和前线工作者之间必须发生的互补工作关系和相互尊重。根据Womack的说法，这种关系是必要的，因为谁都无法单独解决问题 - 领导者并不会足够的贴近一线工作，这是解决任何问题所需要的，而前线工作者也没有更广的组织背景的认知或权\nAfter the near-death experience of eBay in the late 1990s, Marty Cagan, author of Inspired: How To Create Products Customers Love, the seminal book on product design and management, codified the following lesson:\n界定上下文(Bounded contexts)是Eric J.Evans在《领域驱动设计》一书中提出的概念。其思路是开发人员能够理解和更新服务的代码，而不需要知道其关联服务（peers）的内部逻辑。同时，服务间严格通过API协作，不共享数据结构、数据库Schema或内部的对象。界定上下文确保服务间职责的划分，并具有良好定义的接口，同时也提高了可测试性。\nScrumisanagiledevelopmentmethodology,describedas“aflexible,holisticproductdevel- opment strategy where a development team works as a unit to reach a common goal.” It was first fully described by Ken Schwaber and Mike Beedle in the book Agile Software Development with Scrum. In this book, we use the term “agile development” or “iterative development” to encompass the various techniques used by special methodologies such as Agile and Scrum.\n","date":"2017-01-03T00:00:00Z","image":"https://res.cloudinary.com/martinliu/image/upload/pexels-photo.jpg","permalink":"https://martinliu.cn/2017/01/03/devops-booklist/","title":"DevOps书单"},{"content":"关于HP超融合产品家族的变迁简史和相关评论，本文转自 HC 250? HC 380? What are they actually for?。\n转帖：《HC 250? HC 380? What are they actually for?》 http://www.theregister.co.uk/2016/12/05/the_state_of_hpes_hyperconverged_play/ HP/HPE 超融合产品线发展如下图所示 +Comment The positioning of these two hyper-converged systems is confusing. We observe that the physically larger and vSphere-only HC 380, with its brand number larger than the HC 250, is for use by operators requiring operational simplicity, whereas the physically smaller and denser HC 250 is for more complicated operations in both vSphere and Hyper-V environments, yet it covers ROBO needs where customers don\u0026rsquo;t have skilled IT staff.\nGetting some ProLiant DL380 brand goodness in the HC 380 name, Apollo supercomputer brand messages in the HC 250 name, and not yet providing HCOE v2 to the HC 250, has provided confusing brand positioning.\nIt also seems that both systems should support Hyper-V and HCOE v2. That would make customers\u0026rsquo; lives simpler. The HC 380 should have its scale-out limit go past 16 nodes. Thirty-two would be good and then it would match the non-standard and non-recommended 32-node limit of the HC 250. ®\nNutanix Exec: Cisco, HPE, VMware Can\u0026rsquo;t Provide AWS-Like Experience For Hyper-Converged Market http://www.crn.com/news/data-center/300083025/nutanix-exec-cisco-hpe-vmware-cant-provide-aws-like-experience-for-hyper-converged-market.htm\nOne of Nutanix\u0026rsquo;s top executives said Cisco, Hewlett Packard Enterprise and VMware cannot provide a best-in-class experience for their hyper-converged products since they don\u0026rsquo;t own the entire software stack.\n\u0026ldquo;Everybody and their dog is in this space right now,\u0026rdquo; said Sunil Potti, Nutanix\u0026rsquo;s chief product and development officer. \u0026ldquo;But unless you are owning most of the stack, you can\u0026rsquo;t provide that full experience with a single click.\u0026rdquo;\nPotti told attendees of the Raymond James Technology Investors Conference on Monday that up until 18 months ago, much of the market felt that hyper-converged infrastructure – which combines compute, storage, networking and virtualization on server hardware - could be a good product, but questioned whether it would support all use cases.\nBut as end users became more adamant about having hyper-converged architectures deployed for their new workloads, Potti said the space has gone from being the exclusive domain of smaller IT vendors to attracting some of the biggest names in IT.\nAnd while Potti said the big guys bring a lot of go-to-market muscle to the table, some of them don\u0026rsquo;t seem to grasp the importance of providing totally seamless functionality.\n\u0026ldquo;Some of them are very formidable, but some of them are also sleeping giants because they are growing old,\u0026rdquo; Potti said at the conference at the Westin New York Grand Central. \u0026ldquo;You can\u0026rsquo;t just take a Nokia phone, slap on Windows and say \u0026lsquo;I won the smartphone war.\u0026rsquo; There\u0026rsquo;s a reason why those things didn\u0026rsquo;t work.\u0026rdquo;\nPotti pointed to the example of Cisco\u0026rsquo;s hyper-converged offering, which he said competes with VMware\u0026rsquo;s products, but is also dependent on VMware to properly function.\n\u0026ldquo;None of them have their own virtualization experience,\u0026rdquo; Potti said. \u0026ldquo;When you go to Amazon, you don\u0026rsquo;t go buy VMWare for Amazon. It\u0026rsquo;s built in.\u0026rdquo;\nA Cisco spokesman said its customers prefer having a hyperconverged product that integrates with existing converged infrastructure and traditional storage rather than having to create another infrastructure silo. More than 600 organizations have adopted Cisco\u0026rsquo;s HyperFlex since it was launched a few months ago, the spokesman said.\nPaul Miller, VP of marketing for HPE\u0026rsquo;s converged data center infrastructure group, said HPE\u0026rsquo;s new hyperconverged offering is as easy as public cloud, allowing users adjust VMs from their cell phones with just a few clicks. And unlike the hyperconverged-only vendors, Miller said HPE\u0026rsquo;s hyperconverged offering won\u0026rsquo;t become and IT island since it can be managed across a large footprint of infrastructure.\nVMware did not respond to a request for comment.\nPotti said Nutanix, in contrast, evolved beyond simply being a storage technology company four years ago when it started building its own hypervisor and virtualization tools. As a result, Potti said, Nutanix has completely re-imagined how the software stack is built from the ground up.\n\u0026ldquo;Nutanix is a platform player,\u0026rdquo; Potti said. \u0026ldquo;It\u0026rsquo;s not a product player … If you don\u0026rsquo;t provide the full stack, you can\u0026rsquo;t provide that Amazon-like experience.\u0026rdquo;\nNutanix\u0026rsquo;s prime objective is providing an AWS-like experience in the data center, Potti said, and the company isn\u0026rsquo;t trying to replicate the hyper-converged offerings Cisco and VMware are bringing to market.\nThe rising adoption of AWS and other public cloud services over the past five or six years has been tremendously helpful for Nutanix since many end users have already worked through departmental feuds and have grown accustomed to consuming a one-click service across the entire company, Potti said.\n\u0026ldquo;It has emotionally built a cognitive bias toward an architecture like this,\u0026rdquo; Potti said. \u0026ldquo;We are looking to provide an Amazon-like experience for the global enterprise.\u0026rdquo;\n","date":"2017-01-03T00:00:00Z","image":"https://martinliu.cn/images/WinterOwls_Hokkaido_shutterstock_7934020_FF_768_HD_ZH-CN898513788.jpg","permalink":"https://martinliu.cn/2017/01/03/HPE%20%E5%88%86%E5%85%B5%E4%B8%A4%E8%B7%AF%E8%BF%9B%E5%86%9B%E8%B6%85%E8%9E%8D%E5%90%88%E5%B8%82%E5%9C%BA/","title":"HPE 分兵两路进军超融合市场"},{"content":"Nutanix CE是Nutanix社区版软件的简称，它是Nutanix企业版产品的功能精简集合，是体验和测试Nutanix技术的很方便的途径。\nNutanix Community Edition 社区版简介 这个产品目前的位置在 https://www.nutanix.com/products/community-edition/；目前这个页面还没有中文化，下面简单介绍以下。\nFeature Rich Software 它是一个功能丰富的软件 Broad Hardware Support \u0026amp; Available On-demand 很丰富的硬件支持，在网上可以按需体验 Zero Cost 零成本 用Nutanix CE社区版体验，体验超融合技术的三个步骤。\n注册 ： 这次Nutanix社区，下载安装镜像 部署 ： 在你的服务器上部署，或者在Ravello上在线开启体验；官方安装部署视频点这里 玩耍 ： 安装完之后就可以开心地玩耍了，有问题请移步 社区版论坛 用物理机安装和体验的几点注意事项如下：\n物理机安装支持1，3，4个节点的部署；推荐内存在32GB以上；由于版本CE 2016.12.22的CVM的内存需求是24GB，由于加入了自服务门户功能；建议使用SSD硬盘，最好能混搭一些普通硬盘。 安装后的首次启动需要系统能链接互联网，否则CVM会启动不了，首次启动成功之后就不用再联网了 用虚拟机安装，请注意本机的内存，和给虚拟机分配的内存，网上也有修改对内存和CPU限制修改的脚本 产品在社区里的文档页面： 点这里\n参考配置 Intel NUC 最新版一台，i7处理器，两条16GB内存，两条512GB硬盘。它的好处是便携；然而内存还是有限，不能跑多少个虚拟机。\n相关文档 在VMware Workstation上安装Nutanix CE Nutanix Community Edition安装在vSphere环境中 浅尝超融合之Nutanix(上)介绍篇 浅尝超融合之Nutanix(下)安装篇 Nutanix超”容”合之ACS Acropolis Container Service(下)实战篇01 Nutanix超”容”合之ACS Docker Volume Plugin的使用和数据持久化测试 http://nutanix.club/ Nutanix圣经 ","date":"2017-01-02T00:00:00Z","image":"https://martinliu.cn/images/HongKongEye_ZH-CN12285832688_1920x1080.jpg","permalink":"https://martinliu.cn/2017/01/02/Nutanix-CE-all-in-one/","title":"Nutanix CE All In One"},{"content":"这次旅行的目的地是硅谷腹地圣何塞，工作了一周之后，周末在旧金山简单游玩了一下。\n交通 从北京到硅谷（圣何塞）有了海航直飞的飞机还是很方便的，在淡季的时候票价也不错。如果你的目的地就在圣何塞市附近的话，乘坐这个航班无疑是最佳的选择。\n我是星期天从北京出发的，飞机经过了11个多小时的飞行后，抵达圣何塞的时间是：同一天的上午。由于机场离我住的酒店太近了，我就经历了人生第一次，从机场走路去酒店入住。\n我在圣何塞待了大约5天，公司和酒店离的非常近，而且公司每天的餐食足够让人忘记去找饭馆吃饭这回事，这也是我首次出差这么不计较吃饭这回事。\n值得一提的是，一天和一位华人同事聊天，得知他家附近有OUTLETS，当时就说您那天下班回家，求顺道带去。第二天我如约坐上了这位同事的宝马和他一同经历了一次，硅谷人的下班。没想到的不到五点，在从圣何塞去往东湾的路上就非常的堵了，正常情况下40分钟的路程走了快两个小时。不过好在我近半年多创业公司的经理起了大用处，有很多谈资，对于这位硅谷的资深前辈来说也非常有兴趣。\n乘坐Uber替代租车是我本次出行最明智的选择，Uber选择拼车，如果和您同程的话，交通费用会非常的便宜。我的几次必要的打车经历都是用Uber解决的。只是最后一天回家的时候，到时出了状况，由于前一天晚上Uber升级，导致需要密码登录，而我的那个备用手机又没有带，最后只能请房东打了一辆正常的Yellow CAB出租车。\n乘坐Uber从圣何塞到旧金山市区的那一趟，让我在周五的下午再次领略了硅谷的堵车，足足走了3个多小时。从此我再也不觉得帝都是世界上唯一的堵车严重的城市了。\n我在旧金山期间的交通是乘坐公交电车，价格便宜又方便；不过也部分依靠了这个红色旅游巴士，两天45刀的价格倒也不便宜；买票的原因主要是，当我暴走至金门大桥的北岸的时候，觉得好像再也不能走回头路，而且附近并没有方便的公共交通工具。因此就上车了，不过对于第一天的市区游也是增色不少，一下子就让我对三藩市的整个情况摸了个七七八八，对第二天的行程非常有帮助。\n上图就是三藩市有名的叮当单车，其实就是有轨电车，由于保留了怀旧的车厢，因此一下子就成为了一个游客必选的项目。如果不是我买了CITY TOUR的票，我肯定也会去体验一把。\n公司 Nutanix是我工作十几年来所加入的一家最年轻的公司，这家公司在16年9月刚刚IPO，公司只有六七年的时间，超融合架构这块独特的市场空间可以说是他们创造的。\n公司目前还在一栋很平常的办公楼中，由于人员扩张的比较快，左侧的那栋楼也几层入住了。公司的文化还保留了比较浓的创业公司的气质，这么说是由于，公司的中高层大部分已经被来自于：VMWare、EMC、NetApp、Dell、HP等大公司的职业经理人们占据了，公司的执行层面上是不折不扣的职业经理人负责的路线，几天的培训下来，感觉所有的人都赶紧十足，大家对市场和机遇的感受和我们之前经历的所有公司都是不同的。很多本次一起来的同事中，有的是已经有一两年的Nutanix产品经验的，有的已经入职了半年左右的；相比之下我是第二周上班的新丁，在几天的培训过程中，我也是只有沉默的份。\n两个大冰箱，左边其实还有一个冰箱一个冰柜，里面都是各种饮料和食品。 这些小货架上是零食和水果。这间屋子有人搭理，会及时补充缺少了的食品。这几天的培训管两餐，在加上这些零食和补给，基本上晚餐不吃也行了。到下班的时候，可以看见有人在这些货架和冰箱里自然地往背包里装东西，后来的两天里面我晚餐基本没有出去，和很快学会这种行为也很有关，晚餐不吃的另外一个原因是时差。这次我经理了前所未有的严重的时差，几乎每天下午6点左右就困得快要昏倒，到凌晨3点左右肯定是清醒的。当然这些食品肯定比不上一线的互联网公司，可是也基本上赶超了我之前所经理过的所有的传统公司的情况。工作相关的内容就此打住。\n游玩 我住在了教会区的一个非常安静的民宅里面，是租的Airbnb的房间。房间的外形如下所示。\n家里也非常整洁、宽敞和温馨。这家附近有公交车，30分钟可以到达渔人码头所在的北滩。我第一天的路线基本上是从渔人码头沿着海边不行到进门桥下，上桥，从桥上不行到桥的北岸，最CITY TOUR红色双层BUS，回城区，然后横穿过金门公园内部的一部分，在回到联合广场。之后我有步行到了三藩市的China Town吃饭。一天的暴走下来，其实对这个城市的感觉还是非常不错的。有几个可圈可点之处：\n特色景点比较多，这里不一一枚举，都是大家耳熟能详的 城市地形高低起伏，建筑物各具特色，错落有致，绝无前篇一律的感觉。 城市的色彩丰富，特别是那些个精彩的墙壁彩绘 金门大桥 随拍的几张图片如下。\n慕名上桥走一圈的游客还是蛮多的。距离对于我这样的暴走一组来说，也没啥强度。可以感谢的是苍天有眼，让我在这抑郁、寒冷的冬季，让我待了一周已经对天气绝望的心境再次激活。后来要走的几天里，天天是艳阳高照万里无云。\n其他景点 渔老人码头比我想象中的小，而且由于并非捕鱼的季节，有赶上是寒冷的冬天，真的也就是觉得是到此一游，没有看到什么特殊的地方。 China Town的墙壁彩绘，不像是人随手为之，而这样质量的墙壁彩绘在三藩市还有很多很多。\n金门公园是我这个跑步爱好者的毕竟之地，由于本次身体状态不佳，没有跑在这个公园里面；而是从东门到西门的暴走了一趟。公园的面积其实和纽约的中央公园差不多，也就是从东到西大约5公里左右。\n公园里面被分成了很多不同的区域，正值周末各种狗友、航模、跑步、飞碟、航模等等的爱好者聚集在自己的区域里面消遣着周末时光。\n走到了三藩市西侧的海边，面朝大海的位置离注明的悬崖屋餐厅不远，我可以清晰的看到那个餐厅的建筑物。\n斯坦福 对于我来说各个著名的大学有很深的吸引力，想想这所大学和硅谷的IT行业是有多麽重要和紧密的联系。\n上图是校园里著名的教堂，是一座美丽而古典的建筑，是校园的心脏。来这里游览应该从南边的正面进入，直接走到这个教堂，然后在看其他的部分。\n美食 酸面包算是渔人码头景点的美食之一，性价比很高。 面包产自下面这家店。 最后的一次正餐，选择了北滩海景叫做Dinner的餐厅，主要吃个海景；餐食炸鱼陪薯条。 压轴的是这个早餐，点名叫“8 AM”；三藩市早餐分类在点评网站上排第五。吐司三吃。 ","date":"2016-12-31T00:00:00Z","image":"https://martinliu.cn/images/sfan-gate-park.jpg","permalink":"https://martinliu.cn/blog/west-coast-sfo/","title":"美国西岸旧金山之行"},{"content":"DevOps 这个词在去年参加红帽全球用户大会的时候就深深吸引了我，实际上哪个会上 Docker 容器的概念要比 DevOps 还火爆。Docker／openshift 相关的 session 都尝尝是爆满的。从那里开始我逐渐感觉到了开源容器技术的强大和吸引力。\n从红帽开始 OpenShift 的考试就是我在完成 RHCA 红帽认证架构师之后的一个心结，至今也没有完成。不过这根草我早晚是要拔掉的。主要是由于 OpenShift 是 Docker ＋ kubernetes 的组合；是如今企业级 PaaS 容器平台的主要技术路线。总之离开红帽是如此的仓促，说实话这也是我职业生涯中的一个不小的遗憾。当时确实觉得 kubernetes 的命令行操作不是很方便，而且在 OpenShift 并没有降低这个门槛，也即是说在 OpenShift 里面还是要有一定的工作量和技能的要求在编写 kubernetes 的 yml 文件上。在这一点上，及时我熟练掌握了 Rancher 之后，同样发现编写 compose file 也是难以逃避的。在推广一步，大部分 Docker PaaS 平台也都是这样，很多产品也是在界面上提供一个文本输入框，让人输入容器服务定义文件的内容。\n在最近的半年中，我的所有技术研究都集中在 Docker 和其服务编排技术上。与很多用户做过技术交流，PoC 测试，有些单子也落地。总结后，有些结果让我感叹。国内的所有企业不区分规模和行业，其实他们对国内原生的创业公司是欢迎的，由于这些公司提供的是国产软件和技术服务。在 Docker 这个火热的领域中，已经有 20 多家国内创业公司，我想所有的公司也都已经接受到了这一点的福利了。外国软件通常给人的感觉是：不是国产软件（不要小看国内公司对国产软件的诉求），纯英文操作界面和文档，可能的水土不服，高昂的软件价格和服务费，如果技术太新的化很可能厂商也不具备足够的技术实力和服务力量。\n经过了一些 Docker 容器项目之后，可以断言的是容器市场的火爆和它的技术优势是直接相关的。容器化之后的应用可以通过服务编排工具快速地部署／更新、弹性地伸缩和使用资源，优化其传统应用运维的若干缺陷。容器的轻量和 just enough 的隔离技术让资源池的管理更加简单，利用率大幅度提升，这对研发部门的环境管理是不小的提升，使 CI 的过程更加高效和经济。Docker 对微服务的支持也深深地诱惑了所有开发者，做系统微服务实施开发者能想到的实施技术大多数会是容器。\n以上容器的优势和特性使得国内的这些项目落地和实施的可能性进一步提高，甚至很多项目的速度远远超预期；按照我多年的经验看，一个软件技术型的项目，用户纠结半年到一年以上是很正常的。可能也跟国内企业包容本土化软件公司，追捧新潮技术直接相关；我观察到的一些项目，在 2 ～ 4 个月内落单的屡见不鲜。有些试点的 DevOps 咨询项目也落地很快。\n这些项目都殊途同归地指向了 DevOps 这个关键词，这让我不得不从去年开始就关注和学习这个最佳实践。当然，我对 DevOps 的前途非常看好，因此当我听说业内出现了相关认证考试之后，我毫不犹豫地报名参加了。经过 2 个多月的缜密的准备，我终于幸运地一次通过了这个考试。考试获得了两个证书。\nDevOps Master\nDevOps Master 认证自由讲师\n我参加的是讲师认证培训 TTT，很高兴能成为 Exin 在国内的首批 5 个认证人员之一。在准备这个考试的过程中我学习了一些书籍，现在还在深度学习的书有两本。\n我完成了这本黑皮书的读书笔记，很遗憾的是，我发现它的最新版，把封面改成了白底的了，我不能在叫它黑皮书／黑宝书了。这本书我起码看了两遍；目前正在调试它的书中的代码，代码中的营养还是很高的，计划尽快把所有代码调试通过；从而完成我许下多次的线上分享本书的诺言。\n这本书被我称为 CD 红皮书／红宝书。本书早在 10 年就出版了，也就是说比 Docker 早好多年。他给我最大的印象就是，作者每一页上似乎都在介绍这做事情的原则和规矩是什么？我一点也不夸张，他对 CD 的介绍，就是通过讲解一系列在项目上的经验总结。对作者这种级别的经验，和写书的房子只能用一个词总结“服”。这本书太干，我至今还没有消化完。他让我看到了解决发布和变更风险的终极解决方案，没有一次性解决问题的部署／配置／发布工具，有的是历练和打磨了千万次的持续部署流水线；隐约地觉得没用入手的企业都会慢慢跟上的。\n以上是我对 DevOps 的阶段性总结，跨度有半年之久。这半年中我逐渐看清了我的主要兴趣点，抛除所有其他主题，目前剩下的就是：云计算和 DevOps。一方面觉得年纪不饶人，不能可能在和年轻人拼精力、体力和创意；我的背景和经验都让我感觉，在这两个话题上，我还是有很多年的经验和技术积累和总结的。云计算是（公有云＋私有云）未来企业 IT 基础架构的走向；DevOps 是目前看比较正确的运作实践。一个便技术，一个便管理，正好完整覆盖了我的经验；在其对应的开源技术这个分支里，我想它们都还有这很多的为探索和研究的项目。\n","date":"2016-11-07T15:19:08Z","permalink":"https://martinliu.cn/2016/11/07/exin-devops-master-e8aea4e8af81e88083e8af95/","title":"EXIN DevOps Master 认证考试"},{"content":"测试环境说明 我的笔记本电脑的环境描述如下。\nOS MacBook Pro 2011 版， 2.3 GHz Intel Core i5， 8GB DDR3， 256 GB SSD。 OS X EI Capitan version 10.11.5\nDocker Docker for Mac Version 1.12.0-rc2-beta17 (build: 9779)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 $ docker version Client: Version: 1.12.0-rc2 API version: 1.24 Go version: go1.6.2 Git commit: 906eacd Built: Fri Jun 17 20:35:33 2016 OS/Arch: darwin/amd64 Experimental: true Server: Version: 1.12.0-rc2 API version: 1.24 Go version: go1.6.2 Git commit: a7119de Built: Wed Jun 29 10:03:33 2016 OS/Arch: linux/amd64 Experimental: true $ docker-machine version docker-machine version 0.8.0-rc1, build fffa6c9 martin@localhost ~/Documents [9:38:31] $ docker-compose version docker-compose version 1.8.0-rc1, build 9bf6bc6 docker-py version: 1.8.1 CPython version: 2.7.9 OpenSSL version: OpenSSL 1.0.2h 3 May 2016 VirtualBox version 5.0.22r108108\n本机下载的 Docker 镜像 /Users/martin/Downloads/1.12.0-rc2/boot2docker.iso\n~/Downloads/rancher-all/rancher-agent-v1.0.1.tar\n~/Downloads/rancher-all/rancher-agent-instance-v0.8.1.tar\n~/Downloads/habitat-docker-registry.bintray.io-studio.tar\n~/Downloads/rancher-all/rancher-server-stable.tar\n我本机还有一个 Docker Registry 的 vm，这里面提供了我需要积累以后用的镜像存储，想象一下你在飞机上的时候去哪里拉取镜像 ：）\n本机下载的代码 https://github.com/habitat-sh/habitat-example-plans https://github.com/janeczku/habitat-plans https://github.com/chrisurwin/may2016-demo https://github.com/docker/example-voting-app\n注意以上代码可能需要修改才能在本机调试成功。\n创建 Rancher 服务器 生成虚拟机 用 docker-machine 创建 rancher 服务器。\n1 docker-machine create rancher --driver virtualbox --virtualbox-cpu-count \u0026#34;1\u0026#34; --virtualbox-disk-size \u0026#34;8000\u0026#34; --virtualbox-memory \u0026#34;1024\u0026#34; --virtualbox-boot2docker-url=/Users/martin/Downloads/1.12.0-rc2/boot2docker.iso \u0026amp;\u0026amp; eval $(docker-machine env rancher) 导入 Rancher 服务器镜像 用 docker-machine ls 应该看到 rancher 这个节点打了星号。否则 docker 命令会执行失败或者错误。\n1 2 3 docker load \u0026lt; ~/Downloads/rancher-all/rancher-server-stable.tar docker run -d --restart=always --name rancher-srv -p 8080:8080 rancher/server:stable docker logs -f rancher-srv 查看 rancher 服务器的 ip 地址。 docker-machine ip rancher\n用浏览器打开 Rancher 服务器的登录页面。 open http://Rancher_Server_IP:8080\n下面是一些如何让虚拟机保持固定 IP 和 rancher 容器存储的数据持久存在的代码，我没有测试成功，留下大家一起搞，成功了，给我一个回复。另外还有关于稿 jekins 和 mirror 的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 echo \u0026#34;ifconfig eth1 192.168.99.60 netmask 255.255.255.0 broadcast 192.168.99.255 up\u0026#34; | docker-machine ssh node1 sudo tee /var/lib/boot2docker/bootsync.sh \u0026gt; /dev/null docker-machine regenerate-certs node1 -f docker-machine ssh ndoe1 sudo mkdir /mnt/sda1/var/lib/rancher docker@node1:/mnt/sda1/var/lib/boot2docker$ cat bootsync.sh ifconfig eth1 192.168.99.60 netmask 255.255.255.0 broadcast 192.168.99.255 up sudo mkdir /mnt/sda1/var/lib/rancher/ sudo ln -s /mnt/sda1/var/lib/rancher/ /var/lib/ docker load \u0026lt; ~/Downloads/rancher-all/jenkins.tar docker run -d --name jekins --privileged -p 9001:8080 -v /var/lib/docker/:/var/lib/docker/ -v /var/run/docker.sock:/var/run/docker.sock -v /usr/bin/docker:/usr/bin/docker -v /lib64/libdevmapper.so.1.02:/usr/lib/libdevmapper.so.1.02 --label io.rancher.container.network=true jenkins docker-machine create mirror --driver virtualbox --virtualbox-cpu-count \u0026#34;1\u0026#34; --virtualbox-disk-size \u0026#34;8000\u0026#34; --virtualbox-memory \u0026#34;512\u0026#34; --virtualbox-boot2docker-url=/Users/martin/Downloads/boot2docker.iso docker load \u0026lt; ~/Downloads/rancher-all/registry.tar docker run -d -p 80:5000 --restart=always --name registry registry:2 容器运行节点 Rancher Agent 节点 创建 node1 虚拟机 使用 docker-machine 命令创建容器运行节点。\n1 2 3 docker-machine create node1 --driver virtualbox --engine-insecure-registry 192.168.99.20:5000 --virtualbox-cpu-count \u0026#34;1\u0026#34; --virtualbox-disk-size \u0026#34;80000\u0026#34; --virtualbox-memory \u0026#34;1024\u0026#34; --virtualbox-boot2docker-url=/Users/martin/Downloads/1.12.0-rc2/boot2docker.iso docker-machine create node2 --driver virtualbox --engine-insecure-registry 192.168.99.20:5000 --virtualbox-cpu-count \u0026#34;1\u0026#34; --virtualbox-disk-size \u0026#34;80000\u0026#34; --virtualbox-memory \u0026#34;1024\u0026#34; --virtualbox-boot2docker-url=/Users/martin/Downloads/1.12.0-rc2/boot2docker.iso 在 node1 或者 node2 测试运行一个容器，使用 mirror 中的 busybox 镜像。如果你的笔记本内存小于 8GB 的话，node2 就别搞了。一个 node 也够用了。\n1 docker pull 192.168.99.20:5000/busybox:latest docker run 一下这个镜像，验证 node1 工作正常。\n加载 Rancher Agent 的镜像 确保 node1 是 docker-machine ls 中打星号的。\n1 2 3 docker load \u0026lt; ~/Downloads/rancher-all/rancher-agent-v1.0.1.tar docker load \u0026lt; ~/Downloads/rancher-all/rancher-agent-instance-v0.8.1.tar docker load \u0026lt; ~/Downloads/habitat-docker-registry.bintray.io-studio.tar 你翻墙下载回来的 habitat-docker-registry.bintray.io/studio 镜像可能需要打标签，否则回头 hab 命令执行失败。 先用 docer images 看下是否所有 image 的标签信息正确。\n1 docker tag fc27342e5e0e habitat-docker-registry.bintray.io/studio:latest 添加 node1 节点到 Rancher Server。 1 docker run -d --privileged -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/rancher:/var/lib/rancher rancher/agent:v1.0.1 http://192.168.99.100:8080/v1/scripts/33B68ED65CEF18F6D7BD:1466694000000:lug2KswoXOOQV4d09ZNMGTphVs0 现在在 Hosts 页面上应该能看到该刚创建的节点。在页面上创建一个最小化的容器（如 busybox），来拉起 Network Agent 容器。\n调试 habitat 的测试程序 参考的文档 https://www.habitat.sh/tutorials/ 记得一定要把这一组文章先看完，在去调试它的代码，不懂这些基本概念的话，后面对了错了都不知道该怎么搞。\n前置条件，翻墙下载 habitat studio 的 docker image 镜像，load 到 node1 上，下面的所有测试都是在 node1 上完成的。\n安装 hab habitat 的程序只有一个可执行程序， 目前支持 mac 和 linux 版本。下载地址： https://www.habitat.sh/docs/get-habitat 就是一个 tag 包，解压缩后放到 shell 的 PATH 里面就安装完了。\n配置 hab cli 运行 hab setup\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 martin@localhost ~/Documents $ hab setup Habitat CLI Setup ================= Welcome to hab setup. Let\u0026#39;s get started. Set up a default origin Every package in Habitat belongs to an origin, which indicates the person or organization responsible for maintaining that package. Each origin also has a key used to cryptographically sign packages in that origin. Selecting a default origin tells package building operations such as \u0026#39;hab pkg build\u0026#39; what key should be used to sign the packages produced. If you do not set a default origin now, you will have to tell package building commands each time what origin to use. For more information on origins and how they are used in building packages, please consult the docs at https://www.habitat.sh/docs/build-packages-overview/ Set up a default origin? [Yes/no/quit] yes 这里输入 yes Enter the name of your origin. If you plan to publish your packages publicly, we recommend that you select one that is not already in use on the Habitat build service found at https://app.habitat.sh/. You already have a default origin set up as `martin\u0026#39;, but feel free to change it if you wish. Default origin name: [default: martin] 这是用来做 Habitat 包签名和加密用的标识，在代码里面会用到。 You already have an origin key for martin created and installed. Great work! GitHub Access Token While you can build and run Habitat packages without sharing them on the public depot, doing so allows you to collaborate with the Habitat community. In addition, it is how you can perform continuous deployment with Habitat. The depot uses GitHub authentication with an access token (https://help.github.com/articles/creating-an-access-token-for-command-line-use/). If you would like to share your packages on the depot, please enter your GitHub access token. Otherwise, just enter No. For more information on sharing packages on the depot, please read the documentation at https://www.habitat.sh/docs/share-packages-overview/ Set up a default GitHub access token? [Yes/no/quit] yes 这里选择yes Enter your GitHub access token. You already have a default auth token set up, but feel free to change it if you wish. GitHub access token: [default: martin-github-token] 这个 token 需要自己去 github 里面生成 Analytics The `hab` command-line tool will optionally send anonymous usage data to Habitat\u0026#39;s Google Analytics account. This is a strictly opt-in activity and no tracking will occur unless you respond affirmatively to the question below. We collect this data to help improve Habitat\u0026#39;s user experience. For example, we would like to know the category of tasks users are performing, and which ones they are having trouble with (e.g. mistyping command line arguments). To see what kinds of data are sent and how they are anonymized, please read more about our analytics here: https://www.habitat.sh/docs/about-analytics/ Enable analytics? [yes/No/quit] no 这里选择 no » Opting out of analytics ☑ Creating /Users/martin/.hab/cache/analytics/OPTED_OUT ★ Analytics opted out, we salute you just the same! CLI Setup Complete That\u0026#39;s all for now. Thanks for using Habitat! martin@localhost ~/Documents $ 该注意的都写到上面的代码里面了。这个配置的结果在这里\n1 2 3 $ cat ~/.hab/etc/cli.toml auth_token = \u0026#34;martin-github-token\u0026#34; origin = \u0026#34;martin\u0026#34; 调试 Habitat demo 应用 1 git clone https://github.com/habitat-sh/habitat-example-plans 进入到 mytutorialapp 目录，修改 plan.sh 的 第二行代码，我改后的代码是\n1 pkg_origin=martin martin 是我在 hab cli 里面配置的 origin。\n其实下面的测试就执行了两个 hab 的命令，都是在 hab studi 的 shell 里面执行的，这个 shell 其实就是一个 studio 容器的 shell。\n在运行下面的命令，确保你是和 node1 正常通讯的，下面我用 default 节点做演示。做完的演示环境我已经删除了。\n1 2 3 4 $ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS default - virtualbox Running tcp://192.168.99.100:2376 v1.11.1 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 正常的意思是执行所有 docker 命令不报错。\nbuild habitat demo 代码 进入到代码的 plan.sh 的目录 执行 hab studio enter 命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 martin@localhost ~/Documents/GitHub/habitat-example-plans/mytutorialapp $ hab studio enter [±master ●●] hab-studio: Creating Studio at /hab/studios/src (default) hab-studio: Importing martin secret origin key » Importing origin key from standard input ★ Imported secret origin key martin-20160630040241. hab-studio: Entering Studio at /hab/studios/src (default) hab-studio: Exported: HAB_ORIGIN=martin [1][default:/src:0]# build : Loading /src/plan.sh mytutorialapp: Plan loaded mytutorialapp: hab-plan-build setup mytutorialapp: Using HAB_BIN=/hab/pkgs/core/hab/0.7.0/20160614230104/bin/hab for installs, signing, and hashing mytutorialapp: Resolving dependencies » Installing core/node → Using core/gcc-libs/5.2.0/20160612075020 → Using core/glibc/2.22/20160612063629 → Using core/linux-headers/4.3/20160612063537 ↓ Downloading core/node/4.2.6/20160612143531 6.44 MB / 6.44 MB \\ [=======================================================================] 100.00 % 457.82 KB/s ↓ Downloading core-20160612031944 public origin key 75 B / 75 B | [=============================================================================] 100.00 % 575.13 KB/s ☑ Cached core-20160612031944 public origin key ✓ Installed core/node/4.2.6/20160612143531 ★ Install of core/node complete with 4 packages installed. mytutorialapp: Resolved dependency \u0026#39;core/node\u0026#39; to /hab/pkgs/core/node/4.2.6/20160612143531 mytutorialapp: Setting PATH=/hab/pkgs/core/node/4.2.6/20160612143531/bin:/hab/pkgs/core/hab-plan-build/0.7.0/20160614232259/bin:/hab/pkgs/core/bash/4.3.42/20160612075613/bin:/hab/pkgs/core/binutils/2.25.1/20160612064534/bin:/hab/pkgs/core/bzip2/1.0.6/20160612075040/bin:/hab/pkgs/core/coreutils/8.24/20160612075329/bin:/hab/pkgs/core/file/5.24/20160612064523/bin:/hab/pkgs/core/findutils/4.4.2/20160612080341/bin:/hab/pkgs/core/gawk/4.1.3/20160612075739/bin:/hab/pkgs/core/grep/2.22/20160612075540/bin:/hab/pkgs/core/gzip/1.6/20160612080637/bin:/hab/pkgs/core/hab/0.7.0/20160614230104/bin:/hab/pkgs/core/sed/4.2.2/20160612075228/bin:/hab/pkgs/core/tar/1.28/20160612075701/bin:/hab/pkgs/core/unzip/6.0/20160612081414/bin:/hab/pkgs/core/wget/1.16.3/20160612081342/bin:/hab/pkgs/core/xz/5.2.2/20160612080402/bin:/hab/pkgs/core/acl/2.2.52/20160612075215/bin:/hab/pkgs/core/attr/2.4.47/20160612075207/bin:/hab/pkgs/core/glibc/2.22/20160612063629/bin:/hab/pkgs/core/less/481/20160612080021/bin:/hab/pkgs/core/libcap/2.24/20160612075226/bin:/hab/pkgs/core/libidn/1.32/20160612081104/bin:/hab/pkgs/core/ncurses/6.0/20160612075116/bin:/hab/pkgs/core/openssl/1.0.2h/20160612081127/bin:/hab/pkgs/core/pcre/8.38/20160612075520/bin mkdir: created directory \u0026#39;/hab/cache/src\u0026#39; mytutorialapp: Downloading \u0026#39;https://s3-us-west-2.amazonaws.com/mytutorialapp/mytutorialapp-0.1.0.tar.gz\u0026#39; to \u0026#39;mytutorialapp-0.1.0.tar.gz\u0026#39; --2016-07-01 02:27:51-- https://s3-us-west-2.amazonaws.com/mytutorialapp/mytutorialapp-0.1.0.tar.gz Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 54.231.184.216 Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|54.231.184.216|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 1041 (1.0K) [application/x-gzip] Saving to: \u0026#39;mytutorialapp-0.1.0.tar.gz\u0026#39; mytutorialapp-0.1.0.tar.gz 100%[===================================================\u0026gt;] 1.02K --.-KB/s in 0.03s 2016-07-01 02:28:08 (32.1 KB/s) - \u0026#39;mytutorialapp-0.1.0.tar.gz\u0026#39; saved [1041/1041] mytutorialapp: Downloaded \u0026#39;mytutorialapp-0.1.0.tar.gz\u0026#39; mytutorialapp: Verifying mytutorialapp-0.1.0.tar.gz mytutorialapp: Checksum verified for mytutorialapp-0.1.0.tar.gz mytutorialapp: Clean the cache mytutorialapp: Unpacking mytutorialapp-0.1.0.tar.gz mytutorialapp: Setting build environment mytutorialapp: Setting PREFIX=/hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725 mytutorialapp: Setting LD_RUN_PATH=/hab/pkgs/core/node/4.2.6/20160612143531/lib mytutorialapp: Setting CFLAGS=-I/hab/pkgs/core/node/4.2.6/20160612143531/include mytutorialapp: Setting LDFLAGS=-L/hab/pkgs/core/node/4.2.6/20160612143531/lib mytutorialapp: Preparing to build mytutorialapp: Building npm WARN package.json mytutorialapp@0.1.0 No repository field. npm WARN package.json mytutorialapp@0.1.0 No README data nconf@0.8.4 node_modules/nconf ├── ini@1.3.4 ├── secure-keys@1.0.0 ├── async@1.5.2 └── yargs@3.32.0 (decamelize@1.2.0, camelcase@2.1.1, window-size@0.1.4, y18n@3.2.1, os-locale@1.4.0, cliui@3.2.0, string-width@1.0.1) mytutorialapp: Installing \u0026#39;node_modules/nconf\u0026#39; -\u0026gt; \u0026#39;/hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/node_modules/nconf\u0026#39; 忽略了好几百行输出 \u0026#39;node_modules/nconf/node_modules/secure-keys/test/simple-test.js\u0026#39; -\u0026gt; \u0026#39;/hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/node_modules/nconf/node_modules/secure-keys/test/simple-test.js\u0026#39; \u0026#39;node_modules/nconf/node_modules/secure-keys/test/test.secret.key\u0026#39; -\u0026gt; \u0026#39;/hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/node_modules/nconf/node_modules/secure-keys/test/test.secret.key\u0026#39; \u0026#39;node_modules/nconf/node_modules/secure-keys/package.json\u0026#39; -\u0026gt; \u0026#39;/hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/node_modules/nconf/node_modules/secure-keys/package.json\u0026#39; mytutorialapp: Writing configuration mytutorialapp: Writing service management scripts mytutorialapp: Stripping unneeded symbols from binaries and libraries mytutorialapp: Creating manifest mytutorialapp: Building package metadata mytutorialapp: Generating blake2b hashes of all files in the package mytutorialapp: Generating signed metadata FILES » Signing mytutorialapp_blake2bsums ☛ Signing mytutorialapp_blake2bsums with martin-20160630040241 to create /hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/FILES ★ Signed artifact /hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/FILES. mytutorialapp: Generating package artifact /hab/pkgs/core/tar/1.28/20160612075701/bin/tar: Removing leading `/\u0026#39; from member names /hab/cache/artifacts/.martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.tar (1/1) 100 % 121.4 KiB / 900.0 KiB = 0.135 » Signing /hab/cache/artifacts/.martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.tar.xz ☛ Signing /hab/cache/artifacts/.martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.tar.xz with martin-20160630040241 to create /hab/cache/artifacts/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart ★ Signed artifact /hab/cache/artifacts/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart. \u0026#39;/hab/cache/artifacts/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart\u0026#39; -\u0026gt; \u0026#39;/src/results/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart\u0026#39; mytutorialapp: hab-plan-build cleanup mytutorialapp: mytutorialapp: Source Cache: /hab/cache/src/mytutorialapp-0.1.0 mytutorialapp: Installed Path: /hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725 mytutorialapp: Artifact: /src/results/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart mytutorialapp: Build Report: /src/results/last_build.env mytutorialapp: SHA256 Checksum: d4bfb3a44989b8a5b1295eac2600d75f42dd2be6f537344312c8917cba47d05d mytutorialapp: Blake2b Checksum: fbff257eb36fffa61e6cbf5ec89fa3f507095f80f5cca610c2bb72685d758706 mytutorialapp: mytutorialapp: I love it when a plan.sh comes together. mytutorialapp: mytutorialapp: Build time: 1m3s [2][default:/src:0]# 检查结果，在代码的目录中可以看的 result 目录，关注一下这个目录，关键看 build 命令的最后一段。\n1 2 mytutorialapp: hab-plan-build cleanup mytutorialapp: mytutorialapp: Source Cache: /hab/cache/src/mytutorialapp-0.1.0 mytutorialapp: Installed Path: /hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725 mytutorialapp: Artifact: /src/results/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart mytutorialapp: Build Report: /src/results/last_build.env mytutorialapp: SHA256 Checksum: d4bfb3a44989b8a5b1295eac2600d75f42dd2be6f537344312c8917cba47d05d mytutorialapp: Blake2b Checksum: fbff257eb36fffa61e6cbf5ec89fa3f507095f80f5cca610c2bb72685d758706 mytutorialapp: mytutorialapp: I love it when a plan.sh comes together. mytutorialapp: mytutorialapp: Build time: 1m3s 昨晚分享的高潮部分, habitat 导出 docker image 其实就是一条命令，在 habitat Studio 中执行 导出命令 hab pkg export docker martin/mytutorialapp\n导出 docker 镜像的过程和 build 的过程一样，都可能会失败；由于它需要到网上下载所需要的代码，下载所需要的 habitat 模块，core/ 开头的都是 habitat 出品的核心的模块，他们的想法基本也是说把所有的可能用到的模块都做封装，成为自己的 pkg 格式的内容。然后在用他们的 Habitat 服务来解析、部署和运行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 [4][default:/src:0]# hab pkg export docker martin/mytutorialapp hab-studio: Creating Studio at /tmp/hab-pkg-dockerize-XxsS/rootfs (baseimage) Using local package for martin/mytutorialapp Using local package for core/gcc-libs/5.2.0/20160612075020 via martin/mytutorialapp Using local package for core/glibc/2.22/20160612063629 via martin/mytutorialapp Using local package for core/linux-headers/4.3/20160612063537 via martin/mytutorialapp Using local package for core/node/4.2.6/20160612143531 via martin/mytutorialapp » Installing core/hab ↓ Downloading core/hab/0.7.0/20160614230104 2.23 MB / 2.23 MB / [=======================================================================] 100.00 % 500.60 KB/s ↓ Downloading core-20160612031944 public origin key 75 B / 75 B | [=============================================================================] 100.00 % 378.76 KB/s ☑ Cached core-20160612031944 public origin key ✓ Installed core/hab/0.7.0/20160614230104 ★ Install of core/hab complete with 1 packages installed. » Installing core/hab-sup ↓ Downloading core/busybox-static/1.24.2/20160612081725 510.89 KB / 510.89 KB | [====================================================================] 100.00 % 89.61 KB/s ✓ Installed core/busybox-static/1.24.2/20160612081725 ↓ Downloading core/bzip2/1.0.6/20160612075040 141.05 KB / 141.05 KB - [===================================================================] 100.00 % 349.94 KB/s ✓ Installed core/bzip2/1.0.6/20160612075040 ↓ Downloading core/cacerts/2016.04.20/20160612081125 132.32 KB / 132.32 KB | [===================================================================] 100.00 % 370.21 KB/s ✓ Installed core/cacerts/2016.04.20/20160612081125 → Using core/gcc-libs/5.2.0/20160612075020 → Using core/glibc/2.22/20160612063629 ↓ Downloading core/libarchive/3.2.0/20160612140528 584.98 KB / 584.98 KB | [===================================================================] 100.00 % 340.75 KB/s ✓ Installed core/libarchive/3.2.0/20160612140528 ↓ Downloading core/libsodium/1.0.8/20160612140317 187.96 KB / 187.96 KB \\ [===================================================================] 100.00 % 200.27 KB/s ✓ Installed core/libsodium/1.0.8/20160612140317 → Using core/linux-headers/4.3/20160612063537 ↓ Downloading core/openssl/1.0.2h/20160612081127 2.10 MB / 2.10 MB | [=======================================================================] 100.00 % 518.78 KB/s ✓ Installed core/openssl/1.0.2h/20160612081127 ↓ Downloading core/xz/5.2.2/20160612080402 247.38 KB / 247.38 KB \\ [===================================================================] 100.00 % 468.42 KB/s ✓ Installed core/xz/5.2.2/20160612080402 ↓ Downloading core/zlib/1.2.8/20160612064520 73.06 KB / 73.06 KB / [=====================================================================] 100.00 % 315.44 KB/s ✓ Installed core/zlib/1.2.8/20160612064520 ↓ Downloading core/hab-sup/0.7.0/20160614232939 1.54 MB / 1.54 MB | [=======================================================================] 100.00 % 563.90 KB/s ✓ Installed core/hab-sup/0.7.0/20160614232939 ★ Install of core/hab-sup complete with 12 packages installed. » Symlinking hab from core/hab into /tmp/hab-pkg-dockerize-XxsS/rootfs/hab/bin ★ Binary hab from core/hab/0.7.0/20160614230104 symlinked to /tmp/hab-pkg-dockerize-XxsS/rootfs/hab/bin/hab » Symlinking bash from core/busybox-static into /tmp/hab-pkg-dockerize-XxsS/rootfs/bin ★ Binary bash from core/busybox-static/1.24.2/20160612081725 symlinked to /tmp/hab-pkg-dockerize-XxsS/rootfs/bin/bash » Symlinking sh from core/busybox-static into /tmp/hab-pkg-dockerize-XxsS/rootfs/bin ★ Binary sh from core/busybox-static/1.24.2/20160612081725 symlinked to /tmp/hab-pkg-dockerize-XxsS/rootfs/bin/sh Sending build context to Docker daemon 194.3 MB Step 1 : FROM scratch ---\u0026gt; Step 2 : ENV export PATH=:/hab/pkgs/core/glibc/2.22/20160612063629/bin:/hab/pkgs/core/node/4.2.6/20160612143531/bin:/hab/pkgs/core/hab-sup/0.7.0/20160614232939/bin:/hab/pkgs/core/busybox-static/1.24.2/20160612081725/bin:/hab/pkgs/core/bzip2/1.0.6/20160612075040/bin:/hab/pkgs/core/glibc/2.22/20160612063629/bin:/hab/pkgs/core/openssl/1.0.2h/20160612081127/bin:/hab/pkgs/core/xz/5.2.2/20160612080402/bin:/hab/pkgs/core/busybox-static/1.24.2/20160612081725/bin:/hab/bin ---\u0026gt; Running in 117e90c151e7 ---\u0026gt; 7f33585a25ae Removing intermediate container 117e90c151e7 Step 3 : WORKDIR / ---\u0026gt; Running in 952257966d96 ---\u0026gt; c0cf3715cbcf Removing intermediate container 952257966d96 Step 4 : ADD rootfs / ---\u0026gt; d2691da93ccf Removing intermediate container 4aa80e97ea57 Step 5 : VOLUME /hab/svc/mytutorialapp/data /hab/svc/mytutorialapp/config ---\u0026gt; Running in f1edcb653432 ---\u0026gt; bd8888453939 Removing intermediate container f1edcb653432 Step 6 : EXPOSE 9631 8080 ---\u0026gt; Running in 9ca7725ed13e ---\u0026gt; 256a04cd0fe2 Removing intermediate container 9ca7725ed13e Step 7 : ENTRYPOINT /init.sh ---\u0026gt; Running in 81930dff8f4e ---\u0026gt; d7bdec08530e Removing intermediate container 81930dff8f4e Step 8 : CMD start martin/mytutorialapp ---\u0026gt; Running in c8cc53d92bc8 ---\u0026gt; 8d5e0fe85395 Removing intermediate container c8cc53d92bc8 Successfully built 8d5e0fe85395 [5][default:/src:0]# 查看 docker 镜像是否存在。推出 studio 容器，运行 docker images\n1 2 3 4 5 6 7 [5][default:/src:0]# exit logout martin@localhost ~/Documents/GitHub/habitat-example-plans/mytutorialapp $ docker images [±master ●●] REPOSITORY TAG IMAGE ID CREATED SIZE martin/mytutorialapp 0.1.0-20160701024401 8d5e0fe85395 3 minutes ago 187.7 MB martin/mytutorialapp latest 8d5e0fe85395 3 minutes ago 187.7 MB 运行这个 demo 在命令行运行\n$ docker run -it -p 8080:8080 martin/mytutorialapp\n用浏览器打开 node1 的 ip 8080 端口，应该可以看到 hello world 页面。\n在 rancher web 页面添加测试\n在 rancher 中上架这个 demo https://github.com/martinliu/hab-catalog 以上代码是半成品，欢迎协助完成。\n测试 Rancher 官方的 redis demo 参考文章 http://rancher.com/using-habitat-to-create-rancher-catalog-templates/ 它的 demo 和上架的目录都可以正常测试通过，但是服务运行不起来，报主机名错误，redis 节点的群集建立不起来。\n如果您修复了，请回复贴出代码位置。\n福利：调试 docker 官方投票应用 下载投票实例程序。\n1 git clone https://github.com/martinliu/example-voting-app.git 进入该程序的目录，修改所有 image 的来源镜像库，修改为指向本地的 mirror 服务器。 1. result/tests/Dcokerfile -\u0026gt; FROM 192.168.99.20:5000/node 2. result/Dockerfile -\u0026gt; FROM 192.168.99.20:5000/node:5.11.0-slim 3. vote/Dockerfile -\u0026gt; FROM 192.168.99.20:5000/python:2.7-alpine 4. worker/Dockerfile -\u0026gt; FROM 192.168.99.20:5000/microsoft/dotnet:1.0.0-preview1 5. docker-compose.yml -\u0026gt; image: 192.168.99.20:5000/redis:alpine 6. docker-compose.yml -\u0026gt; image: 192.168.99.20:5000/postgres:9.4\n由于以上应用在构建的过程中需要在线安装各种软件包，最好先翻墙，确认你有足够稳定的国外的互联网访问，建议翻墙到美国，然后在执行项目的构建命令。\n1 2 3 4 5 6 7 8 9 10 11 12 ping facebook.com 64 bytes from 173.252.90.132: icmp_seq=0 ttl=79 time=4187.066 ms 64 bytes from 173.252.90.132: icmp_seq=1 ttl=79 time=3186.904 ms 64 bytes from 173.252.90.132: icmp_seq=2 ttl=79 time=2515.415 ms 64 bytes from 173.252.90.132: icmp_seq=6 ttl=79 time=296.457 ms 64 bytes from 173.252.90.132: icmp_seq=7 ttl=79 time=410.215 ms ^C --- facebook.com ping statistics --- 8 packets transmitted, 5 packets received, 37.5% packet loss round-trip min/avg/max/stddev = 296.457/2119.211/4187.066/1537.275 ms docker-compose build 以上结果表明，翻墙成功，以上结果显示翻墙的效果比较差，延迟和丢包都比较严重，可能到只构建的时候下载软件包失败。\n构建完毕之后，可以检查一下是否生产了目标镜像文件，如果输出如下所示，则表明本次本地的项目集成构建成功。\n1 2 3 4 5 $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE examplevotingapp_result latest 9bb4126b0905 5 minutes ago 225.8 MB examplevotingapp_worker latest 292396a5aba4 6 minutes ago 644.1 MB examplevotingapp_vote latest 28052191beea 10 minutes ago 68.31 MB 在当前 node1 节点上做本地的集成结果的功能测试，用 docker-compose 启动这个项目。先检查 compose 文件，然后运行 up。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 $ docker-compose config networks: {} services: db: image: 192.168.99.20:5000/postgres:9.4 redis: image: 192.168.99.20:5000/redis:alpine ports: - \u0026#39;6379\u0026#39; result: build: context: /Users/martin/Documents/GitHub/example-voting-app/result command: nodemon --debug server.js ports: - 5001:80 - 5858:5858 volumes: - /Users/martin/Documents/GitHub/example-voting-app/result:/app:rw vote: build: context: /Users/martin/Documents/GitHub/example-voting-app/vote command: python app.py ports: - 5000:80 volumes: - /Users/martin/Documents/GitHub/example-voting-app/vote:/app:rw worker: build: context: /Users/martin/Documents/GitHub/example-voting-app/worker version: \u0026#39;2.0\u0026#39; volumes: {} $ docker-compose up Recreating examplevotingapp_vote_1 Recreating examplevotingapp_worker_1 Starting examplevotingapp_db_1 Starting examplevotingapp_redis_1 Recreating examplevotingapp_result_1 Attaching to examplevotingapp_db_1, examplevotingapp_redis_1, examplevotingapp_worker_1, examplevotingapp_result_1, examplevotingapp_vote_1 redis_1 | _._ redis_1 | _.-``__ \u0026#39;\u0026#39;-._ redis_1 | _.-`` `. `_. \u0026#39;\u0026#39;-._ Redis 3.2.1 (00000000/0) 64 bit redis_1 | .-`` .-```. ```\\/ _.,_ \u0026#39;\u0026#39;-._ db_1 | LOG: database system was shut down at 2016-06-20 09:58:19 UTC redis_1 | ( \u0026#39; , .-` | `, ) Running in standalone mode redis_1 | |`-._`-...-` __...-.``-._|\u0026#39;` _.-\u0026#39;| Port: 6379 redis_1 | | `-._ `._ / _.-\u0026#39; | PID: 1 redis_1 | `-._ `-._ `-./ _.-\u0026#39; _.-\u0026#39; redis_1 | |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| redis_1 | | `-._`-._ _.-\u0026#39;_.-\u0026#39; | http://redis.io redis_1 | `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; redis_1 | |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| db_1 | LOG: MultiXact member wraparound protections are now enabled redis_1 | | `-._`-._ _.-\u0026#39;_.-\u0026#39; | redis_1 | `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; db_1 | LOG: database system is ready to accept connections redis_1 | `-._ `-.__.-\u0026#39; _.-\u0026#39; redis_1 | `-._ _.-\u0026#39; redis_1 | `-.__.-\u0026#39; redis_1 | redis_1 | 1:M 20 Jun 10:13:36.216 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. redis_1 | 1:M 20 Jun 10:13:36.216 # Server started, Redis version 3.2.1 redis_1 | 1:M 20 Jun 10:13:36.216 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. db_1 | LOG: autovacuum launcher started redis_1 | 1:M 20 Jun 10:13:36.216 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command \u0026#39;echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026#39; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. redis_1 | 1:M 20 Jun 10:13:36.216 * The server is now ready to accept connections on port 6379 vote_1 | * Running on http://0.0.0.0:80/ (Press CTRL+C to quit) vote_1 | * Restarting with stat result_1 | [nodemon] 1.9.2 result_1 | [nodemon] to restart at any time, enter `rs` result_1 | [nodemon] watching: *.* result_1 | [nodemon] starting `node --debug server.js` result_1 | Debugger listening on port 5858 vote_1 | * Debugger is active! vote_1 | * Debugger pin code: 139-254-286 worker_1 | Found redis at 172.19.0.2 result_1 | Mon, 20 Jun 2016 10:13:40 GMT body-parser deprecated bodyParser: use individual json/urlencoded middlewares at server.js:67:9 result_1 | Mon, 20 Jun 2016 10:13:40 GMT body-parser deprecated undefined extended: provide extended option at ../node_modules/body-parser/index.js:105:29 result_1 | App running on port 80 result_1 | Connected to db 打开浏览器测试 vote 应用。\n1 open http://192.168.99.114:5000 正常显示结果如下图所示： 打开浏览器测试 result 应用。\n1 open http://192.168.99.114:5001 正常显示结果如下图所示： 在 Rancher 的 hosts 界面中应该看到这些运行的容器。 至此所有关于应用构建和功能测试的过程完成，按 ctl + c 结束 docker-compose up 的运行。\n1 2 3 4 5 6 ^CGracefully stopping... (press Ctrl+C again to force) Stopping examplevotingapp_worker_1 ... done Stopping examplevotingapp_result_1 ... done Stopping examplevotingapp_vote_1 ... done Stopping examplevotingapp_db_1 ... done Stopping examplevotingapp_redis_1 ... done ","date":"2016-07-01T03:11:10Z","permalink":"https://martinliu.cn/2016/07/01/devops-in-a-box/","title":"DevOps 的起点-入手微型数据中心"},{"content":"Martin 解读 Serverless Serverless 不意味着没有服务器，而是从应用可以在一个抽象层上忽略它的存在，而只关注在功能实现上和自身的请求处理上；每一个功能实现在不是单纯的业务逻辑处理的代码，相反每个功能调用具有了 server 的特质，进化成为了一个具有自省、自知和自治的工作负载单元；他们更像是能够衍生出其它新功能单元的生物体。这样整个 Serverless 应用架构之内，每个生命可以衍生下去，子子孙孙无穷匮也。\n本文编译了：https://blog.docker.com/2016/06/building-serverless-apps-with-docker/ 一下是正文内容。\n处在这技术日新月异的时代里，新的技术浪潮经常对当前的技术产生着威胁和颠覆。在编写应用的时候我们目前经常谈论到“Serverless”技术。它的核心思想是把应用作为一系列的功能/function 来部署，这些功能在需要的时候被按需部署。服务器管理应该是不需要去操心的事情，所有功能被按需调用，被运行在群集之上。\n但是 Serverless 里不意味着没有 Docker，事实上 ”Docker 就是 Serverless”。你可以用 Docker 来容器化这些功能，然后按需地运行在 Swarm 群集上。Serverless 是一种构建分布式计算的应用的方法，而 Docker 是完美的构建和运行他们的平台。\n从 Server 到 Serverless 那么我们如何来编写 Serverless 的应用？让我们先看下这个例子：“一个有 5 个子服务组成的投票应用”：\n它的结构如下：\n两个 web 前端 一个后台的处理投票的 worker 服务 一个处理投票的消息队列 一个数据库 那个后台处理投票的进程是非常容易成为转换为 Serverless 架构的目标。在投票应用内，我们可以运行一点类似于下面的代码，来执行后台任务：\n1 2 3 4 5 6 import dockerrun client = dockerrun.from_env() client.run(\u0026#34;bfirsh/serverless-record-vote-task\u0026#34;, [voter_id, vote], detach=True) Worker 和消息队列能用按需在 Swarm 上运行的容器来替换，并自动地按需扩容。\n我们甚至可以消除掉 web 前端。我们可以这么做：用 Docker 容器来相应每一个 HTTP 请求，每个 HTTP 请求都用一个自生长的跑着轻量 HTTP 服务器的容器来处理。之前使用的是长时间持续运行的 HTTP 服务器，现在变成了具有 HTTP 相应和处理能力的按需跑起来的容器，而且他们能自动地扩容来支持所有访问请求。\n我们新的架构大概如下图所示：\n其中红色的方块是需持续长期运行的服务，而绿色方块成了按需被调用的 Docker 容器。这样这个应用变成了只有少数几个需要被管理的 long-running 服务，在相应请求的时候使用原生的 Swarm 扩容能力，处理能力的上限是 Swarm 群集的上限。\n具体如何实现 这里有三个有用的技巧，可以在你的程序中使用：\n把你代码中的 function 作为按需拉起的 Docker 容器 使用 Swarm 在群集上运行这些容器 从容器里面运行这些功能容器，绕过了一个 Docker API socket 使用以上技术的组合，程序执行负载发生的可能性将和您如何架构你的应用相关。运行后台任务就是一个非常适合的例子，但是整个应用中的其它工作负载也是有可能的，例如：\n考虑到延迟，用启动一个容器来服务所有用户的 HTTP 请求可能是不现实的。可是你可以写一个内置的负载均衡逻辑，让它知道何时需要主动地自动扩容 Web 前端自身，通过在 Swarm 群集上运行更多 web 处理容器。 一个 MongoDB 容器可以在 Swarm 上成为一个具有自省能力的架构，它能自动地运行出正确数量的 shard 和 replica 容器。 接下来 我们已经得到了这些激进的新工具，用做构建应用的抽象层，我们隐约看到了如何深入下去的可能性。我们依然像长时间以来在一堆服务器上构建应用一样，而以后可以来利用 Swarm 能按需地在基础架构里的任何地方执行功能代码的能力。\n希望这些能够给您一些如何构建应用的新思路，但是我们还需要你们的帮助。我们已经有的是一些构建 Serverless 应用的基础功能，然而他们依然不是很完备，我们需要更好的工具、库、样例程序，文档等等。\n这个 Github 库有一些工具、库、代码和文章的链接。基于此，如果您想学习更多的话，请共享任何相关的链接，这样我们可以开始协作在一起。\n大家一起来搞，并祝 hacking 愉快！\n","date":"2016-06-22T16:22:51Z","permalink":"https://martinliu.cn/2016/06/22/building-serverless-apps-docker/","title":"用 Docker 构建 Serverless 应用"},{"content":"Closing General Session 的主题是 Moby Dock‘s Cool Hacks ； 从字面意思上看，这个主题的意思是“超萌码头酷黑客”的意思。我已经看到了关于最后一天开幕主题演讲的评论，说是“剑指商业”什么的；而我认为 Docker 从开始的第一天，无论它是否开源，它都是为了商业利益而已。话在说回到开源，Docker 只是完美的应用了开源软件这种实践而已；而且 docker 把开源这种模式应用的如此成功，并在商业上也如此让人眼红和侧目，这也算是开源软件商业化登峰造极的一种极端性个案。个人认为开源无疑是在软件行业中做出爆款技术当之无愧的首选的实践方式。我在红帽碰到很多参与开源十几二十年的老黑客，他们不乏会表达关于开源纯洁性沦丧的抱怨；我对此也非常理解和认同。而我更认同开源可以对软件技术带来无比活力的这个积极的方面。\n言归正传，小编我还是“模拟现场”播报一下大会闭幕主题演讲的盛况。这是大会的结束的 session，现场的人数明显的少于第一天开幕式的人。在十几分钟内，人们稀稀拉拉的进入了会场。会场中的座位大约还有一部分空位。美女 Mano 和 黑客 Kristie 作为主要演讲人上台。美女上台后先用手机自拍了几下。两个人开始宣布，Docker 大会之后举行为期一个月的黑客大赛，这是我们的传统，Docker 大会虽然今天会结束，而 docer 黑客大赛将从今天开始。我们来请大家欣赏三个非常酷的黑客项目演示。\n本次大会的录音点这里 http://www.ximalaya.com/32280565/sound/17388272\n黑客演示 1：微服务自毁平台 Jeff 登场。Jeff 开始讲述微服务的故事，我们都在试图让基础架构做到冗余，容所有的服务都冗余，让群集能够自愈；但是故障，断网，宕机还是会发生。我们所做的这些真的能够保证业务不宕机么，服务不终端么？你怎么能确认这一点？因此回归到故障的发生上吧？如果服务要出故障，请让它有规律的发生。请程序猿和 ops 都投入到故障处理的战斗中，以此为契机来优化和改造应用，让应用变的更加强壮。我们都听说过混乱猴子，而 Jeff 团队正式帮人们构建一堆这样的工具的人。\n有一个思路是：如何让我的系统的服务出故障，如何主动的在系统中注入故障。我们需要一种特殊的编排工具来在系统中模拟和触发故障的发生。我用容器做工具平台来触发故障注入的动作。当然这个故障是在容器架构的微服务系统中触发这个动作。\nJeff 开始做这个 Demo。说：如果你的”网络没有故障，天下太平。“其实这很无聊的说，有木有？有木有？我现在开始用工具来注入 网络延迟的网络故障吧！ 。用一个基于策略的工具。配置一个网络故障模拟的策略，故障什么时间发生，发生多久。这里设计一个每 10 秒钟注入一次网络延迟故障提高到 600ms 的故障。然后配置故障影响的范围，这里使用 Docker 的 lable 来做故障发生节点的选择的条件。符合标签的系统将受到这次故障影响。我们的这个故障模拟编排系统，帮您提前体验故障的发生。现在你看故障发生了，从这些容器里面 ping google 的网络延迟比之前大多了， 目前延迟到了 600ms。希望你们能开始体验和使用这个而工具。\n黑客演示 2：Serverless 架构的应用不是梦 Ben 是大家在 Docker 大会喜闻乐见的一个黑客，他经常给做 demo 和 session。他绝对符合超萌的标准。\nBen 开讲，Serverless 是如何做的？ben 认为 Serverless 是一种全新的应用编程的思路，而 docer 可以很好的支持这种思路，并实现和执行这种思路。docer 群集可以让 Serverless 引用按需执行，并让该应用的底层变得资源冗余并路由可达。ben 开始演示 他的几张 slides， 说 Sererless == docker 这个概念。本开始讲解：如何用 Serverless 架构来实现投票应用的改造。如何把这个 5 个服务模块的纯粹容器微服务系统转换为 serverless 架构的应用。开始修改源代码，把发入队列的票，变成一个处理投票的容，把 http 服务器变成一个 CGIHander（）服务；但是 nodejs 不支持 CGIhander，肿么办？我用 perl 重写了这部分，为毛用 perl，被忘了它乃是古董级的黑客神器的好不好，呵呵！改造完之后的系统架构如下。架构是把处理 postgresql 意外的模块都重写了。数据库保留在最下层。这种 Serverless 重构实践遵从的原则如下。\n三个原则翻译一下：\n把每个模块的核心功能打包，并作为容器来运行。解读：这意味着把所有服务模块组重构，把每个服务模块中的核心功能代码作为一个在容器里面跑的对象。这里其实牵扯到很深的业务重构和应用重构，程序猿或将抛弃以前的代码，甚至以前所习惯使用的程序开发堆栈。\n把这些容器用 Docker 的 Swarm 跑起来。解读：docker 原生的 Swarm 编排能力将为您的应用提供，功能的运行，workload 的分布，服务的冗余，服务的路由等等支持；这样的架构能支持到 Serverless 的应用的模型。\n从容器中去运行其它容器。解读：容器编排平台或将不是容器生命起源的唯一起点，容器里面的应用可能可以决定系统中需要滋生出什么样的容器，当然说的是需要实现和运行什么功能的容器。\n好了，目前为止，ben 的心的应用重构完成，还是用 docker-compose up 启动了改造之后的应用。现在看到了这个 serverless 的应用工作正常。\nBen 说：我们在这 demo 了 serverless 应用的改造的过程，可以看到 docker 是如何支持这种应用架构的。你可以打包 web front 为服务，它自动的在 Swarm 群集上无限延展这个服务。成为分布式计算的架构。还可以打包微服务的其它应用模块为 Serverless 应用架构。欢迎大家 参与到我的 Serverless github 项目中，和我一起互动，把 Serverless 在 docker 上的应用搞起来。https://github.com/bfirsh/serverless-docker 这里包括了以上演示的应用。\n黑客演示 3：在线更新的无人机 这个团队做 in the air update 无人机实时演示。无人机其实是树莓派加他们的 docker 软件系统。这是一个嵌入式系统的设计。\n实时新旧系统的切换秘密在这里。新版的容器会先运行起来，新系统用一个队列来接收旧系统的数据，这些数据是新旧系统交接的必要的数据，系统会判断需要多长时间，需要收集那些数据来完成这个交接的过程。直到旧系统到新系统的割接完毕。\n程序猿开始更新 v1 的代码，加入了摄像头实时视频功能。更新提交了 v2 的镜像文件。在下图可以实时的监视到无人机的状态。\n无人机在在线更新软件中。并没有掉地上哈哈哈！\n右下角是新版本软件的摄像头把大会现场的视频拍摄，并实时传递到控制台的效果。此图上面的那个图，中间凸起震荡的那个块是无人机软件升级实时更新的过程。\n本黑科技演示完毕。\nhackathon 黑客大赛启动 主此人再次上台启动了黑客大赛。\n为期一个月的 hackathon 正式开始。\n最后看点 CEO CTO 上台感谢赞助商。所罗门开始讲黑客骚扰现象。号召大家通过 http://hackharassment.com 网站来抵制中现象。\nBump UP 是通过手环实现的，人们的手环彼此碰撞会在系统中增加一个点数。宣布了碰撞点数最多的前 5 名，感谢他们在本次大会中，积极的和其它人互动和沟通，请他们去领奖。所罗门号召所有现场的人再次相互碰撞手环，系统系统的点数增加到两百万。来解锁 Docker 奖学金基金。很快大家碰撞起来。奖学金解锁。\n感谢进三千名的社区 贡献者，感谢 docker 的员工。所有人发来的自拍形成了一个西雅图拼图。最后大会圆满结束。\n看到最后的才能做最后的评论。这更感觉是一个黑客大会，引入了 docker 对社会的责任感的概念。商业财富越大的人社会责任感应该更多。更像是黑客公司商业成功之后，继续创新，并开始践行自己的社会责任的大会。大会并没有结束，黑客大赛在接下来的一个月里将在全球各地延续。\n","date":"2016-06-22T02:35:39Z","permalink":"https://martinliu.cn/2016/06/22/closing-general-session-moby-docks-cool-hacks/","title":"DockerCon 2016 D2 超萌码头酷黑客 大会圆满闭幕"},{"content":"看点：开场乌龟引起了喵星人大战，首次有吉祥物开启的科技盛会。 和往常一样 CEO 和 CTO 挑大梁将首日 keynote。 所罗门提出了 Docker 技术发展的三个核心方向和着眼点，并在每个方向上做了新技术发布。 1. 开发者体验提升， 正式发布 Docker for Mac/Windws 2. 编排能力的提升，正式发布 Docker 1.12 ，其中有四项能力提升；这是要废掉所有其他编排器的节奏啊~ 3. 运维体验提升，正式发布 beta.docker.com ；这是和公有云深度结合的产品，分为 AWS 和 Azure 两个模块。 一共有三个实景演示，都没有出现问题，演示很成功。\n现场录音 点上面的播放键，播放整场录音。请注意中间的数秒钟乃至数十秒的中断是正常，请快进收听。\n开场 屏幕上出现了乌龟开始做 demo，运行了一个容器。 猫咪大战，混乱了，猫星人入侵了。猫叫~~乱作一团··· 发生了什么？ dockercon16 吹起了号角。 乌龟再次出现在电脑上，运行了另外一个容器惊喜，这次是美妙的音乐。 调皮的乌龟折腾完了之后，主题曲想起来。4000 多人的场子，大家很期待。\nCEO Ben Golub 演讲 Ben Golub CEO 出场。 Today we are all docker blue. 欢迎所有人。 我们和前两年的不同，我们发布了 1.0 等等。 谈了很多 Docker 取得的成就。 感谢和表扬了社区。 感谢 2900+贡献者。 社区的状态动态，每周超过 300 PR，三分之二来自 Docker 公司之外。 docker meetup 的状况， 250+城市举行，125K 人参加聚会。 内容构建方面，docker hub 上有 460K 个应用，到目前为止有 4.1B 此镜像下载。 感谢 docker 的生态社区。 讲述了这两年的使用场景的变化。Docker 逐渐成为了企业级的应用。 所有穿着红色衣服的起立，他们是 Dockr 公司的员工，感谢他们，请鼓掌。 感谢今年的赞助商。 向 Demo Gods 致敬，给神献上祭品，保证后续的演示顺利。 we pray to the old codes and the new.\nCTO 所罗门演讲 所罗门出场。 我去，4000 多人在场，我老爸也在家看我视频直播。 很荣欣大家来参加，感谢大家来参会。 谁参加过 DockerCon14？ 我们要开始做很多的 demo 在会议过程中。 最精彩的部分是，我们来自全球各个行业的不同层面，多样性简直是不可思议。原因是：Programming is changing the world. 我们在一起的原因是：Docker 是编程创新的助力工具。 We’re building Docker incrementally, in the open. 最好的工具目前看不是那些软件工具巨人的公司提供的，而是来自社区和群众的创新，是你们指引着我们构建了愈来愈多的工具。 社区告诉我们几个方面需要努力。\n1 开发者体验 构建最好的工具，这个工具需要有这些特质：\nget out of the way;\nadopt to you；\nmake the powerful simple\n我们努力地践行着这些理念。 Docker for Mac/Windows 将是最无缝的开发者体验。 Making things easy is really hard. 我们在寻找最佳的系统工程师，我们收购了 Unikernel 公司。 在移动游戏行业里面找到最佳的设计者。\n第一个演示 – Docker for Mac 演示者登台。 我是个开发者，今天第一天上班。 安装了 Docker for Mac 打开这个应用，启动它。 克隆\n1 git clone viting-app 运行\n1 docker-compose up 打开投票应用的两个 web 界面。 我不知道这个应用是什么，但是一个命令就启动了所有 5 个服务。 我发现了程序的 bug。 是否我第一天上班就能修复它？ 分析了一下程序架构图。 查看 docker-compose.yml 文件。 找到了一个 debug 显示的的那一行。 在代码中加入了 live debug 的断点。 开始 review 代码，发现了奇怪的地方。 找到了 git 上的代码，增加了评论，提出源码结果计算方法有问题。 现在删除了有问题的哪一行代码。 删除了断点。 用 live debug 的方式修复代码。 回到程序界面，发现 bug 没了。 做 git commit 提交修正后的代码。 查看了该应用在 staging 环境的情况，发现也有相同的结果计算的问题。 进入该环境的 Docker Cloud 界面，看到了这个运行环境。 查看 result 服务的构建策略是自动构建。 Docker Cloud 自动接收了新的代码，Staging 环境的构建完成并通过了测试脚本，程序正常了。 查看云里的 Staging 环境的 bug 也被除掉了。demo 结束。\nSplice 的 CTO Matt 案例分享 Splice 的 CTO Matt；我们做的是个音乐服务的技术，我们构建的服务像是给音乐人用的 github。 每天都有人上传上很多 TB 的音乐数据。 我们在 Mac 上开发，在 Linux 上部署。 我们使用多种数据存储。 Docker 让我们保持多种环境的一致，降低了 debug 的时间。 所有的程序运行在容器中。 我们一天更新线上的业务 20 多次。 Developer 的第一天工作就能为业务提供价值。 我们使用 Docker for Mac。\n2 Orchestration 编排能力 我们听到很多 happy user 的故事。 感谢所有 7 万多 Docker for Mac beta 的反馈参与者。 我宣布 Docker for Mac/Widnwos beta 完全开放下载。 很多人告诉我们需要在 Orchestration 上更加努力。 它在 ship 方面提供支持，能发布你整个的应用，让你不再关心单个的容器。 Orchestration 是个技术活，只有专家才能干。很少人能做这个工作。 可是用户怎么能即不出现手头人才短缺，又不被某些厂商在这方面给技术锁定呢？ 更好的方法是什么？ Docker 1.12 将内置编排功能。 最佳的编排技术将是 Docker 自己。\n我们先提前介绍一些它的新功能。\nSwarm mode Cryptographic node identity Docker Service API Build-in Routing Mesh 非常简单的演示，你就明白了。 欢迎第三个 编排的演示 Docker 1.12 技术。\n第二个演示 – docker swarm 功能演示 两个人上场。 用一个新的机器，上面只安装了 docker。 有三个节点。 第一个节点上初始化群集 docker swarm init 第二个节点上加入群集 docker swarm join 在第三个节点上加入群集 docker swarm join 三节点的群集建立完成。\n为毛它没有让输入任何安全的信息和选项，这就对了，我们有内置的 PKI 安全通讯机制。 所有节点都有自己的身份标识。密钥定期自动变化。所有通讯都可以追述到发起者的身份。\n你们都懂 docker run 子命令。 docker service 命令是新来的子命令。 service 的定义是将要维持服务的状态。\n1 2 docker service create --name voting-app -p 5000 docker service ls 所有的服务只启动了一个容器，分布在三个节点上。\n看到投票应用页面显示了。\n浏览器访问了第一个节点的 ip:5000 ，然后第二个节点的 ip:5000 端口，发现实际上访问到了第一个节点上的的容器。这就是新的容器路由的功能。所有的节点访问这个服务的端口，都可以路由到该服务的容器里。\n1 docker service scale 6 现在扩容服务的容器。 每次刷新页面，页面上容器的 ID 都在变，这是群集内置的 round robin 负载均衡策略，把访问分发到所有容器。这就是内置的负载均衡功能。\n我们升级这个 app 吧。\n1 docker service update 演示容器镜像文件的更新 选择另外一个 tag 的镜像来升级 现在我们可以对电影投票了\n滚动升级可以支持 加上一次升级 2 个容器的升级选项，因此它现在是做两个一次的服务容器升级，直到所有容器都升级结束。\n我们说的自愈功能是说，能让应用可以在机器宕机的时候，业务也不中断。 请把有两个容器的 node3 关机。 调度器现在自动在 node2 上长出刚才运行在 node3 上的那两个容器。保持 6 个容器的服务配置。\n演示成功，并没有出问题。\nZenly 的创始人案例分享 所罗门高兴的再次上台。 这说明我们的祭品生效了，演示没有出毛问题。 docker 1.12 在几周后就发布，Docker for Mac beta 版本上现在就有这些功能。你们这些已经安装的现在就可以尝试这些功能。 我们自由的扩容业务应用，而服务速度不受到影响。 在大规模的关键业务中的部署才是目标。我们请 Zenly 的兄弟们上台。\nZenly 的人喝了两杯祭品的冰咖啡上台了。 我们有 1M 用户，是最近的三个月内获得的。 500M events/day 一共才 6 engineers 我们运行业务在云上。 我们现在把部分业务迁移回自己的物理机。 我们在 10 台物理机上运行部分业务。 部分运行在 GCE 上。 我们感觉按需扩容很爽。\n3 运维体验 我们谈到开发者体验，业务编排。 群众还告诉我们“Ops experience” 运维体验是需要关注第三个侧面。 Docker 应该深度和云基础架构集成。\nbeta.docker.com 发布 我宣布 beta.docker.com 发布。包括 docker for aws 和 docker for Azure 是最原生的 AWS 和 Azure 体验。是和云基础架构最深的集成。 现在可以用 AWS CloudFormation 来部署 Swarm 群集。 可以自动配置所有的负载均衡端口等配置。\nwww.docker.com/dab 发布 www.docker.com/dab 是新的可移植多容器应用打包格式。 这是新的 ops 体验。是让 developer 和 Ops 更容易工作在一起的方案。\n第三个演示 – 云运维体验 Developer：我想赶紧回家。我还需要赶紧交货。\n1 docker compose bundle 产生了一个.dab 文件，齐活了。 把应用的 .dab 文件给 Ops 即可。 Ops：你的应用是 docker 的么？ 额的个神啊！ 我喜欢在 AWS 上用 Docker。 看我新建 Stack 的 AWS 向导，这里可以配置了一个新的 docker swarm 群集。 看我这有一个已经部署了 100 节点的群集。 所有网络、存储、负载均衡都不用手动配置。 复制 这个网址。 在 Mac 电脑的 shell 粘贴 ，后点击回车。 我们进入了命令行 docker for aws 的特殊的 shell 我能看的所有群集和主机的状态 把你的 .dab 文件给我，就欧了~ 用 USB copy 给你。 把文件 copy 给了 Ops scp .dab 文件到 swarm 群集中。 在进入 shell ls 能看的这个文件\n1 docker deploy voting-app xxx.dab 看这些所有服务都运行了\n1 2 3 4 docker service ls docker service update -p 80:80 voting-app docker service update -p 8080:8080 result-app docker service scale 扩容这些服务的容器数量 打开浏览器确认应用部署结果，找到 ELB 的配置，配置已经自动生成了。 浏览器中访问 ELB 的 80 端口上看的投票页面 在 ELB 的 8080 端口看的结果页面 这下应用部署完毕。 原来你的 Ops 工作怎么这么简单啊！！ I got go home ~~~\n结束 所罗门感谢大家，所请访问 docker.com/getdocker 有需要的尽管说。 请在这几天内，尽量多的告诉我们，你们的需求和使用场景。 请告诉我们 what we build next ! thank you very much ！！\n注意 我是 Maritn Liu 为您播报本次大会的各种信息，对以上内容有任何问题和疑问请加我微信咨询，我的微信号是 martinliu_cn ，这篇文章也会在我的微信公众号（aws-faq）和 ”刀客微播报“上发布。以上会议记录中所有命令的操作并不是准确的演示者输入，尽量参考这些命令来想想其可能的参数和语法，如果你安装了最新版本的 Docker for Mac 可以自己试一下。\n","date":"2016-06-20T19:30:33Z","permalink":"https://martinliu.cn/2016/06/20/dockercon-2016-d1-keynote/","title":"DockerCon 2016 D1 Keynote"},{"content":"Amadeus uses next-generation containerized application platform with OpenShift from Martin on Vimeo.\n以上视频来源于：https://blog.openshift.com/openshift-3-amadeus-red-hat-summit-session-recording-recap/\n","date":"2016-01-12T04:05:46Z","image":"https://martinliu.cn/images/abstract-8.jpg","permalink":"https://martinliu.cn/2016/01/12/e4b88be4b880e4bba3e5ba94e794a8e4b8bae4b8ade5bf83e79a84e5b9b3e58fb0-openshift/","title":"下一代应用为中心的平台 OpenShift"},{"content":"新建库 建立一个用户名开头的库，如我的 github 用户名是 martinliu， 新建的库的名字为 martinliu.github.io ; 这个库将是存放 web 页面的。包括该域名下的站点的所有相关页码代码文件和相关 css,图片等文件。\n更新并上传新库 参考的命令如下：\n[bash] git clone https://github.com/martinliu/martinliu.github.io cd martinliu.github.io echo \u0026ldquo;Martin Liu\u0026rsquo;s Github Homepage\u0026rdquo; \u0026gt; index.html git add \u0026ndash;all git commit -m \u0026ldquo;Initial commit\u0026rdquo; git push -u origin master [/bash]\n打开浏览器测试你的网站，访问网址： http://martinliu.github.io ， 你已经可以看到你的初始化页码了。\nJekyll 博客系统 Github 网站上推荐使用 Jekyll 创建和管理这个博客系统。它是支持 Markdown 语法，不需要使用数据库，纯文本的静态网站和博客系统。使用它可以建立和管理一个风格美观，容易管理的网站，生成的网页可以上传到以上生成的网站库中。\n安装 Jekyll 系统 我的测试系统：Fedora 23。操作步骤如下。 安装依赖的包和 ruby 环境\n[bash] dnf install ruby ruby-devel gem gcc libffi redhat-rpm-config [/bash]\n更用国内的 rubygem 源 [bash] gem source -r https://rubygems.org/ gem source -a http://mirrors.aliyun.com/rubygems/ gem update \u0026ndash;system\ngem install jekyll [/bash]\n##本地测试 jekyll 站点 进入克隆到本地的库，并创建 jekyll 站点。\n[bash] cd martinliu.github.io rm index.html\njekyll new . New jekyll site installed in /root/martinliu.github.io. [root@demo-w540 martinliu.github.io]# ls about.md css _includes _layouts _sass _config.yml feed.xml index.html _posts [root@demo-w540 martinliu.github.io]# jekyll server Configuration file: /root/martinliu.github.io/_config.yml Source: /root/martinliu.github.io Destination: /root/martinliu.github.io/_site Incremental build: disabled. Enable with \u0026ndash;incremental Generating\u0026hellip; done in 0.205 seconds. Auto-regeneration: enabled for \u0026lsquo;/root/martinliu.github.io\u0026rsquo; Configuration file: /root/martinliu.github.io/_config.yml Server address: http://127.0.0.1:4000/ Server running\u0026hellip; press ctrl-c to stop. [/bash]\n编辑站点的相关文件，测试成功之后，在上传到 github 上，然可到 maritnliu.github.io 上检查和本地的显示效果是否相同。\n","date":"2016-01-10T01:01:25Z","image":"https://martinliu.cn/images/abstract-6.jpg","permalink":"https://martinliu.cn/2016/01/10/e794a8-jekyll-github-e5bbbae7ab8be99d99e68081e7ab99e782b9/","title":"用 Jekyll + Github 建立静态站点"},{"content":"Source code on github https://github.com/martinliu/ArduinoProjects\nProject 2 SOS led S.O.S LED device from Martin on Vimeo.\nProject 2 blink led Arduino Project 1 blink LED from Martin on Vimeo.\n","date":"2016-01-04T16:00:59Z","image":"https://martinliu.cn/images/abstract-10.jpg","permalink":"https://martinliu.cn/2016/01/04/my-arduino-project-status/","title":"My Arduino Project status"},{"content":"vimeo 的特别域名没想到还给我留着的 http://vimeo.com/martinliu 从国内访问和上传视频是有问题的，需要用 vpn 才能正常访问，vimeo 能共享到 Wordpress 上的 video 是没有视频的，播放的时候稍微有点卡；就算是稍微卡一点，也比 youku 视频前后的广告好，以后计划转战 vimeo 发布视频了。\n","date":"2016-01-01T14:21:11Z","image":"https://martinliu.cn/images/abstract-12.jpg","permalink":"https://martinliu.cn/2016/01/01/vimeo-video-sharing-vs-youku-com/","title":"vimeo video sharing vs youku.com"},{"content":"IoT 有公众的立场，也有厂商的算盘。微软的动作是比较快得，2015 年春季就发布了 IoT 战略，其他厂商 IBM，Amazon 等等也都有各自的布局。在硬件厂商这一次侧，Raspberry 则占据了比较显眼的位置；确实也吸引了比较多的眼球。它从 2013 年起一气出了很多型号的板子。回忆起来，当时除了记得 SoC 技术是价格非常便宜的，并没有太多关注这种硬件相关的东西。直到昨天我入手 Raspberry 2 model B 后，大致玩了一下，我隐约的感觉，今天谈到的 IoT 和以往确实不同了；这或许是” 范在型智能可互联网 “ 时代的到来，智能和 wifi 的植入是 maker 们欲罢不能的一件事情，在商业上是必要的卖点和噱头，是用户现实的和潜在的需求；可联网和可连接互联网，绝对是两个层面上的概念；封闭的信息孤岛式的网络已经无法通过自身实现其信息的价值，信息价值的实现必须通过与互联网的链接和互动来实现。联网意味着链接互联网，在哪里信息的融合和分析再反馈回到真实世界中，并完成某种动作，在这个闭环中，真实世界被投射到虚拟世界中去，然后再得到一个预期的反馈，计算机信息处理和控制在过程中起到了推动作用，真实世界中的人或者物对它的一个反馈使之所有抽象而似乎无形的信息技术和互联网实现了存在的价值；这是一种虚拟现实世界和人类主动且有意识地互动。\n扯远了，在某东购买的树莓板是这个这样的，如下图：\n它链接外部世界的方式就是通过板子上面的三个接口，下侧比较明显的排针，中上侧白色竖着的，和中右侧的两个白色排线插头。这些主要是链接传感器用的。另外还包括板载的 4 个 USB 口，USB 口也可以接外设和 Wifi 模块。当然还有网线插口。\n这是 Raspberry 的 2 代 B 型版，它的特点是计算处理能力是比较强劲的。感觉做控制中心比较合适，如智能家庭的总控制中心。它还可以和 Arduino 组合起来，Arduino 的处理能力较低，可以通过它作为外部传感器的 hub，单纯的做信息收集，和动作指令的执行（发出继电器开关的开合信号等）。就某种单一具体的 IoT 功能的实现，Raspberry 和 Arduino 没有太大的差异。但是在构建复杂系统的时候，把两者结合起来的设计还是多见的。接下来，我可能会去把 Amazon 上的那个 Arduino 开发套装买回来，这样就配齐了，当然 Raspberry A 型板也可以入。\n如果你把所有的东西都连接到互联网了，那么安全性怎么保证？今天在http://www.wired.com 网站上看到的头条就是《How IoT got hacked 》看完后，不得不倒吸一口凉气。不过安全总是在任何时间点、场合拿出来，可以吓死人的东西。不 hack 出一些值得被人黑的东西来，那你还能做出什么更有意义的事情呢。以上就是本次树莓派入手记录贴。\n","date":"2015-12-29T04:06:28Z","image":"https://martinliu.cn/images/abstract-3.jpg","permalink":"https://martinliu.cn/2015/12/29/iot-e698afe6808ee4b988e8a2abe9bb91e79a84/","title":"IoT 是怎么被黑的？"},{"content":"建议所有管理者都可以反思一下：是否需要 supper chicken 团队。先看下这个视频。 http://video-subtitle.tedcdn.com/talk/podcast/2015W/None/MargaretHeffernan_2015W-480p-zh-tw.mp4\nAbout the book In this wise and witty guide to creating strong company culture, business leader Margaret Heffernan lays the groundwork for a new kind of thinking: Organizations can create seismic shifts by making deceptively small changes.\nFar beyond a prescriptive list, this book spills over with fascinating anecdotes from organizations around the world. Heffernan reveals the surprisingly small changes any organization can make: how to empower every person as a leader: how to open channels as a real, active listening; the important of cutting back hours (and also leaning into crunch time); why leaving the office does wonders for your working brain; how conflict works as an essential tool for creative thinking; why companies that actively solicit involvement beyond their walls are so much more effective; how simple activities strengthen social capital between workers.\nPacked with compelling stories and startling statistics, Heffernan takes readers on a tour across the globe. Drawing from her years of experience as a business leader and ultimately proving that it\u0026rsquo;s often the small changes that make the greatest, most lasting impact.\nThis book is aimed at everyone — from the CEO to the janitor — who wants a better place to work. It looks at the accumulation of small, everyday thoughts and habits that generate and sustain culture: ways of speaking, listening, arguing, thinking, seeing. These aren’t multimillion dollar, multi-year programs; these are small steps that anyone can take at any time, the small steps that mark the beginning of big change.\nPress and reviews Read a Q\u0026amp;A with Margaret on Huffington Post: \u0026ldquo;America\u0026rsquo;s Competition Fetish Kills Creativity and Produces Human Sheep\u0026rdquo;\nAn illustrated excerpt from Beyond Measure on MEDIUM: \u0026ldquo;Small Steps to Huge Change\u0026rdquo;\nRead what TIME has to say about Beyond Measure: \u0026ldquo;The Real Way to Fix Finance Once and for All\u0026rdquo;\nA great synopsis of Beyond Measure in Tech Cocktail: \u0026ldquo;What Makes Some Teams Better than Others\u0026rdquo;\nRead a wonderful review in The Globe and Mail: \u0026ldquo;Corporate culture the \u0026lsquo;secret sauce\u0026rsquo; of success\u0026rdquo;\nAbout the author Margaret Heffernan is an entrepreneur, chief executive, and author. She was born in Texas, raised in Holland, and educated at Cambridge University. She worked for the BBC producing television and radio programs and also developed interactive multimedia products with Peter Lynch, Tom Peters, Standard \u0026amp; Poors, and The Learning Company. She has served as Chief Executive Officer for InfoMation Corporation, ZineZone Corporation, and iCAST Corporation. Her book, Willful Blindness, was named one of the best business books of the decade by the Financial Times, and her most recent book, A Bigger Prize won the Transmission Prize in 2015. She blogs for the Huffington Post and Inc.com.\n","date":"2015-10-12T06:33:12Z","permalink":"https://martinliu.cn/2015/10/12/e8b685e4babae7bb84e68890e79a84e59ba2e9989fe8bf98e698afe8b685e7baa7e59ba2e9989f/","title":"超人组成的团队还是超级团队"},{"content":"今天看到这条让人哀伤的新闻，真是感觉很难过。我是一个多年的 Wordpress 用户，本博客也是 wordpress 些的，而且记录多年的文章。wordpress 是一个能让人很着迷的程序。它是一个GPLv2的开源软件。对我来说有一件事情是始终在于之斗争的，这就是“测试/更换 wordpress 的 Theme 和插件”；不夸张的说，当一个不需要编写一丁点 css/php 代码的人也能够完美地控制一个网站的功能和外表的时候，你会觉得渐渐的忽视了这个网站软件本身，你会被一下子陷入到，那浩如烟海的与之共生的生态系统所开发的免费资源中。wordpress 具备了开源软件的一个核心特质“提供开放的平台，让周边的开发者和设计师能通过扩展开发来够推动它的用户社区的发展和繁荣”。 以 wordpress 为核心的周边生态系统有：功能插件、theme 设计、SOE 咨询、网店功能等等；以上这些养活了互联网上无数的个体或者公司；给无数的网站设计爱好者提供了创造和互动的机会。虽然，我最近对 blog 软件的注意力渐渐地转向了 ghost，但是本站必将持续使用 wordpress，会继续一如既往地关注它可能会给用户带来的惊喜，长期使用和关注一个开源软件的体验是无法替代的，是欲罢不能的。仅此献给 Alex King，希望他的灵魂能升入天堂，一路走好。\nAlex King 是 wordpress 的创始人之一，他的个人 blog 停止于 2015-8-24 日的一篇自己关于他的病情的文章，到目前为止有 142 个回复。http://alexking.org/about 这个页面是他的自述页面。\n","date":"2015-09-30T12:45:29Z","permalink":"https://martinliu.cn/2015/09/30/wordpress-e5889be5a78be4babae88bb1e5b9b4e697a9e9809d-e7bb93e882a0e7998c/","title":"Wordpress 创始人英年早逝-结肠癌"},{"content":"话说本站也经历过很多变迁，使用的系统主要经历如下：google 的 blogspot （正式开始写 blog 的第一篇子在那，后来被墙）\u0026ndash;\u0026gt; 某共享 wordpress 平台（免费，名字已经几乎忘记了）\u0026ndash;\u0026gt; 免费国外 VPS 主机 wordpress (主机的 ip 很不靠谱，经常被墙) \u0026ndash;\u0026gt; 国外付费 VPS wordpress + 国内 CDN，现在这样一直快三四年了。\nWordpress 用了这么多年下来，真是觉得什么都可以做了，其中有一段时间也捣鼓过一阵子 Drupal，但是还是觉得不如 wordpress 好使，它的功能非常成熟；themes 和 plugin 的生态系统非常成熟；价格在 30 ～ 50$的 themes 我也是买过几个了；可是最后还是维持在了当前这个 free theme 。\nGhost 给我的感觉就是简洁、干净和快速。http://hidocker.io 打建的过程中更是让我彻底的感觉到它的这些特点。它依赖的 nodejs 和 ngnix 两个包都只有几 MB 大小，它的安装包也很小。因此安装和配置也非常的简单，数量了 10 分钟之内就完成安装配置。使用了 ghost 两天之后，客观地讲它还是比较初级阶段，很多扩展和的定义都必须修改代码，这可能就会把恐惧修改代码的大批人拒之门外；甚至于安装新的 theme 这样的工作也是在 linux 的 shell 里面完成的。\n之后我会发布一篇详细的安装文档到 http://www.aws-faq.com/ 上，点这里 http://www.aws-faq.com/aws-ec2/ghost-%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE.html\n","date":"2015-09-27T15:03:12Z","permalink":"https://martinliu.cn/2015/09/27/ghost-e58d9ae5aea2/","title":"Ghost 博客"},{"content":"环境准备 本文使用笔记本电脑+KVM 虚拟化进行以下的测试过程，当然也可以用其它的操作系统加虚拟化软件的组合，测试机需要满足以下的条件： 测试虚拟机的建议配置 1C/2GB/10GB 虚拟机使用的网络需要能连接到互联网 虚拟机需要能加载光盘 iso 文件 可以执行起停虚拟机操作，能通过控制它登陆来做初始化配置\n本文测试机是 Lenovo T440s 笔记本电脑，安装的操作系统是 Fedora 22，使用 KVM 虚拟化，用 Virt-Manager 做 GUI 图形管理工具。建立了一个 NAT 的静态虚拟网络，虚拟机可以使用该网络来从互联网下载需要的文件包。\n下载 Fedora Atomic Host 虚拟机文件；下载页面： http://www.projectatomic.io/download/ 点击绿色的下载按钮。下载 qcow2 格式的 Atomic Host 虚拟机文件。复制下载的文件到虚拟机运行的存储目录中，文件名可以是 master.qcow2，新测试虚拟机会基于它创建。\n在通过这个虚拟机模版文件生成测试机前，需要准备一个 init.iso 的文件，用来初始化测试机的主机名和初始用户密码。\n[bash] [root@martin-fedora vm]# cat meta-data instance-id: master local-hostname: master.xenlab.com [root@martin-fedora vm]# cat user-data #cloud-config password: smartvm ssh_pwauth: True chpasswd: { expire: False } [root@martin-fedora vm]# genisoimage -output init.iso -volid cidata -joliet -rock user-data meta-data I: -input-charset not specified, using utf-8 (detected in locale settings) Total translation table size: 0 Total rockridge attributes bytes: 331 Total directory bytes: 0 Path table size(bytes): 10 Max brk space used 0 183 extents written (0 MB) [/bash]\n以上的两个配置文件 meta-data 和 user-data，最后使用 genisoimage 命令生成出文件 init.iso。至此，Atomic Host 测试机的运行镜像文件和初始化配置文件都准备好了。\n创建 Atomic host 测试虚拟机 使用虚拟化的管理工具基于准备好的镜像文件（master.qcow2）创建测新的试虚拟机。在首次启动前，还需要添加光驱设备，指定光驱设备在启动时加载上文中创建的 init.iso 配置参数文件。 首次在虚拟管理工具上启动新创建的 Atomic Host 测试虚拟机，查看整个的启动过程。由于本文的测试网络不是 DHCP 的，因此测试机在启动后，还需要登陆虚拟机控制台，使用默认账户，用户名：fedora 用户，fedora 的密码在前面的配置文件中已经指定。静态 IP 地址参考的配置文件如下：\n[bash] [fedora@master ~]$ cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=\u0026ldquo;eth0\u0026rdquo; BOOTPROTO=\u0026ldquo;static\u0026rdquo; ONBOOT=\u0026ldquo;yes\u0026rdquo; TYPE=\u0026ldquo;Ethernet\u0026rdquo; PERSISTENT_DHCLIENT=\u0026ldquo;yes\u0026rdquo; IPADDR=192.168.10.42 NETMASK=255.255.255.0 BROADCAST=192.168.10.255 NETWORK=192.168.10.0 GATEWAY=192.168.10.1\n[fedora@master ~]$ cat /etc/resolv.conf\nGenerated by NetworkManager search xenlab.com nameserver 192.168.10.1 nameserver 8.8.8.8 [fedora@master ~]$ [/bash]\n至此，Atomic Host 测试虚拟机初始化安装完毕。\nAtomic Host 基本操作 登陆 Atomic Host 测试虚拟机 master 之后首先需要测试是否能和互联网连接，ping 外部的网址，看是否能够正常解析。由于后面很多相关测试都需要从联网下载内容。 用 ssh 工具登陆之后，看下它： [bash] [fedora@master ~]$ cat /etc/redhat-release Fedora release 22 (Twenty Two) [fedora@master ~]$ uname -a Linux master.xenlab.com 4.0.4-301.fc22.x86_64 #1 SMP Thu May 21 13:10:33 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux [fedora@master ~]$ dnf bash: dnf: command not found [fedora@master ~]$ yum bash: yum: command not found [/bash]\n根据以上显示发现它貌似就是一个 Fedora 22 的服务器，不过默认没有 dnf, yum 包管理工具，不过有 rpm。查询一下这个系统上有什么默认安装的软件包：根据 rpm -qa 结果显示，Atomic Host 虚拟机默认安装了 324 个软件包。下面初步尝试一下 Atomic Host 操作系统更新和管理的主要命令 atomic / rpm-ostree\n[bash] [fedora@master ~]$ sudo atomic usage: atomic [-h] {host,info,install,run,uninstall,update} \u0026hellip;\nAtomic Management Tool\npositional arguments: {host,info,install,run,uninstall,update} commands host execute Atomic host commands info display label information about an image install execute container image install method run execute container image run method uninstall execute container image uninstall method update pull latest container image from repository\noptional arguments: -h, \u0026ndash;help show this help message and exit\nerror: too few arguments [fedora@master ~]$ sudo rpm-ostree Usage: rpm-ostree [OPTION\u0026hellip;] COMMAND\nBuiltin Commands: compose upgrade rebase rollback status db\nHelp Options: -h, \u0026ndash;help Show help options\nApplication Options: \u0026ndash;version Print version information and exit\nerror: No command specified\n[fedora@master ~]$ sudo atomic host status TIMESTAMP (UTC) VERSION ID OSNAME REFSPEC\n2015-05-21 19:01:46 22.17 06a63ecfcf fedora-atomic fedora-atomic:fedora-atomic/f22/x86_64/docker-host [fedora@master ~]$ sudo rpm-ostree status [fedora@master ~]$ sudo atomic host usage: atomic host [-h] {rollback,status,upgrade} \u0026hellip; positional arguments: {rollback,status,upgrade} host commands rollback switch to alternate tree at boot status list information about all deployments upgrade upgrade to the latest Atomic tree if one is available\noptional arguments: -h, \u0026ndash;help show this help message and exit\nerror: too few arguments [fedora@master ~]$ [/bash]\n下面使用 atomic host upgrade 来升级这个系统，使它运行在最新的补丁和版本下。这个过程需要下载 180+MB 的升级包，这个过程无法断点续传，但是可以任意中断。再次运行该命令后，可以重新从头下载，直到下载成功。下载成功并升级成功以后，重起操作系统。\n[bash] [fedora@master ~]$ sudo atomic host upgrade Updating from: fedora-atomic:fedora-atomic/f22/x86_64/docker-host\n0 metadata, 5051 content objects fetched; 183267 KiB transferred in 330 seconds Copying /etc changes: 25 modified, 0 removed, 41 added Transaction complete; bootconfig swap: yes deployment count change: 1 Changed: avahi-autoipd-0.6.31-31.fc22.x86_64 avahi-libs-0.6.31-31.fc22.x86_64 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. tcpdump-14:4.7.4-2.fc22.x86_64 tzdata-2015e-1.fc22.noarch udisks2-2.1.6-1.fc22.x86_64 Removed: docker-storage-setup-0.0.4-2.fc22.noarch pciutils-libs-3.3.0-1.fc22.x86_64 Added: docker-selinux-1.7.0-6.git74e7a7a.fc22.x86_64 iptables-services-1.4.21-14.fc22.x86_64 kubernetes-master-0.20.0-0.3.git835eded.fc22.x86_64 kubernetes-node-0.20.0-0.3.git835eded.fc22.x86_64 python-pip-6.0.8-1.fc22.noarch python-setuptools-17.1.1-3.fc22.noarch Upgrade prepared for next boot; run \u0026ldquo;systemctl reboot\u0026rdquo; to start a reboot [/bash]\n在 reboot 之后，这个系统就可以投入使用了。在启动的 GRUB 菜单上可以看到出现两个条目，默认进入最新的这个系统版本。\n[bash] [fedora@master ~]$ sudo atomic host status TIMESTAMP (UTC) VERSION ID OSNAME REFSPEC\n2015-07-15 23:33:20 22.61 db540a53ba fedora-atomic fedora-atomic:fedora-atomic/f22/x86_64/docker-host 2015-05-21 19:01:46 22.17 06a63ecfcf fedora-atomic fedora-atomic:fedora-atomic/f22/x86_64/docker-host [/bash] 进入系统之后，我们看到上面这个命令输出，目前 Atomic Host 的操作系统有了两个版本，该系统可以从最新的系统回退或者回滚到旧的版本。可以认为它同时具有多个可以前后切换的操作系统版本。\n在一个 Atomic Host 上有两种软件交付方式： rpm-ostree 管理部署和升级 host 系统自身的软件 Linux 容器（目前 Docker）提供很多容器来跑各种软件应用服务\n运行第一个 Docker 镜像 现在测试的是 Atomic Host 自身的管理工具，传统的 Linux 系统中，这个软件是用 rpm 包和系统服务的方式，被安装到被管理节点的，可是我们下面使用容器的技术来部署，也达到相同的管理功能。Cockpit 是之前介绍过的一款系统管理工具，兼具对 docker 的管理功能，它可以 Docker image 的形式被下载，并且运行在本机的一个专有权限（提权）的容器中。它可以作为 Atomic Host 的主机管理工具，对 Linix 系统管理不熟练的人可以使用这个图形工具，查看和监控系统的状态，并且可以管理容器中 Image。下面是安装和运行这个特殊功能容器的命令。\n[bash] [fedora@a1 etc]$ sudo atomic run cockpit/ws /usr/bin/docker run -d \u0026ndash;privileged \u0026ndash;pid=host -v /:/host cockpit/ws /container/atomic-run \u0026ndash;local-ssh efd3cbbad8452ff394e1d1a0c309870634207538597ba0cead26d790510e7a5e [/bash]\n上面这条命令执行完后，就可以在笔记本电脑的浏览器，输入网址，来访问这个工具，如： https://192.168.10.41:9090 登陆的用户名和密码是 Atomic Host 的 fedora 和它的密码。\nHW 实战篇 不错 HW 就是 Hello World！它太有名了，掠过对它的介绍。现在可以让 docker 命令出场了。在命令行中不加任何参数，看下它的默认输出。输出一下它的版本信息。\n[bash] [fedora@master ~]$ sudo docker version Client version: 1.7.0.fc22 Client API version: 1.19 Package Version (client): docker-1.7.0-6.git74e7a7a.fc22.x86_64 Go version (client): go1.4.2 Git commit (client): 74e7a7a/1.7.0 OS/Arch (client): linux/amd64 Server version: 1.7.0.fc22 Server API version: 1.19 Package Version (server): docker-1.7.0-6.git74e7a7a.fc22.x86_64 Go version (server): go1.4.2 Git commit (server): 74e7a7a/1.7.0 OS/Arch (server): linux/amd64 [/bash]\n下面的实战内容是和过程如下：\n下载 fedora image\n构建 httpd image\n构建 HW 主页\n构建并测试 HW 网站\n具体的命令执行过程如下：\n[bash] [fedora@master ~]$ sudo docker run -i -t fedora bash Unable to find image \u0026lsquo;fedora:latest\u0026rsquo; locally latest: Pulling from docker.io/fedora ded7cd95e059: Already exists 48ecf305d2cf: Already exists docker.io/fedora:latest: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security. Digest: sha256:10ba981a70632d7764c21deae25c6521db6d39730e1dd8caff90719013858a7b Status: Downloaded newer image for docker.io/fedora:latest [root@f1c79aa4c931 /]# dnf update -y Fedora 22 - x86_64 608 kB/s | 41 MB 01:09 Fedora 22 - x86_64 - Updates 439 kB/s | 12 MB 00:27 Last metadata expiration check performed 0:00:19 ago on Fri Jul 17 13:30:18 2015. Dependencies resolved. Package Arch Version Repository Size Installing: python-pip noarch 6.0.8-1.fc22 fedora 1.7 M python-setuptools noarch 17.1.1-3.fc22 updates 425 k Upgrading: bash x86_64 4.3.39-4.fc22 updates 1.6 M\n\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.\nTransaction Summary Install 2 Packages Upgrade 59 Packages Total download size: 48 M Downloading Packages: (1/61): python-pip-6.0.8-1.fc22.noarch.rpm 434 kB/s | 1.7 MB 00:03 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. Installed: python-pip.noarch 6.0.8-1.fc22 python-setuptools.noarch 17.1.1-3.fc22\nUpgraded: bash.x86_64 4.3.39-4.fc22 bash-completion.noarch 1:2.1-7.20150513git1950590.fc22 coreutils.x86_64 8.23-10.fc22 curl.x86_64 7.40.0-5.fc22 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. systemd.x86_64 219-19.fc22 systemd-libs.x86_64 219-19.fc22 tzdata.noarch 2015e-1.fc22\nComplete! [root@f1c79aa4c931 /]# [root@f1c79aa4c931 /]# [/bash] 上面的过程下载和启动了一个 fedora，然后更新系统到最新的包，为安装 Web 服务器打好了基础。\n[bash] [root@f1c79aa4c931 /]# dnf install -y httpd Last metadata expiration check performed 0:06:11 ago on Fri Jul 17 13:30:18 2015. Dependencies resolved. Package Arch Version Repository Size Installing: apr x86_64 1.5.1-3.fc22 fedora 111 k apr-util x86_64 1.5.4-1.fc22 fedora 96 k fedora-logos-httpd noarch 22.0.0-1.fc22 fedora 33 k httpd x86_64 2.4.12-1.fc22 fedora 1.2 M httpd-filesystem noarch 2.4.12-1.fc22 fedora 24 k httpd-tools x86_64 2.4.12-1.fc22 fedora 87 k mailcap noarch 2.1.44-1.fc22 fedora 36 k\nTransaction Summary Install 7 Packages\nTotal download size: 1.6 M Installed size: 4.4 M Downloading Packages: (1/7): apr-1.5.1-3.fc22.x86_64.rpm 128 kB/s | 111 kB 00:00 (2/7): apr-util-1.5.4-1.fc22.x86_64.rpm 100 kB/s | 96 kB 00:00 (3/7): httpd-filesystem-2.4.12-1.fc22.noarch.rpm 123 kB/s | 24 kB 00:00 (4/7): mailcap-2.1.44-1.fc22.noarch.rpm 123 kB/s | 36 kB 00:00 (5/7): httpd-tools-2.4.12-1.fc22.x86_64.rpm 185 kB/s | 87 kB 00:00 (6/7): fedora-logos-httpd-22.0.0-1.fc22.noarch.rpm 151 kB/s | 33 kB 00:00 (7/7): httpd-2.4.12-1.fc22.x86_64.rpm 363 kB/s | 1.2 MB 00:03\nTotal 264 kB/s | 1.6 MB 00:06 Running transaction check Transaction check succeeded. Running transaction test Transaction test succeeded. Running transaction Installing : apr-1.5.1-3.fc22.x86_64 1/7 warning: Unable to get systemd shutdown inhibition lock Installing : apr-util-1.5.4-1.fc22.x86_64 2/7 Installing : httpd-tools-2.4.12-1.fc22.x86_64 3/7 Installing : fedora-logos-httpd-22.0.0-1.fc22.noarch 4/7 Installing : mailcap-2.1.44-1.fc22.noarch 5/7 Installing : httpd-filesystem-2.4.12-1.fc22.noarch 6/7 Installing : httpd-2.4.12-1.fc22.x86_64 7/7 Verifying : httpd-2.4.12-1.fc22.x86_64 1/7 Verifying : apr-1.5.1-3.fc22.x86_64 2/7 Verifying : apr-util-1.5.4-1.fc22.x86_64 3/7 Verifying : httpd-filesystem-2.4.12-1.fc22.noarch 4/7 Verifying : httpd-tools-2.4.12-1.fc22.x86_64 5/7 Verifying : mailcap-2.1.44-1.fc22.noarch 6/7 Verifying : fedora-logos-httpd-22.0.0-1.fc22.noarch 7/7\nInstalled: apr.x86_64 1.5.1-3.fc22 apr-util.x86_64 1.5.4-1.fc22 fedora-logos-httpd.noarch 22.0.0-1.fc22 httpd.x86_64 2.4.12-1.fc22 httpd-filesystem.noarch 2.4.12-1.fc22 httpd-tools.x86_64 2.4.12-1.fc22 mailcap.noarch 2.1.44-1.fc22\nComplete! [root@f1c79aa4c931 /]# [root@f1c79aa4c931 /]# exit exit [fedora@master ~]$ [/bash] 上面在一个互动的 Bash 里面完成了 httpd 的安装，exit 命令之后，容器会停止运行，可以把这个停下来的镜像文件用下面的命令提交到本地的 image 库中。\n[bash] [fedora@master ~]$ sudo docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f1c79aa4c931 fedora \u0026ldquo;bash\u0026rdquo; 17 minutes ago Exited (130) 3 minutes ago desperate_franklin [fedora@master ~]$ sudo docker commit f1c79aa4c931 fedora-httpd c77c91fd4af681e736afc2ec76fc316732e25f52f6f3dd8aa97c973f28c55eb2 [fedora@master ~]$ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE fedora-httpd latest c77c91fd4af6 25 seconds ago 605.7 MB docker.io/cockpit/ws latest 9a4331b694a6 3 weeks ago 572.2 MB docker.io/fedora latest ded7cd95e059 7 weeks ago 186.5 MB [/bash]\n第一个名为 “fedora-httpd” 的就是刚才安装完毕之后，停止的 docker image，用 commit 提交到本第的库中待用。下面开始准备网站的内容，其实只有一个主页，上只有一句话“HW”\n[bash] [fedora@master ~]$ pwd /home/fedora [fedora@master ~]$ vi index.html [fedora@master ~]$ cat index.html Hello World! [fedora@master ~]$ tar -cf mysite.tar index.html [fedora@a1 ~]$ ls Dockerfile index.html mysite mysite.tar [fedora@master ~]$ vi Dockerfile [fedora@master ~]$ cat Dockerfile FROM fedora-httpd MAINTAINER MartinLiumartin@aws-faq.com\nAdd the tar file of the web site ADD mysite.tar /tmp/\nDocker automatically extracted. So move files to web directory RUN cp /tmp/index.html /var/www/html\nEXPOSE 80\nENTRYPOINT [ \u0026ldquo;/usr/sbin/httpd\u0026rdquo; ] CMD [ \u0026ldquo;-D\u0026rdquo;, \u0026ldquo;FOREGROUND\u0026rdquo; ] [/bash]\n上面这段命令中最重要的是 Dockerfiler 文件，这个文件的语法还有很多，以上是一个最简化的例子。使用它可构建一个具有静态页面内容的网站。下面开始构建这个网站的 Docker image。\n[bash] [fedora@a1 ~]$ sudo docker build -rm -t mysite . Warning: \u0026lsquo;-rm\u0026rsquo; is deprecated, it will be replaced by \u0026lsquo;\u0026ndash;rm\u0026rsquo; soon. See usage. Sending build context to Docker daemon 31.74 kB Sending build context to Docker daemon Step 0 : FROM fedora-httpd \u0026mdash;\u0026gt; 05ce6f68d3f2 Step 1 : MAINTAINER A D Ministator email: martin@aws-faq.com \u0026mdash;\u0026gt; Running in 7ee99e26ab76 \u0026mdash;\u0026gt; 03cc8c0deff1 Removing intermediate container 7ee99e26ab76 Step 2 : ADD mysite.tar /tmp/ \u0026mdash;\u0026gt; 52abfb1966ad Removing intermediate container e6c20f7ca5ed Step 3 : RUN mv /tmp/* /var/www/html \u0026mdash;\u0026gt; Running in ef455353caff \u0026mdash;\u0026gt; 6e24f9a9ea6f Removing intermediate container ef455353caff Step 4 : EXPOSE 80 \u0026mdash;\u0026gt; Running in 252b59576b54 \u0026mdash;\u0026gt; 7dd7c049c9d2 Removing intermediate container 252b59576b54 Step 5 : ENTRYPOINT /usr/sbin/httpd \u0026mdash;\u0026gt; Running in 572c3dafa53a \u0026mdash;\u0026gt; fa01c160e081 Removing intermediate container 572c3dafa53a Step 6 : CMD -D FOREGROUND \u0026mdash;\u0026gt; Running in b133650a6e18 \u0026mdash;\u0026gt; f828e1847160 Removing intermediate container b133650a6e18 Successfully built f828e1847160\n[fedora@master ~]$ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE mysite latest 1bd6d7c1970f 45 seconds ago 605.7 MB fedora-httpd latest c77c91fd4af6 18 minutes ago 605.7 MB docker.io/cockpit/ws latest 9a4331b694a6 3 weeks ago 572.2 MB docker.io/fedora latest ded7cd95e059 7 weeks ago 186.5 MB\n[fedora@master ~]$ sudo docker run -d -P mysite 6122ac7d4dff6cc73c4abc1523ac5dd02606c90d4e42da64823942d787694c1f [fedora@master ~]$ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6122ac7d4dff mysite \u0026ldquo;/usr/sbin/httpd -D 37 seconds ago Up 35 seconds 0.0.0.0:32768-\u0026gt;80/tcp evil_bardeen e5032443ab69 cockpit/ws \u0026ldquo;/container/atomic-r 16 minutes ago Up 16 minutes stoic_sammet [fedora@master ~]$ curl localhost:32768 Hello World! [/bash]\n在最后的命令行输出中，成功的看到了 Hello World!的出现。用的是 curl 的命令行 web 浏览器。\n","date":"2015-07-18T13:29:45Z","permalink":"https://martinliu.cn/2015/07/18/atomic-host-e58e9fe5ad90e4b8bbe69cbae69c80e7ae80e6b58be8af95/","title":"Atomic Host 原子主机最简测试"},{"content":"本次演讲用了大约 25 分钟，超时了大约 5 分钟多，但是其中有些观点还是没有叙述的很倒位。只能算是我的一种理解和解读，希望对道场的媒体朋友们对认识红帽公司有帮助。\n演讲源版 slide 和录音在这个网页上： http://investors.redhat.com/events.cfm 的这部分：\nJun 24, 2015\n10:30 AM - 1:00 PM ET\nRed Hat Analyst Day\nListen to webcast View Presentation\n12.2 MB\nAdd to Briefcase\nView Additional Information\n","date":"2015-07-14T14:20:24Z","permalink":"https://martinliu.cn/2015/07/14/e7baa2e5b8bde5aa92e4bd93e697a5/","title":"红帽媒体日"},{"content":"Ovirt 服务器虚拟化测试 本文安装和测试的软件是 Ovirt+KVM 的服务器虚拟化，这两个项目是红帽 RHEVM+KVM 服务器虚拟化的上游社区产品。可以通过这个文档清晰的了解到红帽服务器虚拟化产品的大体功能，基本特点。本测试文档使用的是 Centos7+社区 yum 源；因此是最新的 ovirt 和 kvm 的功能。如果是正式的企业级需求测试，请使用光纤或者传统存储，从而达到和 vmware 等商业产品最好的类比测试。尽量避免使用嵌套 kvm 虚拟化的方式，除非您很熟悉 Linux，使用两个笔记本是最简单的测试环境。\n下图是 Ovirt 服务器的详细架构图。其中的 ovirt-engine 是本文安装和部署的部分，是用一个 centos7 的虚拟机安装的。Host1 也是用一个 centos7 的虚拟机安装的。半年之前我也配置过一次嵌套 kvm，根本是一头雾水，而且还没有成功，不过这次的配置过程却这么简单容易，就正常工作了。希望简单一点的人，可以把 Host1 用物理机来安装，也会节省很多时间。\n[caption id=\u0026ldquo;attachment_53901\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;512\u0026rdquo;] ovirt 架构图[/caption]\nKVM 嵌套虚拟化准备 在测试 KVM 服务器虚拟化的过程中，如果您能有独立的物理机跑 Hypervisor，那么您可以忽略本节。至今进入 ovirt 的安装。 下面的测试的物理机是 Lenovo T440s 笔记本，运行的 Fedora 22 操作系统，使用 KVM manager 做虚拟机的管理工具。本次测试用到两个虚拟机：\novirt: 运行服务器虚拟化的管理机 ovirt，这个程序类似于 vmware 的 vcenter。\novirt-host : 用来被 ovirt 管理的 hypervisor；使用 kvm 嵌套 kvm 的方式，来跑虚拟机。\n确认本机的服务器虚拟机 CPU Bios 配置正常。\n[bash]\negrep -c \u0026lsquo;(vmx|svm)\u0026rsquo; /proc/cpuinfo\n[/bash]\n本机是 i5 的 CPU，双核开启超线程，显示为 4。还没有启用嵌套 KVM 的虚拟机，需要新建下面这个配置文件，操作系统不同，可能稍微不同，下面是以 Fedora 22 为例。\nvi /etc/modprobe.d/kvm-nested.conf 编辑以上文件，增加下面这行参数即可 options kvm_intel nested=1\n运行下面的命令，为操作系统内核加載此功能。\n[bash]\nmodprobe -r kvm_intel # unload modprobe kvm_intel # reload again\ncat /sys/module/kvm_intel/parameters/nested Y\n[/bash]\n用上面最后的 cat 的命令确认嵌套功能启用正常，看到的是 Y 即可。\n查看本机虚拟化的 Cpu 相关参数。\n[bash]\n[root@martin-fedora vm]# virsh capabilities | egrep \u0026ldquo;/model|/vendor\u0026rdquo; Westmere Intel none dac [root@martin-fedora vm]#\n[/bash]\n到此，物理机的相关准备工作完成。下面使用 Martin\u0026rsquo;s Perfect CentOS7 模板新建一个 2C/4Gd 的虚拟机 ovirt-host; 用这个虚拟机作为跑虚拟机的 hypervisor 把建立好的虚拟机先别开机，需要对它的配置做修改。编辑 ovirt-host 虚拟机的配置，给这个嵌套的 KVM hypervisor 增加和物理机相同的 cpu 属性。\nvirsh edit ovirt-host\n本嵌套 kvm 的虚拟机 cpu 参数如下，如果测试的物理机使用非 i5 的 CPU， 实际的配置参数应该和下面不同。\n[bash]\n[/bash]\n保存配置，启动这个虚拟机，配置好主机名和网络 ip 地址。安装 ovirt yum 源。做 yum update 之后，reboot 待用。\n[bash] yum -y update yum install http://plain.resources.ovirt.org/pub/yum-repo/ovirt-release35.rpm\n[/bash]\n安装 ovirt 服务器虚拟化管理机 使用 Martin\u0026rsquo;s Perfect CentOS7 模板新建一个 1C/4G 的虚拟机 ovirt；这个虚拟机上还需要配置 NFS 服务器，用来做 跑虚拟机的共享存储和用于存储 iso 光盘的存储。\n安装和配置 NFS 的过程如下：\n安装 nfs 服务相关的包 yum install -y nfs-utils\n创建存储目录 mkdir -p /srv/ovirt/{iso,export,sata} chown -R vdsm:kvm /srv/ovirt/ chmod -R 770 /srv/ovirt/\n编辑 nfs 配置文件 /ect/exports ， 加入下面三行。\n/srv/ovirt/iso 192.168.10.0/24(rw,anonuid=36,anongid=36,all_squash) /srv/ovirt/export 192.168.10.0/24(rw,anonuid=36,anongid=36,all_squash) /srv/ovirt/sata 192.168.10.0/24(rw,anonuid=36,anongid=36,all_squash)\n由于 centos 7 的 nfs 默认是 v4，这和 ovirt 不兼容，需要修改配置文件改为 v3， 编辑 /etc/nfsmount.conf 加入下面两个参数。\nDefaultvers=3 Nfsvers=3\n重启动 nfs 服务器 ，设置开机启动服务 systemctl start rpcbind.service \u0026amp;\u0026amp; systemctl enable rpcbind.service systemctl start nfs-server.service \u0026amp;\u0026amp; systemctl enable nfs-server.service\n下面开始安装 ovirt 服务器。\nyum -y update yum install http://plain.resources.ovirt.org/pub/yum-repo/ovirt-release35.rpm yum -y install ovirt-engine\n安装完后，用 engine-setup 命令配置和部署 ovirt 服务器。\n[bash]\n[root@ovirt ~]# engine-setup [ INFO ] Stage: Initializing [ INFO ] Stage: Environment setup Configuration files: [\u0026rsquo;/etc/ovirt-engine-setup.conf.d/10-packaging-jboss.conf\u0026rsquo;, \u0026lsquo;/etc/ovirt-engine-setup.conf.d/10-packaging.conf\u0026rsquo;] Log file: /var/log/ovirt-engine/setup/ovirt-engine-setup-20150711225251-f9k7an.log Version: otopi-1.3.2 (otopi-1.3.2-1.el7.centos) [ INFO ] Stage: Environment packages setup [ INFO ] Yum Downloading: ovirt-3.5-patternfly1-noarch-epel/x86_64 (0%) [ INFO ] Stage: Programs detection [ INFO ] Stage: Environment setup [ INFO ] Stage: Environment customization\n\u0026ndash;== PRODUCT OPTIONS ==\u0026ndash;\nConfigure Engine on this host (Yes, No) [Yes]: #回车，选择 Yes Configure WebSocket Proxy on this host (Yes, No) [Yes]: #回车，选择 Yes\n\u0026ndash;== PACKAGES ==\u0026ndash;\n[ INFO ] Checking for product updates\u0026hellip; [ INFO ] No product updates found\n\u0026ndash;== ALL IN ONE CONFIGURATION ==\u0026ndash;\n\u0026ndash;== NETWORK CONFIGURATION ==\u0026ndash;\nSetup can automatically configure the firewall on this system. Note: automatic configuration of the firewall may overwrite current settings. Do you want Setup to configure the firewall? (Yes, No) [Yes]: No #选择 no，由于本机的服务没有安装防火墙 Host fully qualified DNS name of this server [unknown.prolexic.com]: ovirt.xenlab.com #回车继续\n\u0026ndash;== DATABASE CONFIGURATION ==\u0026ndash;\nWhere is the Engine database located? (Local, Remote) [Local]: #回车，选择 Local 继续 Setup can configure the local postgresql server automatically for the engine to run. This may conflict with existing applications. Would you like Setup to automatically configure postgresql and create Engine database, or prefer to perform that manually? (Automatic, Manual) [Automatic]: #回车，选择 继续\n\u0026ndash;== OVIRT ENGINE CONFIGURATION ==\u0026ndash;\nEngine admin password: Confirm engine admin password: [WARNING] Password is weak: it is based on a dictionary word Use weak password? (Yes, No) [No]: yes Application mode (Virt, Gluster, Both) [Both]: #回车，选择 Both 继续\n\u0026ndash;== PKI CONFIGURATION ==\u0026ndash;\nOrganization name for certificate [xenlab.com]:\n\u0026ndash;== APACHE CONFIGURATION ==\u0026ndash;\nSetup can configure the default page of the web server to present the application home page. This may conflict with existing applications. Do you wish to set the application as the default page of the web server? (Yes, No) [Yes]: Setup can configure apache to use SSL using a certificate issued from the internal CA. Do you wish Setup to configure that, or prefer to perform that manually? (Automatic, Manual) [Automatic]:\n\u0026ndash;== SYSTEM CONFIGURATION ==\u0026ndash;\nConfigure an NFS share on this server to be used as an ISO Domain? (Yes, No) [Yes]: no # 选择 no，本测试手工配置 NFS，不需要安装程序配置。 继续\n\u0026ndash;== MISC CONFIGURATION ==\u0026ndash;\n\u0026ndash;== END OF CONFIGURATION ==\u0026ndash;\n[ INFO ] Stage: Setup validation [WARNING] Cannot validate host name settings, reason: resolved host does not match any of the local addresses [WARNING] Less than 16384MB of memory is available\n\u0026ndash;== CONFIGURATION PREVIEW ==\u0026ndash;\nApplication mode : both Update Firewall : False Host FQDN : ovirt.xenlab.com Engine database name : engine Engine database secured connection : False Engine database host : localhost Engine database user name : engine Engine database host name validation : False Engine database port : 5432 Engine installation : True PKI organization : xenlab.com Configure local Engine database : True Set application as default page : True Configure Apache SSL : True Configure WebSocket Proxy : True Engine Host FQDN : ovirt.xenlab.com\nPlease confirm installation settings (OK, Cancel) [OK]: #回车，选择 OK 继续 [ INFO ] Stage: Transaction setup [ INFO ] Stopping engine service [ INFO ] Stopping ovirt-fence-kdump-listener service [ INFO ] Stopping websocket-proxy service [ INFO ] Stage: Misc configuration [ INFO ] Stage: Package installation [ INFO ] Stage: Misc configuration [ INFO ] Initializing PostgreSQL [ INFO ] Creating PostgreSQL \u0026rsquo;engine\u0026rsquo; database [ INFO ] Configuring PostgreSQL [ INFO ] Creating/refreshing Engine database schema [ INFO ] Creating CA [ INFO ] Configuring WebSocket Proxy [ INFO ] Generating post install configuration file \u0026lsquo;/etc/ovirt-engine-setup.conf.d/20-setup-ovirt-post.conf\u0026rsquo; [ INFO ] Stage: Transaction commit [ INFO ] Stage: Closing up\n\u0026ndash;== SUMMARY ==\u0026ndash;\n[WARNING] Less than 16384MB of memory is available SSH fingerprint: DF:FF:42:14:80:35:E2:7D:68:3A:1F:83:65:6E:89:EA Internal CA 99:17:7A:42:D0:9D:D7:33:DE:C3:3E:07:EE:15:5D:01:28:63:4A:BF Web access is enabled at: http://ovirt.xenlab.com:80/ovirt-engine https://ovirt.xenlab.com:443/ovirt-engine Please use the user \u0026ldquo;admin\u0026rdquo; and password specified in order to login In order to configure firewalld, copy the files from /etc/ovirt-engine/firewalld to /etc/firewalld/services and execute the following commands: firewall-cmd -service ovirt-postgres firewall-cmd -service ovirt-https firewall-cmd -service ovirt-fence-kdump-listener firewall-cmd -service ovirt-websocket-proxy firewall-cmd -service ovirt-http The following network ports should be opened: tcp:443 tcp:5432 tcp:6100 tcp:80 udp:7410 An example of the required configuration for iptables can be found at: /etc/ovirt-engine/iptables.example\n\u0026ndash;== END OF SUMMARY ==\u0026ndash;\n[ INFO ] Starting engine service [ INFO ] Restarting httpd [ INFO ] Stage: Clean up Log file is located at /var/log/ovirt-engine/setup/ovirt-engine-setup-20150711225251-f9k7an.log [ INFO ] Generating answer file \u0026lsquo;/var/lib/ovirt-engine/setup/answers/20150711225734-setup.conf\u0026rsquo; [ INFO ] Stage: Pre-termination [ INFO ] Stage: Termination [ INFO ] Execution of setup completed successfully\n[/bash]\n安装成功，用浏览器，访问 ovirt 服务器 IP 地址使用 admin / 密码 登陆管理员控制台，第一次比较慢，验证安装是否完全成功。\n使用命令确认 nfs [root@ovirt ~]# showmount -e Export list for ovirt.xenlab.com: /srv/ovirt/sata 192.168.10.0/24 /srv/ovirt/export 192.168.10.0/24 /srv/ovirt/iso 192.168.10.0/24\n在 ovirt 服务器中添加这三个存储，然后在命令和中确认 iso 存储已经可用。\n[bash]\n[root@ovirt ~]# engine-iso-uploader list Please provide the REST API password for the admin@internal oVirt Engine user (CTRL+D to abort): ISO Storage Domain Name | Datacenter | ISO Domain Status ovirt-iso | Default | active\n[/bash]\n把需要安装的光盘镜像文件，先复制到 ovirt 服务器上，然后传入 iso 存储。\n[bash]\n[martin@martin-fedora iso]$ scp CentOS-7-x86_64-Minimal-1503-01.iso root@192.168.10.25:/root/ The authenticity of host \u0026lsquo;192.168.10.25 (192.168.10.25)\u0026rsquo; can\u0026rsquo;t be established. ECDSA key fingerprint is SHA256:KMGYLWZu14ZKaUwizIORgQ598Bpc0PKzNWF0qop2VAQ. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026lsquo;192.168.10.25\u0026rsquo; (ECDSA) to the list of known hosts. root@192.168.10.25\u0026rsquo;s password: CentOS-7-x86_64-Minimal-1503-01.iso 100% 636MB 90.9MB/s 00:07 [martin@martin-fedora iso]$\n[/bash]\n用这个命令上传光盘。 engine-iso-uploader upload -i ovirt-iso /root/CentOS-7-x86_64-Minimal-1503-01.iso\n之后就可以在控制台中创建虚拟机了。在 Web 界面上安装虚拟机，是需要安装客户的程序的，在 Fedora 22 笔记本中安装它们。 yum install spice-xpi virt-viewer\n点击新创建的虚拟机，启动之后，选择控制台，打开后，开始系统安装。\n参考文档 本文没有做截图，是由于以下参考文档都有相关截图和步骤说明；因此，在使用本文档的过程中，一定要同时打开这几篇文档。\nhttp://www.ovirt.org/QuickStart_Guide#Install_oVirt_Engine.28Fedora.29%60\nhttp://jensd.be/?p=550\nhttps://xrsa.net/2015/02/04/installing-ovirt-3-5-on-centos-7-hosted-engine/\nhttp://www.server-world.info/en/note?os=Fedora_22\u0026amp;p=kvm\u0026amp;f=8\n","date":"2015-07-12T11:16:44Z","permalink":"https://martinliu.cn/2015/07/12/ovirt-e69c8de58aa1e599a8e8999ae68b9fe58c96e6b58be8af95/","title":"Ovirt 服务器虚拟化测试"},{"content":"很高兴能有机会跑在波士顿的一些地方，还骑行了两次。基本上也了解了这个城市，熟悉了运动的地形，领略了城市的风光，感受了这个城市的运动文化和气息。纽约的行程安排的它紧凑了，导致就跑了一次中央公园，给以后留下很多探索的空白。\n波士顿的跑步 第一跑 - 12 公里 推辞了饭局的夜跑，跑步过程中被阵雨浇透，找错了回来的桥，路程没有记录完整。\n第二跑 - 8 公里 本想跑的比前一次更远，结果起晚了，跑了 8 公里就被晒的不行，汗狂出，提前失去斗志，返回。这时感觉还是有跑友会更好些。\n第三跑 - 10 公里 陪同事满跑 10K，在一个海湾处，居然海湾是闭合的，跑了三圈，其实那个 Castle Island Park 有点意思，可惜没有进去。\n第四跑 - 10 公里 领略了市内最繁华的街道，最美的市中心公园，跑过了 林阴道，再次重温河边的感觉，这是下午下班后的跑步，不管你是什么时间，什么地点跑，基本上到处都是跑步的人。\n波士顿骑行 第一次 46.4 km 自行车租金是 25 刀，下午开完会发现其它两个同伴时差严重，因此我独自骑行出去。骑行的方向其实是波士顿马拉松延伸的方向，只是那个路线是要在公路上的，车多没法骑行那个赛道，骑车出去闲逛，也超过了一个全马的距离，基本上把哈佛和 MIT 逛清楚了。\n第二次 21.7 km 第二次，本来不想去，可是需要给伙伴去带路，就带他们走了一遍昨天的路，让他们也浏览了我看过的景点。\n纽约跑步 - 中央公园 10KM 中央公园打卡跑过，很满意的得到了这个路线，公园里里面的运动氛围很强，爽跑一圈。\n","date":"2015-07-09T15:42:07Z","permalink":"https://martinliu.cn/2015/07/09/boston-nyc-running-log/","title":"Boston 和 NYC 的 运动日志"},{"content":"行程 在波士顿的住宿是非常完美的体验。先住了两天剑桥的 LeMeridien（SPG）；由于 6 月是我的生日，因此酒店给我加了早餐，使用 IBM 的企业代码订房确实便宜了一大块。剩下几天住的 Westin Waterfront，和另外一个 SPG 白金卡同事同住，由于是白金卡，所以直接就给升级到套房了，当然附赠免费早餐；今房间一看，很大的两间房间，各自独立的电视和洗手间。\n说下在美国第一次做长途 BUS 的感受，我是在网上定的票。从波士顿到纽约 4 个多小时的路程，28$的价格。由于我记错了时间，同事开车送我去车站后，我看了票后，才惊醒，到达候车室的时候，我的那班车已经开车 15 分钟了。车票是电子邮件中的二维码。我问车站的工作人员，他说你需要去 standby 下一班车，下一班车要过 1 小时后发车，我到了那边 standby 的队列中。心里真是有点没谱，如果那个车上没有空位的话，我就残了。还好，开始上车时第一批是买了那班车票的人；第二批是 standby 的人，还好有空座位。最后一波是需要副现金上车，而没有买票的人，那部分人好像话了 50 多刀。在开车的过程中没有停车，车上居然有卫生间，就在车的尾部，我也用了一下，确实很方便，很干净。到了纽约之后，一下车我就走向最近地铁站开始了我的纽约之行。\n波士顿 波士顿有美国的雅典之称，到处透露着历史感，街道相当干净，气温体感非常舒服。这是一个运动的城市每年的波士顿马拉松比赛不知道吸引了多少人，作为一个跑步爱好者，我到此地也算是朝圣之旅了。到的第二天，就有 BAA 的 10 公里的比赛，我看到了才意识到，应该提前报名，说不定可以参加上呢！\n在波士顿我跑了三次。第一次本想早晨跑，提前规划好的路线，可是早晨下雨，没有跑成。结果晚上回来后，同事拉我去配客户吃饭，没去，夜跑了十二公里。在跑的中间下雨了，是阵雨，淋了我 20 多分钟，浑身湿透了，快回到酒店的时候雨停了。回来查跑步轨迹一看，还是跑错了路线，返回的桥还是选择错了，回程的路线基本正确。第二次跑步是早晨晨跑，起的有点晚，还是在查尔斯河边和前一次一样，这次看到了很多早晨练习划船的人，非常多的人在河上划着各种船，有些是有教练指导的，有些是自己联系的。第三次是和同事一起，在海边找了一个港口的地方，港口恰好是环形封闭的，跑了 3 圈，10 公里。第四次是开晚会去跑步，在市中心的酒店跑到城市中心公园，有跑回查尔斯河，然后返回，返回过程中遇到上坡下坡，一个人有点累，10 公里做罢。回程一边找路一边欣赏城市，也算是把波士顿城区看了仔细。剩下两次运动是骑行，这里骑行的人也很多。自己骑了一次，和同事一起骑行一次，一共 50 公里。顺便欣赏了哈佛和 MIT 学校的校园。\n波士顿的龙虾不可以不提，吃了三次，后两次在同一家吃的，这家专门做龙虾，吃的非常过瘾。\n纽约 在纽约我住在 airbnb 的一个民宅里，主人是个南美小国的人，他没有工作；估计也是租来的房子，然后转祖一间卧室做房东，airbnb 算是让他也有钱赚，有生计了。这个公寓里中央公园很近，我去中央公园跑了一次，感觉非常好，那里有浓厚的运动气息，各种人在里面跑步，骑车，散步，骝狗。两次穿过中央公园都有看到跑步比赛。我买了一张 5 天的地铁票，算是用足了。去了很多景点，感受到了大纽约的感觉。现在感觉纽约一周可以逛的差不多，4 天根本不够。我最完美的两天是大都会博物馆和自由女神/爱丽丝岛。大都会博物馆里面我足足泡了一天，停没电了 3 个讲解器；直到人闭馆赶人，我才走，看了四分之三不到。真是有点走马观花，很多没有看仔细。自由女神像其实可以注册一下，就能够登到它的身体里，到达头部，从眼睛往外看，我也是去了才知道。爱丽丝岛值的仔细看，它是美国移民博物馆，看了它，彻底颠覆了我对美国移民的看法。\n时间有限，工作太忙，就这个流水帐，算是总结一下这次美国东岸之旅吧！\n图片 以下图片都是手机拍摄。\n[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;53844,53845,53846,53847,53848,53849,53850,53851,53852,53853,53854,53855,53856,53857,53858,53859,53860,53861,53862,53863,53871,53865,53866,53867,53868,53869,53870,53873,53874,53877,53876,53875,53878\u0026rdquo;]\n","date":"2015-07-09T14:31:15Z","permalink":"https://martinliu.cn/2015/07/09/e9a696e6aca1e7be8ee59bbde4b89ce6b5b7e5b2b8e4b98be69785/","title":"首次美国东海岸之旅"},{"content":"Icingaweb 2 用户权限管理 icingaweb 2 是诸多 GUI 中最新的一种，也有替代其它之前所有 GUI 的趋势，目前看还比较新，只有最基本的功能。登陆 Web 界面的用户，用户和组的信息可以使用自己的数据库存储或者配置文件存储，也可以使用外部的 LDAP 集成，使用 php-ldap 模块集成外部的 LDAP/MS AD 服务器。 具有完整的 RBAC 模式; User -\u0026gt; Group -\u0026gt; Role = Permission Set（操作 action） + monitoring/filter/objects(范围 scope)\nIcinga2 的联系人和联系人组 在 icinga2 服务器端，在配置文件中定义了组和用户，他们在 Web GUI 界面上叫做 Contacts / Contactgroups 。\n[bash] [root@icinga2-test conf.d]# cat users.conf /**\nThe example user \u0026lsquo;icingaadmin\u0026rsquo; and the example group \u0026lsquo;icingaadmins\u0026rsquo;. */ object User \u0026ldquo;icingaadmin\u0026rdquo; { import \u0026ldquo;generic-user\u0026rdquo;\ndisplay_name = \u0026ldquo;Icinga 2 Admin\u0026rdquo; groups = [ \u0026ldquo;icingaadmins\u0026rdquo; ]\nemail = \u0026ldquo;martin@aws-faq.com\u0026rdquo; }\nobject UserGroup \u0026ldquo;icingaadmins\u0026rdquo; { display_name = \u0026ldquo;Icinga 2 Admin Group\u0026rdquo; } [/bash]\nUser / UserGruop 是 Icinga 出发通知的对象，定义在这个配置文件中，使用规则把他们和监控对象（host/service/等）关联起来，在通知规则中实现不同的通知策略。如发邮件等。\nIcinga2 的 HA 和分布式架构 icinga2 的 Cluster 是通过多个运行的实例配置在一起的，有这样几个特性：实例之间使用 SSL 的加密通信；彼此之间是双向连接；用 Zone 来分隔不同租户的配置域；基于 Hash 的负载分配；系统的各种功能组件由 Cluster 来管理其分布。它可以实现某个节点宕机后的自动分布监控数据采集命令在其它节点上的执行。\nicinga2 Client 是远程执行的一种节点，它和 Cluster 中的所有节点形成群集，在数据中心的其它网段或者地点采集本地的监控状态数据，然后把结果传送回上级的 Cluster 群集节点。icinga2 可以通过配置向导完成远程 client/Satellite 卫星节点的配置。它们之间的通行是基于证书的 TLS 加密，这个证书可以借用 puppet 的证书。远程 Client/Satellite 节点可以运行在三种模式下：具有本地监控配置，没有本地监控配置，靠上级群集发送监控配置。\n其它企业级功能在后续文章中继续评测，您可以通过下面的评论，来提出您所关注的待评测功能。\n","date":"2015-07-09T08:44:43Z","permalink":"https://martinliu.cn/2015/07/09/icinga2-e4bc81e4b89ae7baa7e58a9fe883bde8af84e6b58b1/","title":"icinga2 企业级功能评测1"},{"content":"应用为王，操作系统是心跳。从整个行业的角度，而不只是操作系统和某种工具的角度看，行业已经发生了重大的变化。下面是一些例证。\nVMWare 几年前说操作系统已死，可是最近却发布了 Linux 操作系统的容器技术的产品线。\n微软也把它的一些技术开源了，并且在这些方面取得了一些它们认为可喜的进展。\nIDC 的调查显示，数据中心的操作系统目前是两个主要选择：Linux 和 Windows。以上说明了：开源不再是非主流，而进入了数据中心主流技术，企业现在开发的应用将不得不在两种操作系统中做出选择。\n[caption id=\u0026ldquo;attachment_53819\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;800\u0026rdquo;]](http://martinliu.cn/paul%e7%9a%84%e5%bc%80%e6%ba%90%e9%80%bb%e8%be%91%e6%80%9d%e7%bb%b4/cormier_keynote_800px/) Keynote 笔记[/caption]\n从这个角度出发，Red Hat 的使命才刚过开始，它中在用 Linux 和相关开源技术来变革整个企业数据中心的技术堆栈；从基础架构一直到应用开发。\n为何开源技术当今如此之火热？开源技术正在解决和处理现实社会中那些最复杂的业务问题。为什么会这样？驱动因素是什么？是动态变化的企业业务需求。\n开源技术最擅长的是快速地创新，这成为了企业技术创新和业务变革的动力，IT 也逐渐因此从成本中心转变为价值和创新中心。\n开源不仅仅只是看到源代码，更重要的：它是自由开放的平台，是分享的平台，它萌生了持续不断的创新，一个创新基于另外一个创新之上，一环接一环地扩散开来，根本停不下来。 这意味着技术问题能够被更快、更好地解决；而不是丢给私有软件技术厂商们各自独自解决，企业最等来消费他们的产品。\nLinux 是计算供给层，毫无疑问云计算和软件定义存储都基于它。它不能叫做一个 Linux 社区，而是一组相关的社区项目协作在一起共同创新，这样才带来了企业可以使用的高性能稳定的操作系统；这样 Red Hat 才有可能给企业带来企业级 Linux 操作系统。\nKVM 是计算的虚拟化抽象层，VMWare 最先进入这一企业市场，它试图用封闭的管理层和锁定的模式来控制这个市场，从而控制客户。Red Hat 的使命是：为企业提供了 Linux 操作系统和至上的开放虚拟化技术；企业可以在这个层面消费开源开放虚拟化技术，并做出备份的方案选择。\n没有 Linux 和开放虚拟化云计算就不存在。公有云提供商使用这些技术构建了共有云服务。可是企业不想让自己的业务运行在防火墙之外，因此 OpenStack 项目应运而生。它让企业构建私有云成为可能。Red Hat 在 OpenStack 上面所有的贡献都 100%的提交到社区，成为主流代码的一部分；从而 OpenStack 能够运行在 Red Hat Linux 和 KVM 之上，这使得 Red Hat 巨大的 Linux 生态系统的价值服务与 OpenStack 领域；企业能够借此放心地在 OpenStack 构建的私有云，并运行企业重要的业务。\n在开源的开发框架里，开发人员可以有更多、更新的开发语言、开发工具、库和社区的支持，这使他们能更快地解决业务问题。这些框架首先被广泛应用于互联网行业公司。Red Hat 基于 JBoss 社区为企业提供了企业级的应用服务器、集成工具、规则引擎和丰富的开发语言。让企业级应用能像互联网公司一样地使用开放应用所需的开发框架和开发平台。相比私有技术公司用了四十多年达到目前的程度，开源领域的快速创新用十几年就做到了，发展速度比私有软件快很多。\n现在看到了基础架构和开发框架都极大地受到了开源技术的影响、冲击和变革。运维和开发之间亟待出现一种融合技术，来改善目前的互为孤岛的现状。这种联系将使开源技术为他们带来最大的共同价值。\n容器技术实际上在操作系统中存在了很多年了，只是最近才被引入开源领域；它的出现将确实会改善孤岛问题，为开发人员解决了应用在各种混合的计算和存储平台之间的可移植性、一致性和敏捷性等问题。\n开发和运维之间的割裂还导致了业务创新的迟钝，这个问题已经持续存在很多很多年了。因此 Red Hat 发布了 Red Hat Atomic Enterprise Platform。让企业应用可以安全地在各种形式的计算平台上一致地运行。Red Hat 发布了 OpenShift v3 ，它是一些列容器的自动化调度和部署管理工具集合，并包含全套的开放应用开发框架平台。它能帮助企业基于容器技术发展出新一代的混合应用。\n为何企业 IT 技术会有这些变革？为何这些变革会发生？其实还是企业不得不快速地响应业务的变化，企业不得不使用 IT 技术来创造出更多的价值，应用开发不得不跟上需求变化的脚步，基础架构的运作和运维再也不允许我们手工地安装一台服务器，频繁地去手动更改网口跳线。企业必须面对和适应动态的业务变化，不光要从开发层面，同时从运维层面。\n企业需要构建和重写无状态的业务应用，并使用软件定义存储来解决传统存储的空间不能无限扩容的问题。Gluster 和 Ceph 在这方面已经日臻成熟，并或将去替换私有的传统存储技术。\n企业应用 DevOps 是一种趋势，它不是一个理论，而是一种实践。Red Hat 的全线企业级开源技术平台已经做好了准备，企业现在就可以开始 DevOps 实践之旅。\n开源和闭源之战将不可逆转地持续下去，Red Hat 将持续守护开源阵营。私有软件技术不愿意看到逐渐开放的变化，他们不希望开放，不愿意去分享；Pual 坚信开放不仅仅是看到代码而已，而是与之共生，是开放的软件开发流程，是基于开放代码上的不断创新活动。这是一场宏大的战役，开源逐渐开始在一些战斗中取胜，待到明年此时，或将看到开源是如何在企业 IT 基础架构上全面获胜的。\n本演讲的官方 Blog 报道：http://summitblog.redhat.com/2015/06/24/paul-cormier-announces-new-products-and-technologies-at-red-hat-summit/\n下面是演讲实况视频。\n","date":"2015-07-01T06:52:00Z","permalink":"https://martinliu.cn/2015/07/01/red-hat-summite4b98bpaule79a84e5bc80e6ba90e980bbe8be91e6809de7bbb4/","title":"Red Hat Summit之Paul的开源逻辑思维"},{"content":"时差如期而至，现在时本地时间清晨 3：40，我还是一点睡意也没用，百无聊赖中计划一下明天的跑步路线。根据 Boston 的 Garmin 的热力地图，我观察了一下 Clarles 河附近的跑步路线，看着很不错。计划明天早晨跑右侧的这一部分。如下图所示。 这部分是 Charles 河入海口的这个部分。从酒店出门大概的路线如下：\n从酒店 右拐 到 Sidney St + Massachusetts Ave， 在右拐一直到河边\n到河边的桥头，右拐顺河边向东跑，一直跑到头\n在 Longfellow bridge 桥下，顺着 Edwin H Land Blvd 穿过该桥\n延河边来到 Museum of science 前，左拐，绕 Lechmere Canal Park，来到科学博物馆门前的路\n经过 Charles 大坝这条路，到河的南岸\n在 State Police 警察局门口右拐到河边，眼查尔斯河滨大道一直往西跑\n经过 Boston University Bridge，继续向前跑\n经过 Western Ave Bridge 继续向前跑\n到了 John W. Weeks Bridge 上桥过河，到达河对岸\n进入 Dewolfe St， 到 Arrow St 右拐\n跑回 Massachusetts Ave, 沿着街道一直跑回去\n跑步的实际路线图和数据贴图如下。\n","date":"2015-06-21T08:15:46Z","permalink":"https://martinliu.cn/2015/06/21/boston-running-1-charles-river/","title":"Boston Running #1 Charles River"},{"content":"本来想写一个安装手册，可是安装完成之后发现其实非常简单，最后就把题目改为评测了。本文也不是全面的评测文章，关于它的能力和功能，待后续了解的深入了在继续更新本文。\nicinga2 架构分析 请下载和查看这个 icinga2 官方的文档：[su_button url=\u0026ldquo;http://pan.baidu.com/s/1qW3JkJE\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; background=\u0026quot;#cccc00\u0026quot; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: cubes\u0026rdquo;]下载点这里[/su_button]\n为什么用 icinga，原因如下：\n[su_list icon=\u0026ldquo;icon: eye\u0026rdquo;]\nNagios 的架构不能扩展 增加模块是比较困难的 不是群集和分布式监控架构 安全性相对糟糕 配置功能有限 [/su_list]\n安装配置 icinga2 的安装可以说非常简洁，基本上配置好 yum 源，几条命令就装万了，而且就可以用了。只是在 web 界面选择和配置上稍微有点麻烦，它目前有三个可以安装配置的界面：classic, icinga-web, icinga-web2； classic 太老了，不具有极其强烈的怀旧情节，就别碰了。建议生产环境中还是使用 icinga-web；web2 太新了，很多集成的项目的都还没有做好，还比较初级，功能不完善。\n~~待续~~~~\n","date":"2015-06-18T14:14:51Z","permalink":"https://martinliu.cn/2015/06/18/icinga2-e79b91e68ea7e5b7a5e585b7e8af84e6b58b/","title":"icinga2 监控工具评测"},{"content":"首先安装 RHEL7 使用光盘安装最小化系统，安装完成之后，关闭防火墙和 SELinux（为了测试方便），配置主机名为 FQDN 格式，如 fm1.8.xenlab.com； 加本机的主机名解析到/etc/hosts 文集中。之后注册到 RHN。\n[bash]\n[root@fm18 ~]# subscription-manager register [root@fm18 ~]# subscription-manager attach \u0026ndash;auto [root@fm18 ~]# subscription-manager repos \u0026ndash;disable=\u0026quot;*\u0026quot; [root@fm18 ~]# subscription-manager repos \u0026ndash;enable=rhel-7-server-optional-rpms [root@fm18 ~]# subscription-manager repos \u0026ndash;enable=rhel-server-rhscl-7-rpms [root@fm18 ~]# subscription-manager repos \u0026ndash;enable=rhel-7-server-rpms [root@fm18 ~]# rpm -ivh http://yum.puppetlabs.com/puppetlabs-release-el-7.noarch.rpm [root@fm18 ~]# yum -y install http://yum.theforeman.org/releases/1.8/el7/x86_64/foreman-release.rpm [root@fm18 ~]# yum -y install http://ftp.sjtu.edu.cn/fedora/epel/epel-release-latest-7.noarch.rpm [root@fm18 ~]# yum clean all [root@fm18 ~]# yum makecache [root@fm18 ~]# yum update -y [root@fm18 ~]# reboot [root@fm18 ~]# yum install foreman-installer\n[/bash]\n安装 foreman-installer 可能会出现的错误是 ruby 包依赖的问题，导致这个问题的原因可能有：网速太满导致的 yum meta-data 失效，国外的 epel 源下载失败等。解决方法是：使用国内较快的 epel 源，在安装 foreman-installer 前，清除 yum 缓存，重新建立 yum 原数据缓存。\n我的测试机的 yum 源配置如下：\n[bash]\n[root@fm18 yum.repos.d]# yum repolist Loaded plugins: fastestmirror, product-id, subscription-manager Loading mirror speeds from cached hostfile\nepel: mirrors.neusoft.edu.cn repo id repo name status epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 8,076 foreman/x86_64 Foreman 1.8 379 foreman-plugins/x86_64 Foreman plugins 1.8 199 puppetlabs-deps/x86_64 Puppet Labs Dependencies El 7 - x86_64 17 puppetlabs-products/x86_64 Puppet Labs Products El 7 - x86_64 175 rhel-7-server-optional-rpms/7Server/x86_64 Red Hat Enterprise Linux 7 Server - Optional (RPMs) 5,832 rhel-7-server-rpms/7Server/x86_64 Red Hat Enterprise Linux 7 Server (RPMs) 7,036 rhel-server-rhscl-7-rpms/7Server/x86_64 Red Hat Software Collections RPMs for Red Hat Enterprise Linux 7 Server 3,596 repolist: 25,310 [root@fm18 yum.repos.d]# cat /etc/yum.repos.d/epel.repo [epel] name=Extra Packages for Enterprise Linux 7 - $basearch baseurl=http://download.fedoraproject.org/pub/epel/7/$basearch #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7\u0026amp;arch=$basearch failovermethod=priority enabled=1 gpgcheck=1 gpgkey=https://fedoraproject.org/static/352C64E5.txt mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7\u0026amp;arch=$basearch [epel-debuginfo] name=Extra Packages for Enterprise Linux 7 - $basearch - Debug baseurl=http://ftp.sjtu.edu.cn/fedora/epel/7/$basearch/debug #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-7\u0026amp;arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 gpgcheck=1\n[epel-source] name=Extra Packages for Enterprise Linux 7 - $basearch - Source baseurl=http://ftp.sjtu.edu.cn/fedora/epel/7/SRPMS #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-source-7\u0026amp;arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 gpgcheck=1 [root@fm18 yum.repos.d]#\n[/bash]\n以上应该是安装 foreman-installer 宝过的攻略了。接下来该安装 foreman 的各个组建和插件了。使用 foreman-installer -i 发现是个不错的方法。还可以顺便了解一下当前 foreman 版本的各个主要功能项，如下所示：\n[bash]\n[root@fm18 yum.repos.d]# foreman-installer -i Welcome to the Foreman installer!\nThis wizard will gather all required information. You can change any parameter to your needs.\nReady to start? (y/n) y\nMain Config Menu\n[✓] Configure foreman [✓] Configure foreman_cli [✗] Configure foreman_compute_ec2 [✗] Configure foreman_compute_gce [✓] Configure foreman_compute_libvirt [✗] Configure foreman_compute_openstack [✓] Configure foreman_compute_ovirt [✗] Configure foreman_compute_rackspace [✗] Configure foreman_compute_vmware [✓] Configure foreman_plugin_bootdisk [✗] Configure foreman_plugin_chef [✓] Configure foreman_plugin_default_hostgroup [✗] Configure foreman_plugin_digitalocean [✓] Configure foreman_plugin_discovery [✗] Configure foreman_plugin_docker [✗] Configure foreman_plugin_hooks [✗] Configure foreman_plugin_openscap [✗] Configure foreman_plugin_ovirt_provision [✗] Configure foreman_plugin_puppetdb [✗] Configure foreman_plugin_salt [✓] Configure foreman_plugin_setup [✓] Configure foreman_plugin_tasks [✗] Configure foreman_plugin_templates [✓] Configure foreman_proxy [✗] Configure foreman_proxy_plugin_abrt [✗] Configure foreman_proxy_plugin_chef [✗] Configure foreman_proxy_plugin_openscap [✗] Configure foreman_proxy_plugin_pulp [✗] Configure foreman_proxy_plugin_salt [✓] Configure puppet Display current config Save and run Cancel run without Saving Choose an option from the menu\u0026hellip; [root@fm18 yum.repos.d]# puppet agent \u0026ndash;test Info: Retrieving pluginfacts Info: Retrieving plugin Info: Caching catalog for fm18.xenlab.com Info: Applying configuration version \u0026lsquo;1434466089\u0026rsquo; Notice: Finished catalog run in 0.21 seconds [root@fm18 yum.repos.d]#\n[/bash]\n输入数字即可进入每个选项打开和关闭这个功能和服务，这个是对 foreman 的功能配置管理，不光是首次安装可以使用，以后的服务器功能变更也可以这么作，这个对我这样不感冒 answerfile 的人来说甚好。如果是首次安装，可以什么都不选择，来一个说装就装的默认安装也不错。安装完全成功之后，就会显示登陆网址和 管理与密码等信息。用初始的 admin 密码登陆后，修改密码，你的全新的 foreman 就安装成功了。注意在，运行 foreman-installer 过程中是需要联网的，安装过程会按照需求，下载所需要的组建包，例如数据库和 web 服务器等等其它必须的包。登陆后界面如下：\n[gallery size=\u0026ldquo;medium\u0026rdquo; link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;53781,53782,53783\u0026rdquo;]\n接下来需要作配置自动化的测试了，我做了一个录像，通过一个简单的示例来说明，如何在 foreman 中测试 pupput module。过程中我使用一个最简单的 /etc/motd 文件的配置的类。演示的内容涉及：\n[su_list icon=\u0026ldquo;icon: check-square\u0026rdquo;]\n安装 puppet module 到生产环境中\n导入并且定制 puppet 类的功能\n测试和验证 puppet 类是否工作正常\n[/su_list]\n视频下载：[su_button url=\u0026ldquo;http://pan.baidu.com/s/1ntpBXfN\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; background=\u0026quot;#cccccc\u0026quot; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: cloud-download\u0026rdquo;]下载在这里[/su_button]\n本文参考文档：\nhttp://theforeman.org/manuals/1.8/index.htm\nhttp://itgeeker.net/centos-7-epel-china-mirror-repository/\n","date":"2015-06-16T16:25:34Z","permalink":"https://martinliu.cn/2015/06/16/e59ca8-rhel-7-e4b88ae5ae89e8a385-foreman-1-8/","title":"在 RHEL 7 上安装 Foreman 1.8"},{"content":"如何安装：\n[bash]\nsudo dnf install powertop\nsudo powertop\nsudo systemctl start powertop.service\nsudo systemctl enable powertop.service\n[/bash]\n[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;53761,53762,53763,53764,53765\u0026rdquo;]\n使用 Tab 和 shift + tab 键在以上屏幕直接切换。\n我发现我主要使用 Tunables 这个 tab 来找出可以安全关闭的设备服务。以上测试是在我目前的 Fedora 22 on Lenovo T440s 上作的。\n本文参考：http://fedoramagazine.org/saving-laptop-power-with-powertop/\n","date":"2015-06-13T14:27:17Z","permalink":"https://martinliu.cn/2015/06/13/e794a8-powertop-e7bb99e7ac94e8aeb0e69cace794b5e88491e79c81e794b5/","title":"用 powertop 给笔记本电脑省电"},{"content":"Katello 的系统架构如下图：\nKatell 系统是一个复合型开源项目，是 Pulp, Candlepin 和 Foreman 的组合。Foreman 默认使用 Puppet 作配置管理。\n它的安装文档见官方手册：http://www.katello.org/docs/2.2/installation/index.html\n为了简化安装，请下在本站提供的 CentOS7 完美安装模板。使用它来创建一个虚拟机，6GB 内存，2VCPU；网络上为了方便，请在 virt-manger 中新建如下所示的网络。\n虚拟机启动之后，确保 host 能正常联网。启动刚才创建的虚拟机，配置好 IP，ping 外网网站，确保它能正常联网即可。其它安装命令如下：\n[bash]\nyum -y localinstall http://fedorapeople.org/groups/katello/releases/yum/2.2/katello/RHEL/7Server/x86_64/katello-repos-latest.rpm yum -y localinstall http://yum.theforeman.org/releases/1.8/el7/x86_64/foreman-release.rpm yum -y localinstall http://yum.puppetlabs.com/puppetlabs-release-el-7.noarch.rpm yum -y localinstall http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm yum -y install foreman-release-scl\nyum -y install katello\nkatello-installer -v \u0026ndash;foreman-admin-username admin \u0026ndash;foreman-admin-password smartvm \u0026ndash;capsule-dns true \u0026ndash;capsule-dns-interface eth0 \u0026ndash;capsule-dns-zone xenlab.com \u0026ndash;capsule-dns-forwarders 192.168.10.1 \u0026ndash;capsule-dns-reverse 10.168.192.in-addr.arpa \u0026ndash;capsule-dhcp true \u0026ndash;capsule-dhcp-interface eth0 \u0026ndash;capsule-dhcp-range \u0026ldquo;192.168.10.100 192.168.10.240\u0026rdquo; \u0026ndash;capsule-dhcp-gateway 192.168.10.1 \u0026ndash;capsule-dhcp-nameservers 192.168.10.10 \u0026ndash;capsule-tftp true \u0026ndash;capsule-tftp-servername $(hostname) \u0026ndash;capsule-puppet true \u0026ndash;capsule-puppetca true\n[/bash]\n以上的安装命令如果成功，katello 服务器将具有一下功能：\nForeman 服务器：用于自动化网络安装 linux 系统\nPuppet Master 服务器\nRepos 管理服务器\nDNS，DHCP，PXE 服务器\n安装成功之后，使用默认的用户名和密码就可以登陆了。\n","date":"2015-06-07T16:35:05Z","permalink":"https://martinliu.cn/2015/06/07/e59ca8centos-7e4b88ae5ae89e8a385e983a8e7bdb2katello2-2/","title":"在CentOS 7上安装部署Katello2.2"},{"content":"初始化安装 下载最新版 CentOS7 DVD 选择 mini 安装。\n网络配置 安装过程中设置了静态网络地址，如下：\n[bash]\n[root@centos7-tmp ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 TYPE=Ethernet BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=eth0 DEVICE=eth0 ONBOOT=yes DNS1=192.168.10.1 DOMAIN=xenlab.com IPADDR=192.168.10.8 PREFIX=24 GATEWAY=192.168.10.1 UUID=5fb06bd0-0bb0-7ffb-45f1-d6edd65f3e03\n[/bash]\n软件包 Change log:\nyum install wget telnet perl perl-devel net-tools kernel-devel\nyum install vim-enhanced.x86_64\nyum -y install git\nyum install acpid\nyum install tree\nyum install ntp\nyum install unzip\nRepo 软件更新源 Change log:\n初始化安装，添加了个几个国内的源\nrpm -Uvh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm\n/etc/yum.repo/bk/dvd.repo ；这个是在用 KVM 虚拟机挂 ISO 文件光驱的时候用的，到时候 mount /dev/cdrom /media/dvd , 把该文件方的夫目录中即可使用 iso 文件中的 repos\n当前的软件源如下：\n[bash]\n[root@centos7-tmp ~]# yum repolist Loaded plugins: fastestmirror Repository base is listed more than once in the configuration Repository updates is listed more than once in the configuration Repository extras is listed more than once in the configuration Repository centosplus is listed more than once in the configuration Loading mirror speeds from cached hostfile\nbase: mirrors.163.com epel: mirrors.neusoft.edu.cn extras: mirrors.btte.net remi-safe: remi.kazukioishi.net updates: mirrors.btte.net repo id repo name status base/7/x86_64 CentOS-7 - Base 8,652 epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 8,022 extras/7/x86_64 CentOS-7 - Extras 128 remi-safe Safe Remi\u0026rsquo;s RPM repository for Enterprise Linux 7 - x86_64 123 updates/7/x86_64 CentOS-7 - Updates 609 repolist: 17,534 [root@centos7-tmp ~]# [/bash]\n系统服务配置 Change log:\n关闭 SELinux\n关闭 NetworkManager\n关闭 FirewallD\nsystemctl enable acpid.service\n开启 truned-adm virtual-guest 服务模式\nsystemctl enable ntpd\n[bash]\n[root@centos7-tmp tuned]# tuned-adm list Cannot talk to Tuned daemon via DBus. Available profiles:\nbalanced blog latency-performance network-latency network-throughput powersave throughput-performance virtual-guest virtual-host Cannot talk to Tuned daemon via DBus. It seems that tuned daemon is not running, preset profile is not activated. Preset profile: virtual-guest [/bash]\n模板文件封装 用 sys-unconfig 关机。用 virt-sysprep, virt-sparsify 去除不必要信息，压缩。\n[bash]\n[root@martin-fedora vm]# ll -h total 12G -rw-r\u0026ndash;r\u0026ndash; 1 qemu qemu 81G Jun 5 22:36 centos7-tmp.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 81G Jun 5 22:34 centos7-tmp.qcow2.bk -rw-r\u0026ndash;r\u0026ndash; 1 root root 2.9G Jun 5 07:56 rhel66-clone-1.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 1.6G Jun 3 15:01 rhel66-clone.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 81G Jun 3 13:03 rhel66.qcow2 -rw-r\u0026ndash;r\u0026ndash;. 1 root root 81G Jun 1 00:59 rhel71.qcow2 [root@martin-fedora vm]# export TMPDIR=/home/martin [root@martin-fedora vm]# virt-sparsify \u0026ndash;compress centos7-tmp.qcow2 centos7-tmp-v1.qcow2 Input disk virtual size = 85899345920 bytes (80.0G) Create overlay file in /home/martin to protect source disk \u0026hellip; Examine source disk \u0026hellip; Fill free space in /dev/centos/root with zero \u0026hellip; 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 Clearing Linux swap on /dev/centos/swap \u0026hellip; 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 Fill free space in /dev/sda1 with zero \u0026hellip; Fill free space in volgroup centos with zero \u0026hellip; Copy to destination and make sparse \u0026hellip;\nSparsify operation completed with no errors. Before deleting the old disk, carefully check that the target disk boots and works correctly. [root@martin-fedora vm]# ll -h total 12G -rw-r\u0026ndash;r\u0026ndash; 1 qemu qemu 81G Jun 5 22:36 centos7-tmp.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 81G Jun 5 22:34 centos7-tmp.qcow2.bk -rw-r\u0026ndash;r\u0026ndash; 1 root root 520M Jun 5 23:11 centos7-tmp-v1.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 2.9G Jun 5 07:56 rhel66-clone-1.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 1.6G Jun 3 15:01 rhel66-clone.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 81G Jun 3 13:03 rhel66.qcow2 -rw-r\u0026ndash;r\u0026ndash;. 1 root root 81G Jun 1 00:59 rhel71.qcow2\n[/bash]\nyum update -y 2015-07-10 : Done yum updated. 删除了不需要的 Kernel，安装了 unzip, 修改启动过程为直接文字启动。\n2015-11.15: update kernel to 7.1, set old kernel 1: package-cleanup \u0026ndash;oldkernels \u0026ndash;count=1\n使用方法 root 密码 martinliu.cn 开机后记得一定要先修改。\n百度网盘下载地址 [su_button url=\u0026ldquo;http://pan.baidu.com/s/1pJurap9\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: codepen\u0026rdquo;]centos7-tmp-v7[/su_button]\n","date":"2015-06-05T15:44:52Z","permalink":"https://martinliu.cn/2015/06/05/e5ae89e8a385e5ae8ce7be8e-centos7-e8999ae68b9fe69cbae6a8a1e69dbf/","title":"安装完美 CentOS7 虚拟机模板"},{"content":"今天是红帽服务团队深圳 Bootcamp 的最后一天，我是最后一个 session 的演讲者，讲的内容是补丁管理，这是个老生常谈的话题，看看我怎么构思和解读的。\n[su_button url=\u0026ldquo;http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/06/Patch-Management.pdf\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; size=\u0026ldquo;2\u0026rdquo; icon=\u0026ldquo;icon: cloud-download\u0026rdquo;]PPT 下载在这里[/su_button]\n主要思路还是把目前的相关知识梳理一边。特别是借鉴了公司安全大师 Shawn 的一些内容。\n玩好防塔游戏 把操作系统的该打的补丁都打好，避免已知漏洞的暴露。\n做好安全加固 修补 Achilles 的脚后跟，是说把安全配置基线落实到系统中，并行成为长效保持机制。\n其实这些还是和配置管理有关和 CMDB 有关，真是老生常谈呵呵\n","date":"2015-06-04T05:15:53Z","permalink":"https://martinliu.cn/2015/06/04/achillese79a84e8849ae5908ee8b79f/","title":"Achilles的脚后跟"},{"content":"下面是随手的几个截图。\n一部分 F22 新功能评测在这里 http://fedoramagazine.org/whats-new-fedora-22-workstation/\n","date":"2015-05-28T16:02:23Z","permalink":"https://martinliu.cn/2015/05/28/fedora-22-e4bdbfe794a8e4bd93e9aa8ce4b88de99499/","title":"Fedora 22 使用体验不错"},{"content":"Kenote 的在我的工作中已经完全替代 PPT 了。其实我的电脑上还有 LiberOffice，不过要编写什么 ppt，还是必须要使用 Keynote，这可能就是所谓的由奢入俭难吧，哈哈！\n通常做完的 Slides，还需要导出成 ppt 和 pdf 格式，然后上传到网盘上，一般在讲完当天，就最好能通过微信把下载链接发给用户。想想十多年来也做了至少上万页的 ppt，可恶的事工作性质其实还没有太大变化。\n现在看着这个课程，有点想法是：是否有必要把自己的重要的 ppt 也录制成课程，做系列的播出。没准也能卖出几千份哈哈\n","date":"2015-05-24T15:08:31Z","permalink":"https://martinliu.cn/2015/05/24/e68891e5b7b2e7bb8fe5be88e4b985e6b2a1e794a8ppte4ba86/","title":"我已经很久没用ppt了"},{"content":"No Content Found\n","date":"2015-05-24T08:37:06Z","permalink":"https://martinliu.cn/2015/05/24/fedora-22-e5b086e4ba8e5e69c8826e697a5e58f91e5b883/","title":"Fedora 22 将于5月26日发布"},{"content":"ppt 点这里下载：[su_button target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; size=\u0026ldquo;2\u0026rdquo; icon=\u0026ldquo;icon: cloud-download\u0026rdquo;]下载[/su_button]\n参考文档： AS 深圳 2014 演讲 PPT 最终稿 http://pan.baidu.com/s/1i3KQFRJ QCon 北京 2015（PPT） http://pan.baidu.com/s/1sj2t1yl 这两个目录里面干货还是不少，可以下载了慢慢看。\n学习了一写文档后，逐渐对互联网公司的架构挑战需求和现状有了一些了解。下面先聊下这方面的一些理解。\n中国规模交易量 什么叫中国规模交易量，以淘宝 2014-11-11 双十一当天的数据举例：\n[su_list icon=\u0026ldquo;icon: rocket\u0026rdquo;]\n交易创建 80000 笔/秒 支付 38000 笔/秒 24 小时完成交易额 571 亿元人民币 // 93 亿美元 [/su_list]\n乍一看这个数字可能没什么感觉，可以比较一下美国的情况。全美所有的传统商场在“黑色星期五”一天的销售也仅为 91 亿美元，即使加上网络销售的 24 亿美元也比天猫“双十一”多不了太多。也就是说，美国黑五当天全网的电商是中国淘宝/天猫一家的四分之一。\n因此中国人口基数大，网民数量大，假如您能激起大众的兴趣的话，你是不缺访问量的。对于意外的大规模的峰值访问量的处理，如果系统架构和应用没有提前经过特别的架构调整、优化；用膝盖都能想到系统挂掉、基础架构崩溃、交易数据出错是必然的事情。\n理解到这个潜在的风险、需求和调整，我们所有设计和从事 IT 基础架构技术服务的人，可以想想，不向前看，不向 BAT 学习，不站在他们的肩膀上设计和调整自己的应用的话。想保证系统平安，除非业务是失败的业务（没有流量），否则没有平安可言。\n架构特点 且不说马云家系统已经多么牛叉，我们看下京东的架构，我们也可以看到其架构设计在两个维度都非常清晰到位。业务架构维度上尽可能的松耦合，所有业务单元分解清晰，貌似莫名的遵循了分布式架构的要求；这样每个业务单元都可以对 IT 资源的消耗联动，弹性的供给必要的业务处理能力。IT 架构维度上分解为三个层次：应用架构、数据架构、基础架构。基本上 JD 的这个 PPT 改变了我对这个企业的印象。从我的职业经验告诉我，这份 PPT 中规中矩，比较专业，堪称教科书式的架构设计。相对马云家的架构师的 PPT 图画的比较豪放，风格不同。JD 这份 PPT 下载在这里。\n[su_button url=\u0026ldquo;http://pan.baidu.com/s/1o6MI0t0\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; size=\u0026ldquo;2\u0026rdquo; icon=\u0026ldquo;icon: cloud-download\u0026rdquo;]AS 深圳 2014 京东架构设计-吴博[/su_button]\n除了分层细致设计业务架构之外，我们还能看到，电商公司多使用多数据中心多活的模式并发处理海量交易量，每个数据中心都可以处理全业务，都能在灾备和并行处理上一石二鸟。这和我们高贵的传统企业不同，他们往往可以实现同城双中心运行，异地数据中心往往是灾备中心；有些灾备切换并不是全业务的切换，有些灾备中只用于灾备切换演练，并不真的运行业务；有些异地灾备中心也会和主数据中心中的一部分业务做周期性的切换运行。这些高贵的客户往往把核心的数据放在主机上，这在他们想扩展到 3 个或者更多个数据中心的时候，略显尴尬；新增的数据中心也要配置一套新主机系统么？新的主机上数据和应用怎样快速迁移过来？需要多长时间？数据同步的和其他两个数据中心一致么？这些问题的回答都不简单？主机硬件固然是贵？但是所有问题都解决周全的话，可能更贵。\n全新的纯 X86 的架构就在面前，BAT 已经证明了它和开源技术组合在一起就是多快好省的架构。因此，IT 架构的转型也成了必然选择。试想转型之后的机房，每个机架都是标准化的工作单元，它可能是几种类型：纯物理机计算节点、纯虚拟机计算节点（服务器虚拟化或者 OpenStack 等）、纯物理机存储节点（软件定义存储）；或运行容器的物理机或者虚拟机。另外机架上的网络设备和核心网络设备必然有他们自己的设计。这是我的一个猜测，有机会还需要和 BAT 的人多了解。\n开源技术 BAT 用到的开源技术真的是不甚枚举，也没有必要逐一分析。基本上各个领域里从开发堆栈、到架构堆栈和运维管理堆栈；各个方面的前几位的项目都有实践和应用。\n红帽 那么红帽的互联网平台解决方案是什么？红帽的定位是基础架构技术厂商，因此红帽的全套技术框架就是它的互联网解决方案。如下图所示。\n有些产品模块需要稍微说明一下，方便和开源项目对应起来。\n[su_list icon=\u0026ldquo;icon: linux\u0026rdquo;]\nRed Hat Storage server / ICE : Gluster, Ceph Red Hat Enterprise Linux : Fedora Linux RHEV-M : Ovirt - 服务器虚拟化 RHELOSP ： OpenStack 企业版 IaaS 平台 OpenShift ：OpenShift 社区 JBoss : JBoss 社区 Satellite ： Puppet + Foreman 等等其它配置管理工具 CloudForms ：CloudForms 社区 - 混合云管理 [/su_list]\n红帽的技术支持范围还包括很多操作系统内的功能组件，包括：HA-Proxy，LVS，MySQL 等等。在技术面的广度上，并不限于以上框架图。不过那幅图是全堆栈的最简易的展示。\n","date":"2015-05-17T06:29:33Z","permalink":"https://martinliu.cn/2015/05/17/redhate4ba92e88194e7bd91e5b9b3e58fb0e8a7a3e586b3e696b9e6a188/","title":"RedHat互联网平台解决方案"},{"content":"不是好不好，而是用不用？ 要说 OpenStack 的优点，技术人员能说出一堆词汇，如开源、弹性、稳定、可扩展、迅速搭建私有云、对硬件要求不高、解耦、能快速扩展新业务等等。但实际应用的案例为何这么少。\n国内传统企业用的少，互联网公司用了不少了，创业公司捣鼓 OpenStack 部署公有云服务的业务也不少了，总体看 OpenStack 水平高的人不在数量巨大的传统企业里，当前人员也不存在这个流向，更重要的是传统企业没有合适的在 OpenStack 上跑的 workload。因此少。\n一个数据是，这两年计划部署 OpenStack 的企业为 84%，可见大多数企业仍观望。这问题出在哪里？\n原因同上。\n技术仍旧是问题。OpenStack 的问题是半年快速迭代，发布新产品，速度太快，老版本跟不上。理论上，新版本向下兼容。但在一些版本较大改动，加入新的功能时，如果企业已经深度应用了旧版本，可能面临技术无法升级，或者需要重度开发的问题。\n开发改动大么？那些地方大改动了？深度开发的部分是什么组件？是遵循了向下一个版本兼容的原则了么？代码提交会社区了么？OpenStack 社区版升级了，企业就一定要升级旧的版本么？什么情况下升级版本？什么情况下打补丁知道么？OpenStack 是云操作系统，我们看到的常见的开发场景是：界面友好度的调整、虚拟机功能的增强、辅助管理功能的增加等等。如果基于某个版本把这些附加功能开发出来了，其实业务需求清晰和随后调整不大的话，其实是可以用一定时间的。升级有两个原因：修复 bug，增加新版本的功能。我见过创业公司把之前开发的东西一次一次废掉重来的情况，主要原因还是他们首先不能提交代码会社区，其次开发的东西不是外挂式和主框架松耦合的。企业面对开发是谨慎的，往往不会在投入大量功能评估后，在清晰的需求下二次开发。二次开发做的多得还是想做 OpenStack 生意的创业公司，而传统企业的这些金主客户，我感觉他们还真没有这个需求和闲工夫。因此开发重，不能平滑进入下一代新版本不是用的少和不用的原因。\n另外与企业规模有关。多大企业需要使用 OpenStack，需要部署在哪些生产环境，是否是全面替代，还是迁移，包括从 VMware 迁移到 OpenStack，或者是新应用局部部署 OpenStack？这些不考虑清楚，没办法应用。\n这是一个很普遍的误区，太多人这么想了。从 VMWare 迁移到 OpenStack 真的这么重要么？真的存在这个场景了？服务器虚拟化和 OpenStack 是两种同类型的基础架构技术。服务器虚拟化跑传统的有状态应用；OpenStack 跑需要弹性扩展的无状态应用。有状态应用不适合跑在 OpenStack 上。也不太可能不做任何改变就能适应 OpenStack 环境。企业的无状态应用少，但这是一个发展过程和阶段。原因在于无状态应用和合适在 OpenStack 上跑得 workload 太少了。企业目前的应用 workload 是因，OpenStack 部署少是果。不存在 OpenStack 替代服务器虚拟化的事情，他俩会并存很长时间，不是非黑即白的替代逻辑。\n当前看，对企业应用需求的评估太少，大多是 IT 产业（厂商）一头热，鼓吹 OpenStack 太好，反而令人生疑。\n说的好就怀疑了？这里说的应用需求评估有两方面。或者两个理解方向。这里可能是说 OpenStack 功能性方面，客观的讲，当一个技术在风口上的时候，说好话的多，这是客观规律，多年前服务器虚拟化也这样，现在热度低了，它再发新版本大家连个搭理的功夫都没有了，也没有啥评测文章出来，这都是自然规律。OpenStack 也有失去热捧的那天，我最近看了一些基于它创业的技术型公司也都在反思和总结经验中。\n怎么用，谁来带头？ 当前案例也有，如电信运营商阿尔卡特朗讯（名字太长，以后会不会再加上西门子诺基亚）、诺基亚、西班牙电信；汽车领域宝马汽车、银行企业西班牙 BBVA、传媒领域时代华纳有线等。这些企业具有标杆意义，不具有示范效应。企业规模不一样，生产环境不同，这是最大的不同。这些案例最明显的是以信息为核心资源的企业，IT 系统建设较为完善和复杂，有意愿、有钱尝试新的 IT 技术。\n规模、环境、以信息为核心资源、IT 成熟、有意愿、有钱；这些都不能说成是中外企业 IT 的差异，也完全和是否用 OpenStack 无关的因素。我朝存在大量的传统大型企业，都已经排名全球 100 强了，很多是我们的客户。它们的市值比以上公司大得多。举个例子：CCB 的市值是 2015 年 4 月 30 日 - 成交量 4.88 亿股 市值 18,151.51 亿；宝马的市值是 2012 年 12 月 宝马市值增至奔驰两倍 达 3700 亿元；这么高大上制造型企业，连 CCB 的零头都不如。\n总体看，当前应用较多的是 IT 产公司（包括互联网公司），国内互联网公司如去哪儿、携程等公司都有应用。\n传统的金融部门呢，我国核心的制造企业呢？可能本人孤陋寡闻，如果多一些传统企业的案例会好一些。\n做过 OpenStack 测试的，验证过功能的很多，包括我以前了解的 CloudStack 的测试和评估也很多。金融行业企业它们都懂 OpenStack，甚至有些做定制开发的也有。这些作者可能确实看不到。他们已经准备好了，时间到了，无状态的合适的 workload 出现了，OpenStack 这种东西自然就上去了，根本不用急着看案例。\n这么多企业如何选择？ 每个厂商说完 OpenStack 的好处之后，必然要说自己公司长处，这对用户来说，容易困扰：市面上一堆的 IT 企业，该如何选择？比如中国，传统 IT 企业几乎都有 OpenStack 的团队，如红帽、HP、戴尔、IBM、华为等；还有些初创企业如 AWcloud 、99cloud 等，也是不容忽视的力量。\n企业自己的 OpenStack 专业团队还真不多见，现在传统企业还没有合适 workload 就养一堆 OpenStack 工程师是罕见的。\n红帽说自己的优点是，在开源方面具有优势，懂底层的代码，而像 HP 这样的公司，自己写了 Unix 代码，比较封闭等。它强调的是开源。\n红帽就是做开源的，无需强调开源了好么？这也不是红帽的优势。红帽在 OpenStack 上做的工作和他在 RHEL 上的工作、和在 JBoss，在 Ceph，在其他任何产品上做的工作和优势没有任何差异，就是“提供企业支持”，提供长生命周期的企业支持。懂底层代码的人很多很多，红帽其中的一部分。而从公司层面，提供商业化发行版，并且对其发出的每个版本做长生命周期的企业支持和服务，是很少的公司可以做的。这是红帽的优势。作者对开源业务模式欠了解。\n当然，像华为这种公司也可以强调是软硬件通吃，更能提供整体的解决方案。像联想这种公司，可以强调资金实力和技术实力，以及对行业的理解能力。\n不评价。\n都有道理，如果要选择，还是选择资金实力、历史悠久的公司可能靠谱一些。有些初创企业在技术上领先，但它们的首要问题是活下来，才能保障 3~5 年的服务期。\nOpenStack 的全方位长期的核心级别技术服务是很重要的。\n运维之后，是否被绑定 IT 公司？ 企业要上 OpenStack，最缺的是技术人，而不是钱、技术等问题。\n市场上 OpenStack 人员不少了，真的有岗位出来，肯出钱，从业者不成问题。\n着重说明的是，OpenStack 不是产品，只是架构。所以，在开源社区开发的各类版本，只有在“封装”之后才可以使用。一般的企业不具备这种技术实力，所以需要 IT 公司帮助实施、运维、开发等工作。\n封装之后可用是个普遍的错误观点，纯属于界面看着难受不改就不用的想法。选择合适的发行版，附加有能力的公司来做架构设计和实施，虚拟机就可以跑起来了，就可以上线了。不做定制开发就用了的也大有人在。我也问过一个云计算创业的公司，你们用的什么版本？回答是我们选择了一个版本就是部署了，碰到 bug 我们自己的研发就看代码搞定了。它们关注的事提供虚拟机给客户，这才是业务。\n极端的情况，假如企业用了 A 公司提供的某个版本的产品，A 公司忽然倒闭或者技术实力跟不上，无法后续运维，B 公司接手是否可行？理论上可以，由于代码开源，B 公司可以直接读 A 公司开发过的产品；但实际操作，要看系统规模的大小，以及复杂度。毕竟，当前是推广阶段，这种实施失败的案例极少。\n要看开发的是什么？有代码就可以维护的。规模大小和复杂是无法接手的因素么？他俩加一起也不能就直接推出接不上手吧？在这种场景下，现实项目的操作实践是，抛弃 A 公司做的，B 公司再从头做一遍。看到的项目案例也是这样。\n中国企业的贡献有多大？ 如果只从基金会来看，中国企业仍旧没有进入核心层。基金会的白金会员只有 8 个名额，AT\u0026amp;T、惠普、IBM、Inetl、Rackspace、Red Hat 和 SUSE 等，每年缴纳 50 万美金的费用。除非有企业退出，否则不可能进入。在最新的 Kilo 版本中，按照贡献代码数来计算，中国企业贡献最多的几位是华为、99Cloud、Awcloud、Kylin Cloud（为啥都叫 Cloud）；尤其是华为，代码贡献是 2681，远超其他公司。有嘉宾解释这个排名时说，华为人也太多了，别家都是初创企业，比不了。这种大公司一旦下决心布局，立即显示出整体的优势，举个例子，如联想在 2015 年 1 月加入基金会，3 月就正式成为企业代码贡献者，以它的战略和技术背景来看，绝对是 2015 年黑马。当然，初创公司的专注度、贴身的服务能力、快速的反应能力，也是大公司比不了的，各有所长。中国企业在这一轮技术升级中，几乎都抓住了好机会。接下来要比战略和市场行动了，其实是一场长跑。\n国人对 OpenStack 的贡献多少？和企业是否用 OpenStack 也没有必要的联系。OpenStack 的出现，也不是给企业 IT 带来整体升级的机会。现实看 OpenStack 只是一种基础架构技术而已。它和传统的服务器虚拟化技术是同层面的东西。只是它带有更多的和网络存储技术的相关性；特别是在网络、存储相关的技术上确实颠覆传统技术的势头十足。但是这只是现象。实际变了么？\n后续问题是什么？ 总体感觉，OpenStack 已经过了市场炒作期，完胜其他三个开源架构；但处于普及期，尚未真正进入大规模的应用阶段。有技术原因，也有市场原因，还有厂商推广原因。比如技术，每一个版本的功能是否有较大提升，在新技术之间的快速迭代和平衡问题，怎么做好开源的商业化问题，又不能受控于几家核心的企业？在打包后的产品中，怎么解决各个厂商分化的问题？\n纠结下一个版本新功能的人，属于根本不知道自己当前需要使用 OpenStack 什么功能的人。上游大厂的利益划分和最终对用户的影响并不大。各个厂商提供的功能和模块往往是不冲突的，即使是是重叠了，对用户也是好事。OpenStack 架构最大的好处就在于，它是分布式架构，任何一个用户不可能用足它的全功能场景。常规跑虚拟机的场景用到了 OpenStack 的全套功能的很小一部分。当然 OpenStack 社区虽然没把用户的利益完全放在第一位，对用户来说，用户是由自由选择其中的任何功能组件的，就是搭积木而已。\n比如市场，对于企业来说，如何选择合适的机会应用，这考量 IT 企业对 OpenStack 的全面评估以及对自己业务的评估，而不仅仅站在 IT 的角度看技术发展。其实，最考验的是 IT 厂商的交付能力、运维能力以及服务能力，这才是最关键的。没有交付能力的 IT 厂商，你再吹捧 OpenStack 的好处，那也是别人家的，也是圈子内的，和你没有一毛钱关系。用户要的是效率，是业务的可靠性和连续性，是 IT 的扩展性和精简、敏捷、高效，不站在用户角度推广 OpenStack 的厂商就是耍流氓。\n红帽本身来讲看的还是发布的发行版是否足够稳定，是否修复了足够的 bug，是否在安装部署方面有提升。其它交付和运维等等是周边生态系统公司的范围。红帽对 OpenStack 社区的重要价值，还在于向社区提交 bug 修复，这些 bug 很多都是红帽客户碰到的。一旦提交成功了，未来版本中基本就没有这个问题了。\n真实情况是，云计算还没有真正普及，怎么谈 OpenStack 的应用呢？\n敢问云计算怎么才算是真正普及？OpenStack 也不是填饱肚子的最后一个馒头。云计算相关技术发展的还不够快么？君不见容器如日中天么？那天人们谈云计算，不谈 OpenStack 的可能都有，OpenStack 只是云计算发展过程中的一个场景而已。\n比如推广，要接地气，要说人话，不能自说自话，一厢情愿的说自己好。\n凡是开这种会，没人说自己不好的对么？\n在饭桌上听来的段子。在香港 OpenStack 峰会中，某企业也学其他厂商发帽子，由于企业 LOGO 是绿色的，它发的竟然是“绿帽子”。还有一家企业，觉得要贴合中国元素，在展台挂上了灯笼。不过是“白灯笼”，不是红灯笼。可想而知，这两排慎人的白灯笼，距离用户有多远就滚多远吧。\n。。。。。！！！！\n原文微信：http://mp.weixin.qq.com/s?__biz=MjM5MzYwMTE5OQ==\u0026amp;mid=205642335\u0026amp;idx=1\u0026amp;sn=abc8da56bfa748c895a6f7e61ee70d7c\u0026amp;scene=1\u0026amp;key=1936e2bc22c2ceb550a9ed47d35d37ac6649fc2fd92aedfaeae9a37f83c1bc9a01d8c07369a095226703791790b8081a\u0026amp;ascene=0\u0026amp;uin=ODYyMzEyOTQw\u0026amp;devicetype=iMac+MacBookPro8%2C1+OSX+OSX+10.10.3+build%2814D136%29\u0026amp;version=11020012\u0026amp;pass_ticket=9113SDOfWN%2BqnP3yogS7%2FwP2x2VDHEgF3ksia4%2Bbngq1OKnK1y4ajPkfu8mgg8MO\n","date":"2015-05-14T16:36:27Z","permalink":"https://martinliu.cn/2015/05/14/openstack-enterprise-ready/","title":"OpenStack Enterprise Ready"},{"content":"[bash] [root@rhevm03 export]# cat /etc/exports /var/lib/exports/iso _(rw) /export/rhev_import_export_disk _(rw,sync,no_subtree_check,all_squash,anonuid=36,anongid=36) /export/template *(rw,sync,no_subtree_check,all_squash,anonuid=36,anongid=36)\n[root@rhevm03 export]# engine-image-uploader -N cfme5351 -e export-nfs-rhevm -v -m upload /tmp/cfme-rhevm-5.3-51.x86_64.rhevm.ova [/bash]\n然后从 Web Console 上导入这个模板，创建一个目标规格的虚拟机。\n","date":"2015-03-30T03:13:47Z","permalink":"https://martinliu.cn/2015/03/30/import-cloudforms-into-rhevm/","title":"Import CloudForms  into rhevm"},{"content":"\nPractical Linux Infrastructure by Syed Ali Link: http://amzn.com/148420512X\n[gallery size=\u0026ldquo;medium\u0026rdquo; ids=\u0026ldquo;53654,53655\u0026rdquo;]\nCI/CD 要自动化尽可能多的测试案例，从而对代码获得更多的信心。另外，它还要执行一个完整的软件系统的 build，并确保 checked in 的代码并不会搞坏其它东西。任何失败，开发人员都不得不去调查原因。有这样的一些软件可以帮助实施 CI/CD 的 pipeline：\n[wm_list bullet=\u0026ldquo;icon-linux\u0026rdquo; class=\u0026quot;\u0026quot;]\nJenkins (http://jenkins-ci.org)\nCruiseControl (http://cruisecontrol.sourceforge.net)\nBuildbot (http://buildbot.net)\n[/wm_list]\n公有云解决方案比私有云方案是不是更贵还是便宜，这取决于企业的规模。\n","date":"2015-03-29T14:10:37Z","permalink":"https://martinliu.cn/2015/03/29/practical-linux-infrastructure/","title":"Practical Linux Infrastructure"},{"content":"在本网站的网页永久链接结构性调整了之后，本以为搜索引擎更新会是一个缓慢的过程，今天去 bing 和 baidu 一看，简单翻了若干页之后，发现已经全部更新完毕了。而且搜索 ： site:martinliu.cn 返回结果的顺序也和以前不一样了。貌似旧文章比较靠前，不过顺序无所谓，只要指向的链接完全 OK 就可以了。\n","date":"2015-03-29T13:40:16Z","permalink":"https://martinliu.cn/2015/03/29/wordpress-update/","title":"wordpress update"},{"content":"服务器虚拟在我的 lab 中是必选项，管理控制器端 RHEVM 安装在主服务的一个虚拟机里面。在主服务器上使用 targetcli 做了一个 iscsi 的共享存储。使用这个命令可以方便的实现 iscsi 设备。把最终的存储文件放在了 SSD 盘上的一个 100GB 的瘦制备文件上。 [bash] ╭─root@w540 ~ ╰─$ targetcli targetcli shell version 2.1.fb37 Copyright 2011-2013 by Datera, Inc and others. For help on commands, type \u0026lsquo;help\u0026rsquo;.\n/\u0026gt; ls o- / \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [\u0026hellip;] o- backstores \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [\u0026hellip;] | o- block \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [Storage Objects: 0] | o- fileio \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [Storage Objects: 1] | | o- iscsi1 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [/root/iscsi01.img (100.0GiB) write-back activated] | o- pscsi \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [Storage Objects: 0] | o- ramdisk \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Storage Objects: 0] o- iscsi \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Targets: 1] | o- iqn.2003-01.org.linux-iscsi.w540.x8664:sn.82939fa1cd49 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [TPGs: 1] | o- tpg1 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [no-gen-acls, no-auth] | o- acls \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [ACLs: 0] | o- luns \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [LUNs: 1] | | o- lun0 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [fileio/iscsi1 (/root/iscsi01.img)] | o- portals \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [Portals: 1] | o- 0.0.0.0:3260 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [OK] o- loopback \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Targets: 0] /\u0026gt; [/bash]\n以上 iscsi 的存储配置参考：https://access.redhat.com/solutions/894163\n如果需要让所有的节点都能无障碍访问 iscsi 存储，就需要把 acl 设置为允许所有节点访问。使用下面这个命令\n[bash] /\u0026gt; iscsi/iqn.2003-01.org.setup.lun.test/tpg1/ set attribute authentication=0 demo_mode_write_protect=0 generate_node_acls=1 cache_dynamic_acls=1\nParameter demo_mode_write_protect is now \u0026lsquo;0\u0026rsquo;.\nParameter authentication is now \u0026lsquo;0\u0026rsquo;.\nParameter generate_node_acls is now \u0026lsquo;1\u0026rsquo;.\nParameter cache_dynamic_acls is now \u0026lsquo;1\u0026rsquo;.\n/\u0026gt; ls\no- / \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [\u0026hellip;]\no- backstores \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [\u0026hellip;]\n| o- block \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [Storage Objects: 0]\n| o- fileio \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Storage Objects: 0]\n| o- pscsi \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [Storage Objects: 0]\n| o- ramdisk \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [Storage Objects: 1]\n| o- test1 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [nullio (100.0MiB) activated]\no- iscsi \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [Targets: 1]\n| o- iqn.2003-01.org.setup.lun.test \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [TPGs: 1]\n| o- tpg1 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [gen-acls, no-auth]\n| o- acls \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [ACLs: 0]\n| o- luns \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [LUNs: 1]\n| | o- lun0 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [ramdisk/test1]\n| o- portals \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Portals: 1]\n| o- 12.12.12.1:3260 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [iser]\no- loopback \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [Targets: 0]\no- srpt \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Targets: 0]\n/\u0026gt; saveconfig\nLast 10 configs saved in /etc/target/backup.\nConfiguration saved to /etc/target/saveconfig.json\n/\u0026gt; exit\nGlobal pref auto_save_on_exit=true\nLast 10 configs saved in /etc/target/backup.\nConfiguration saved to /etc/target/saveconfig.json [/bash]\nRHEVM 的安装过程非常简洁，基本用 Satellite 配置了一下它所需要的 repos，做好视图，然后就推送给了一个 kvm 虚拟机，使用 pxe 安装好之后就行了。\nRHEVM 需要的 repos 和基本的安装命令： [bash]\nsubscription-manager repos \u0026ndash;enable=rhel-6-server-rpms subscription-manager repos \u0026ndash;enable=rhel-6-server-supplementary-rpms subscription-manager repos \u0026ndash;enable=rhel-6-server-rhevm-3.5-rpms subscription-manager repos \u0026ndash;enable=jb-eap-6-for-rhel-6-server-rpms subscription-manager repos \u0026ndash;enable=rhel-6-server-rhevh-rpms yum install rhevm rhevm-dwh rhevm-reports engine-setup [/bash]\n回答完 engine-setup 的所有问题就可以登录风格统一的黑底色的 RHEM 界面了。实际上有三个登录界面：用户的，管理员，和报表的。\n下面需要安装跑虚拟机的 Hypervisor 了，RHEV 的 Hypervisor 有两种，一种是精简话的裁剪 rhel 版本叫做 RHEVH（偏向 vshpere 的做法），还有一种就是 rhel 的标准版，然后安装 Hypervisor 相关的包（偏向 OpenStack 的做法）。下面我会安装第二种做法。目的是：我有两台相同配置的计算节点，我希望把动态的变更他们的功能；一会做 RHEV 虚拟机的演示，一会做 OpenStack nova 的演示。\n用了一个组合视图安装了这两个服务器虚拟化节点。组合视图里如下所示： 如上图所示：1）视图 1 是基础的 RHEL 操作系统 repo；2）视图 2 是 RHEV 相关的 repos 视图，其中包括了安装 RHEVM 和 host 的所有需要的 repo。考激活秘钥控制每个 repo 的默认是否开启，它们对安装后的 os 可见，但是默认并不是开启的，因此，我设置 rhevm 和 jboss 为默认关闭的，由于安装 rhev host 的情况比较多，需要安装 rhevm 的话，可以手动 enable 这需要的 repos 即可。\n安装和配置完存储之后的 RHEVM 控制台： 目前由于没有安装 OpenStack 环境，所以没有 Glance 服务，因此 iso 镜像只能暂时放在了 dis06 的一个服务器虚拟化 Hypervisor 节点上，目前是临时的方案，回头一定把 iso 放到 Glance 服务上 host。\n下面上传一个 iso 之后就可以创建虚拟机了。 [bash] [root@rhevm03 ~]# engine-iso-uploader \u0026ndash;iso-domain=iso-dis06 upload /tmp/turnkey-jenkins-13.0-wheezy-amd64.iso Please provide the REST API password for the admin@internal oVirt Engine user (CTRL+D to abort): Uploading, please wait\u0026hellip; ERROR: mount.nfs: Connection timed out\n[/bash]\n由于这个命令上传不成功，也不想排错了；到目前这个状态其实就可以在 Satellite 里面使用 RHEV 的资源提供者的方式来安装虚拟机了，如下图所示：\n手动创建 RHEV 虚拟机 1：通过 New Host 设置相关参数。选择 Deploy on 为 rhevm03（rhevm），这个配置让 sat6 去联系 RHEVM，rhevm 的配置信息必须提前输入到 sat6 中。然后还要在 sat6 中设置虚拟机的三种规格，就是 Computer profile 中的选项，这个选项确定了 cpu，ram，磁盘和网络等信息。剩下的就是最重要的 Lifecycle Evn 和 Puppet Env 了，这两个选项确定把系统安装为标准的 rhel6 的核心最小化安装。当然可以一次性完成某种应用的全套安装和配置。\n手动创建 RHEV 虚拟机 2：通过 Virtual Machine 参数可以看到 1，2，3 都来自标准的规格配置，如果需要手动修改的话，可以在这里修改，这里可以看到默认的存储是 w540-iscsi-lun0 这个之前在 RHEVM 里面配置好的 iscsi 存储。\n手动创建 RHEV 虚拟机 3：点击提交之后，sat6 就开始了实时创建 rhev 虚拟机的过程，sat6 使用 REST API 告诉 RHEVM 这些信息，然后 RHEVM 再确定使用哪个 Hypervisor 来建立并运行虚拟机。\n问题来了：如果需要在 RHEV 资源池里建立 n 个相同配置的虚拟机，管理员该如何操作？\n在 sat6 里面，管理员重复以上操作，当然需要手动操作 n 次。这样是不是很麻烦，确实很麻烦！！如何解决？这就需要一种能够实现 Orchestration 功能的工具来做，也就是自动化编排工具。这种工具最好是统一的能够跨异构资源池的，能够满足如下需求：今天企业可能是纯的 vshpere 的虚拟化环境，接下来企业有可能引入其他服务器虚拟化资源池技术，如：RHEV，Hyper-V；在以后还可能引入 OpenStack 资源池。那么这种自动化编排工具和底层的类似 satellite6 的（标准化部署工具）必须形成一个统一的平台来操作所有异构的资源池。也就是说：在 Orchestration 工具中统一管理异构资源池，并配合标准化部署工具，实现 workload 的标准化自动化部署。红帽的 Orchestration 工具是 CloudForms。它能够对接业内所有流行的资源池，如下图所示：\n上图是 Satellite 的上层 Orchestration 的能力，底层必须还有标准化的部署工具支持，也就是 Satellite6，它对以上基础架构类型的支持情况，如下图所示：\n使用 CloudForms 做上层 Orchestration 的调度，必须依赖于底层的 workload 的标准化，标准化到什么程度，从虚拟机供给的角度可以参考 Amazon AWS 的 EC2 的实际案例。如下图所示：\nAWS 服务的我曾研究过一点，上图的全图下载点这里 \u0026ndash;\u0026gt; aws-服务-脑图\n以上所有是 Martin\u0026rsquo;s Lab 的搭建的一部分，下周可能去一个银行客户演示。需要做的优化还很多，请关注后续更新。\n","date":"2015-03-27T02:11:40Z","permalink":"https://martinliu.cn/2015/03/27/e69c8de58aa1e599a8e8999ae68b9fe58c96-rhev/","title":"服务器虚拟化 RHEV"},{"content":"\n安装 zsh 在任何系统上几乎都是差不多。Zsh 是一款功能强大的交互式 shell，与 Bash 相比，Zsh 下面几点表现令人印象深刻：\n[wm_list bullet=\u0026ldquo;icon-linux\u0026rdquo; class=\u0026quot;\u0026quot;]\n自动补全\n拼写纠错\n定制性强\n美观的命令提示符（这点吸引力最大）\n[/wm_list]\n相信你安装之后，对上面几点会有更加真切的感受！\n下面是 RHEL 7 上的安装过程。\n[bash]\n[root@w540]# yum install git [root@w540]# curl -L https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh | sh [root@w540]~# cat .zshrc\nPath to your oh-my-zsh installation. export ZSH=/root/.oh-my-zsh\nSet name of the theme to load. Look in ~/.oh-my-zsh/themes/ Optionally, if you set this to \u0026ldquo;random\u0026rdquo;, it\u0026rsquo;ll load a random theme each time that oh-my-zsh is loaded. #ZSH_THEME=\u0026ldquo;robbyrussell\u0026rdquo; ZSH_THEME=\u0026ldquo;bira\u0026rdquo; # 后面的文字都省略，我就修改了这个文件的这一个参数，bira 的提示符感觉比较新颖和实用 [root@w540]~# zsh ╭─root@w540 ~ ╰─$ ls anaconda-ks.cfg Desktop Documents Downloads initial-setup-ks.cfg ist Music Pictures Public Templates Videos ╭─root@w540 ~ ╰─$ [/bash]\n下面是装完之后的截图，以后我的测试机的默认 shell 应该都是这个样子了：）\nzsh 的功能还是比较强大的，然后再加上 ohmyzsh 这套配置参数文件和工具插件，shell 下地工作效率应该可以提高了。下面是一下参考网站：\n[wm_list bullet=\u0026ldquo;icon-linux\u0026rdquo; class=\u0026quot;\u0026quot;]\noh-my-zsh 入手中文参考：http://tuhaihe.com/2013/05/17/oh-my-zsh.html\noh-my-zsh 官网（作者认为这是他此生做的最有意义的一件事）：http://ohmyz.sh/\nzsh 官网：http://www.zsh.org/\n[/wm_list]\nMac OS X 用户则建议实用 iTerm2 来替换原声的 terminal。下载 item2 在这里：http://iterm2.com/\n","date":"2015-03-23T02:47:45Z","permalink":"https://martinliu.cn/2015/03/23/e585a5e6898b-zsh-e5928c-oh-my-zsh/","title":"入手 zsh 和 oh-my-zsh"},{"content":"这种方法论的东西很久不感冒了，可是这次耐心看了一下，确实有温故而知新的作用，有点意思，特此推荐一下。\n这个方法论的网站在：http://www.impactmapping.org/\n上图是此方法分析的思路。网上搜索了一下，多看到很多介绍敏捷方法的网站在推荐。下图是次方法的宣传海报。\n这里还从 YouTube 上搬运回来一个视频，可以参考一下。\n","date":"2015-03-20T02:22:16Z","permalink":"https://martinliu.cn/2015/03/20/impact-mapping/","title":"Impact Mapping"},{"content":"关于 Project Atomic 项目 Project Atomic 项目相关的开源技术组件如下：\n[wm_list bullet=\u0026ldquo;icon-linux\u0026rdquo; class=\u0026quot;\u0026quot;]\nlinux kernel systemd OSTree and rpm-ostree Docker kubernetes Fedora and CentOS [/wm_list]\n该项目的网站在： http://www.projectatomic.io/\n加入 Project Atomic 邮件列表 项目一般性讨论： https://lists.projectatomic.io/mailman/listinfo/atomic\n项目开发者：https://lists.projectatomic.io/mailman/listinfo/atomic-devel\n项目版本发布更新：https://lists.projectatomic.io/mailman/listinfo/atomic-announce\n填写自己的邮箱后，别忘了在邮箱里收信，并且确认。如下图所示：\n问 Project Atomic 问题和讨论 http://ask.projectatomic.io/en/questions/ 这里是项目的论坛可以在这里提问和帮助其他人。\n了解 Project Atomic 代码 https://github.com/projectatomic/ 项目的代码在 Github 网站上可以看到，如果你 watch 这个项目的话，可以收到所有开发者对该项目的所有代码更新等活动。\n","date":"2015-03-19T03:23:37Z","permalink":"https://martinliu.cn/2015/03/19/e5a682e4bd95e58f82e4b88e-project-atomic/","title":"如何参与 Project Atomic"},{"content":"FY16 Sales SKO Marco: 正像所有公司做的模式是一样的，红帽的销售启动大会在澳门开始了。澳门是个让人腻味的地方，每天早晨的集体晨跑成了一个亮点。小小的慢跑群正在成长中。\n","date":"2015-03-17T13:23:32Z","permalink":"https://martinliu.cn/2015/03/17/fy16-sales-sko-marco/","title":"FY16 Sales SKO Marco"},{"content":"今天走入了天津市大学软件学院，和同学们分享了我对开源软件的一些看法和经历；很多同学对如何成为架构师感兴趣。全程学生们没有玩手机和睡觉的，感觉效果应该还不错。ppt 在这里\u0026ndash;\u0026gt;《开源软件之系统架构师篇》可惜对其中一个同学的回答后来想着欠妥 :(\n","date":"2015-03-12T12:05:14Z","permalink":"https://martinliu.cn/2015/03/12/e8b5b0e8bf9be5ada6e6a0a1e58886e4baabe5bc80e6ba90/","title":"走进学校分享开源"},{"content":"对 blog 做了结构性调整：把永久网址链接简化到只有文章标题；省略了之前带有复杂的分类层级的部分；之前想更多地加入关键字的想法，目前看真的想太多了。Blog 还是要越简单，越简洁越好。就像我目前的 Theme 一样，除去了浮夸和花哨的修饰，专注内容，专注文章质量。\n","date":"2015-03-10T15:47:16Z","permalink":"https://martinliu.cn/2015/03/10/e5afb9bloge5819ae4ba86e7bb93e69e84e680a7e8b083e695b4/","title":"对blog做了结构性调整"},{"content":"网页的 永久链接 的配置是在：Settings \u0026ndash;\u0026gt; Permalink Settings； 通过这个设置把 Wordpress 默认的代码型网页网址 http://martinliu.cn/?p=123 变成了 搜索引擎更友好，而且人也更容易懂的网址。例如我目前的：http://martinliu.cn/文章标题/\n我之前的永久链接其实已经改过好多次了，期间多次是由于更新网站分类结构，还有是由于看了多篇纠结的 wordpress SOE 文章导致。前几次修改都是很粗暴的直接修改，并没有顾忌到对以前搜索引擎的已经抓取的网页做保护。这次我必须对当前已经纳入搜索引擎的网页做保护了，毕竟文章现在比较多了，非常有必要对搜索引擎用户做保护。\n本次修改主要参考了文章是：A Simple Guide to Changing Your Permalinks Without Breaking Your WordPress Website 此文推荐了一个简洁的方法，使用插件： Simple 301 Redirects\n安装和激活插件后，我的配置过程如下。首先，更新永久链接到新的设置。\n然后再去 Simple 301 Redirects 的配置做如下修改：(插件有 bug，最后配置网址是 /%postname%/ .html 了发现 301 重定向不成功。)\n最后到搜索引擎里面看下是否所有的已有抓取的网页都可以正常访问。在搜索引擎中搜索： site:martinliu.cn\nbing 搜搜结果点这里 在结果页面上点击任何一个文章，文章应该被正确加载出来了。\n","date":"2015-03-10T15:29:36Z","permalink":"https://martinliu.cn/2015/03/10/e5ae89e585a8e79a84e7ae80e58c96e4ba86e7bd91e9a1b5e79a84e6b0b8e4b985e993bee68ea5/","title":"安全地简化了网页永久链接"},{"content":"一下午讲了两场：头一场给两个渠道部门和总代的两位老大；后一场讲给曙光的产品经理。讲的我满头汗，感觉思路非常清晰，越来越清晰了，数据中心的基础架构如果转型到开放架构，那么需要的是什么？是一套综合的方案体系。是一套自动化高效的运管体系。\n","date":"2015-03-10T14:37:18Z","permalink":"https://martinliu.cn/2015/03/10/e4b880e4b88be58d88e8aeb2e4ba86e4b8a4e59cba/","title":"一下午讲了两场"},{"content":"《天将雄师》豆瓣上评分很低的电影，才 6 分多；我看到的却很享受，是我不正常，还是世界不正常了：）\n","date":"2015-03-10T10:56:31Z","permalink":"https://martinliu.cn/2015/03/10/e5a4a9e5b086e99b84e5b888/","title":"天将雄师"},{"content":"MacBook 和 Macbook Pro 的$1299 相同价位的配置。http://www.apple.com/mac/compare/results/?product1=macbook\u0026amp;product2=macbook-pro-retina-13\n不难看出这两个本子，基本就是针对两种不同类型的人群。选择 Macbook 意味着纯文档处理类型的人；选择 Macbook Pro 意味着需要更强处理和运算能力的技术人员。颜色上新增了银灰和土豪金。\n看后我觉得我会选择，土豪金的 Macbook，哈哈哈哈~需要考察一下实物才能做这个最后的决定。下面是 Apple 官网上关于 MacBook 的设计视频广告，我看完后感觉，电脑作为商品来讲，做广告到这个份上，也就快到头了。\n","date":"2015-03-10T02:34:45Z","permalink":"https://martinliu.cn/2015/03/10/e696b0macbooke698afe4b8aae6808ee6a0b7e98089e68ba9/","title":"新MacBook是个怎样的选择 ？"},{"content":"本来不能算是 day1，由于 day1 早就开始了，不过作为第一个 post 发布出的记录，还是叫它 day1 吧，后续会逐步更新我的进展。\n","date":"2015-03-08T15:49:44Z","permalink":"https://martinliu.cn/2015/03/08/martins-lab-build-day-1/","title":"martin's lab build day 1"},{"content":"\n上图是红帽产品和技术架构的全貌。来源是：http://www.redhat.com/en/technologies/cloud-computing 这张图我用在了我的首次给公司内部的全体销售培训上。由于我是 IT 管理背景的，因此我很习惯从云管理层往下看云引擎的各个层面。但是管理层产品，其实是后来整合纳入的。红帽起家的旗舰产品还是在底层的 RHEL。总之，我想在一个 Lab 里面实现以上所有的部分，所谓实现是让其每个部分都能在运行在假象的一个有意义的业务场景里。还好，红帽的产品全都是基于 x86 平台的，因此我用几个笔记本，再加上我家里的这台 HP MicroServer G8 服务器应该能够全部部署出来。\n做这样的一个 lab 还是要一定的规划和设计的，这些初步的规划和设计都在我的本子里手写的，就不在这里敲字了，随后我会抽空上几张图。\n主服务器基本配置 硬件：Lenovo W540 CPU Intel i7, RAM 32 GB, SSD 512GB, HD 1TB\nOS : RHEL 7.1\n订阅是红帽公司的业务模式，也是红帽认为最自豪的部分，红帽相信可以成为开源技术和用户之间的催化剂，它不断参与最优秀的开源技术创新，并为其用户提供最强有利的技术服务和支持。红帽技术员工可以申请一个红帽雇员订阅。我的订阅可以在网上查到如下图所示：\n红帽的服务必须是基于订阅的每一个节点（物理、虚拟）都需要有有效的订阅，否则红帽的支持服务不能生效。对于一个已经成功注册到红帽官网，并且状态正常的服务器，应该显示如下的注册状态：\n[bash] [root@w540 ~]# subscription-manager list\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+ 安装的产品状态 +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+ 产品名称： Red Hat Enterprise Linux Server 产品 ID： 69 版本： 7.0 构架： x86_64 状态： 已订阅 状态详情： 开始： 2014 年 09 月 09 日 结束： 2015 年 12 月 08 日 [/bash]\n红帽员工订阅意味着所有红帽产品。\n基本服务配置 KVM KVM 的上手还真比我想象的速度要慢一些，起码比我用 XenServer 的经历更加纠结一些。总之现在可以彻底的忘记其它任何的选项，KVM 可以满足我的所有需求了。由于主服务器有 512SSD + 32GB RAM + 8 vCPU，所以我打算把产品里的所有管理控制节点 VM 都部署在这个机器上。预计有 10 个左右的虚拟机。 安装配置方面这里就不赘述了。只把困扰我许久的几个网络配置贴出来，供参考。\n网桥 0 的功能是为所有虚拟机提供外网链接，使他们和主机一样直通主机所物理链接的局域网。 [bash] [root@w540 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 DEVICE=br0 ONBOOT=yes TYPE=Bridge BOOTPROTO=none STP=on DELAY=0 DNS1=192.168.0.1 DEFROUTE=yes IPV4_FAILURE_FATAL=yes IPV6INIT=no DNS2=4.4.4.4 IPADDR=192.168.0.5 PREFIX=24 GATEWAY=192.168.0.1 NM_CONTROLLED=no [/bash]\n主机原本的一块物理网卡的配置，由于增加了这个网桥，需求更新如下： [bash] [root@w540 ~]# cat /etc/sysconfig/network-scripts/ifcfg-enp0s25 DEVICE=enp0s25 ONBOOT=yes BRIDGE=br0 NM_CONTROLLED=no BOOTPROTO=none [/bash]\nkvm 这块处理这个折腾我很久的 br0 之外，其它的功能看起来还不错，运行在 SSD 上的虚拟机也启动和运行速度飞快。\nRepo 服务器 Repos 是红帽软件仓库的简称。它具体指每个订阅内所有软件频道里面下载出来的软件包目录。下载到的某个软件包频道的 repos 目录中是一堆的 rpm 包文件，这样的目录可以制作成本地 Repos 服务器，能够提供给所有 LAN 里 RHEL OS 用来做软件的安装和升级用。 用主服务器上 1TB 的慢速普通盘来保存这些下载的 repos，安装 http 服务器，把它共享给本 lab 的 lan 中。具体的几个参考脚本如下。\n在把本服务器注册到红帽网站之后，他会默认 attach 一堆可能不需要的 repos，因此我的做法是先关闭掉所有的默认开启，然后再开启我所需要并且关注的东西。 [bash] [root@w540 repos]# subscription-manager repos \u0026ndash;disable=\u0026quot;*\u0026quot; [/bash] 以上命令的结果会反问，所有的被关闭的 repos。下面许开启我当前需求的 repos。 [bash] [root@w540 repos]# cat rhel7-enable.sh subscription-manager repos \u0026ndash;enable=rhel-7-server-extras-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-capsule-optional-6.0-rpms subscription-manager repos \u0026ndash;enable=rhel-ha-for-rhel-7-server-rpms subscription-manager repos \u0026ndash;enable=jb-eap-6-for-rhel-7-server-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-capsule-6.1-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rt-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-openstack-6.0-rpms subscription-manager repos \u0026ndash;enable=rhel-server-rhscl-7-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rhn-tools-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-capsule-6.0-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-openstack-5.0-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rhevh-rpms subscription-manager repos \u0026ndash;enable=rhel-atomic-host-rpms subscription-manager repos \u0026ndash;enable=rhel-rs-for-rhel-7-server-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-capsule-optional-6.1-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rhev-mgmt-agent-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-openstack-6.0-installer-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rh-common-rpms subscription-manager repos \u0026ndash;enable=jb-eap-6.3-for-rhel-7-server-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-optional-6.0-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-6.1-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-supplementary-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-optional-6.1-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-optional-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-6.0-rpms subscription-manager repos \u0026ndash;enable=jb-ews-2-for-rhel-7-server-rpms [/bash]\n接下来可以用命令来从红帽 CDN 同步下载每个 Repos 里面的软件包。 [bash] [root@w540 rhel70]# cat sync.sh reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-satellite-6.0-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-extras-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-rhevh-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-satellite-capsule-6.0-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-openstack-5.0-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-rhev-mgmt-agent-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-atomic-host-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-optional-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-rs-for-rhel-7-server-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-rh-common-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-server-rhscl-7-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-openstack-6.0-installer-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-openstack-6.0-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=jb-eap-6.3-for-rhel-7-server-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-ha-for-rhel-7-server-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-supplementary-rpms \u0026ndash;download_path=/data/Repos/rhel70/ [/bash]\n安装 httpd 的过程就不叙述了，下面就贴一个本机的配置文件。 [bash] Alias /repos \u0026ldquo;/data/repos\u0026rdquo; \u0026lt;Directory \u0026ldquo;/data/repos\u0026rdquo;\u0026gt; Options None AllowOverride None Order allow,deny Allow from all Require all granted\n[/bash]\n最后，在任何需要的机器上本地 repos 源的配置文件可以类似如下： [bash] [root@sat6-leb yum.repos.d]# ls rhel70.repo [root@sat6-leb yum.repos.d]# cat rhel70.repo [rhel-7-server-rpms] name=rhel-7-server-rpms baseurl=http://192.168.0.5/repos/rhel70/rhel-7-server-rpms/ gpgcheck=0 enable=1\n[/bash]\n当然，我的目标是以后这个 lab 网内所有的机器都需要受到 satellite 6 服务器的管理和控制，并不需要在每个服务器上手动的去安装和管理 repos 内容和订阅。下面分阶段安装各种控制器节点的时候，在详细说明如何使用 satellite 6 做种子服务器生出所有的其他节点。这里的 repo 服务器还是作为最初的种子服务器，它使安装 satellite 6 服务器的源。也是作为 lab 中对于 satellite6 的一个备份选项。\nNFS 服务器 本机的存储空间比较大，可以作为慢速 NFS 共享存储和 ISO 镜像文件服务器使用，因此，安装 nfs 服务器之后，就可以把本地的满速普通硬盘使用 nfs 的方式共享到 lab 内网了。配置文件参考如下： [bash] [root@w540 ~]# cat /etc/exports /data/nfs 192.168.0.(rw,async) /data/iso 192.168.0.(rw,async) /home/test 192.168.0.(rw,async) [root@w540 ~]# showmount -e localhost Export list for localhost: /home/test 192.168.0. /data/iso 192.168.0._ /data/nfs 192.168.0._ [root@w540 ~]# [/bash]\nNTP 服务器 根据红帽知识库文档，选择本机这个物理服务器作为 lab 内网的时钟服务器，所有的虚拟机和其他物理机都和他同步时钟。最终的配置还没有确定。随后更新靠谱的可以供参考的配置\n","date":"2015-03-08T15:42:01Z","permalink":"https://martinliu.cn/2015/03/08/e4b8bbe69c8de58aa1e599a8e690ade5bbba/","title":"Martin's lab 主服务器搭建"},{"content":"我耐心看了以下这篇文章《AWS Lambda Debuts for Running Code in the Cloud 》。我还没有来得及去测试一下这个服务，我只是对它感到新奇。有了它，业务应用可能就只需要 Dev 了，而不需要 Ops 了；更不用提什么 DevOps 了。当然这个观点稍微有点极端了。它的确实现了：程序代码可以基于事件在 AWS 的各种服务中运行。看完了那片文章我也没有察觉到它底层到底使用的是什么技术。只是说 AWS 再次走到了共有云服务的最前端。\n传统的共有云服务里，大家还停留在虚拟机提供，网络隔离的认识阶段。数据库服务、大数据服务、配套的程序部署和管理监控服务，对于一般性的共有云提供商，也不尽完全。曾经和作共有云的人聊过，他们觉得：传统企业数据中心的拥有着和管理这依然有巨大的纠结“失去对服务器的管控，就会有事业的风险”。因此，可见对服务器的管理是多么的重要。但是，如果你拥有了服务器的控制，并坐拥巨大的私有云建设的资金，那么您能如何很快交付出靠谱的云服务呢？说实话，目前私有云的建设很缓慢，也就是作个大批量的服务器虚拟化。IaaS 的建设案例还很少，即使有人说他们建成了新一代的云平台，近看一下大多还仅仅是增强版的虚拟机提供。当然这个虚拟机的提供是基本功，做不好这一客其它的云服务也面谈。我们详细观察以下 AWS，它大量的服务，像是 RDS，LB，Auto Scaling 等等功能，无处不见 AWS EC2 的扎实功底和无限变化。\n国内的广大用户，已经选择了私有云了；越大的企业，越有条件大赶快上云建设。只是却是道路艰辛，图省事的有钱人，可以上全套 V 公司的云计算，却是它的吸引力、炫耀力和安慰力都是无法阻挡的。底层上的技术的引用是至关重要的，越省事的套件，等同于越少的弹性和自由度，等同于更少的自由发挥的空间，和更少的创造。AWS 是基于 Xen 的服务器虚拟化技术，和一堆的其他开源技术。入手这条路解决了启动费用高的问题，带来了无限的创新和发展自由空间。他们不需要商业化软件或者产品么，例如，AWS 是重要的 Citrix netscaler 用户。\n","date":"2015-02-15T13:14:59Z","permalink":"https://martinliu.cn/2015/02/15/e4bda0e8bf98e59ca8e4b8bae5a4b1e58ebbe69c8de58aa1e599a8e6849fe588b0e784a6e89991efbc9f/","title":"你还在为失去服务器感到焦虑？"},{"content":"以上图片用 FreeMind 软件生成，下载英文版原图点击这里：aws-service-map.mm\n下载中文版 PDF 全图点击这里：aws-服务-脑图\n","date":"2015-02-11T14:41:22Z","permalink":"https://martinliu.cn/2015/02/11/aws-e69c8de58aa1e7b4a2e5bc95e59cb0e59bbe/","title":"AWS 服务索引地图"},{"content":"2014 Red Hat Summit- Paul Cormier, Red Hat keynote\n","date":"2015-02-09T05:24:15Z","permalink":"https://martinliu.cn/2015/02/09/2014-red-hat-summit-paul-cormier-red-hat-keynote/","title":"2014 Red Hat Summit- Paul Cormier, Red Hat keynote"},{"content":"\n是我很久没有看电影的原因么，总之看了还是觉得不错的。可是豆瓣的评分颇低，无所谓他人怎么看了，我自己娱乐好了就行。下一部想看的是《unbreak》\n导演: 弗朗西斯·劳伦斯 编剧: 丹尼·斯特朗 / 彼得·克莱格 主演: 詹妮弗·劳伦斯 / 乔什·哈切森 / 利亚姆·海姆斯沃斯 / 伍迪·哈里森 / 唐纳德·萨瑟兰 / 更多\u0026hellip; 类型: 剧情 / 动作 / 科幻 / 冒险 制片国家/地区: 美国 语言: 英语 上映日期: 2015-02-08(中国大陆) / 2014-11-21(美国) 片长: 123 分钟 又名: 饥饿游戏：自由幻梦 I(台) / 饥饿游戏终极篇：自由幻梦 1(港) / 饥饿游戏 3：自由幻梦(上) / 饥饿游戏：自由梦幻(上) / 饥饿游戏 第三部(上) / 嘲笑鸟(上) / Seashore IMDb 链接: tt1951265\n","date":"2015-02-08T14:47:40Z","permalink":"https://martinliu.cn/2015/02/08/e9a5a5e9a5bfe6b8b8e6888f3efbc9ae598b2e7ac91e9b89fe4b88a-hunger-games-mockingjay-part-1-2014/","title":"饥饿游戏3：嘲笑鸟(上) The Hunger Games: Mockingjay - Part 1 (2014)"},{"content":"从去年新增的服务中可以看出，其中多半是管理和基础服务类型的更新。因此，我感觉这也预示着，公有云技术的领头羊的发展也上到一定的成熟度上了。相比而言，企业私有云的建设还是纠结在几个症结上：选择私有云平台软件难，选择部署实施的落地工具和服务难，市场上相关的人才难找，大多出人连试点的经验还没还有获得，云应用-无状态应用踪影难觅。这些事实下，我看到了私有云建设的广阔服务前景，特别是企业服务这块。感觉有技术的实力派大牛们，应该趁着国产化软件的浪潮，踏踏实施做两年企业级产品，踏踏试试走下企业服务的路。别惦记着风头的那些钱，别惦记着做个公有云服务出来走出国门走向世界。我朝企业不差钱的主，土豪的企业有的事。毕竟近水楼台先得月。\n有一段时间没有关注 AWS 了，下面是在 aws-faq.com 发的新贴。顺便梳理了一下过去一年的更新情况，\nhttp://www.aws-faq.com/featured/aws-服务 2015 年开年有啥更新.html\nAWS 在去年新增了 6 个服务，整体的更新和服务升级的频率是一周一次；也就是说他们发布新版本的频率是每周一次，当然这是有网上发布信息为依推理出来的；感觉一周很可能超过一次。他们的电商也其它业务的发布评论，很可能就更高了。\nAWS 的公有云服务的技术成熟度和领先度我感觉是第一名的。它激发和促进了整个行业的发展。对私有云的促进和很明显。OpenStack 的更新是半年一个新版本。其参考和兼容 AWS 服务是很明显的。它可以很大的满足于企业自建云服务的需求。\n","date":"2015-02-08T14:24:33Z","permalink":"https://martinliu.cn/2015/02/08/2014e5b9b4awse69c8de58aa1e69bb4e696b0e680bbe7bb93/","title":"2014年AWS服务更新总结"},{"content":"AWS-FAQ post - AWS 一月有什么动态?\nhttp://www.aws-faq.com/blog/aws-blog/aws-%E4%B8%8A%E5%91%A8%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88-2015-%E5%B9%B41%E6%9C%88.html\nAWS 邮件服务的推出还是比较有趣，虽然很晚推出这个服务，但是还是推出了 __ 总之 1 月的动静不大 ","date":"2015-02-07T15:07:42Z","permalink":"https://martinliu.cn/2015/02/07/aws-faq-post-aws-e4b880e69c88e69c89e4bb80e4b988e58aa8e68081/","title":"AWS-FAQ post - AWS 一月有什么动态?"},{"content":"用 163 邮箱注册了http://bugzilla.redhat.com/ ; 提交了一个 satellite 的 bug。\n","date":"2015-02-02T15:40:52Z","permalink":"https://martinliu.cn/2015/02/02/e68f90e4baa4e68f90e4baa4e4ba86e4b880e4b8aabz/","title":"提交提交了一个BZ"},{"content":"先上几张 Fedora 21 server 安装的截图。\n[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;53424,53425,53426,53427\u0026rdquo;]\n新的配色还是不错的，重点看第三张图，虽然不全，已经基本上看出 F21 服务器版的软件包了。\n安装之后发现确实 Cockpit 的界面已经可以登陆了，是黑色的风格。\n在继续安装和探索之前，我有装了一个默认选项的 f21 server ，想通过这个节点的节目添加后统一管理。\n[gallery columns=\u0026ldquo;1\u0026rdquo; size=\u0026ldquo;large\u0026rdquo; ids=\u0026ldquo;53433,53434,53435,53436,53437,53438,53439,53440,53441,53442,53443,53444,53445,53446,53447,53448\u0026rdquo;]\n我感觉有了这个工具，新手们可以轻松第完成大部分 Linux 系统的维护工作了。\n如果你点击了启用 docker , eth0 的网络配置会丢失，会被 docker 那走作网桥，给他的 image 用作网关。这个测试最好是虚拟机多网卡。\n","date":"2015-01-27T16:22:18Z","permalink":"https://martinliu.cn/2015/01/27/fedora-21-server-e6b58be8af95-cockpite7af87/","title":"Fedora 21 Server测试 - Cockpit篇"},{"content":"我使用这新安装的 F21，连接着公司阿姆斯特丹的 VPN，流畅的使用 Firefox ， Chrome 上网，在没有墙的世界里顺利传行着。重返 Linux 世界，想起来很久没有用 windows 桌面了，渐渐适应和熟悉这感觉，且有些怀旧。\n之前 Fedora 是没有太多的体验，用的最多的是 opensuse + kde 桌面的组合。目前，看到 fedora magazine 上很多更新，感觉真的是发展的太快了。 http://fedoramagazine.org/see-whats-coming-in-fedora-22-workstation/ 看了下这个帖子，上面说 F22 的提升包括：更长的电池寿命、gnome Wayland 更多改进、开始应用 bundle 的开发、更好的第三方应用支持、提升 Terminal、改善开发工具等等。查看更多细节：Christian’s blog post\n","date":"2015-01-26T14:26:12Z","permalink":"https://martinliu.cn/2015/01/26/fedora-22-e69c89e4bd95e580bce5be97e69c9fe5be85/","title":"Fedora 22 有何值得期待"},{"content":"再次安装桌面版的 Linux 操作系统 ，并打算作为主要的工作平台。已经是 fedora 21，需要新贴纸了。\n接下来作的：http://www.linuxidc.com/Linux/2015-01/111481.htm\n剩余没做的是按照搜狗输入法。\n","date":"2015-01-25T10:10:09Z","permalink":"https://martinliu.cn/2015/01/25/e5868de6aca1e585a5e6898blinux-fedora-21/","title":"再次入手Linux - Fedora 21"},{"content":"我的 Satellite 虚拟机下载了所有常用的 repo，100GB 的磁盘空间都占满了，无奈必须扩容，否则没法用了。\n扩容的前提条件正好满足：根分区在最后一个分区。\n由于是 kvm 的虚拟机，所以首先需要扩大硬盘文件的大小： qemu-img resize my.img +100G 。\n下面去操作系统里扩容。先要用 fdisk 删除根分区。记录初始的其实点。然后用 n 命令新建分区，输入原始其实点位置，回车默认接受结束点的最后一个位置。w 存盘。\nreboot 系统，起来之后用命令扩容分区： resize2fs /dev/vda2 ； 在线扩容需要等一段时间，100GB 的空间初始化在我的普通磁盘上做了 5 分钟左右。在此 reboot 机器，起来之后在看 df -kh 发现已经增加了 100GB 了，接下来再也不用担心类似情况了。\n","date":"2015-01-21T15:46:31Z","permalink":"https://martinliu.cn/2015/01/21/e8999ae68b9fe69cbae6a0b9e58886e58cbae689a9e5aeb9/","title":"虚拟机根分区扩容"},{"content":"RHEL 7 中已经引入了比较完备的性能优化、调整和监控的工具。对于我这个监控背景的人来说，不具体看下，实在忍不住。\n首先，从这篇 KB 学起来把。 https://access.redhat.com/articles/785283\nRHEL 下性能调优的工具有三种。\nPerformance Co-Pilot\nTUNA\nTuned\n下面依次简单说下这几个工具。\nPerformance Co-Pilot 监控工具 [caption id=\u0026ldquo;attachment_53397\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;1000\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/01/Screenshot-from-2015-01-11-000449.png) PCP Charts - Overview View[/caption]\nPCP 是一个工具集，它分为两个部分：\nPCP Collectors ： 性能指标数据采集器，它可以从系统内核或者其他数据源来持续的采集数据。是由几个系统服务组成。 These are the parts of PCP that collect and extract performance data from various sources, e.g. the operating system kernel.\nPCP Monitors ：性能参数集中查看和监控的图形界面。它可以同时连接多台服务器。These are the parts of PCP that display data collected from hosts (or archives) that have the PCP Collector installed. Many monitor tools are available as part of the core PCP release, whileother (typically graphical) monitoring tools are available separately in the PCP GUI package.\n极简实施测试方法：\n安装 pcp 的相关软件包（在需要被监控的机器上安装 pcp 即可，在需要使用图形界面查看的机器上安装 pcp-gui） $ yum install pcp pcp-gui\n启用数据收集器的服务（在需要被监控的机器上运行这些服务，在监控的周期完成之后，可以考虑关闭这些服务） $ chkconfig pmcd on; service pmcd start $ chkconfig pmie on; service pmie start $ chkconfig pmlogger on; service pmlogger start\n查看监控到的图形： 在 pcp-gui 主机的 host 文件中加入被监控主机的地址解析\n在 RHEL 7 桌面的程序中，找到并运行 PCP Charts 程序\n它默认就是连接到本机，因此加入我们需要查看的性能参数图形即可。点击 open view ，选择 overview 视图即可。当然，它内置的监控视图还有很多，当然如果你希望，还可以把远程的服务器性能实时状态（点击新建视图）视图也加入进来。其它视图如下图所示。\n[caption id=\u0026ldquo;attachment_53396\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;520\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/01/Screenshot-from-2015-01-11-000611.png) 内置监控视图[/caption]\n更多信息求助 man PCPIntro documentation.\n主要适用场景：\n在 RHEL 下作应用或者操作系统的性能测试或调优，如果不需要或者没有必要使用第三方工具的话，它应该是首选。\n对生产系统性能做瓶颈定位，用它可以收集和追踪系统一段时间（一天、一周、一个月）的各种性能参数的表现情况，收集下来的数据可以作单点的或者横向的分析。它能够收集的参数还是相当全面的。\nPCP 的目的是了解系统的实时的性能状态，为性能调优找到方向和目标。也可以作为日常性能监控的工具之一，为性能派错提供一臂之力。\nTUNA TUNA 则适合于复杂性能参数的调整，能对很多 kernel 和网络的性能参数在图形界面中配置，对于一次性要修改 n 个文件的深度复杂性能调优，它可以是一个提高工作效率的利器。而且，如果是某种性能参模版，可以用它作配置的导入导出。这一便于工程师，面对一对类似系统做重复的手工劳动。\n[gallery size=\u0026ldquo;mobile\u0026rdquo; link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;53398,53399,53400\u0026rdquo;]\n极简实施测试方法：\nInstall the necessary packages: $ yum install tuna\nStart the tuning application $ tuna\nFor more information, please see the man tuna documentation\n主要适用场景：\n高效深度调优\n工作在范围比较大的性能参数上\n需要保存并且一致地实施这些参数配置到其它机器上\n希望使用图形界面操作\nTUNED 写了一堆文字了，现在我才开始我需要作的正事。我的需求是：优化一台物理的测试机的性能。我希望用最少的时间，直接让系统进入针对 kvm 虚拟机性能优化的基础优化状态（性能优化基线）。目前我还没有时间关心所有的性能参数细节，我只想快速完成这件事。方法如下：\n安装 tuned $ yum install tuned\n使用 tuned-adm 选择并加载 $ tuned-adm list Available profiles:\nbalanced blog latency-performance powersave sap throughput-performance virtual-guest virtual-host Current active profile: balanced tuned-adm profile virtual-host // 最重要的就是这个命令，让操作系统优化成虚拟机 host 服务器的性能优化调整基线\n上面这条命令其实就是我写本文的目的。打完这条命令，我可以洗洗睡了。如果你还睡不着，可以看下下面这个文章。\nRed Hat Enterprise Linux 7.0 - Performance Tuning Guide - 3.7. tuned-adm\n性能 提升方法 性能调优有几个方面需要考量。工具方面，需要选择一个合适的工具集，需要这个工具集能够统一的覆盖所有需要管理和调优的操作系统类型和版本；目的在于能够得到所有系统的基于统一工具的性能快照（当前的状态基线）；流程方面，需要建立性能调优和持续性能改进的流程。它应该和 ITIL 里的可用性管理和容量管理关联起来。性能提升的流程应该有一下几个活动：\n目标选择：选择当前环境性能基线快照目标的对象服务器，选择尽可能要典型、全面、量要够。针对采样对象，作统一的性能参数收集，选择必选和候选的性能参数指标。指标要选的有目的和有特点。目标采样对象可能会慢慢的扩大到更多的对象。目标采集的性能参数也需要，每次都 review，可以作有必要的调整。\n性能参数收集：最好在相同的时间段内收集一定时长的性能参数。建议使用一种统一的工具，这样可以更好第做横向对比。实在不行，可以对同一种操作系统使用一种工具。当然采集工具的数量越少越好，越多工作量越大，分析报表的成本越高。这个阶段 RHEL 上可以使用 PCP。\n建立性能调优目标：每一种业务应用或者某一类系统的基本性能诉求可能是一致的，把收集回来的数据，做分析整理和加工，对比历史的、业内标准的或者同行业的参考数据。得出本次性能参数调整的目标参数集。不同类型的系统，目标调整的参数集应该是不同的。\n实施性能优化参数：手工的或者用自动化工具来在目标系统中实时系统参数调整。当然，建议提前做测试，保证不会影响业务正常运行，也可以使用分批分拨实施的方法。建议的方法如下，a)使用自动化配置管理工具，如 puppet 或类似方案，把参数调整模版用 puppet 的模块来表达，并持续改进，发布最新的版本到目标 host group 上去即可。b）使用手工的方式实施，这里可用用到 tuna 工具。\n调优结果分析：再次收集一个周期的性能数据。对比这些数据和第二步骤中的数据。分析和记录本次调优的成败和总结。找出提升的部分，无提升的步骤。为下次调优做些后续的注意事项。\n以上活动应该在 IT Service mnager 的负责下定期执行。目标就是提升系统性能和效率，确保每个业务都能运行在最高的性能，为系统的容量管理和性能管理给出可靠的参考数据。\n最后，tuned 并没有写在上面的流程中，并不是说它没有到。它其实应该被用在每个操作系统实例安装和初始化的阶段。它提供的是红帽为 RHEL 推荐的最基础的性能调优参数建议，是性能调优基线的基线。实施方法很简单，在系统初始化的 post action 中加入这个条目，针对不同类型的系统激活一个合适的 profile 即可。\n性能 提升不是一蹴而就的，而是一个长期的过程。可以使用 PDAC 的思想，扎实的走好以上建议流程。使用自动化运维工具和必要的数据分析工具加速以上流程。\n","date":"2015-01-10T16:42:29Z","permalink":"https://martinliu.cn/2015/01/10/rhel-e680a7e883bd-e68f90e58d87e696b9e6b395e5928ce5b7a5e585b7/","title":"RHEL 性能 提升方法和工具"},{"content":"关于 virt manager Virt Manager 是一个不错的 kvm 虚拟机管理工具，能够方便地管理虚拟机。我的测试机目前已经完全转向 RHEL7 上跑 KVM 虚拟机，通过 virt-manager 去管理的方案。\n安装 virt-manager：yum install -y virt-* ； 装完之后重新启动机器即可使用。\n建议初始配置 安装完后有几个环境的配置推荐可以做一下。\nStorage Pool ： 一个默认的 + 两个自建的\nDefault ：这是 virt-manager 安装时默认创建的，它和操作系统在同一个卷上，我的测试机使用 SSD 卷，因此我所有虚拟机都会使用这个卷，这样速度比较快 hd ：这是测试机上普通磁盘的一个目录，目的是把那些不需要快速 IO 的虚拟机跑着这里，节省 SSD 的磁盘空间 iso ：这是普通磁盘上的 iso 文件目录，单独挂在这是为了，使用方便 虚拟网络 （一个默认+两个新建）\ndefault ： 这个是安装了 virt-manager + kvm 之后就有的，是用 NAT 的方式，带 dhcp，默认虚拟机可以连接物理机所在的外围 virbr1/virbr2 ：是我根据自己的需要建立的，只能和 host 物理机通讯，无 dhcp 我最近做 OpenStack 的实践，OpenStack 需要最好隔离的几个网络跑不同的数据，因此 virbr1/2 正好符合 OpenStack 的测试需求。另外我在物理机的操作系统上搭建了 yum 源服务器，因此任何一个虚拟机都可以通过 http 访问我放在物理机上的 repo 目录，我只需要更新这些 repos 目录里面的 rpm 包的内容，我的 lab 环境中的所有虚拟机（不管是在何网络）都可以使用到最新的系统更新包和软件包了。这样大大提高了虚拟机里面软件测试的效率，所有虚拟机像是在本地安装 rpm 软件包一样，再也不需要联网下载，我只需要每周去公司联网同步一下这些目录即可。\n有了以上配置之后，就可以高效工作了，效率感觉比 vmware workstation 要高，速度快稳定。下面是虚拟机创建的流程，里面有些我的推荐做法。\n本想看下，virt-install 的使用方式，感觉那个参数太多，容易敲错，还是界面比较容易上手，而且出错的机会不高。\n命令行常用操作指南（持续更新中） virt-manager 主要操作还是在命令行比较高效，特别是下面的这些操作，在使用过程中，比较多用，用的多了感觉比 GUI 操作方式效率高多了。\nvirt-manager 的命令行功能调用有两种方式：\n直接 virsh 回车 ，之后就进入了 virsh # 的一个专门的 shell，help 就能看的里面支持的所有命令 在普通 shell 下 直接 virsh \u0026lt;操作命令\u0026gt; \u0026lt;参数\u0026gt;， 这两个方式的调用没有差异，感觉全凭个人的操作习惯。\n下面是一些常用的虚拟机管理功能命令参数和实例。\n开启一个虚拟机\nvirsh # start server8-a\n查看所有虚拟机(on and off)\nvirsh list \u0026ndash;all\n关闭一个虚拟机\nvirsh # shutdown server8-a\n对一个虚拟机作一个快照\nsnapshot-create-as server8-a flat-os \u0026ldquo;before customization\u0026rdquo;\n查看虚拟的所有快照\nsnapshot-list server8-a\n返回到之前的一个 snapshot\nvirsh # snapshot-revert \u0026ndash;domain server8-a flat-os\n克隆一个虚拟机到新文件（用于模板的复制创建新 vm，或者 vm 的备份）\n[root@w540 Desktop]# virt-clone -o rhel70-tmp -n rhel70-tmp-clone -f /data/vm/cloned-new-vm.img\nCloning rhel7-tmp.img | 195 GB 00:00:03 Clone \u0026lsquo;rhel70-tmp-clone\u0026rsquo; created successfully.\n","date":"2015-01-06T15:55:02Z","permalink":"https://martinliu.cn/2015/01/06/kvm-virt-manager-e5ae9ee794a8e58f82e88083e6898be5868c/","title":"KVM Virt-Manager  实用参考手册"},{"content":"举例如下：\nwget -c -b -t 0 -O CentOS-7.0-1406-x86_64-Everything.iso http://mirrors.sohu.com/centos/7/isos/x86_64/CentOS-7.0-1406-x86_64-Everything.iso -o centos.log\n下载一个 7GB 的 DVD 文件，能够断点续传，能够把状态写入 centos.log 文件中。具体参数说明如下：\n[su_table]\n本文参考：http://blog.chinaunix.net/uid-14735472-id-111049.html\n","date":"2014-12-24T01:43:03Z","permalink":"https://martinliu.cn/2014/12/24/wget-e4b88be8bdbde5a4a7e69687e4bbb6-e696ade782b9e7bbade4bca0/","title":"wget 下载大文件-断点续传"},{"content":"Red Hat APAC Tech Exchange, Macau\nDay 3 - 4 December 2014 \u0026ndash; Track C\nCommand to Run bash \u0026lt;(curl -sSL https://bit.ly/get-fabric8) -k\nDocument to read https://docs.docker.com/installation/\nhttp://fabric8.io/v2/index.html\nhttps://github.com/fabric8io/quickstarts\nMy document: https://access.redhat.com/articles/881893\nBlogs http://rawlingsj.blogspot.com/\nhttp://macstrac.blogspot.co.uk/\n","date":"2014-12-04T02:46:04Z","permalink":"https://martinliu.cn/2014/12/04/workshop-creating-docker-management-environment/","title":"Workshop: Creating a Docker management environment"},{"content":"Instance Details Replace userX with your user id. For example, user1 \u0026ndash;\u0026gt; user 30\nOn your laptop cd ~/.ssh wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhte-splunk-lab wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhte-splunk-lab.pub chmod 600 rhte-splunk-lab chmod 644 rhte-splunk-lab.pub\nssh -i ~/.ssh/rhte-splunk-lab -l ec2-user gw-userX.apac.red\nOn all RHS Nodes sudo su - subscription-manager attach \u0026ndash;pool 8a85f9864675056e014684868378649c subscription-manager repos \u0026ndash;disable=* subscription-manager repos \u0026ndash;enable rhel-6-server-rpms \u0026ndash;enable rhs-3-for-rhel-6-server-rpms \u0026ndash;enable rhel-scalefs-for-rhel-6-server-rpms\nyum -y update\ncat /etc/redhat-* # should say Red Hat Enterprise Linux 6.6 (Santiago) and Red Hat Storage 3.0 Update 2\n/sbin/service glusterd restart\nOn RHS-01 gluster peer probe rhs-02.userX.apac.red gluster peer probe rhs-03.userX.apac.red gluster peer probe rhs-04.userX.apac.red\ngluster pool list\ngluster volume create splunk replica 2 rhs-01.userX.apac.red:/srv/brick1/splunk rhs-02.userX.apac.red:/srv/brick1/splunk rhs-03.userX.apac.red:/srv/brick1/splunk rhs-04.userX.apac.red:/srv/brick1/splunk\ngluster volume set splunk storage.owner-uid 1001 gluster volume set splunk storage.owner-gid 1001 gluster volume set splunk user.nfs disable\ngluster volume start splunk\ngluster volume info gluster volume status\nOn Splunk Master and Splunk Search Nodes subscription-manager attach \u0026ndash;pool 8a85f9864675056e014684868378649c subscription-manager repos \u0026ndash;disable=* subscription-manager repos \u0026ndash;enable rhel-7-server-rpms\nyum -y update\nwget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/splunk-6.2.0-237341-linux-2.6-x86_64.rpm \u0026ndash;no-check-certificate\nOn all Splunk Nodes subscription-manager attach \u0026ndash;pool 8a85f9864675056e014684868378649c subscription-manager repos \u0026ndash;disable=* subscription-manager repos \u0026ndash;enable rhel-7-server-rpms \u0026ndash;enable rhel-7-server-openstack-5.0-rpms \u0026ndash;enable rhel-7-server-rh-common-rpms\nyum -y update\nyum -y install wget lvm2\nwget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/splunk-6.2.0-237341-linux-2.6-x86_64.rpm \u0026ndash;no-check-certificate\n/bin/systemctl start lvm2-lvmetad.service /bin/systemctl start lvm2-monitor.service\npvcreate \u0026ndash;dataalignment 1024k /dev/xvdb1 vgcreate splunkdb /dev/xvdb1 /sbin/lvcreate -a y -l 100%VG -n splunkdb splunkdb mkfs.xfs -i size=512 /dev/mapper/splunkdb-splunkdb\nOn all Splunk Nodes echo -e blkid /dev/mapper/splunkdb-splunkdb | cut -d \u0026quot; \u0026quot; -f 2\u0026quot;\\t/opt/\\txfs\\tdefaults,inode64,noatime\\t0\\t0\u0026quot; \u0026raquo; /etc/fstab mount /opt\nyum -y localinstall splunk-6.2.0-237341-linux-2.6-x86_64.rpm\necho -e \u0026ldquo;splunk\\t\\tsoft\\tnofile\\t10240\u0026rdquo; \u0026raquo; /etc/security/limits.conf echo -e \u0026ldquo;splunk\\t\\thard\\tnofile\\t20480\u0026rdquo; \u0026raquo; /etc/security/limits.conf\nOn Splunk Master and Splunk Search cd /lib/systemd/system wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/splunkd.service \u0026ndash;no-check-certificate\nsed -i.bak \u0026lsquo;/^After|^Requires/d\u0026rsquo; splunkd.service sed -i.bak \u0026lsquo;/Description/a After=network.target local-fs.target\u0026rsquo; splunkd.service systemctl daemon-reload systemctl enable splunkd.service systemctl start splunkd.service\nrunuser -l splunk -c \u0026lsquo;splunk status\u0026rsquo; q y systemctl restart splunkd.service runuser -l splunk -c \u0026lsquo;splunk status\u0026rsquo;\nOn Splunk Peer Nodes yum install -y glusterfs-fuse python-httplib2 attr\nmkdir /mnt/glusterfs echo -e \u0026ldquo;rhs-01.userX.apac.red:/splunk\\t\\t/mnt/glusterfs\\t\\tglusterfs\\t\\tdefaults,_netdev,backup-volfile-servers=rhs02.userX.apac.red:rhs-03.userX.apac.red:rhs-04.userX.apac.red\\t0\\t0\u0026rdquo; \u0026raquo; /etc/fstab mount /mnt/glusterfs\nrunuser -l splunk -c \u0026lsquo;mkdir -p /opt/splunk/var/lib/splunk/glusterfs\u0026rsquo; runuser -l splunk -c \u0026lsquo;mkdir -p /mnt/glusterfs/$(hostname -s)\u0026rsquo;\ncd /lib/systemd/system wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/splunkd-pre.service systemctl enable splunkd-pre.service systemctl start splunkd-pre.service\necho OPTIMISTIC_ABOUT_FILE_LOCKING = 1 \u0026raquo; /opt/splunk/etc/splunk-launch.conf\nwget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/splunkd.service systemctl daemon-reload systemctl enable splunkd.service systemctl start splunkd.service runuser -l splunk -c \u0026lsquo;splunk status\u0026rsquo; q y systemctl start splunkd.service runuser -l splunk -c \u0026lsquo;splunk status\u0026rsquo;\ncd /opt/splunk/bin wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhsBucketMover.py wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhsBucketMover.sh wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhsLinkChecker.py\nchown splunk:splunk/rhs*\non gw-userX.apac.red iptables -t nat -A PREROUTING -p tcp \u0026ndash;dport 8001 -j DNAT \u0026ndash;to-destination 10.100.0.211:8000 iptables -t nat -A PREROUTING -p tcp \u0026ndash;dport 8002 -j DNAT \u0026ndash;to-destination 10.100.0.212:8000 iptables -t nat -A PREROUTING -p tcp \u0026ndash;dport 8003 -j DNAT \u0026ndash;to-destination 10.100.0.213:8000\nWeb GUI on Splunk Master (http://splunk.userX.apac.red:8000/) Settings \u0026ndash;\u0026gt; Indexer Clustering Replication Factor 3 Search Factor 2 Enable Clustering - accept until restart and hit ok\non each Web GUI on Splunk Peer 01 (http://gw-userX.apac.red:8001/) Web GUI on Splunk Peer 02 (http://gw-userX.apac.red:8002/) Web GUI on Splunk Peer 03 (http://gw-userX.apac.red:8003/)\nSettings \u0026ndash;\u0026gt; Indexer Clustering Enable Clustering Type - Peer host = https://splunkmaster.userX.apac.red port 8089 replication port 8090\nWeb GUI on Splunk Search (http://search.userX.apac.red:8000/) Settings \u0026ndash;\u0026gt; Indexer Clustering Enable Clustering Type - Search host = https://splunkmaster.userX.apac.red port 8089 replication port 8090\non Splunk Master Node cd /opt/splunk/etc/master-apps/_cluster/local directory wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/indexes.conf runuser -l splunk -c \u0026lsquo;splunk apply cluster-bundle \u0026ndash;answer-yes\u0026rsquo; admin password runuser -l splunk -c \u0026lsquo;splunk show cluster-bundle-status\u0026rsquo;\nOn each Node runuser -l splunk -c \u0026lsquo;splunk search \u0026ldquo;| rest /services/data/indexes | table title, homePath, coldPath\u0026rdquo;\u0026rsquo;|grep demo \u0026lt; look for $SPLUNKDB/glusterfs/demo/colddb\non Splunk Master Node su - ec2-user\ncd ~/.ssh wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhte-splunk-lab wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhte-splunk-lab.pub chmod 600 rhte-splunk-lab chmod 644 rhte-splunk-lab.pub\ncd /tmp wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/eventgen.tar.gz scp -i ~/.ssh/rhte-splunk-lab eventgen.tar.gz splunkpeer-01.userX.apac.red:eventgen.tar.gz scp -i ~/.ssh/rhte-splunk-lab eventgen.tar.gz splunkpeer-02.userX.apac.red:eventgen.tar.gz scp -i ~/.ssh/rhte-splunk-lab eventgen.tar.gz splunkpeer-03.userX.apac.red:eventgen.tar.gz\nOn each Peer Node cd /opt/splunk mv ~ec2-user/eventgen.tar.gz /opt/splunk chown splunk:splunk eventgen.tar.gz runuser -l splunk -c \u0026lsquo;splunk install app /opt/splunk/eventgen.tar.gz\u0026rsquo; runuser -l splunk -c \u0026lsquo;splunk restart\u0026rsquo;\ncd /opt/splunk/etc/apps/eventgen/samples cp sample.tutorial1 demo_data sed -i.bak s/main/demo/g demo_data cd /opt/splunk/etc/apps/eventgen/local cp ../README/eventgen.conf.tutorial1 eventgen.conf sed -i.bak \u0026rsquo;s/main/demo/g;s/sample.tutorial1/demo_data/g\u0026rsquo; eventgen.conf\nrunuser -l splunk -c \u0026lsquo;splunk restart\u0026rsquo;\nLog into WebUI on Splunk Master search \u0026ldquo;index = demo\u0026rdquo; timeframe = realtime \u0026gt; 5 minutes\ncheck /opt/splunk/var/lib/splunk/demo/db\n","date":"2014-12-04T02:34:03Z","permalink":"https://martinliu.cn/2014/12/04/workshop-redhat-storage-splunk/","title":"workshop redhat storage and splunk"},{"content":"第一章 人造与天生 1.1 新生物文明 生物的工程化和机器的生物化，这个词出现在我脑海中，并且通过描述一个生动的实际的实验。对生物系统的机器化和机器系统的生物化做对比和类比。开篇就乐观的去迎接新生物文明。\n1.2 活系统只胜利 放生学的成果会促进或活系统向更高阶的智能程度进化，使之机器智能具有自我维持的能力\n1.3 学会向我们的创造物低头 用非常感性的方式道出了人造物的未来和前景；人造物终究会具有生物的特性，能自活、有适应力和创造力，最后人们失去对他们的控制，并与之对等相处。\n总体看，第一章在说人造智能的前景和方向，机器和生物特性相互融合是发展的方向。其中也有一丁点环保的意思，人还要保护生态的完整性，人需要想生物界学习的太多了。\n第二章 蜂群思维 2.1 蜜蜂指导：分布式管理 用蜂群的而神秘性和特征，以及人们历史上对他的认识和研究，提出：它是分散和高度统一的矛盾复合体是，是一个非常极端的模式，这种模式可能是人造智能机器最佳的智能神经模式，分布式管理是统一、集中、集权是管理的反面。分布式管理模式是分布式系统的灵魂之一。\n2.2 群氓的集体智慧 群氓其实具有高级智慧的可能性和存在性，证明了群体中，简单个低级交互叠加之后可以产生对群体的复杂控制，这种群策群力的抉择能力是单个个体所无感知的，但是确实发生在整个群体上，并有效地扑朔迷离的控制这超多数量简单个体所组织的庞大蜂群。\n2.3 非均质的看不见的手 本想客观记录，不想在本文中投入任何感性，禁不住还是想表扬一下翻译者；这种神人实在不多，把这些晦涩难懂的跨界巨大的文章，翻译到这个程度真是值得赞赏，从行文和用词上，真非常达意、恰当和易懂。\n涌现这个概念提出了，它使蜂群和蚁群的操控模式的共性；是非线性的存在；不想人、或者高级生物的意识、是按时间连续的，它是蜂群的另外一个，看似无用、无聊和没有意义的特征之一。继续分析蜂群的奥妙中。\n2.4 认知行为的分散记忆 类比人的智慧模式，人也潜在的具有上面的蜂群的那些特征。\n2.5 从量变到质变 简单、相同类事件的大量发生可带来一个必然的结果，这是预测说，也是反馈性控制的根基定律。把它和具有涌现型意识的事物管理在一起后，就形成了智能控制了，也就是，让机器有所为，有所不为的行为控制，这就到了一种高度的自发的智能程度。它是一种自发的智慧，他们积累和叠加后经过质变，就失控了，而这种状态就是更高的智能程度“意识”；现在看到机器能够令人恐惧的一面了。\n2.6 群集的利与弊 群集就是分布式并行的网络结构，或者是内部组成逻辑，或者是机体组织方式。总结分析了具有这种内质的活系统，在理论上应该具有的特点和优势。\n2.7 网络是二十一世纪的目标 蜂群思维的应用不容易，他需要人们的自我否定，而人是很难去颠覆已有的常识；本文用互联网网络证明了蜂群的事实存在性。\n这一章的干货真的不少，其中的活系统是关键词。它应该是本书的精华之一。\n第三章 有心智的机器 3.1 取悦身体的机器 第一遍读，真不理解作者在扯什么无聊的闲篇充篇幅。再一看其实不是，这一章是循序渐进的描述和论证方法，逻辑上有点严谨的。本节说的是那种最弱智的简单人造机器，已经开始讲述智能机器人了，是智能生物的实施和实践。用真实案例证明它的价值。单体的智能机体的生产。\n3.2 快速、廉价、失控 简单躯体和简单思维逻辑的组合，是可以实现出非常游泳的个体，这些个体如果能就具有群体的包容架构特性，他们将可能出自治的可能性，注意是群体上体现出的自治性，如果可以实现群体的自治，这样包容架构的简单机体在整体上，具有了群级别的共享的智能，它可能反过来在控制到群的个体的行为。\n3.3 众愚成智 平行彼此对等关联，上下级结构的相互影响。不同层级上德简单任务群体之间可以按，上下级的方式组合起来。各个群体之间，彼此各异，又相互作用，在这种局面下可以形成“集体层面统一的智慧”。这样的微混沌状态中蕴藏着“群体才具备的统一智慧”；群体\u0026ndash;\u0026gt;个体行为\u0026ndash;\u0026gt;聚合作用\u0026ndash;\u0026gt;混沌态\u0026ndash;\u0026gt;整体统一反应\u0026ndash;\u0026gt;智慧（智慧可能抬高了，可以是智能）\n3.4 嵌套层级的优点 分布模式下的控制理论。自上而下的模式理论上都是行不通的，简单局部的控制能组合出可以运作的系统；用杂耍抛球机器人的实现，证明了这种方式的可行性和价值；这样做出的有意识地控制，就能产生智能的行为，并可自行地正常运作下去。\n3.5 利用现实世界的反馈实现交流 中央大脑的从上之下的控制模式下，让机器去模拟人脑对外界的感知，产生唯一真实地外界参考模型，不断更新修正脑中的外部世界模型，之后有中央大脑决定行为方式，同时保持不同部分的正常控制的思路，非常符合常识。但其实是不可用的模式。颠覆人们的常识好像是 KK 的习惯。而行的后，根据结果的正确判断，产生出下一步的动作，这种现实反馈得出的控制行为，可以让机器求生成功。也就是机器能够生存了，看到了把，有更进一步了。\n3.6 无躯体则无意识 躯体\u0026ndash;\u0026gt;行为\u0026ndash;\u0026gt;感知\u0026ndash;\u0026gt;基于规则的控制=意识。这个推导出了，意识要依托与躯体存在。行为规则下控制躯体成为意识；基于经验反馈的感知后控制行为，这种是高级的控制模式，是智能。这和我看的另外一本书有相关，《人性论》说道人性的三个层次：1 基于意识和经验的知性；2 理性；3 德性。它也是从物理现实世界到精神道德层面的逐层递进。\n3.7 心智/躯体的黑盲性精神错乱 本书跨界确实大，用医学上的临床案例证明意识和躯体的共存性和非孤立存在性，说明心智和躯体的高度一致性。人的躯体是心智的奴隶，我也有一个例子证明：某人一大神晚上睡不着，说打坐一个小时后，心智平静，方的安睡。心智甚至可以达到自我毁灭、毁灭躯体的地步。智附着于躯体，智能可以人造产生，而且人造智能可以有强大的威力。\n总结 前三章我在分机上一气呵成做完意识读书笔记，感觉它结构式论述万兆；失控后可产生出智慧的控制；失控和意识控制是完美的矛盾统一，是极低智慧个体聚合融合为群体后，简单控制量变到质变之后，产生出人造智能，群体架构分布式处理管理的躯体成了智能机器。从理论上这种机器智能是可以实施的。\n","date":"2014-12-02T16:01:07Z","permalink":"https://martinliu.cn/2014/12/02/kk-e5a4b1e68ea7-e8a782e5908ee6849f-e4b98be5898de4b889e7aba0/","title":"KK 失控 观后感 之前三章"},{"content":"[caption id=\u0026ldquo;attachment_53304\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;802\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2014/12/10407649_10152796900375816_4259586778690078611_n-e1417451217310.png) If there is anything you need, I won\u0026rsquo;t be far away.[/caption]\n半年了，第一次出差，赶上公司开大会，Apac 整个技术部门的人都汇聚一堂，这是一个 geek 的盛会。期待的看点还是很多的。更有周三超过百人的 geek running。周末会绕道香港，在转机去新加坡，在哪有一周的产品培训。这趟洗肺之旅，不知道能够创下多少公里的跑步里程，我已经按耐不住，脚底板发痒了。\n悲催的我明天才能够拿到港澳签注，因此只能乘坐下午 4 点的航班，到晚上才能到澳门。比其他所有人的到达时间，整整晚了一天。由于签注还没到手，还有一点点忐忑，毕竟我的程三张机票都出好了。但愿明天顺利出发。\n","date":"2014-12-01T16:14:51Z","permalink":"https://martinliu.cn/2014/12/01/e6988ee5a4a9e6beb3e997a8e8a781/","title":"明天澳门见"},{"content":"虚拟桌面 的业务价值 虚拟应用产生在虚拟桌面之前，虚拟应用是一种和 VPN 类似的原创访问方法。它其实最初实现的是图形 GUI 的远程访问，注意不是文字终端。它和 VPN 具有本质的区别，在于虚拟桌面是“终端不留数据/秘”的；这个它性拜它的传输协议所赐，虚拟桌面传输的主要是图像信息和键鼠指令。它的另外一个特性是“维护渐变”，在终端上维护近似于零（除了安装和配置虚拟桌面连接客户端程序外）；在服务器端应用升级和维护简单，主要是通过升级和更新一堆的 Windows 操作系统来实现。因此，主要的业务价值有两点：1）数据安全；2）维护简单。基于这些价值取向，它可以很好地胜任一下业务场景： [su_list icon=\u0026ldquo;icon: flag\u0026rdquo;]\n多网隔离、集中上网、运维/外包/审计人员访问管理 前端操作环境和后端业务数据的分离 呼叫中心、处理中心和窗口柜员 移动办公、BYOD 安全研发、协作研发 3D 虚拟桌面 等等等等 [/su_list]\n业务价值很精练，业务场景太多这里就不赘述。\n关键技术点 下面是虚拟桌面/应用的基本原理架构图。 通过上图可以对虚拟桌面的技术架构一目了然。虚拟桌面基础架构就是在数据中心里面部署的一堆 Windows 虚拟机，核心就在于让远程用户可以操作使用这些虚拟机里面的应用或者这些虚拟机桌面。鉴于此，核心技术主要有两个方面：Windows 操作系统虚拟机的集中发布更新和管理；远程访问协议和所有终端管控策略。\nWindows 虚拟机的发布和更新 Windows 的虚拟机有两种：Server 和 Desktop；虚拟应用技术主要是利用 Windows Server 操作系统天然的多用户性质，实现一份安装程序的多用户同时使用。虚拟桌面是复制 n 个预装应用的 Desktop 桌面操作系统来实现 n 个用户的使用。\n1）虚拟机克隆 使用服务器虚拟化技术可以方便地从 OS 模板中克隆出 n 个虚拟机，它的挑战在于：\n创建和更新的速度要快，特别是在虚拟机数量大的情况下 可否永久保持用户的个人数据，更新操作不会清空旧的个人数据 存储空间要节省 2）Stream OS 流化操作系统 这种方案是一种古老而容易被人遗忘的技术。就是很久很久以前的无盘工作站的思路。虚拟机或者物理机以网络启动的方法获得一个运行的 Windows 操作系统。所有的操作系统启动镜像都在服务器端统一管理，一种镜像可以对应启动 n 可操作系统，这些操作系统目前多以虚拟机的形式存在。它的特点\n虚拟机对磁盘的消耗非常小，磁盘是写缓存和用户数据。它的大小可以是 0 或者几个 GB。 创建的速度快 大批量虚拟机启动过程对网络有一定的压力，一般需要使用隔离的万兆网 同样有个人数据保持的问题 更新速度非常快，所有的操作系统在母盘更新后，需要重启来更新 不管用什么方式集中管理虚拟机，总之桌面虚拟化是要同时玩转这几个球水晶球。\n存储成本和性能 操作系统更新和个人数据保持 虚拟应用和虚拟桌面的混搭 虚拟机发布更新方式的混搭 远程访问协议 远程访问协议哪家强，可以公允的说还是 Citrix ICA 强。本文不是评测访问协议，只是点到为止。远程 GUI 界面发的虚拟访问方式一共有以下几种：\n[su_list icon=\u0026ldquo;icon: flask\u0026rdquo;]\nCitrix ICA/ HDX ICA : Citriix 的发家的技术，具有网络适应性强可用于广域网，后台管控策略精细，用户体验高等特点。 PCoIP ：最早适用于非虚拟桌面领域的，后来和 VMWare 和 Teradici 共同研发之后用在了 VDI 的访问上。 RDP ：Windows Server 操作系统自带的远程桌面访问协议，不管你用还是不用它就在那里，它的技术日趋成熟，体验越来越好，不容忽视，从 MS 许可证的角度讲，任何一个虚拟桌面就需要购买微软的虚拟桌面 windows 许可证。 SPICE ：它是一个开源的协议，可以和 KVM 配合实现 Windows 和 Linux 的远程桌面范围，自身的成熟度和完整度都一般。由于代码的开放性，有使之在某些公司手里成为可造之材。 其它 ：国内主要的方式是类似于破解 RDP 的形式，基于 RDP 做一些改进和优化。 [/su_list]\n总之一句话“优秀的访问协议”是好的虚拟桌面的天然基因，但它并不是虚拟桌面的全部。几个核心的考察指标包括：\n是否支持集中管理：在一个集中的管理服务器上实现对虚拟机、用户、访问终端等等的集中统一管理。 管理的颗粒度：你不清楚的话，就到厂商的管理控制台上数数就行 带宽消耗：带宽消耗和视觉效果 100%是成反比的，节省带宽就以为这降低显示效果，但是还要要求不降低操作灵敏度的情况下，是否支持 WAN。这些看似矛盾的因素就是要在一个共同体里同时寻找。 客户端设备兼容：是否任何有计算能力有显示输出的设备都可以操作。主要是设备的类型和操作系统。 服务器虚拟化技术 没有服务器虚拟化似乎不成虚拟桌面项目。它是运行虚拟机的载体。选择的范围主要几家：vSphere，XenServer、Hyper-V 和 KVM。可以说他们和虚拟桌面是强相关的有一定的兼容性制约。如果不差钱，那么直接买最贵的。如果非常清晰自己的业务需求，则可以推导出自己合适的技术。\n网络技术 一个完美的虚拟桌面基础架构需要实现数据中心 100%的包裹，需要实现外网设备统一的访问入口。说的更形象一点：虚拟桌面平台的虚拟机操作环境可以成为数据中心企业数据的传输终点，所有用户和数据的交互都在这里发生，数据是否能继续它的旅程传输出去，是受到策略的控制。外部客户访问这个入口，入口想一扇门，打开它用户就能够访问到自己的所有的应用和桌面，这扇门对外只开放一个端口，它起到了远程访问协议的代理服务器的功能，它把虚拟桌面基础架构中成百上千的 IP 地址的访问都终结掉，给防火墙策略的制定减轻了压力，实为容易忽视的关键技术点。\n项目的成败 毫不夸张的讲，能给你把大规模虚拟桌面项目做成功的人才对你有真爱。大规模虚拟桌面项目太复杂，实施难度大，成本高，这是业内的共识。对于大的组织，业务需求的梳理和确认需要有厂商引导，在这个过程中最尖锐的问题会在与：1）应用的兼容性；2）外设的兼容性。目前的 Windows 应用并非天然能够在虚拟机里面运行的，特别是在有负载外设需要通过远程协议链接的时候，更是如此。让企业修改应用是一个非常头痛的事情；选择修改应用，使之更适用于虚拟化环境，从长远看是明智的选择，并非企业的让步。而逼着厂商来适应一个糟糕的，或者本不该出现在虚拟桌面环境中的应用，即使是花了很大的代价实现了，也是投入和产出及不划算的。\n成本结构的烦恼，宏观的看成本中排名前几位是：存储、服务器、软件许可。也就是说桌面虚拟化厂商玩命的在硬件厂商打工。如何节省存储和服务器成本，方法可以是：减少虚拟机的资源消耗量。注意有些情况下是在不极大降低虚拟的数量上来做的，这就不得不去细看一下虚拟机的制备方法上，各家的优势了。方法也可以是：调整 VDI 和虚拟应用使用的比例。\n实施的过程不仅是搭建和测试，更要命的时用户的接受程度。在有些地方是需要强推，在某些情况下是要把技术问题留给厂商解决。一切都在于实施成本的平衡，没有一帆风顺的实施。实施的过程也是不断积累运维经验的过程，企业需要做好学习和提高的准备，这个球也不好接住。\n总结 桌面虚拟化和应用虚拟化是两个不同的技术。在一个项目和客户里，可能是两种不同的技术路线，在很多情况下也是混合使用的。它们构成了“企业应用交付基础架构”，这个基础架构在数据中心里地地位和网络设备、服务器、存储、数据库等等是相同的。只是它处在一个比较特殊的位置。很多人可能还不能理解到这一层。\n从 ITSM 的角度看，它提供了一种 IT 服务。用户通过它可以安全高效地使用各种企业业务应用和数据。企业可以用应用交付基础架构，轻松地把业务系统部署到任何的工作场所；并得到更好地数据安全性的保证，更快速地交付各种业务（甚至所有内网应用）给最终用户（不管他们身在何处）。\n","date":"2014-11-23T10:16:23Z","permalink":"https://martinliu.cn/2014/11/23/e8999ae68b9fe6a18ce99da2-e4b98be68891e8a781/","title":"虚拟桌面 之我见"},{"content":"无意中找到一个新的 Wordpress 主题 Mustang Lite 作者为WebMan。安装完之后觉得非常满意，本来这是一个多用途很复杂的主题现在让我给彻底精简了。感觉比较简洁，简洁的主题是我的最爱。\nWordpress 也升级到最新版本\n","date":"2014-11-22T16:38:28Z","permalink":"https://martinliu.cn/2014/11/22/e581b6e98187e4b880e4b8aae4b88de99499e4b8bbe9a298/","title":"偶遇一个不错主题"},{"content":"在最近一段时间里面，兴趣和心情持续承受着巨大的挑战。一边是亘古不变的哪些发愁的思绪，一边是潮水般涌来的新事物；还有不断的适应和调整。总之心神俱疲的感觉越来越重，是该进入正常运行态了，该恢复状态了，跑步不能中断，业精于勤！跑起来！\n","date":"2014-11-18T15:28:47Z","permalink":"https://martinliu.cn/2014/11/18/e8b791e6ada5e4b88de883bde5819c/","title":"跑步不能停"},{"content":"昨天晚上折腾了很晚，结果扩展的 8GB 内存条死活和系统不兼容，导致 ESXi 安装卡在内存检查哪里。在京东上直接退货，然后订货 HP 专用内存条。今天下午新条子火速送达。装上后系统在也卡了。ESXi 安装顺利完成。下载了 vClient 后，导入了几个常用 ISO，安装好了 RHEL6 和 7 的模板机。接下来可以开始方案的研究了。由于这台服务器有着巨大的折腾的空间，未来的硬件升级 whish list 包括：\n[su_list icon=\u0026ldquo;icon: heart-o\u0026rdquo;]\n增加 SSD 磁盘，加速 IO 密集的虚拟机 增加到 16GB 内存，可惜不能上 32GB，短板，相当的短 增加新的硬盘，当前的 1TB 用完后，还有三个盘位 升级 CPU 到 Xeon e1256l v2，据说性能可以提升三倍，逻辑 CPU 数可以到 8 颗 [/su_list]\n开源的东西还好，基本上都是结构简洁的居多，我可能从配置管理相关的技术开始搞起来，如 Formen，Puppet；再到 Ceph\u0026amp;gluster 等存储应用，再到 OpenStack 这样较复杂的应用。\n","date":"2014-11-18T15:16:50Z","permalink":"https://martinliu.cn/2014/11/18/e7a1ace4bbb6e5b0b1e7bbaae58fafe5bc80e5b7a5e4ba86/","title":"硬件就绪可开工了"},{"content":"难以置信我在 11.11 这一天也出手了。在过去的一年多里，烧过了跑步装备，烧过了跑步 GPS 手表之后；在光棍节那天，我毅然开始搭建 home lab 了。一直不想把家里也搞成工作的场所，但是来自大学时代攒机的冲动在此刻颠覆了我。\n这台主机仅仅是个开端，它只是一个空机箱，只有主板、CPU 和 2GB 内存。以后什么都需要扩展。在网上看了几篇讨论 DIY 这款机器的帖子之后，果断在京东上下单了。下单的价格是 2799，感觉目前这应该是全网最低价。另外还采购的配件有一条 8GB 的 HP 服务器用内存条，一块 1TB 的硬盘。另外，我也单独为 lab 开了一个页面，点击左侧链接就可以过去，以后关于对它的折腾都会记录在那边。\nTO Do list：\n[su_list icon=\u0026ldquo;icon: check-circle\u0026rdquo;]\n收货后组装开机 购买 2.5 寸硬盘托架，加装入家里过剩的笔记本硬盘一块，在光驱位置附近。 安装 vmware EXSi 在 2.5 寸的盘上 [/su_list]\n","date":"2014-11-13T16:29:38Z","permalink":"https://martinliu.cn/2014/11/13/e68891e79a8411-11e98787e8b4ad/","title":"我的11.11采购"},{"content":"在没有计划下，在偶然的空闲中，在一个大清早，居然看上电影了，不得不记录一下，为了最近疲惫的身心，为了留下一丁点的记忆和回味，为了首都这宝贵的蓝天。电影比较好看，最近思虑过甚，无力评论，且留下豆瓣链接。\n导演: 韦斯·鲍尔 编剧: 诺亚·奥本海姆 / 格兰特·迈尔斯 / T·S·诺林 / 詹姆斯·达什纳 主演: 迪伦·欧布莱恩 / 阿梅尔·艾米恩 / 李基弘 / 布雷克·库珀 / 托马斯·桑斯特 / 威尔·保尔特 / 德克斯特·达登 / 卡雅·斯考达里奥 / 克里斯·谢菲尔德 / 乔·阿德勒 / 亚历山大·弗洛里斯 / 雅各布·拉提摩尔 / 兰德尔·D·坎宁安 / 派翠西娅·克拉克森 / 唐·麦克马纳斯 类型: 动作 / 科幻 / 悬疑 / 惊悚 官方网站: themazerunnermovie.com 制片国家/地区: 美国 / 加拿大 / 英国 语言: 英语 上映日期: 2014-10-28(中国大陆) / 2014-09-19(美国) 片长: 113 分钟 又名: 迷宫行者 IMDb 链接: tt1790864\n","date":"2014-11-05T07:41:56Z","permalink":"https://martinliu.cn/2014/11/05/e8bfb7e5aeabe8a18ce88085-maze-runner/","title":"迷宫行者 The Maze Runner"},{"content":"北马 是我今年的目标，是第一次挑战 42.195 千米，是第一次搞 全马。备战的训练计划就差一个月的十几次训练，目前的状态，感觉还是“不踏实”。主要有几个方面，目前的两次长距离训练，一次 28 公里，一次 30 公里，跑下来，都是咬牙跑完最后的将近 10K。问题主要有：越往后感觉体力越不是很足，渐渐的会感到信心的缺失，渐渐的会感到脚底板和脚趾的疲劳和疼痛，这会传导至小腿到膝盖，特别是右膝盖，在 15k 以后总会感到有点不舒服。貌似右膝盖倒成了我最严重的挑战了，如果它老人家出了问题，就麻烦了。我可不想半途而废，更不想跑完后，让人抬着回家。心中只想着：能 5 小时内无伤痛顺利完赛。目前确定每天早晨起来锻炼，观察双腿的和膝盖的情况，非训练日在小区快走，一定要磨合出稳定发挥状态的感觉。\n","date":"2014-09-21T16:01:51Z","permalink":"https://martinliu.cn/2014/09/21/e5a487e68898-e58c97e9a9ac/","title":"备战 北马"},{"content":"RHEL 7 是一个划时代的版本，比 6 有很多的重大改变，特别是系统底层的管理这块，很多命令集都发生了变化。对我而言需要在一个新的平台上提升 linux 的技能，还是很凑巧的事情。逐渐感觉到红帽从操作系统层面，向上往云的方向，向下往软件定义的 XXX 方向，横向直接积压其它服务器虚拟化技术的势头逐渐明显。传统数据中心转型在即，整个技术堆栈需要重新定义和规划；创新型小公司不断挑战传统巨头厂商的地位，市场在重新定义和分化，仿佛这是进入战国时代的节奏。\n","date":"2014-09-21T15:40:15Z","permalink":"https://martinliu.cn/2014/09/21/start-rhel/","title":"Start over from RHEL"},{"content":"随着北马的临近，备战的训练也越来越重要，由于始终没有试过 30K 的距离，逐渐对长距离感到焦虑，因此放弃了 My Ascis 以距离为目标的训练计划，转投 Garmin 训练计划中的全马训练计划。Garmin 的计划中多是以时间为导向的，以跑步强度为训练内容，例如 EasyRun 30 分钟；Threshold Run 6 分钟，恢复跑 2 分钟，重复四次。\nforerunner 220 开箱测试 开箱之后，手表本身有 70%多的电，上手到公司门口，试试搜星的速度，在原地不动的情况下，由于是首次搜星，而且需要在搜星的过程中同步设置手表时钟。基本上花了大约 3~5 分钟的时间。公司门口在有十几层高的楼宇，应该会影响大搜星的速度。下面是绕公司楼一周的路线图。\n从图中可以看到路线的左下角还是有一定的偏差。\n手表数据上传 Garmin Express Garmin Connect 的网站奇慢无比，主要是由于，该网址里使用了 google font，由于 google 的服务被墙，导致页面加载 google 字体需要长时间的等待，直到超时之后才会显示页面的内容。\n有了 Garmin Express 这个客户端程序就可以避免使用网站了。而且它能自动检查手表的链接状态，USB 口一旦插上设备，不管手表里面有几条记录，基本上，几秒钟就能够同步完成。\n这个应用更是设备软件更新的神器，这个版本比以前的版本好太多了，同步数据在也不用发愁了。\n手机蓝牙同步 Forerunner 220 可以和手机通过蓝牙通信，只要手表和手机配对成功之后，手机上的 Garmin Connect App 立刻开始数据同步。同步到 app 的数据直接上传到网站上。\n这种方式是空前的爽，根本不需要使用电脑，也不需要在链接什么 USB 联线。上传完毕之后在稍微编辑一下标题、路线和分类，基本上这个记录下次在网页上看就非常有意义了。\n执行网站上的训练计划 首先，需要在 Garmin Connect 网站里面选择一个训练计划，激活训练计划的时候需要设定开始和结束时间，不管时间长短，它都会按照训练目标，自动设定每天的训练内容。\n有了这个计划之后，就可以在日历上看到实际上每天的训练安排了；如果愿意的话应该可以同时安排多个训练计划，训练计划可以一个接一个排满全年。加入一年跑两个全马，或者多个的话，就可以提前一次性安排好一年的训练计划。\n在日历页面里，点击发送到设备，网页就会调用 Garmin Express，Garmin Express 打开之后，它就会把网站日历上的所有训练计划条目都下载到手表里面。下载完毕之后，就可以在手表的 Training - Training Calendar 里面上下浏览每天的训练条目了。\n执行一项计划的训练内容 按照网站上的安排，我今天的训练内容如下：\nW11D5a-Easy Run 2 Steps\nRun 30:00\nColl Down\n选中 Do Workout，点击红色按键，表滴的一声，并且震动一下，示意可以跑步了。跑步的过程中，屏幕上有四种模式的切换：\n[su_list icon=\u0026ldquo;icon: play\u0026rdquo;]\n训练屏幕，由于是 30 分钟的 Easy Run，因此屏幕上就项内容，上面是配速，下面是 30 分钟的倒计时时钟。 数据屏幕 1 显示的三四条跑步数据自己可以定制。 数据屏幕 2 显示的三四条跑步数据自己可以定制。 默认的电子表时钟屏幕 [/su_list]\n三十分钟快到的时候，手表滴滴的在最后 5 秒倒计时提示，在最后一秒中，手表开始振动一次，示意这个训练内容完成了。然后手表会显示，开始 Cool Down，until press lap button。 我在操场里放松走了一圈，倒走了 800 米后，按 lap 键，手表就示意本项训练内容完成，示意保存该活动记录。\n跑间歇跑 Intervals 总感觉到跑完上面的 30 分钟 Easy Run 不过瘾，随后测试手表中默认带一个间歇表训练：4*1km ； 1：00 rest。点击开始这个计划之后，手表的第一个屏幕显示的是配速和距离，在距离快完成的最后 5 秒钟，手表开始滴滴的示意，最后一秒钟，手表振动，并且提示 Rest 1 分钟，接着手表开始一分钟倒计时，就这样，周而复始 4 次。\n后记 搜星速度没有预想的那么快，但是在操场上确实够快，不过比 Rorerunner 10 的速度快多了。连接之前买的 200 多的心率带，没有成功，并不像网上说的：随便那一条就可以配对成功。不过用了一段时间心率带后，现在想想，真的是个鸡肋功能，有一条即可，需要测了，连接手机测几次即可。这也是我下决心买 220 无心率带版本的原因。分析下来，620 比 220 多的那些数据和功能，都是通过心率分析出来的；由于现在我彻底不关系心率了，因此，所有和心率相关的东西都变得苍白了。就这样我只用了一个小时就下单 220 了。在天猫 Garmin 专卖店 1390 下单，居然不到 24 小时就收到货了。顺丰真是神速，24 小时内就把货从杭州送达。价格方面赶上暑假减价 100。http://detail.tmall.com/item.htm?id=37128865969\n","date":"2014-09-12T15:32:36Z","permalink":"https://martinliu.cn/2014/09/12/got-new-garmin-forerunner-220/","title":"评测 Forerunner 220"},{"content":"刚发到手的机器是一台无奈的就机器，没想到没有过一周的时间，IT 说研发那边居然多出了一台新机木有人用，说可以给我；收到的新机是一个未拆封的纸箱。我热泪盈眶的对 IT 说“你是一个好人”。\n这个机器基本上介于普通笔记本和超基本之间，重量很轻，比较赞赏的地方有两点：240GB 的 SSD 硬盘，安装的 fedora20 启动速度果断迅速，一般 10 秒内就可以输入密码了；显示平面的分辨率是 1920*1080，看完这个屏幕后，在看我的老款 MacBook Pro 的低分屏，感觉差距很大。\n","date":"2014-09-06T11:22:45Z","permalink":"https://martinliu.cn/2014/09/06/e6848fe5a496e4b8ade697a7e69cbae68da2e696b0e69cba/","title":"意外旧机换新机"},{"content":"这次把样式更新为 Editor（by Array）。选择这个主题的原因有几点。\n[su_list icon=\u0026ldquo;icon: smile-o\u0026rdquo;]\nEditor 是一个简约风格的主题，这种轻量级主题即简洁大方，速度快，可谓鱼和熊掌能够兼得。 Feature image 是特大的 1000*625，最近两年特别喜欢这个样式，而且这个图片既可以在 list 中现实也可以在 single post 中显示。 目前看和 CDN 插件不冲突 [/su_list]\n这就是使用免费主题的优势，随时更换心情，想换就换。\n","date":"2014-09-06T10:24:01Z","permalink":"https://martinliu.cn/2014/09/06/e69cace58d9ae5aea2e5868de6aca1e69bb4e696b0e6a0b7e5bc8f/","title":"本博客再次更新样式"},{"content":"二零一四年八月我跑步距离总计超过一百八十公里，创造个人月跑新纪录！\n这个月多次跑 20 公里，一次超过 10 公里也比较多，总跑步天数也多。值得纪念一下。希望今年能够顺利完成一次全马。\n","date":"2014-09-06T02:13:18Z","permalink":"https://martinliu.cn/2014/09/06/e585abe69c88e4bbbde8b791e6ada5e59b9ee9a1be/","title":"八月份跑步回顾"},{"content":"3 伏天的雾霾让人无奈，只好逃离北京去避暑。第一站崇礼。崇礼的距离不算近，但是最让人感到欲哭无泪的还是拥堵的八达岭高速，堵的真实让人走投无路啊！没有最堵只有更堵，让逃离帝都的人在出京路上非常糟心。交通在出了北京界后，就仿佛进入了另外一个世界，天也是蓝的，路是畅通的。\n上图为崇礼聚龙滑雪场的雪道。\n上图是草原天路的大风车。\n上图是草原天路的草甸，非常多的野花。\n上图是草原天路上露营的装备，发挥了重要的作用，让野餐不在面包+香肠。\n上图是路过海沱，绵绵高山峡谷景色非常迷人。\n延庆柳沟豆腐宴，看着不错，口味一般，可以管饱，哈哈哈！\n延庆的色素菊花田本帖子本来可以很长，太忙了，到此为止吧。\n","date":"2014-08-04T09:40:59Z","permalink":"https://martinliu.cn/2014/08/04/e981bfe69a91-e5b487e7a4bc-e6b5b7e6b2b1-e5bbb6e5ba86-2-e697a5e6b8b8/","title":"避暑 崇礼 海沱 延庆 2 日游"},{"content":"周四中午去，晚上加班到 12 点多；周五下午和 CIO 会议，晚上回北京到家 11：30 多，想睡觉，失眠睡不着中。\n","date":"2014-07-11T17:51:48Z","permalink":"https://martinliu.cn/2014/07/11/e8a5bfe5ae89e587bae5b7ae/","title":"西安出差"},{"content":"周六奥森 6.22 公里，天气太热，没有能坚持到北园一圈。\n周日北工大 7.12 公里，天气依然很热，空气污染重，坚持了 45 分钟，\n正式备战北马的节奏么？不是，还是锻炼身体最重要。\n","date":"2014-07-06T14:34:28Z","permalink":"https://martinliu.cn/2014/07/06/e591a8e69cabe8b791e6ada5/","title":"周末跑步"},{"content":"\n导演: 大卫·欧·拉塞尔\n编剧: 埃里克·辛格尔 / 大卫·欧·拉塞尔\n主演: 克里斯蒂安·贝尔 / 布莱德利·库珀 / 艾米·亚当斯 / 杰瑞米·雷纳 / 詹妮弗·劳伦斯 / 路易·C·K/ 杰克·休斯顿 / 迈克尔·佩纳 / 谢伊·惠格姆 / 亚历桑德罗·尼沃拉 / 伊丽莎白·霍尔姆 / 保罗·赫尔曼 / 萨伊德·塔格马奥 / 马修·拉塞尔 / 托马斯·马修\n类型: 剧情 / 犯罪\n官方网站: www.americanhustle-movie.com\n制片国家/地区: 美国\n语言: 英语 / 阿拉伯语\n上映日期: 2014-07-04(中国大陆) / 2013-12-20(美国)\n片长: 103 分钟(中国大陆) / 138 分钟(美国)\n又名: 瞒天大布局(台) / 骗海豪情(港) / 人人都是骗子 / American Bullshit\nIMDb 链接: tt1800241\n[su_quote]观后感：社会题材的东西感觉越来越喜欢了，相信还会看第二遍，情节非常好看，给周末增色不少！[/su_quote]\n","date":"2014-07-05T15:39:20Z","permalink":"https://martinliu.cn/2014/07/05/e7be8ee59bbde9aa97e5b180-american-hustle-2013/","title":"美国骗局 American Hustle (2013)"},{"content":"和同事们在群里面那么一聊，本着以赛代练的方针，备战北马正式开始，报名 衡水湖 马拉松，首次全马居然在衡水湖，想不到啊！想不到！\n","date":"2014-07-05T15:25:02Z","permalink":"https://martinliu.cn/2014/07/05/e8a1a1e6b0b4e6b996-e9a9ace68b89e69dbe/","title":"衡水湖 马拉松"},{"content":"当前的电脑 我现在用的 MacBook Pro 是 3 年前买的，更新到 8GB 内存，500GB 普通硬盘，不得不说，除了充电器两头电线用到掉皮，里面的电线裸露之外，这台电脑还是我用过的做长时间，并且性能和质感保持最佳的电脑。这是一台 BYOD 的设备。\n想入手的 MacBook Air 刚才在苹果香港 store 看了一下，觉得 MacBook Air 性价比应该合适入手了：\n[su_list icon=\u0026ldquo;icon: rocket\u0026rdquo;]\n最吸引我的地方还是超级本的轻薄，背包可以轻很多了。 MacBook Pro 还是扩展性和性能更佳的，但是作为日常办公来说，而且越来越不可能在这样的电脑上跑多个虚拟机的重测试环境。但是新版的 MacBook 还是比 air 重不少。 CPU：双核 i7 1.7 说实话，还是比较低的，但是，想到耗电和发热，也必须忍受这个短板。 RAM：8GB 内存，和我目前的情况一样，按我现在的使用水平，3GB 以上的可用内存是常态，因此及时是要做测试，跑三个内存 1GB 的虚拟机也应该是没有问题的；要是慢的话 CPU 应该是瓶颈。目前没有试过。 存储：256 GB 对于一般用户来说可能不够。可以参考下图我的分析。如果能合理的把多媒体文件导出到家用 NAS 的话，应该没有问题。 [/su_list]\n关于存储 我的多媒体文件在整个硬盘上占到将近一半，甚至超过了操作系统和应用软件和数据文件的总和。因此加入我买新本的话，上面应该不会导入这么大批的文件，照片什么的应该会用这台老机器存储。这台机器上的空间，应该至少还能用两年。但是，估计以后就全都导入到云里面了，百度云基本上都是给 TB 基本的可用空间。\n","date":"2014-07-02T07:35:34Z","permalink":"https://martinliu.cn/2014/07/02/macbook-air-e8bf99e4b8aae680a7e4bbb7e6af94e580bce5be97e585a5e6898be4ba86/","title":"MacBook Air 这个性价比值得入手了"},{"content":"坐等 Mac Mini 的最新版本在秋季发布，还需要忍耐一个燥热的夏季，等不急了！这个机器适合用在 Lab 测试机。\n","date":"2014-07-02T07:16:05Z","permalink":"https://martinliu.cn/2014/07/02/mac-mini/","title":"mac mini"},{"content":"在东湖公园里面跑步绝对是一种享受，跑一圈大约是 7 公里左右。我这三天的会议跑了三条路线。\n[su_list icon=\u0026ldquo;icon: rocket\u0026rdquo;]\n东湖宾馆 ，其实是故意跑进去的，虽然入口都是武警站岗，还是从一个工地跑了进去，最后翻墙出来，看到墙头就有摄像头，狂汗~~~ 武汉大学，正门湖边，路不好，跑了 4 公里，返回，往返 8k。 东湖公园，风景优美、跑步的道路舒适、不枉此行，快速跑了 6k [/su_list]\n","date":"2014-07-01T16:37:47Z","permalink":"https://martinliu.cn/2014/07/01/e6ada6e6988ce4bc9ae8aeaee4b889e6aca1e685a2e8b791/","title":"武昌会议三次慢跑"},{"content":"武昌会议第二天，两天重复不换台，重复着：起床、跑步、吃饭、开会、吃饭、开会、吃饭。。。。。。。。 手机被上收到会议桌最前方，没有 break，不需使用手机。 电脑必须关掉，所有记录只能用纸和笔。\n","date":"2014-06-29T16:02:00Z","permalink":"https://martinliu.cn/2014/06/29/e6b5b8e6b3a1e5bc8fe5bc80e4bc9a/","title":"浸泡式开会"},{"content":"今天是实在不应该出差！！\n","date":"2014-06-27T15:52:58Z","permalink":"https://martinliu.cn/2014/06/27/e697a0e5a588e587bae5b7ae/","title":"无奈出差"},{"content":"今天是非常特殊的一天，发生了一件另外无奈的事情。真是不想在这天也出差，但是还要它是旅程；用了一个半小时才从三环爬到了西站。上车后，高铁 4 个小时准时的把我送到了武汉。\n到了酒店后，由于这里就在东湖旁边，因此先去跑一圈是最重要的。 跑的过程中才知道，这里是著名的毛泽东下榻过的东湖宾馆。做讨厌的是，湖边被商业包裹着，没法入内。最终从一个工地进入，出来时就麻烦了，不想大摇大摆的，从被卫兵拒绝的门口跑出来，后来翻墙出来了。 洗过澡后，和同时们一起去吃饭了。 这是同事推荐的一家，非常火爆的店，6 点半到店，排了一个多小时对，终于可以上桌了。 口味太赞了，性价比超级高，我现在敲键盘的手指还有油闷大虾的香味。吃了很多，喝啤酒聊天，非常完美的一餐。\n","date":"2014-06-27T15:46:16Z","permalink":"https://martinliu.cn/2014/06/27/e6ada6e6b189-e4bc9ae8aeae/","title":"武汉 会议"},{"content":"首先，确保自己所在的地点位于接受范围以内。如北京距离河南在距离商丘 1000 公里以内的范围，因此能够正常接受电波。\n如果，出差去到其他国家的话，可以参考下面的电波发射点地图。\n然后，就是手动或者自动对时了。手表需要放在非隔离的空间中，不能在一个没有窗户的房间。\n最后，我最近天天晚上 1 点左右手工对时，电波接收正常。\n","date":"2014-06-25T06:14:41Z","permalink":"https://martinliu.cn/2014/06/25/e794b5e6b3a2e8a1a8-e5afb9e697b6e68a80e5b7a7/","title":"电波表 对时技巧"},{"content":"昨天中午去天津，下午完事了就会北京。经过天津站前广场，稍微观察了一下，这次发现天津站修的如此的高大上，广场非常的宽敞，河岸的风景也十分的靓丽。就是车站里面的秩序还是不行，售票厅里的自助售票机是坏的，进站派长队等着检查身份证和安检。\n一位移民海外的长者看了我发的这几个照片，好奇的问道：天朝是不缺高达上的，就是差环境了，等环境治理好了，会考虑回去养老。\n","date":"2014-06-25T04:47:28Z","permalink":"https://martinliu.cn/2014/06/25/e5a4a9e6b4a5-e79fade69a82e587bae5b7ae/","title":"天津 短暂出差"},{"content":"\n导演: 罗伯特·斯特罗姆伯格\n编剧: 保罗·迪尼 / 琳达·伍尔芙顿\n主演: 安吉丽娜·朱莉 / 艾尔·范宁 / 沙尔托·科普雷 / 莱丝利·曼维尔 / 伊梅尔达·斯汤顿 / 朱诺·坦普尔 / 萨姆·赖利 / 布伦顿·思韦茨 / 肯内斯·库兰汉姆 / 莎拉·弗林德 / 汉娜·纽 / 伊莎贝尔·莫洛伊 /迈克尔·希金斯 / 艾拉·珀内尔 / 杰克逊·比尤斯\n类型: 动作 / 爱情 / 奇幻 / 冒险\n官方网站: movies.disney.com/maleficent\n制片国家/地区: 美国\n语言: 英语\n上映日期: 2014-06-20(中国大陆) / 2014-05-30(美国)\n片长: 98 分钟(中国大陆) / 97 分钟(美国)\n又名: 黑魔后：沉睡魔咒(港) / 梅尔菲森特 / 玛琳菲森 / 黑法魔女 / 睡美人外传\nIMDb 链接: tt1587310\n[su_quote]怀揣着一颗童心体味一个纯美的童话世界，童话世界中存在这亦正亦邪，存在着邪恶和纯美的动态变化，最终正义战胜了邪恶，世界恢复到美丽的平衡中！我给它 7 颗星。[/su_quote]\n","date":"2014-06-23T07:29:48Z","permalink":"https://martinliu.cn/2014/06/23/e7baafe7be8ee5928ce982aae681b6e79a84e79bb8e4ba92e8bdace58c96-maleficent/","title":"纯美和邪恶的相互转化-Maleficent "},{"content":"在京东入手 GW-6900 这块 6 局电波表。主要的吸引我的就是六局电波功能，其它的太阳能、防水等等其它功能都是浮云，可惜的是目前还没有手动接受电波成功过。\nGW-6900 表的样子就是如上图，比较经典的三眼设计。网上评价说：表盘偏大不适合手腕细者、表颜色发亮。到手拆箱试戴后，这两个疑虑都统统打消了。\nGW-6900 手动电波对时还没有成功，等待晚上自动对时了。\n总体觉得这块表比较适合生活休闲佩戴，在一些非高大上的工作场合也适合。\n从工作的角度看，它内置的 48 世界城市时钟也很有用，特别是第二时钟功能，按右上键直接调出最关心的其它时区时间，操作非常方便。要是找其它某个时区的时间，也就多点几就能看到。\n官方介绍：http://www.casio.com.cn/wat/g-shock/GW-6900-1/index.html\n操作手册：http://www.casio.com.cn/resource/files/support/wat/support/book/3179.pdf\n","date":"2014-06-21T12:29:31Z","permalink":"https://martinliu.cn/2014/06/21/casio-g-shock-gw-6900e5a4aae998b3e883bde585ade5b180e794b5e6b3a2/","title":"CASIO G-SHOCK GW-6900 太阳能六局电波"},{"content":"当静下心来读书成为一个奢望，我们还是能通过其它的方式来亲近书籍，感受另外一种听书的方式。推荐下面这个听书 Podcast，他们读的书还是挺吸引人的。\n[caption id=\u0026ldquo;attachment_52878\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;967\u0026rdquo;] 一个人的书房[/caption]\n他们的书单：《搭车去柏林》《巨流河》《断舍离》《流波上的舞》《追风筝的人》《安妮日记》《冬牧场》《生死的幻觉》《梦里花落知多少》\niPhone 上收听地址：https://itunes.apple.com/cn/podcast/yi-ge-ren-de-shu-fang/id612325017?mt=2#\n","date":"2014-06-16T09:27:33Z","permalink":"https://martinliu.cn/2014/06/16/e68ea8e88d90-e4b880e4b8aae4babae79a84e4b9a6e688bf-podcast/","title":"推荐Podcast - 一个人的书房 "},{"content":"这是一个特殊的日子，所有的事情高高低低、起起落落；在一波又一波中挫折着，前行着！\n","date":"2014-06-16T08:30:51Z","permalink":"https://martinliu.cn/2014/06/16/e7acace4b889e4b8aae9a9ace5b9b4/","title":"第三个马年"},{"content":"免费主题 The Night Watch + 七牛 CDN 给力，最终网页绝大多数能够非常快速打开，今天到为止了。\n","date":"2014-06-15T19:01:04Z","permalink":"https://martinliu.cn/2014/06/15/e8afa5e79da1e8a789e4ba86/","title":"该睡觉了"},{"content":"实践证明我曾经买的所有的 blog theme 都不适合我，最后还是回到了免费主题上，非商用 blog，付费主题慎用，除非你的定力很好，不好折腾。\n","date":"2014-06-15T18:58:00Z","permalink":"https://martinliu.cn/2014/06/15/e6b2a1e5ae8ce6b2a1e4ba86/","title":"没完没了"},{"content":"一个 bolg 要经过多少次折腾和重定义，我已经不记得是第几次晚上换主题换到 2 点才睡觉了。要说我为什么？我不过是把其它人熬夜看足球的精力用在了一项觉得有意思的事情上。\n本次更新主要是，更改一下此 blog 的方向，以后发布的内容将不会在有技术帖，原来的技术贴依然欢迎留言和讨论；今后的风格是简洁风格，多以生活内容为主。\n","date":"2014-06-15T18:12:21Z","permalink":"https://martinliu.cn/2014/06/15/e59b9ee5bd92e588b0e69c80e7ae80e6b481e79a84e78ab6e68081/","title":"回归到最简洁的状态"},{"content":"[video width=\u0026ldquo;640\u0026rdquo; height=\u0026ldquo;360\u0026rdquo; mp4=\u0026ldquo;http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2014/02/The-Citrix-Story-25-Years-of-Imagination-Innovation-and-Growth.mp4\u0026rdquo;][/video]\n以上视频从 YouTube 转载。是 Citrix 给自己的拍摄的生日礼物。真正的 25 岁生日那天在今年四月份。下面是维基百科上对 Citrix 的介绍。\n这个短片拍的是挺有意思的，可以让你快速得回顾一下这个公司的历史。\n","date":"2014-02-10T11:09:21Z","permalink":"https://martinliu.cn/2014/02/10/e4ba8ecitrix-25e591a8e5b9b4e79a84e69585e4ba8b-imagination-innovation-growth/","title":"于Citrix 25周年的故事 Imagination Innovation Growth"},{"content":"今天广为关注的的新闻末过 Facebook 的单人管理上万服务器。上网看了一下此新闻的出处：http://www.datacenterknowledge.com/archives/2013/11/20/facebook-ops-staffer-manages-20000-servers/ 本文的描述如下：Delfina Eberly, Director of Data Center Operations, Facebook, presented the Tuesday morning keynote about optimizing data center operations. In terms of hardware, Facebook, because it runs such an enormous volume of servers, focuses on serviceability, including starting from the ground up by influencing server design to ensure easiest and least time consuming methods to repair equipment in the data hall.\n她是 Facebook 公司的数据中心运营总监，在昨天早晨发表了关于如何优化数据中心运维的演讲。从硬件方面看，为了满足它们巨大的用量，她们不得不把精力完全放到硬件的服务提供性上，说白了“黑猫，白猫，能捉到耗子的就是好猫”，因此她们被逼去自己从服务器硬件设计开始构造自己的数据中心神殿。为什么说是被逼的，你可以想象：加入 IBM，DELL，HP 之流的 sales 推门进去，告诉她们你们买我们的服务器吧，保证好用！可能在她们也买得起，但是绝对用不起，用不起是由于：服务器的采购，供货，修复，维保，这一切都靠供应商的话，从时间和效率上将 Facebook 觉得耗不起。一旦依赖了供应商，自己就必然失去了主导权，多了一重羁绊，无法满足 facebook 这样公司的高速成长。一切创新其实都是被逼出来的。\n这让我感兴趣 Mark 最近在搞些啥，我简单转发两个我看到并感兴趣的网站。\nInternet.org 这个网站上最抢眼的还是首页最上端的那个视频，很可惜国内用户看不到 youtub，我在这里把 Mark 的这个视频在我的网站上转贴一下。\n[video width=\u0026ldquo;640\u0026rdquo; height=\u0026ldquo;360\u0026rdquo; mp4=\u0026ldquo;http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2014/02/Making-the-Internet-Affordable.mp4\u0026rdquo;][/video]\n这个视频主要是 Mark 亲自现身说法说如何让上网成本更低，争取能做到让全世界更多的人民上网的宏大理想。听完之后，这不能不让我和今天的另外的一个新闻“facebook 收购 Onavo”联系起来，表面上看 Onavo 是他实现这个理想的一种工具；另外一个邪恶的说法，则说：”他想控制这个世界所有人上网的流量“；我们拭目以待，他们是如何改造地球的吧！\n另外一个网站是这个，开源计算机项目网站。我一直对开源的项目尤为感兴趣，甚至于开源的“窗台农庄项目”。但是主要还是开源软件了解的多。这个网站是 Facebook 主导的一个项目，目的在于开放他们部分服务器硬件和数据中心设计的技术。确实是一个很不错的学习资料。在这里我又看到了类似于 QQ 和中国移动竞争的类似场景。如果这个项目火了，这让那些买服务器的公司情何以堪啊！但是我因此加深了 IBM 卖掉 PC 业务给联想的这个事实。国人一直在接受人家过期的技术和业务，这样值得么？从业务的角度上讲，短期是还是值得的，原因是：国内 IT 的发展总是滞后于欧美 3 到 5 年时间。我感觉滞后的原因主要还是语言和文化的不通。\n如果对 Facebook 的数据中心感兴趣的话还可以看看这个 FAQ, http://www.datacenterknowledge.com/the-facebook-data-center-faq/\n","date":"2014-02-08T03:17:37Z","permalink":"https://martinliu.cn/2014/02/08/e5bc80e6ba90e69c8de58aa1e599a8e79a84e697b6e4bba3e79c9fe588b0e4ba86efbc9f/","title":"开源服务器的时代真到了？"},{"content":"本帖系技术贴，目的在于总结一下这次对本站点优化的经历。总之结果很重要，把基本上所有页面都优化到大约 0.8 秒左右的载入速度。如果你也是在独立 LAMP 服务器上运行 WordPress 的话，我想本文可能对你会有所帮助。 Wordpress 服务器配置 服务器是在阿里云上的主机，主机的配置比较低：1vCPU，1GB 内存；后台数据库是 RDS 服务。\n服务器的操作系统是 Debian，安装的 php 的情况见 phpinfo.php 的输出。\nWordPresss 所安装的插件如下：akismet syntax-highlighter download-monitor update-twitter-php google-sitemap-generator use-google-libraries wordpress-popular-posts wordpress-seo jiathis wp-easyarchives kimili-flash-embed wpjam-qiniu memcached wp-pagenavi nextgen-gallery wp-postviews optimize-db wp-recentcomments regenerate-thumbnails wp-super-cache revslider wp_video-master shortcodes-ultimate yet-another-related-posts-plugin simple-google-analytics\nWordpress 插件：WP Super Cache Super Cache 使用的是： mod_rewrite 缓存模式。 并开启了：使用对象缓存系统来存储缓存文件。 (实验室功能) 这个功能和 memcached 插件是相关的。在 CDN 的配置这里，开启了 CDN 的支持，并把 off-site URL 指向了 http://martinliu.qiniudn.com 七牛的空间。\n现在很多页面查看源码的时候，都可以看到是 0.8 秒以内的速度，这个速度起码是本站点有史以来的最快速度。不光服务器速度快了，更重要的是所有静态文件也都是用的大陆的本土 CDN 站点了。\nWordpress 插件：**memcached 和 MemCached 服务 **\n这个插件我第一次用，真可谓是神器，它需要和操作系统的 memcached 服务配合起来使用；这个插件的安装比较反常规：不能在控制台里面启用，根本就启用不了，需要安装插件后，在未激活的状态下，把它的文件手工放到 wp-content 目录里面即可。操作系统的 memcached 的服务安装和配置也比较简单，总之运行基本全都靠默认的配置参数即可。另外 php 的 memcached 模块也要安装并启用。它们配合起来能够把页面的 request 次数降低到冰点。我的主页用这个组合之前需要 30 次左右的 request，用了之后就 3 次了，它主要是靠内存做缓存，从而加速了网站。\n上图是本站首页的测试结果，亮点在它只有 3 个请求，Web 服务器只是做了三个响应就完事了，这个页面的内容就全都可以发给浏览器了。减少了 20 多次请求的处理，这些请求的结果都被 memcached 给缓存到内存里面了，目前只能够给 memcached 开 80MB 的缓存空间，也就这点内存常驻的网站缓存解决了大问题。加速页面的响应速度。不得不说 memcached 服务还是挺 NB 的。\n上图是一个常规的文章页面，请数量从以前的 30 左右降到 10 以内，我什么也不说了。当然上面这连个图里面也能看出本网站的一点问题，这里也不说了。\nWordpress 插件：WPJAM 七牛镜像存储 本次折腾主要冲着这个来的。CDN 我是第一次玩，不过用一次之后，感觉也挺简单的。先要找一个免费的 CDN 服务商开一个空间，之后一般送 1GB 空间一个月 1GB 流量，对我的网站来说足够了。配置完之后就拿到了一个二级域名，然后还有几个重要的 Key 编码。安装了水煮鱼做的这个插件之后，配置完，什么也不用管，网站的哪些静态文件就在首次访问的时候，被自动传到 CDN 上面了，下次网页再被打开的时候就全都走 CDN 上下载了，从而把 Apache 的基本所有静态文件的请求都 offload 走了，从而降低了服务器的负荷，提升了它对动态内容的反应速度。我的服务器只有 1GB 内存，用了 CDN 之后，我也不是很担心内存不够用的问题了。\n未尽事宜 由于时间仓促，有几个活也没有时间做。1）我的域名 martinliu.cn 的 DNS 查询的速度有时候挺慢的，快也要 500ms，有时候甚至超过一两秒，不知道是 DNSPod 不给力还是我的服务器自身有问题。2）CDN 的正规用法需要在服务器端写一个脚本，把 wordpress 里面需要 CDN 加速的文件都上传到自己 CDN 的空间里面，并且可以编写脚本定期增量传输。由于最近太忙，以后有时间在研究这个问题吧。3)wordpress-popular-posts 此插件在每个页面上都占用一定的时间，不知道是否能把它消除到。4）Gravatar 头像的加速，否则这些图标在评论多的帖子上从国外站点下载，实在是太慢了。\n","date":"2014-02-07T16:18:06Z","permalink":"https://martinliu.cn/2014/02/07/e4bc98e58c96wordpresse9a1b5e99da2e588b0e4b880e7a792e58685/","title":"优化 WordPress 页面到一秒内"},{"content":"[audio m4a=\u0026ldquo;http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2014/01/chan.m4a\u0026rdquo;][/audio]\n垂绥饮清露，流响出疏桐。 居高声自远，非是藉秋风。\n\u0026ndash;虞世南【初唐】\n","date":"2014-01-08T10:11:22Z","permalink":"https://martinliu.cn/2014/01/08/e5a4a9e7b181e4b98be99fb3-e697a0e8a880e58fa4e8af97-e89d89/","title":"天籁之音 五言古诗 蝉"},{"content":"我在 Garmin 网站上建立了一个”长跑俱乐部群“ Beijing LSD Club ； 欢迎各位爱好者加入。LSD 的意思是：Long Slow distance running ； 简单说就是长跑。\n群的地址： http://connect.garmin.com/group/514228 ；\n我今天在 Garmin Connect 上面的群搜索哪里，那么一搜：北京、Beijing；居然什么也没用；我就不信了，北京用 Garmin 的表的跑友应该也不少，何不大家都聚集起来，互相分享互相激励。热烈欢迎大家参加！\n","date":"2014-01-08T05:19:28Z","permalink":"https://martinliu.cn/2014/01/08/garmin-beijing-lsd-club/","title":"Garmin  Beijing LSD Club"},{"content":"了解一位著名的美国马拉松运动员。非常年轻，非常优秀的跑者。Ryan Hall holds the American records for the half marathon and 20k, and his 2:04:58 marathon time is the fastest ever by an American. Ryan’s wife, Sara, is also a professional runner. Their Hall Steps Foundation urges the running community to help end global poverty.\nBirthplace: Kirkland, Washington High School: Big Bear High School, Big Bear Lake, California College: Stanford University (Major – Sociology, Class of 2006) Ryan and his wife Sara, currently currently train in Flagstaff, AZ and Palo Alto, CA Personal Bests 1,500m – 3:42.70 (2001) 5,000m – 13:16.03 (2005) 10,000m – 28:07.93 (2007) 20,000m – 57:54 (2006) American Record Half-marathon – 59:43 (2007) American Record Marathon – 2:04:58 (2011) fastest American performance of all time [su_quote]“I run because I believe that God has created me to run. When I run, I feel like I am fulfilling the purpose for which I was created. I know that I may not always run, but that God has used running as a part of my life to lead me down a path that I would not have taken otherwise. If I had never run, I would have never went to Stanford, met Sara, or be doing what I am doing now. I believe that God wants me to run to bring glory to his name and to further his kingdom on earth in some way. Some of my most intimate moments with God have been out in the trails, on the race course, or on the track. This is why I love to run.”[/su_quote]\n[video width=\u0026ldquo;740\u0026rdquo; height=\u0026ldquo;500\u0026rdquo;]http://v.youku.com/v_show/id_XMjk0NzcxMzg4.html[/video]\nRyan Hall 是位美國長跑選手，他在 2008 年的時候贏得了奧運的馬拉松參賽資格，並且在北京奧運馬拉松項目排名第十，他以 59 分 43 秒成為美國半馬紀錄保持人，也是美國史上第一位半馬在一個小時內完成的男人。\nRyan 的爸爸是曾經被巴爾地摩棒球隊選中，受到父親喜愛棒球的影響，他小時候其實是想要成為一位投手，常常在院子裡用網球做投球練習。雖然那時候的 Ryan 對跑步還沒產生興趣，但他小時候在體育課的跑步項目已經非常的突出。父親那時就已經看出他的天分，告訴 Ryan 說：「如果你願意花時間練習，你可以成為世界頂尖的跑者。」\nRyan 高中比賽時的照片\n在 13 歲的某個星期六的一大早，他心中突然湧出想要跑步的強烈慾望，於是繫緊鞋帶，跟著也有鐵人經驗的爸爸出門慢跑。那天，他跑了 24 公里。他形容他第一次的慢跑經驗：「很痛苦，真的很痛苦。我們必須要休息很多次，我的小腿也是前所未有的疼痛著，每跨出一步我的臉就會痛苦的抽搐，而且當我們終於回到家的時候我直接癱軟在沙發上，一直到中午我都還無法動彈。」高中的時候 1500 公尺他就跑出 3 分 43 秒的成績。\n開始跑步之後他就有個夢想－參加奧運。Ryan 甚至在萬聖節的南瓜上雕刻奧運的五環標誌。在 2004 年的時候他參加了奧運馬拉松選拔賽，可惜並沒有入選。大受打擊的 Ryan 覺得自己的人生已經毀滅了，他開始懷疑自己的人生價值。幸好他的信仰幫助他走過一切，這是上帝給他的磨練，他應該要從跑步裡得到快樂，而不是向上帝尋求安慰。\n果然，上帝並沒有放棄他，在 2006 年的時候開始嶄露頭角，打破了許多記錄。在那一年的 10 月 8 號 Ryan 打破了美國 20K 的記錄，57 分 54 秒，比上一個記錄快了 48 秒。2007 年，他成為美國跑最快的馬拉松選手，在休士頓馬拉松那場比賽，他跑出了 2 小時 08 分 24 秒的成績，同年的 11 月，他也獲得了 2008 年北京奧運馬拉松的參賽資格，這時的他已經是全美國最有名的跑者之一。雖然在北京奧運上他只獲得了第十名的成績(2：12：33)，但是在 2012 年的時候他又再度獲得了倫敦奧運的參賽資格。他也是美國史上罕見跑過兩次奧運馬拉松的選手。\nRyan：「我一直很想要成為一個超級英雄，但我想這是我唯一最接近的時刻。順帶一提，那位美國先生是我姐夫。」\nRyan Hall 每個禮拜的訓練量都超過 150 公里以上，那到底要怎麼補充能量呢？平常他會大量的補充水果、蔬菜、和適量的碳水化合物、蛋白質和脂肪。同時他也會確保他會獲得足夠的 Omega-3 脂肪酸，他也吃很多抗氧化劑含量高的天然食物，例如綠茶、莓果類、肉桂等，可以迅速恢復體力的食物像是鳳梨或是乳漿蛋白質(whey protein)和果汁。這樣吃下來有時一天還會吸收超過 6000 卡的熱量。「在訓練耐力跑的時候，身體會需要很多的食物，當作燃料跟幫助身體恢復。」Ryan 說。\nRyan 很喜歡吃生魚片噢！\n但是在比賽前 Ryan 反而會少吃一點含纖維的食物，「上場前一天吃這些食物會不舒服，還會脹氣。」相反的，比賽前一天是可以吃一些簡單的碳水化合物和含有一點點脂肪的瘦肉蛋白(lean proteins with a touch of fat)。另外，他建議在比賽前兩到三小時要 200~400 卡的食物，這時身體消化得比較慢而且能補充一點體力，重要的是要吃自己習慣並且常吃的食物。\nRyan 跟老婆 Sara 都是美國優秀的選手，兩人在史丹佛認識、相愛，並在 2005 年結婚，身為基督徒的他們在 2009 年創立了一個基金會－The Hall Steps Foundation，目的是在於幫助貧困的人脫離貧窮，可愛的是他們也身兼義賣衣服的模特兒，省下請專業模特兒的錢。Ryan 跟 Sarah 的感情也非常的好，在 Ryan 的 Twitter 也常常看見他們一起出去釣魚、健身，去哪裡兩個人都會在一起。\n「每天 Sara 都會讓我覺得很驕傲，但是今天我特別的以她為榮。」Ryan 說\nFrom: 把跑步當信仰的男人 ─Ryan Hall\n美国半马纪录保持者 Ryan Hall 的跑步教学视频:\n长距离间歇跑训练(快速储备耐力)网页链接\n短距离间歇跑训练(提高速度耐力)网页链接\n高抬腿 训练(激发腿部活力)网页链接\n直曲腿交叉跑(超有效爆发力)网页链接\n动态拉伸训练(提高冲刺动力)网页链接\n","date":"2014-01-01T09:56:27Z","permalink":"https://martinliu.cn/2014/01/01/ryan-hall/","title":"著名美国马拉松运动员 Ryan Hall"},{"content":"有了这 3 本书我们再也不用担心 GPU 的测试了。\n[su_button url=\u0026ldquo;http://www.citrix.com/wsdm/restServe/skb/attachments/RDY12010/Reviewer%27s%20Guide%20for%20HDX%203D%20Pro%20-%2001%20XenServer.pdf\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;3d\u0026rdquo; background=\u0026quot;#4e7f22\u0026quot; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: download\u0026rdquo;]Part 1 下载点击这里 Reviewer’s Guide for Remote 3D Graphics Apps [/su_button]\n[su_button url=\u0026ldquo;http://www.citrix.com/wsdm/restServe/skb/attachments/RDY12011/Reviewer%27s%20Guide%20for%20HDX%203D%20Pro%20-%2002%20vDGA.pdf\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;3d\u0026rdquo; background=\u0026quot;#4e7f22\u0026quot; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: download\u0026rdquo;]Part 2 下载点击这里 Reviewer’s Guide for Remote 3D Graphics Apps [/su_button]\n[su_button url=\u0026ldquo;http://www.citrix.com/wsdm/restServe/skb/attachments/RDY12202/Reviewer%20Guide%20for%20HDX%203D%20Pro%2003%20vGPU%20GA.pdf\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;3d\u0026rdquo; background=\u0026quot;#4e7f22\u0026quot; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: download\u0026rdquo;]Part3 下载点击这里 Reviewer’s Guide for Remote 3D Graphics Apps [/su_button]\nThis document helps you set up a simplified lab to review hardware-accelerated GPU virtualization for Windows desktop VDI workloads on Citrix XenServer. True GPU virtualization (a.k.a vGPU) on NVIDIA GRID cards is supported since Service Pack 1 of Citrix XenServer 6.2. It extends high-performance GPU sharing capabilities beyond Windows Server RDS workloads, that we cover in part 1 and part 2 of this series of Guides; Part 3 walks through the following topics:\n[su_list icon=\u0026ldquo;icon: comment-o\u0026rdquo; icon_color=\u0026quot;#b920ab\u0026quot;]\nHow to obtain the necessary components for the feature review Install NVIDIA GRID GPU, and configure vGPU in XenServer Assign vGPU to XenDesktop 7.1 Windows Desktop VM’s Install and publish GPU-accelerated Virtual Desktops (VDI) using Studio Access GPU-accelerated Virtual Desktops (VDI) from Citrix Receiver on any device Verify 3D applications on multiple desktops are sharing the same physical GPU [/su_list]\n","date":"2013-12-31T11:36:27Z","permalink":"https://martinliu.cn/2013/12/31/reviewers-guide-remote-3d-graphics-apps/","title":"Reviewer’s Guide for Remote 3D  Graphics Apps "},{"content":"虽然是第二次办理签证，是自己 送资料那种，但是还是少复印了一页材料，下面是一点经验总结：\n[su_list icon=\u0026ldquo;icon: check\u0026rdquo;]\n新加坡签证的办理，必须到新加坡大使馆的网站上看须知，所以网站一定要去看：http://www.mfa.gov.sg/content/mfa/overseasmission/beijing/ch.html 本页下面的内容就是签证办理的注意事项了，最好还是到网站上看，以防止网站上有更新的东西。 户口本复印必须要完整，户口本的每一页都需要复印一页 签证费是 153 一个人，自己准备零钱 旅游签证是 35 天有效期，从签发的那天算，35 天后，不管你是否入境，签证都作废了，所以不可以提前太早去办理签证 通常情况下，北京 3 个工作日就可以取签证了 送资料的时间是周 1 ～ 5 早晨 9 点到 11 点，去晚了就关门了 [/su_list]\n[su_quote]下面是官网的详细说明，需要逐字逐句的阅读，而且每个字都要理解，并且照做，你的签证材料准备的就妥妥的了！[/su_quote]\n申请签证必须提供以下材料。若有必要, 本馆有权要求申请者提供其他材料。\n**护照：**护照原件及护照照片页复印件。护照有效期应在六个月以上（从入境日期开始计算），并至少有一张空白签证页。\nForm 14A **签证申请表格（原件）：**一份用英文填写完整，并有申请者亲笔签名的申请表格。\n彩色照片：二张（一张贴在表格上，另一张供扫描用）。照片应符合下列要求：\n两寸，彩色，白底 的三个月内的近照；\n正面免冠（如按特殊宗教或风俗要求戴帽或配饰，帽子或配饰不得掩盖申请者面部特征）。\n**中国身份证：**原件及复印件。（注：申请商务签证者，只需复印件）\n**签证费（概不退还）：**人民币 153 元 (请自备零钱) 。\n**另，申请旅游签证需提供其他材料如下：**\n在职证明： 申请人若为在职员工，必须提供由就职公司出具的在职证明信原件一份。证明信中需注明公司同意其休假，并详细注明申请者在该公司任职时间、职务及工资。在职证明信必须列有公司及有关联系人的地址、电话和传真号码。信函必须加盖公章。申请人若无工作，则必须提供证明其个人经济状况的文件，如银行存款证明 (原件及复印件)。银行存款证明的金额没有具体要求但银行签发日期必须是签证申请递交日期的 1 个月内。此证明应能够如实的反映您的经济能力。\n**户口簿：**申请者户口簿 (全本，每页：原件及复印件) 。如为集体户口，可在警察局办理户籍证明，并提供原件及复印件。\n另，申请商务签证需提供其他材料如下:\n**委托书：**如本人不能亲自来使馆申请签证，需出具委托书，委托书要注明被委托人的姓名及身份证号码（中英文均可）。被委托人必须携带自己身份证原件并提交复印件。即使是同一个人被委托，请在申请及领取签证时各递交一张委托书。\n新加坡公司商业注册简况打印件：由新加坡会计与企业管理局（http://www.acra.gov.sg）出具的新加坡公司最新商业注册简况打印件一份，该简况的打印日期距递交日期不得超过 6 个月。由新加坡政府机构、大学邀请或出席在新加坡召开的展览会、大型会议等的申请者，无需出具 V39A 表格和新加坡公司商业注册简况。申请者只需递交该机构或组织签发给申请者的邀请函原件。邀请函上必须要有该机构或组织邀请人的签名和申请者的名字。\n**V39A 表格原件（介绍信）：**由新加坡注册公司代表人(必须 21 周岁以上的新加坡公民或新加坡永久居民) 用英文填写完整的原件一份。信上必须注明新加坡公司的地址、电话、传真号码, 公司章和公司代表人的新加坡身份证号码与签名。\n签证申请者必须本人亲自来本馆递交申请。以下情况除外:\n若申请人未满18周岁，可由其父母代办，但必须出具能证明其关系的出生公证书或户口本和父母身份证（原件及复印件）；\n若夫妻关系，可由其配偶代办，但必须出具能证明其关系的结婚证或户口本和配偶身份证（原件及复印件）；\n如申请人已退休或60周岁以上，可委托他人办理，但需提供本人退休证原件、复印件及委托书（注明被委托人的姓名和身份证号码）。被委托人必须携带自己身份证原件并提交复印件；\n如申请人由在华的新加坡公民或新加坡永久居民作介绍，介绍人(必须21周岁以上) 需亲自来本馆递交申请，并提供填好的 V39A表格原件（介绍信） 及其新加坡身份证或护照的原件及复印件；\n申请商务签证者。\n**签证递交及领取时间：**周一至周五上午 9：00 至 11：00 （只受理材料递交）周一至周五下午 4：00 至 4：30 （只受理签证领取）\n**签证办理时间：**一般三个工作日（递交申请日包含在内）\n**签证咨询:**建议申请者及介绍人请仔细详读此申请内容。若有任何其他问题，可拨签证热线 +86-10-65329380 咨询。\n重要注意事项\n未填好的表格、材料不齐或不符合要求有可能导致拒签或推迟受理。\n签证申请是否被批准，及批准的有效期限都由签证官根据申请者个别情况决定。\n申请者应在签证批准后再购买机票。凡因提前购买机票而签证未被批准所造成的经济损失，本馆对此不负责任。\n签证的签发日期一般是签证的申请日，签证一旦被签发其有效期将不再变更。申请者不应过早递交申请材料。若签证已过期，申请者须重新递交申请材料。申请者在领取签证时，应仔细核对签发日期及签证有效期。建议申请者在出国前一至二周递交申请。\n签证持有者并不一定可以入境新加坡。签证持有人须符合入境规定方可准许入境，如有效护照，足够的资金和往返机票（如需要）。新加坡移民与关卡局官员有权决定其是否可入境。\n新加坡移民与关卡局官员在签证持有者入境时决定其停留天数。申请者应留意护照的入境章和批准的停留期限 。\n","date":"2013-12-31T03:30:33Z","permalink":"https://martinliu.cn/2013/12/31/e696b0e58aa0e59da1e7adbee8af81e794b3e8afb7e68980e99c80e8a681e69d90e69699/","title":"新加坡签证申请所需要材料"},{"content":"\nGarmin ForRunner 620\n尺寸: 4.5 x 4.5 x 1.25 cm 重量: 43.6 g 1“ 彩色/触摸式萤幕 180x180 续航力: 手表模式 6 周 / 训练模式 10 小时. 50m 防水 支援 live tracking - 可与手机连线, 将轨迹及时传送出去, 与朋友分享. 支援蓝牙 LE 支援 Wifi 支援 Running Dynamics 支援 Recovery Advisor 支援 VO2 max estimate\nGarmin ForRunner 220\n尺寸: 4.5 x 4.5 x 1.2 cm 重量: 40.7 g 1“ 彩色/非触摸式萤幕 180x180 续航力: 手表模式 6 周 / 训练模式 10 小时. 50m 防水 支援 live tracking - 可与手机连线, 将轨迹及时传送出去, 与朋友分享. 支援蓝牙 LE 不支援 Wifi 不支援 Running Dynamics 不支援 Recovery Advisor 不支援 VO2 max estimate\n","date":"2013-12-21T11:16:37Z","permalink":"https://martinliu.cn/2013/12/21/garmin-fr620-e7acace4ba8ce59d97e8b791e6ada5e6898be8a1a8e79baee6a087/","title":"Garmin FR620 第二块跑步手表目标"},{"content":"跑了一整年了，回顾一下数字：从咕咚运动和 Garmin Connect 里面记录的总和里程为九百多公里；跑步主要是为了强健体魄和挑战自我。同时也有非常多的其他好处：减压、提振精气神、消除负面情绪等等。每次跑到欲罢不能的时候，都是一种畅快的肉体和精神之旅。跑步所到达的城市有十几个；国外的城市有：新加坡、新奥尔良、洛杉矶、圣地亚哥。下面是所有跑步地点的清单：\n所有跑步地点的地理分布如下： 从跑步成绩方面还取得了一些个人记录： 这些记录是由我的 GPS 跑步手表记录的。所有的数据都上传到 Garmin Connect 网站上，数据还算比较准确。 这块表的功能比较简单，能记录跑步的轨迹、速度等等，可以存储最好个人记录，和 7 个最近的跑步活动。还算是比较实用，带着它我跑完了人生第一个半程马拉松。\n让我跑的最爽的几个地方是：北京奥林匹克森林公园、新加坡的 Gardon by the bay 温室植物园、崇礼的草原天堂之路、沈阳的浑河畔、新奥尔良密西西比河畔等等。 由于我热衷于晨跑，当你迎着朝阳，挥汗如雨、在吸收正能量的过程中；你能领略到别人无法想象的景色，这些美景都深深的留在了脑海里。\n以上四张图片：\n上左：沈阳浑河河畔，我从靠近市中心的大桥王东南方向，沿着河边非常专业的骑行道路一气跑下去，已经快到鹭岛附近，跑了 15 公里。那是在盛夏，北京闷热沈阳比较凉爽，跑出的汗多，但是体温不太高，跑的大汉淋漓，爽透了。 上右：北京的春天气候非常好，早晨 7 点清凉的很。为了备战金鸡湖半程马拉松比赛，周末驱车 30 多分钟，跑 10 多公里回家，浑身无伤痛感，无精神压力的奔跑完全可以让任何一个人上瘾 下左：崇礼的草原天堂之路，本来是去那里看草原和大风车的，但是下夕阳西下的时候，看到那一眼望不到边的草原，新修的公路就在脚下，顿时脚跟发痒，直接开跑，跑了 3 公路多山路，主要是为了搜集地点，3 公里山路下来，基本上人山合一，完全置身于世外了 下右：在美国新奥尔良的密西西比河河畔，和同事们一起跑可谓是人生的一大乐事，其实需要感谢我的所有跑友们，他们是跑步乐趣的催化剂，无限低放大了跑步的乐趣，能给我更多跑步的理由，我们的跑步微信群是大家参与度极高的圈子，每个人的日常跑步作业都在上面实时发布。 最开心的还是看着两岁多的宝宝能一天天的长大，跑步是唯一的让我与她拉近时间和空间距离的方法。我已经无法停止跑下去的步伐。 ","date":"2013-12-19T15:20:47Z","permalink":"https://martinliu.cn/2013/12/19/2013-year-running/","title":"2013 Year Of Running"},{"content":"当您的 XenServer 测试机需要增加硬盘的时候，你需要通过简单的几条指令把新硬盘添加为本地存储。\n下面的实例情况是：\n测试机有两块硬盘\nOCZ SSD 硬盘一块\nSATA 不通硬盘一块\n还有一个 U 盘插在系统上\nSATA 的硬盘是我需要加载的新硬盘\n这个新的硬盘希望被处理成 XenServer 本地的 SR\n添加过程中主要需要使用这样几条指令：\n查看当前系统上的检查出来并且挂载中的分区： cat /proc/partitions\n详细查看这些存储和设备对应的情况： ls -l /dev/disk/by-id/\n创建新的本地 SR: xe sr-create content-type=user device-config:device=/dev/disk/by-id/scsi-SATA_ST9320325ASG_5VD7G964 host-uuid=3850317b-d23a-4ed0-87f9-2b27854319e5 name-label=\u0026ldquo;SATA320\u0026rdquo; shared=false type=lvm\n[bash] [root@XS62 ~]# cat /proc/partitions major minor #blocks name\n7 0 52378 loop0 8 0 250059096 sda 8 1 4193297 sda1 8 2 4193297 sda2 8 3 241669447 sda3 8 16 312571224 sdb 8 17 204800 sdb1 8 18 312235312 sdb2 8 32 4137984 sdc 8 36 4137856 sdc4 252 0 241655808 dm-0\n[root@XS62 ~]# ls /dev/disk/by-id/ scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part3 scsi-SATA_ST9320325ASG_5VD7G964-part2 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part1 scsi-SATA_ST9320325ASG_5VD7G964 usb-Generic_Flash_Disk_4266F915 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part2 scsi-SATA_ST9320325ASG_5VD7G964-part1 usb-Generic_Flash_Disk_4266F915-part4\n[root@XS62 ~]# ll /dev/disk/by-id/ total 0 lrwxrwxrwx 1 root root 9 Nov 22 19:52 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2 -\u0026gt; ../../sda lrwxrwxrwx 1 root root 10 Nov 22 19:52 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part1 -\u0026gt; ../../sda1 lrwxrwxrwx 1 root root 10 Nov 22 19:52 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part2 -\u0026gt; ../../sda2 lrwxrwxrwx 1 root root 10 Nov 22 19:52 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part3 -\u0026gt; ../../sda3 lrwxrwxrwx 1 root root 9 Nov 22 19:52 scsi-SATA_ST9320325ASG_5VD7G964 -\u0026gt; ../../sdb lrwxrwxrwx 1 root root 10 Nov 22 19:52 scsi-SATA_ST9320325ASG_5VD7G964-part1 -\u0026gt; ../../sdb1 lrwxrwxrwx 1 root root 10 Nov 22 19:52 scsi-SATA_ST9320325ASG_5VD7G964-part2 -\u0026gt; ../../sdb2 lrwxrwxrwx 1 root root 9 Nov 22 19:52 usb-Generic_Flash_Disk_4266F915 -\u0026gt; ../../sdc lrwxrwxrwx 1 root root 10 Nov 22 19:52 usb-Generic_Flash_Disk_4266F915-part4 -\u0026gt; ../../sdc4\n[root@XS62 ~]# xe sr-create content-type=user device-config:device=/dev/disk/by-id/scsi-SATA_ST9320325ASG_5VD7G964 host-uuid=3850317b-d23a-4ed0-87f9-2b27854319e5 name-label=\u0026ldquo;SATA320\u0026rdquo; shared=false type=lvm cf0893c3-9398-d802-0706-66a8699c3a59 [/bash]\n从上面的命令可以看到，最后一条命令完成后，系统返回了新 SR 的 ID;然后在登录 XenCenter 就可以看到这个存储了，虚拟现在就可以使用这个存储了。\n","date":"2013-11-25T10:39:00Z","permalink":"https://martinliu.cn/2013/11/25/xenservere6b7bbe58aa0e7a1ace79b98e5819ae69cace59cb0e5ad98e582a8/","title":"XenServer 添加硬盘做本地存储"},{"content":"对于亚马逊 AWS 的测试用户来说，你要知道你的免费套餐的截止日期，否则预期就会收费了，会计时收费，像叫停车费一样。我今天收到了亚马逊的提醒邮件，被告知，我的免费套餐将在本月截止，然后我不得不终止了该服务器。\n我是去年 10 月 19 日开通的这个免费实例，作为一个一年的 AWS 用户来说，深深的体会到了 AWS 的强大，它的管理控制台非常成熟，它的提供的服务非常全面，它的云市场做的相当好。对于任何一个普通人，你可以无痛，无压力的面对一个自己的数据中心，你可以假象你拥有一个世界上最高级的数据中心，你可以给你的应用任意、随时随地的附件任何一种高级的数据中心基础架构服务，你可以具有无限的资源，并且这个资源不限制类型和容量。共有云必将和私有云二分天下，共有云必将赢得所有中小企业用户。\n[caption id=\u0026ldquo;attachment_52574\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/09/EC2_Management_Console.png) EC2_Management_Console[/caption]\n[caption id=\u0026ldquo;attachment_52575\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/09/Try_Cloud_Computing_Free_with_AWS_Free_Tier.png) Try_Cloud_Computing_Free_with_AWS_Free_Tier[/caption]\n","date":"2013-09-24T05:26:22Z","permalink":"https://martinliu.cn/2013/09/24/aws-e5858de8b4b9e5a597e9a490e688aae6ada2e5908ee5bf85e9a1bbe7bb88e6ada2/","title":"AWS 免费套餐截止后必须终止"},{"content":"迪斯尼是一个有魔力的组织，在它的电影里冤家可以变伙伴。甚至 CloudStack 和 OpenStack 两大私有云死对头来到迪斯尼这个神奇的地方也可以“在一起”。当迪斯尼决定建设自己的云计算基础设施时，与很多企业一样面临一个艰难的抉择，从众多云计算技术方案和产品中选择一条道路。如今的云计算市场规模已 达数百亿美元，水已经很深，领头的是亚马逊这样的公共云巨头，以及亚马逊的对手们：Rackspace、Google、CloudStack、 Eucalyptus、OpenNebula 等多种私有云和公共云技术与服务，每家都有绝活和独到之处。\n对于身价上千亿美元的娱乐和媒体巨头迪斯尼来说，业界可供选择的云计算路线太多，到底是走公共云、私有云、混合云还是多重云的路子？\n迪斯尼的选择是走自己的路。（迪斯尼的系统架构师 Lopez 将 9 月 9 日在CloudBeat上介绍其云计算建设经验。）\n在概念验证阶段，迪斯尼更加青睐 CloudStack，在私有云领域 CloudStack 吸引力很多大型用户，如 Zynga 和诺基亚都选择了 CloudStack。迪斯尼的系统架构师 Lopez 表示，相比 OpenStack，CloudStack 的部署和运行速度要快得多。迪斯尼可以在数天能 部署好 CloudStack 服务，而 OpenStack 则需要数周。当然，两大私有云服务部署周期相差如此之大的部分原因也与迪斯尼的特殊要求和原有技术 投资有关。\n不管怎样，迪斯尼目前对 CloudStack 非常满意，但迪斯尼的团队希望在私有云中增加对象存储技术。这一次迪斯尼倾向使用 OpenStack 阵 营的对象存储工具——Swift。事实上，开源的 OpenStack 之所以如此流行，与大量参与者提供的丰富功能密不可分，Swift 就是一个很好的例 子。\n于是，迪斯尼的团队与 Citrix 合作，确保 OpenStack 的 Swift 技术能够与 CloudStack 搭建的私有云紧密集成。在迪斯尼这个神奇的地方，OpenStack 和 CloudStack 之间的深沟裂隙被弥合了。\n在迪斯尼的案例中，CIO 能够参考的经验是：云计算的实施方案并非黑白分明，非此即彼，随着云计算服务商提供越来越多的相对独立的云计算功能，CIO 们可以不受“站队”的局限，从不同阵营选择最好的云计算工具进行整合。\nHow Disney built a giant cloud by bolting two together 下面这个文章值得读一下。 http://venturebeat.com/2013/08/30/how-disney-built-a-giant-cloud-by-bolting-two-together/\n转帖：迪斯尼云计算之路选择 CloudStack 原文链接： 文章来自IT 经理网\n","date":"2013-09-03T08:25:46Z","permalink":"https://martinliu.cn/2013/09/03/cloudstack-swift/","title":"CloudStack+Swift 我心中的黄金搭档"},{"content":"今天公司到货了 K1，K2 的 GPU 卡，这让我不得不学习一下这个产品。\n到货实物如下：\n[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;52542,52543,52544,52545,52546,52547\u0026rdquo;]\n此卡的简单技术指标如下。\nGRID K1 GRID K2 详细 K1 K2 技术参数指标， 下载 ； 这个表格清晰的说明了这两种卡的硬件技术参数。重要的是看它软件合作伙伴这一块。硬件在好，没有支持的软件也不行，我们必须还有看看它的软件合作伙伴：http://www.nvidia.com/object/grid-software-partners.html\n首先，是认证的虚拟应用合作伙伴，这里只有 Citrix XenApp；只有 Citrix 可以做 3D 设计软件的应用虚拟化；其它无人能及，基于 Citrix 的应用虚拟化可以真正的把一块 GPU 的共享程度达到最大，能够更加节约支撑的硬件资源。节省每一度电。还要看支持的 API 的版本号，这个说明了对 3D 软件的兼容性，如果这个版本号类型少，支持的低，那么这种方案是不可用的；由于 3D 软件根本就跑不动。\n总之，Citrix + nVIDIA K1 k2 + XenServer （GPU 直通） + HDX 3D Pro = 业内最好的 3D 虚拟桌面平台方案；而且这个方案里还能具有，其它全部的使用场景，包括：vdi，共享桌面，虚拟应用，流桌面，远程物理桌面等等方式。可以说这是一举多得，面面俱到的解决方案。\n","date":"2013-08-16T11:52:58Z","permalink":"https://martinliu.cn/2013/08/16/xendesktop-nvidia-k1-k2-best-3d-vdi/","title":"XenDesktop + nVIDIA K1/K2 = BEST 3D VDI"},{"content":"\n安全加固移动性笔记本电脑 桌面级操作系统更新管理 分支机构或者远程办公环境计算机管理 弹性的在瘦机和 PC 直接选择 有限的网络访问环境 成本节约或已有硬件利用 XenClient 本地虚拟桌面通常是虚拟桌面项目中的一个容易被忽视的环节。其实它的使用场景随处都是。\n","date":"2013-08-15T05:14:31Z","permalink":"https://martinliu.cn/2013/08/15/xencliente69cace59cb0e8999ae68b9fe6a18ce99da2e585b8e59e8be5ba94e794a8e59cbae699af/","title":"XenClient本地虚拟桌面典型应用场景"},{"content":"http://brightcove.vo.llnwd.net/pd16/media/1485836774/1485836774_2603380124001_3DCar4CitrixTV.mp4\nDescription\nWindows 7 HDX3D Windows Server 2008R2 3D Network Constrained Environment (Simulating 3G speeds) No network constraints Windows Client iPad Client NVidia Demo software utilized is available on NVidia.com Solarwinds Software used for monitoring network traffic\n看点:\n桌面虚拟化中的高精尖场景，成本高、技术高、效果精益求精 Citrix XenDesktop + nVidia = 业内最好 3D 设计虚拟桌面平台 Citrix 可以兼顾 VDI+独占 GPU 和 共享桌面+共享 GPU 两种模式 来源：http://www.citrix.com/tv/#videos/9008\n","date":"2013-08-14T15:38:07Z","permalink":"https://martinliu.cn/2013/08/14/xendesktop-7-hdx-3d-pro/","title":"XenDesktop 7 HDX 3D Pro"},{"content":"With the release of Citrix XenServer 6.2, Citrix is pleased to announce that XenServer is now fully open source. In this video, Richard Sharp, Vice President of XenServer Product Development, explains why Citrix open sourced XenServer, what it means to our customers and how it will help the entire XenServer platform.\nhttp://brightcove.vo.llnwd.net/e1/uds/pd/13639319001/13639319001_2488040716001_XenServer-OSS-Richard-Sharp-Final.mp4\nWith the release of Citrix XenServer 6.2, Citrix is pleased to announce that XenServer is now fully open source. In this video, Richard Sharp, Vice President of XenServer Product Development, explains why Citrix open sourced XenServer, what it means to our customers and how it will help the entire XenServer platform.\n","date":"2013-08-01T09:26:51Z","permalink":"https://martinliu.cn/2013/08/01/citrix-xenserver-is-now-fully-open-source/","title":"Citrix XenServer is Now Fully Open Source"},{"content":"Sameer Dholakia, Vice President and General Manager of the Citrix Cloud Division, talks about the full open source strategy for XenServer. Learn why Citrix made XenServer open source and how this will benefit our customers and ecosystem partners.\nhttp://brightcove.vo.llnwd.net/e1/uds/pd/13639319001/13639319001_2503709704001_Sameer-Dholakia-v3.mp4\nSameer Dholakia, Vice President and General Manager of the Citrix Cloud Division, talks about the full open source strategy for XenServer. Learn why Citrix made XenServer open source and how this will benefit our customers and ecosystem partners.\n","date":"2013-08-01T09:21:01Z","permalink":"https://martinliu.cn/2013/08/01/a-new-open-source-strategy-for-citrix-xenserver/","title":"A new open source strategy for Citrix XenServer"},{"content":"自学的能力让你的能力变得无穷大。所谓学无止境，能力上能否得到无止境的提升就是个人为题了。你学习的时间？学习的态度？学习的内容？学习的方法？都决定了你的学习效果。基本上要学习一种新的技术或者产品，大多数人一般都止步于如何操作和运用它；能更深入的理解它的架构和特性，甚至做出横向的比对，就是第二个阶段，这样的人很少。\n学习 Citrix 技术的几个途径如下，我们通常都用到那些？请在下面投票。\n[poll id=\u0026ldquo;3\u0026rdquo;]\n什么是您认为学习 Citrix 技术的好的方式方法？请于本帖留言。\n","date":"2013-08-01T09:09:27Z","permalink":"https://martinliu.cn/2013/08/01/e6808ee4b988e4bdbfe682a8e79a84mpvpatpdefe983bde697a0e7a9b7e5a4a7/","title":"怎么使您的MP/VP/ATP/DEF都无穷大"},{"content":"今天上苹果网站上发现一个很酷的东西 Mac Pro，我觉得它 catch my eyes；真的设计的很离谱，很合理，我很喜欢，帖几张图共同赏析一下。\n[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;52469,52473,52470,52471,52472,52476,52478,52479,52474,52481\u0026rdquo;]\n连接详情，访问 apple 官网： http://www.apple.com.cn/mac-pro/\n","date":"2013-07-19T07:02:46Z","permalink":"https://martinliu.cn/2013/07/19/mac-pro-e5be88e7a6bbe8b0b1-e5be88e59088e79086-e5be88e5969ce6aca2/","title":"很离谱，很合理，很喜欢"},{"content":"Citrix 项目实施秘籍文档慢慢泄露中。点击本文标题直达 Citrix-Book.org 最佳实践网站\n","date":"2013-07-09T17:05:58Z","permalink":"https://martinliu.cn/2013/07/09/e4b883e7aba0e88a82e7bb86e8aeb2citrixe8999ae68b9fe6a18ce99da2e59fbae7a180e69eb6e69e84e690ade5bbba/","title":"七章节细讲Citrix虚拟桌面基础架构搭建"},{"content":"[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;52454,52455,52456\u0026rdquo;]\nXenDesktop 7 问世以来，目前处于市场初级推广阶段；虽然还没有大范围的推广，如果业内的合作伙伴们如果还没有尝试过，那么你们就 Out 了。为了更好的指导大家的测试工作，这里介绍两篇文档：\nXenDesktop7 快速安装手册 XenDesktop7 安装和配置手册 from yandong 另外隆重推荐的是这个开放维基百科网站“Citrix-book.org Citrix 最佳实践”；退出这个网站的原因是我看到，目前网络资源过于纷乱，大多数技术大拿们都有自己的 bolg 和微博；但是干活资源过于分散；这个网站本着开放自由的出发点，鼓励和欢迎所有的大难能到这里集中和上传你的干活技术资料。投稿方式为自由注册，自行在线新建和编辑文档；也可以根据网站指引投稿。\n","date":"2013-07-08T03:45:59Z","permalink":"https://martinliu.cn/2013/07/08/xendesktop-7-e68aa2e9b29ce6b58be8af95/","title":"XenDesktop 7 抢鲜测试"},{"content":"刚刚入手了一台 Lenovo ThinkCenter M92/M92p Tiny 测试机，虽然配置不高但是出于 geek 习惯，还是要动动螺丝刀的。下面是拆机过程，供参考。 [gallery columns=\u0026ldquo;2\u0026rdquo; link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;52429,52430,52431,52432,52433,52434,52435\u0026rdquo;]\n这款机器目前在国内好像还没有正式买，起码联想中国官网上连技术指标也查不到。美国网站上是有这个机器的介绍。\n[caption id=\u0026quot;\u0026quot; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;960\u0026rdquo;]](http://www.lenovo.com/products/us/desktop/thinkcentre/desktops-towers-us-only/m92-m92p/) ThinkCenter M92P[/caption]\nAt a Glance Up to 3rd generation Intel® Core™ i7 Up to Windows 8 Pro Up to 1TB HDD, Up to 128GB SSD Up to 32GB memory (4x8GB) M92/M92p Tower Tech Specs M92/M92p Tiny Tech Specs 我所测试的是 M92 Tiny 型。改机默认安装的 Win8 操作系统。如果把它改装为跑 Hypervisor 的服务器的话，它应该属于 Microserver 的范畴。\n接下来，我准备在这个机器上做些改动和测试。\n如果有可能的话，更换硬盘为 SSD 硬盘，升级内存到最大两条 8GB，共 16GB\n安装和测试 XenClient：使用集中管理器，来更新本地硬盘的 Widnows 虚拟机操作系统\n安装和测试 XenServer：在上面跑 XenDesktop 的虚拟机，看看做多能达到多少个用户的密度，分别测试共享桌面和 VDI 桌面，看看共享桌面的密度会在这个机器上比 VDI 高几倍？\n测试跑 CloudStack 的计算节点，试想如果实验室里面有一摞 16 个机器，都做在一个群集上，跑跑大数据 Hadoop 应用，应该也是很好的使用场景\n","date":"2013-05-24T01:32:28Z","permalink":"https://martinliu.cn/2013/05/24/microserver-lenovo-thinkcenter-m92m92p-tiny/","title":"Microserver Lenovo ThinkCenter M92/M92p Tiny"},{"content":"[caption id=\u0026ldquo;attachment_52426\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;640\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/05/a02cee3bjw1e4xxhq050wj20hs0ppgq6.jpg) 成人理想体重范围[/caption]\n终于为我的体重找到了依据，我的体重目前开来很标准。跑步则是保持体重，提高体质的基础。\n","date":"2013-05-23T01:42:12Z","permalink":"https://martinliu.cn/2013/05/23/e4bda0e79a84e4bd93e9878de6a087e58786e4b988efbc9f/","title":"你的体重标准么？"},{"content":"我说的是跑步的跑：）\n目前的情况是，我的足迹分布在国内 6 个城市。还有很多国内城市没跑过，也还有很多外国城市没有跑过，好在还有很多年的时间来丰富这张跑步地图。\n","date":"2013-05-21T15:47:44Z","permalink":"https://martinliu.cn/2013/05/21/e68891e683b3e8b791e9818de585a8e4b896e7958c/","title":"我想跑遍全世界"},{"content":"[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮 Eric [/box]\n英文版：《Citrix Virtual Desktop Handbook》\n中文版：[download id=\u0026ldquo;20\u0026rdquo;]\n本书是 XD 虚拟桌面实施工程师的必备读物，请相关人员仔细阅读。\n","date":"2013-05-14T05:59:11Z","permalink":"https://martinliu.cn/2013/05/14/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbbe4b8ade69687e78988/","title":"XenDesktop虚拟桌面精品书籍导读(中文版)"},{"content":"XenApp 实施工具，隐藏 Windows Explorer 中的各种东西。\nHideLibraries Hide libraries icon in the navigation pane of Windows Explorer. HideFavorites Hide favorites icon in the navigation pane of Windows Explorer. HideNetwork Hide network icon in the navigation pane of Windows Explorer. HideComputer Hide computer icon in the navigation pane of Windows Explorer. HideHomeGroup Hide home group icon in the navigation pane of Windows Explorer ShowLibraries Show libraries icon in the navigation pane of Windows Explorer. ShowFavorites Show favorites icon in the navigation pane of Windows Explorer. ShowNetwork Show network icon in the navigation pane of Windows Explorer. ShowComputer Show computer icon in the navigation pane of Windows Explorer ShowHomeGroup Show home group icon in the navigation pane of Windows Explorer Logoff In order to changes take effect the explorer shell process needs to be restarted. Specifying the option causes your windows session to logoff immediately. Reboot In order to changes take effect the explorer shell process needs to be restarted. Specifying the option causes the computer to reboot immediately. Help Displays this usage information.\n点此处下载： [download id=\u0026ldquo;19\u0026rdquo;]\n几乎是做 XenApp 共享桌面的必备工具。\n","date":"2013-05-14T04:10:35Z","permalink":"https://martinliu.cn/2013/05/14/hide-windows-explorer-items/","title":"隐藏Windows  Explorer中的各种东西"},{"content":"[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮 Eric [/box]\n今天是《Citrix Virtual Desktop Handbook》第二讲的最后一期，专门论述一下 PVS 的设计。在本期之后我会把所有以往的内容整合在一个完整的白皮书中，稍等几日。。。\n请期待基于本系列 5 篇文章的完整版中文白皮书下载。\nCitrix 桌面虚拟化实施部署白皮书 第二讲之第五期：PVS 的设计\nProvisioning Services Citrix Provisioning Services（PVS）使用流化的技术简化了虚拟桌面和物理桌面的部署。计算机从一个单个的共享磁盘镜像上被实时制备（Provisioned），管理员完全不需要去管理或者是给每个单独的用户操作系统打补丁。\n1) **决断：**Farm**（场）的数量******\n一个 Provisioning Services 的场代表着 Provisioning Services 基础架构的最高层级。所有在一个场的 Provisioning Servers（服务器）都共享同一个 SQL 数据库哦 Citrix License 服务器。当确定需要多少个 Provisioning Services 的场时，我们一般需要考虑以下几个因素：\nl **网络：**Provisioning Servers 会始终和场数据库通信以获取系统配置信息。因此，一般来说每个 target devices 聚集的地理位置应该部署一个独立的场，当然，如果异地之间的网速足够快，理论上也可以只建立一个 Provisioning Services 场。\nl **重要程度：**管理者应该决定它可以容仍什么样的风险。尽管可能性非常的低，但是 Provisioning Services 场如果出问题还是会影响整个组织架构的使用。如果一个公司需要非常高等级的可用性，那么多个场的搭建就可以避免这个问题。\nl **可管理性：**管理者可能需要在基于组织架构划分的基础上，例如国家、地区，又或者是不同部门之间，来进行单独的系统管理。尽管听起来这会增加管理的复杂程度，但是实际上只会增加有限多的配置、桌面创建过程，以及操作系统镜像更新。\n2) **决断：站点（**Sites**）的数量******\n每个 Provisioning Services 的场都包含一个或者多个的站点。一个 Provisioning Services 的站点是一个逻辑的实体组成部分，包含了 Provisioning Servers（服务器）、vDisk pools，以及 target devices 的集合。多个站点共享同一个数据库。Target devices 可以在同一个站点中容错到其他的 Provisioning Servers 上。在以下的情况下我们建议创建多个站点：\nl **网络：**站点用来控制 Provisioning Services 的流数据量。例如，一个站点可以根据站点、rack、或者是刀箱来创建，以确保流数据始终保持在本地而不变成一个网络瓶颈。\nl **组织架构：**另外一个需要创建多个站点的实际理由是企业组织架构的改变。例如，两个公司通过收购合并了，但是有需要在企业整合过程中保持资源的独立。\n3) 决断：数据库的配置\nProvisioning Services 的数据库存储有所有一个场内的的系统配置信息。Provisioning Services 6.X 版本支持一下版本的 SQL 数据库，包括 Express、标准版、企业版的 SQL Server 2005、2008R2 以及 2012 版。选择哪一个 SQL 版本其实是取决于你需要哪一个级别的容错水平。以下的表格是一个 SQL 2008R2 版本的示例：\nProvisioning Services 场的数据库的大小很少会超过 250M 容量，即使在大型环境下也不会。所以，在测试环境下 Express 版本是最佳选择，因为不需要容错功能。\n下面的公式是用来计算 Provisioning Services 的数据库的容量大小：\n4) 决断：数据库；离线模式\n如果到 Provisioning Services 场的数据库的连接断开，已经连接到 Provisioning Servers 的 target devices 仍然可以正常工作，但是新的 target devices 将会无法启动。\n支持离线数据库功能可以让 Provisioning Services 在失去连接到数据库后仍然可以保持正常操作。在服务器启动时会对数据库做个快照，然后定期保持同步。如果连接丢失，Stream Services 会使用最新的一个快照以获取场的配置信息。一旦数据库连接建立起来了，Stream 过程会把断线期间的变化同步到数据库中。\n需要注意的是，离线数据库功能默认下是关闭状态的，而且也仅仅是在生产环境下的稳定的场环境下推荐使用。评估环境下不推荐使用\n5) 决断：服务帐号\nStream 和 SOAP 服务会和其他许多不同的 Provisioning Services 基础架构中的组件进行通信，如下图所示：\n6) 决断：设备集合\n设备集合是用来创建和管理 target devices 逻辑组。创建设备集合可以简化设备管理，因为将来的操作可以不用基于 target device 级别，而是基于集合这个级别。\n设备集合可以基于物理地理位置、子网范围、组织架构中不同的部门来设计。也可以考虑基于 vDisk 的分配来创建不同的设备集合，这样所有分配到一个特定 vDisk 的所有的 target devices 就能被快速的定位。\n7) 决断：**Provisioning Server**（服务器）的内存\n运行 Provisioning Services 的 Windows 操作系统会把 vDisk 的部分内容缓存在内存（系统缓存）中以降低从存储中读取的操作。从存储中读取数据的速度是显著低于从内存中读取数据的，所以，正确计算 Provisioning Servers 的内存是非常关键的。请参见以下的公式：\n简单地说，就是给每个 vDisk 分配 2G 左右的内存。\n8) **决断：**Scale Up**还是****Scale Out**\n题外话：首先对这两个词进行一下解释：\nScale Out(向外扩展)：就是指企业可以根据需求增加不同的服务器应用，依靠多部服务器协同运算，借负载平衡及容错等功能来提高运算能力及可靠度。\nScale Up(向上扩展)：指企业后端大型服务器以增加处理器等运算资源进行升级以获得对应用性能的要求。\n随着 Farm 场的增长，管理员需要作出决定以判断是不是需要给 Provisioning Server 增加更高的资源，也可以是在场中增加更加多的 Provisioning Servers，一下了可以是考虑因素：\nl **冗余：**将用户符合扩展到其他负荷不重的服务器上会有助于降低当 Provisioning Servers 宕机情况下爱所影响的用户数量。如果公司无法接受单点高性能服务器宕机所造成的损失，那就考虑 Scaling Out，就是我们说的向外扩展（既增加多台服务器）。\nl **容错时间：**在一个单台的 Provisioning Server 上所连接的 Target Devices 越多，在服务器宕机后所需要的恢复时间也就越多。Citrix 的内部测试显示在 Provisioning Services 5.6 SP2 版本下，1500 台 Target Devices 需要大约 8 分钟恢复生产能力；\nl **数据中心容量：**数据中心一般都是只有有限的空间、电源、冷却能力，此时，可以考虑 Scaling Up，即向上扩展（增加单台服务器的处理能力）。\nl **硬件成本：**刚开始时，可能 Scale Up 会有更高的性价比，但是继续往后可能 Scale Out 会开始更具性价比，应该做一个成本分析；\n9) 决断：**vDisk**的存储位置\n一个场可以包含一个或者多个的 vDisk 存储。一般来说有两个主要的选择：\nl 本地存储或者是 DAS**：**DAS 可以是本地的，或者是基于 Block 的存储类型，Provisioning Server 可以直接访问，例如 SATA、SCSI、iSCSI，以及光纤。本地的 vDisk 就只能被本地的 Provisioning Server 所反问，因此，vDisk 应当被手动或者自动的复制到其他的 vDisk 存储位置上。\n注意：将 vDisk部署在本地存储上并不会造成单点故障，因为 Provisioning Service的负载均衡技术可以让 target devices自动的在其他 Provisioning Servers之间做容错动作。\nl NAS**：**NAS 是一种基于文件级存储的 solution。NAS 协议包括 CIFS 和 NFS。NAS vDisk 可以被多个 Provisioning Server 同时所访问。NAS 由于不需要 vDisk 复制功能所以能保证 vDisk 在一个场内的多台 Provisioning Server 之间保持连续性。\n注意：NAS反而会造成单点故障，如果网络共享功能不可用，所有从这个 vDisk上 Streamed的 target device都会变得不可用了。\n10) 决断：评估存储容量\n一个 vDisk 包含了一个 VHD 基础镜像文件、一个 properties 文件（.pvd），也可以能包含了一个链条 VHD 差异磁盘（.avhd）。每当一个 vDisk 被 Provisioning Services versioing 所更新时，一个新的差异磁盘就会被创建。\n一个 vDisk 所占空间的评估因素大致有以下几点：\nl **vDisk****的总容量：**顾名思义\nl **vDisk chain****的最大版本数：**vDisk versioning 简化了 vDisk 升级以及管理的负担，他能够更加灵活和健壮的管理 vDisks。\n备注：太多的差异磁盘会显著降低 Provisioning Services的性能，建议不要超过 5-7个的版本数。\nl **vDisk****版本变化百分比：**差异磁盘的大小是随着对 vDisk 的改动多少而随着变化的。改得越多，差异磁盘的大小就越大。以下的计算公式可以用于计算 vDisk 容量：\n举例如下：\n比如你计划部署三个 vDisk：\n Windows 7 (x64) image = 40GB\n Windows 7 (x86) image = 35GB\n Windows XP image = 20GB\n每个 vDisk 都不会超过 5 个差异磁盘。预计一个差异磁盘大致是 20%的主 vDisk 镜像文件大小，那么估计 Provisioning Services 存储所需要的空间如下：\n11) 决断：**RAID**级别\n存储子系统的 RAID 级别会对应用程序和用户的工作负荷产生直接的影响。RAID 0、1 以及 10 对读操作是最优，而 RAID 5 和 6 是对写操作是最优。对于 Provisioning Services 来说，不同的 RAID 级别有如下推荐配置：\nProvisioning Services 中 vDisk 主要是读操作，而对 Write Cache 来说主要是写操作。所以：\nl Write Cache**：**推荐 RAID 0、1、10 因为这几种 RAID 的写惩罚较低\nl **vDisk ****存储：**推荐 RAID 0、1、5、10，它可以让读操作分配到 RAID 中的其他磁盘中；\n如果可能，建议将 vDisk 放在 RAID5 上，而写缓存放在 RAID10 上。如果 vDisk 和写缓存一定要放在一起，那么建议采用 RAID10。\n12) 决断：写缓存的位置\n写缓存可以有以下位置：\nl **缓存在 Target Device****的硬盘上：由于 Provisioning Servers 不用处理写请求，放在这里会减轻 Provisioning Servers 的资源消耗。尽管没有放在内存中这么快，这种方式的读写都是在本地，还是能提供快速的响应时间；**\nl **缓存在 Target Device****的硬盘上永久保存：**和第一种方式类似，区别在于用户重启之后存储永久保存。该功能目前还是测试阶段，仅在 Windows 2008 R2 和 windows 7 上支持。\nl **缓存在 Target Device****的内存中：**尽管这种方式在性能上是最优的，但是如果 RAM 别耗尽了也会印象系统的稳定性；\nl **缓存在 Provisioning Server****的磁盘上：**缓存在 Provisioning Server 的磁盘上作为临时文件存储。所有的写操作均发生在 Provisioning Server 服务器上。这样配置当然会增加 Provisioning Server 的磁盘 IO 操作和网络负担。配置上这种方式最为简单，不过这种方式下 target device 由于所有的到写缓存的读写请求都必须经过网络，target device 的性能会受到较大影响。这种方式仅在 POC 阶段推荐！\nl **缓存在 Provisioning Server****的磁盘上永久保存：**和上一种方式基本类似，区别在于用户重启之后存储永久保存。这种方式的好处在于 target device 能够保存对 vDisk 所做的改变，在重启之后也仍然保留。任何对 vDisk 的改变都会将缓存文件强制标记为失效状态。例如，如果 vDisk 被设置为 Private Image Mode，一下所有的操作都会导致缓存文件被标记为失效状态：\nn o Placing a vDisk in Maintenance mode\nn o Mapping the drive from the console\nn o Changing the location of the write cache file\nn o Using Automatic update\n写缓存包含了 target device 的 MAC 地址和磁盘识别符，他能独一无二的区分出每一台 target device。一个 target device 可以被分配多个 vDisk，因此，也可以关联多个缓存文件。\n将写缓存部署在 target device 上是最为推荐的配置方法，因为既不用消耗而外的 RAM 内存，又不会减少 Provisioning Servers 的扩展性。\n13) 决断：写缓存的大小\n写缓存的大小取决于很多隐私，一般来说都是基于评估和典型的用户配置文件大小。一般来说应当能够存储一下数据：\nn Temporary application data\nn User profile temp files\nn Windows Event Logs\nn Citrix Logs\nn Antivirus pattern files\nn Citrix Application Streaming/Microsoft App-V Cache\n备注：启用了用户配置文件重定向操作能减少写缓存所需要的大小。\n写缓存的大小极大程度上取决于安装或者是 Streamed 到 vDisk 上的应用程序的大小以及用户配置文件的大小。推荐配置的起点是 2GB。对于大部分虚拟桌面来说，我们有如下推荐配置：\n此外，Windows 的 pagefile 也会写入和写缓存同样的磁盘中，所以：\n例如，如果 Windows 7 的 vDisk 设计是 1.5GB 的 pagefile，那么写缓存的一个安全的评估数据应该是：\n不过由于 Hypervisor 都不能将磁盘精确到小数点后，我们姑且分配 4GB 的空间吧。\n14) 决断：**vDisk**的格式\nProvisioning Services 支持固定磁盘以及动态磁盘格式。\nl **固定磁盘格式：**对于私有模式（private mode）的 vDisk，固定尺寸大小的 vDisk 可以对存储 vDisk 磁盘上进行的磁盘碎片整理操作，这对写操作的性能提升会有帮助。不过在私有模式下，访问 vDisk 受限于一个 target device，我们说仅当对 vDisk 进行维护模式时才有实际意义。\nl **动态磁盘：**相比较而言他需要更少的磁盘空间，但是在写操作上性能会显著降低。尽管在共享模式下（Shared Mode）的 vDisk 不会对 vDisk 执行写操作，不过对完成 vDisk 合并时所要花费的时间会增加许多。\n15) 决断：**vDisk**的大小\nvDisk 的大小主要取决于操作系统以及安装在操作系统上的应用程序的多少，我们预估的大小如下表所示：\nvDisk 的大小如果设置的太小或者是太大，日后我们还可以在 Provisioning Services 中调整。为了精确的评估 vDisk 的大小，请遵循以下的准则：\nl **Target Device****的空间：确认目前作为主 target device 服务的计算机所正在使用的磁盘空间大小；**\nl **应用程序大小：**当应用程序安装时，所需要的空间也在增长。计划大 25%的增长\n16) 决断：**vDisk**复制\n如果 vDisk 是存储在 DAS 上就需要在他自己有变化的时候复制到其他 DAS 上。Provisioning Services 支持 vDisk 从本地复制到 Provisioning Servers 上，也可以支持在使用共享存储时跨越多个站点之间的复制。复制可以是手动或者是自动：\nl **手动复制：**简单，但是更耗时；\nl **自动复制：**大型环境下自动复制更快。一些自动化工具，例如 Microsoft DFS-R 还支持带宽控制。唯一缺点是如果复制出错，管理员还不支持，除非复制平台支持复制重传。\n17) **决断：微软****Volume Licensing**\nProvisioning Services 支持 Microsoft Key Management Service (KMS)和 Multiple Activation Key (MAK) volume licensing。\nl KMS Volume Licensing**：可以在用户的本地网络上激活，无需连接到微软的网站。一台 KMS 服务器支持不受限的 JMS 客户端。微软公司推荐部署两台 KMS 服务器。**\nn Office 2010 的部署只支持 KSM 激活方式；\nl MAK Volume Licensing**：**MS 的一次性激活方式。\n18) 决断：高可用\nProvisioning Services 是虚拟桌面基础架构中最重要的组成部分，因此为了避免单点故障，需要考虑一下推荐步骤：\nl MAK Volume Licensing**：**MS 的一次性激活方式。\nl **数据库：**Provisioning Services 支持两种数据库的高可用方式：\nn 离线的数据库；\nn 镜像数据库\nl Provisioning Servers**（PVS****服务器）：**所有在一个站点之间的 Provisioning Servers 都能够被配置为向 target device 提供同一个 vDisk。每个站点最少部署两台 PVS 服务器。\nn Provisioning Services 启动文件应当配置为高可用。在启动文件中可以配置高达 4 台 PVS 服务器的列表。Target Device 会按照顺序连接这些 PVS 服务器。后续所响应的服务器可以不是当初提供 Streaming 服务的服务器。当然，我们也可以配置负载均衡。\nl **vDisk****和存储：**对于 DAS 上存储的 vDisk，应当做好同步操作。对于 NAS 上的 vDisk，NAS 存储必须提供一条高可用的网络共享连接；\nl **网络：**Provisioning Servers（PVS 服务器）的网卡应当配置为 Teamed。\n19) 决断：带宽需求\n带宽评估对于整体性能是有至关重要的，特别是当 Target Device 启动的时候。带宽是随着操作系统的不同而有所区别的。Target Device 启动所需要的时间可以参考下面的公式：\n例如，500 个 Windows 7 的 Target Devices 在 1G 以太网下需要 40M 启动：\n1. 1 GB Ethernet = 125MB/s\n2. 500 targets x 40 MB = 20GB\n3. 20GB/125MBs = 160 seconds\n下面的表格列举了在 10GB 网络下启动 500 台不同操作系统的 Target Device 时大致的带宽和启动加载时间：\n备注：防火墙会增加网络延迟，同时也会造成网络瓶颈，如果可能，最好禁用防火墙，如果实在不能避免，最好能开放一下端口的完全访问能力：\n20) 决断：网络配置\n为 PVS 服务器提供 10Gbps 网络能提供最够需要的带宽，如果做不到的话，1Gbps 也可以提供足够的带宽，但是有可能会成为 PVS 服务器的瓶颈。将多块网卡做 Teaming 处理能提供更高的吞吐量，增加网络性能，也能阻止网络的单点故障。下表列出了 PVS 服务器的网络配置属性，从最大容量到最小：\n以下的 NIC 属性应当正确配置在 PVS 服务器以及 Target Devices 的 NIC 上：\n简单地说，就是禁用 Checksum Offloading 属性；关闭 Auto Negotiation，使用强制配置；启用 Jumbo Frame。\n21) 决断：交换机配置\n用于 PVS 服务器和 Target Devices 的网络交换机应当做一下优化：\nl 生成树协议（Spanning Tree Protocol**）/PortFast****：**禁用生成树协议，启用 PortFast；\nl 风暴控制 Storm Control**：**在 Cisco Catalyst 交换机上将 Unicast 流量值设置大一些，或者是禁用 Unicast Filtering。\nl Broadcast Helper**：**启用之，这样可以转发 PXE 和 TFTP 流量；\n22) 决断：**Bootstrap**交付\n在一个 Target Device 开始启动过程的时候，他会首先加载一个 bootstrap 程序，该程序会初始化 Target Device 和 PVS 服务器之间的流化会话过程。有三种方法让 Target Device 能收到 bootstrap 程序：\nl Broadcast Helper**：**启用之，这样可以转发 PXE 和 TFTP 流量；\nl 使用带有 DHCP**选项的 PXE**方式；\nl 使用不带有 DHCP**选项的 PXE**方式；\nl 使用 Boot Device Manager**；**\n在企业无法提供 PXE 或者是 TFTP 服务的情况下，或者是无法对 DHCP Scope 选项修改的情况下，可以考虑使用 Boot Device Management 工具通过一个 ISO 文件来提供 bootstrap 文件。\n23) 决断：审计\n默认下审计功能是禁用的，管理员可以将将其打开。打开后该工具可以记录在 Provisioning Services 场内组件所做的配置修改记录，并将结果记录至数据库中。\n24) 决断：防病毒\n大部分的防病毒软件都会是扫描所有的文件和系统进程，对性能影响很大。所以在 PVS 环境下必须优化防病毒软件的配置。请参见 CTX124185 - Provisioning Services Antivirus Best Practices。\n","date":"2013-05-07T02:36:41Z","permalink":"https://martinliu.cn/2013/05/07/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbbpart5/","title":"XenDesktop虚拟桌面精品书籍导读(part5)"},{"content":"来自 http://www.intelligenthq.com/uncategorized/top-10-cloud-computing-companies/\nCitrix 榜上有名排名第三，这就是我看好 CloudStack 一年多的回报，国内 CloudStack 目前看还没有什么生机，希望能早点发展起来。\nWe all know change is constant, especially in technology. Look at Toshiba, a world leader and innovator in high technology. This week, the company made an interesting move and announced the opening of Toshiba’s first datacenter in Europe, located in France.\nToshiba Cloud \u0026amp; Solutions Division is directed at professional markets, public and private-sector companies, and entities within the Toshiba Group. The creation of this datacenter is in line with the Group’s goal of accompanying its clients right from the design of IT products and solutions through to hosting related services tailored to specific needs.\nThe datacenter also hosts firms located in other regions, illustrating Toshiba’s broader ambitions. “Developing this first datacenter in Rhône-Alpes highlights the importance of the Grand Lyon project for Toshiba and embodies the group’s investment in the development of its Cloud offering,” explains Philippe Hartmanshenn, Managing Director of Toshiba Systèmes France’s Cloud \u0026amp; Solutions Division.\n“This allows us to move both internal and external client resources and services offsite to our high-security servers – located in France. We also plan to use the datacenter to develop and integrate business solutions for our clients from every sector.”\n__I felt the need to highlight this as it shows the importance of the cloud, as an important tool to innovation regardless of industry.\nSo who are the Top 10 players of cloud computing services that has been making waves recently?\n1. Google\nGoogle Cloud is the approach of Google to provide enterprise solutions to companies. Google Cloud Platform allows you to build applications and websites, store and analyze data on Google’s infrastructure. Companies can build websites, applications and service on this platform. Apart from these Google also offers Google Apps for businesses, which is now growing. Google has recently unveiled a “patent pledge” that it hopes will shield cloud software and big data developers from litigation. The pledge, which is like a non-aggression pact, covers ten patents related to Google’s MapReduce technology.\n2. Microsoft\nThe foundations of the Cloud OS are Windows Server and Windows Azure, complemented by the full breadth of our technology solutions, such as SQL Server, System Center and Visual Studio. Together, these technologies provide one consistent platform for infrastructure, apps and data that can span your datacenter, service provider datacenters, and the Microsoft public cloud.\n3. Citrix\nCitrix Cloud Platform provides the latest and most advanced open source software platform to build highly scalable and reliable cloud computing environments. Citrix offers three form of cloud computing – Hosted public cloud, Hosted private cloud and On-premise private cloud; Recently as per Info-Tech Research Group, Citrix Cloud platform is announced the Champion in Cloud Management Vendor Landscape. Citrix recently announced the availability of CloudPortal™ Business Manager 2.0, a cloud services delivery platform that enables enterprises and service providers to unify the commerce, user management, provisioning and operational aspects of a cloud into a single cloud interface for delivering anything as a service (XaaS).\n**4. Joyent ** San Francisco infrastructure-as-a-service provider, Joyent is the high-performance cloud infrastructure company, offering the only solution specifically built to power real-time web and mobile applications. Recently with the combined efforts of Joyent and Xeround (a cloud database company), Joyent customers can now access free and highly available with zero management MYSQL database. Xeround relational database is only available for Joyent Cloud platform.\n**5. CenturyLink ** CenturyLink, 3rd largest telecommunication company in USA and an established leader in providing networking solutions and cloud hosting services. CenturyLink recently announced that it’s providing 100 Gigabyte per sec (Gbps) networking solutions and will continue to provide best cloud infrastructure and IT hosting solutions. Savvis, a subsidiary of CenturyLink has collaborated with VMware Cloud Applications Marketplace to provide wide variety of applications packages to its clients from various software and hardware vendors.\n6. Amazon\nAmazon EC2 is an Infrastructure as a Service Cloud Computing Platform provided by Amazon Web Services (AWS), which allows users to provision or deletion of virtual computers. Amazon is one of the true innovators in Web-based computing, offering pay-as-you-go access to virtual servers and data storage space. Recently Amazon announced AWS CloudHSM, a new service enabling customers to increase data security and meet compliance requirements by using dedicated Hardware Security Module (HSM) appliances within the AWS Cloud. The CloudHSM service allows customers to securely generate, store and manage cryptographic keys used for data encryption in a way that keys are accessible only by the customer.\n7. IBM\nIBM Smart Cloud – IBM’s enterprise-class public cloud infrastructure-as-a-service (IaaS)delivers secure and scalable hosted IT infrastructure with on-demand access to virtual server and storage resources. BM recently announced global availability for its cloud service on five continents—plus a new center opening in Spain—based on its industry-leading sourcing business to host SAP applications and other core operations. Now clients can turn to cloud computing for enterprise applications while reducing the overall cost of IT and at the same time, expanding online access and investing in innovative analytics, social business and mobile computing.\n8. Salesforce\nSalesforce.com’s CRM solution is broken down into several broad categories: Sales Cloud, Service Cloud, Data Cloud, Collaboration Cloud and Custom Cloud. Saleforce is aiming be the first cloud computing company to hit the $4 billion annual revenue by 2014 and you can assume this from its 3rd quarter earnings. Salesforce will concentrate on social media, mobile computing and real time in a project it refers to as Cloud 2.\n9. Rackspace\nRackspace, an open cloud company is delivering enterprise-level hosting services to businesses of all sizes and kinds around the world since 1998 and have grown to serve more than 190,000 customers. Rackspace integrates the industry’s best technologies for each customer’s specific need and delivers it as a service via its commitment to fanatical support. Rackspace recently opened the doors to its Open Cloud Academy by launching a pilot training program. The Open Cloud Academy is an educational program designed to provide students with affordable IT certifications, specifically around open cloud technologies.\n10. Verizon Terremark\nVerizon started its cloud computing services as a part of its enterprise solutions. Its infrastructure services have helped many of the world’s top enterprises improve IT performance and evolve business processes. Verizon Terremark sets the standard for IT deployments with advanced infrastructure and managed service offerings that deliver the scale, security, and reliability necessary to meet the demanding requirements of enterprises and governments around the world. Terremark launched its Enterprise Cloud Private Edition a single-tenant environment and its OS- and network-agnostic strategy shows the telco cloud understands the value of accessibility and integration.\n","date":"2013-05-07T02:31:30Z","permalink":"https://martinliu.cn/2013/05/07/top10e585a8e79083e68e92e5908de5898de58d81e79a84e4ba91e8aea1e7ae97e585ace58fb8/","title":"Top10全球排名前十的云计算公司"},{"content":"[su_box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮 Eric [/su_box]\n桌面虚拟化项目的实施白皮书 《Citrix Virtual Desktop Handbook 5.x》，点击下载。\n四、 控制层 Control Layer 控制层是设计架构的第四层。在上面有关用户的三个层面我们所做的决定都会汇总起来到控制层。\n访问控制器 访问控制器子层的职责是给每个用户提供予以支持访问控制层的基础架构组件。这么说可能比较绕口，那就换个说法吧，访问控制器一般包括例如 Web Interface、StoreFront，以及 NetScaler Access Gateway；\n1) 远程访问架构\n如果有用户需要远程或者是离线的移动访问能力，那么就要设计远程访问基础架构了。\n**A. ****决断：拓扑** 网络拓扑的设计对远程访问架构能够支撑功能性、性能以及安全性至关重要。远程访问架构应当和安全团队一起合作以确保符合企业的安全规范。以下三种主要的拓扑结构我们在设计师可以考虑，每种的安全性逐渐递增：\nl 1-Arm (Normal Security**，单臂模式)****：**在这种架构下，Access Gateway 使用一个物理的或者是逻辑的 Bonded 的网络接口，再加上 VLAN 和 IP 子网的设计，来传递用户和后台虚拟桌面的流量。\nl **2-Arm (High Security **双臂模式)**：**在双臂模式下，Access Gateway 利用两张或者更多的物理或者逻辑 Bonded 的网络接口卡，再加上 VLAN 和 IP 子网的设计，来传递用户和后台虚拟桌面的流量。前段用户的流量被导向这些网络接口卡的第一张网卡上，前后端的流量是被分离设计的，就是说说后端虚拟桌面架构服务器的流量是被定向到第二张网卡上的。通过这样的设计我们就可以 DMZ 区来分离前后端的流量，同时还可以定制防火墙策略和流量监控策略。****\nl **Double-Hop DMZ (Very High Security): **这种模式既利用了双臂拓扑下的特性，又使用了两个单独的 Access Gateway 设备。有一些企业使用了三个物理的/逻辑的防火墙结构来保护他们的内部网络。这三个防火墙将 DMZ 区划分为两个区域来提供额外的内部网络安全。\n在第一个 DMZ 区的 Access Gateway 设备处理用户的连接，完成 SSL VPN 的安全功能。这个 Access Gateway 设备加密客户端连接，判断用户的认证方式，控制能够访问的内部网络服务器；\n第二个 DMZ 区域的 Access Gateway 设备充当与一个代理设备角色。这个 Access Gateway 设备启用 ICA 协议将客户端连接穿越第二个 DMZ 区到后端的服务器场。在第一个 DMZ 区的 Access Gateway 设备和内部网络的 Secure Ticket Authority（STA）也是通过第二个 DMZ 区的 Access Gateway 设备来进行代理的。\n**B. ****决断：平台** 在 Access Gateway 部分，我们曾经讨论过只要是涉及到远程访问，我们都会考虑 NetScaler Access Gateway 设备。问了确定合适的 NetScaler 平台来满足项目需求，必须确定一些关键资源。由于所有的远程访问流量都是通过 SSL（安全套接层）来加密，再通过 HTTPs 的 HTTP（超文本协议）协议来传输。所以有两种资源 metric 需要确认：\nl **SSL****吞吐量：**SSL 吞吐量是定义为每秒钟能处理的 GB SSL 流量；\nl **SSL**每秒交易量（TPS**）：**TPS metric 定义在每秒每个应用程序交付控制器（ADC）能处理的 SSL 交易数量\n关于这两个参数的更详细解释，可以参考：Best Practices for implementing 2048-bit SSL\n平均的 SSL 带宽开销在和虚拟桌面的开销比较起来时经常忽略。但是 SSL 带宽的计算将会有助于确定总带宽是否足够。固定带宽加上数据包头开销常常随着加密算法的不同而变化，总带宽开销也常常随着数据包尺寸大小的变化而不同。理想状态下，开销数字应当通过 POC 或者是 Pilot 来实际测试得来，但是在没有这些数据的情况下，在工作负荷带宽基础上加上 2%是一个合理的数字。因此，在确定 NetScaler 平台的时候，SSL 的吞吐量常常是最大并发带宽乘以 1.02，即：\nSSL 吞吐量 = 最大并发带宽 × 1.02\n例如：假设 128M 是最大的并发带宽，那么最合适的 NetScaler 模型应当计算为：\n约 130Mbps = 128M × 1.02\nNetScaler 有三种平台，每种都提供了大量的不同的扩展性：\nl VPX**：VPX 平台的 NetScaler 和硬件的 NetScaler 提供完全一致的功能，不过他只适合于小型的测试环境使用。**\nl MDX**：NetScaler MDX 是 NetScaler 设备的硬件版本。他能支持大型网络可扩展环境；**\nl SDX**：NetScaler SDX 设备是在物理 NetScaler 设备和虚拟 NetScaler 设备之间的一个桥梁。一个 SDX 设备能够划分为多个虚拟的 NetScaler 设备。**\n2) StoreFront\nCitrix StoreFront 是 Web Interface 的下一代产品，它验证用户连接到后台的 XenDesktop 站点、XenApp 场，以及 AppController（SaaS 应用），然后枚举或者是聚合可用的桌面和应用程序到商店以便让用户通过不同操作系统平台上的 Receiver 来访问，包括安卓、iOS、Linux、Windows、Win8/RT 以及 Web 站点。\nC. **决断：Web Interface**还是 StoreFront Web Interface 和 StoreFront 是两种不同的解决方案，在一些功能方面有重叠。所以我们要认真评估我们的需求。一般来说，新的方案应该使用 StoreFront，因为 Web Interface 已经不再有新功能添加了。可以参考下面的链接了解 Citrix 桌面产品的生命周期：Lifecycle Milestones for Citrix XenDesktop\n下面的表格也示例了在何种情况下该使用什么产品：\n下面的表格对两种产品在未来功能的开发目标上进行了一个对比，Web Interface 已经不再会有革命性的功能添加了：\n下面的表格是功能对比：\n有一些 Web Interface 有的功能也会被完全整合到未来的 StoreFront 新版本中去：\nA. **决断：Web **服务的高可用 如果 StoreFront 服务器不可用，或者是其他对应的 Web 服务不可用了，那么用户就不能连接到新的会话，例如打开新的虚拟桌面，无法打开应用程序等操作，因此，至少需要规划两台 StoreFront 来预防单点故障问题。我们可以考虑的方案包括：\nl DNS Round Robin**：在多个服务器之间提供基本的负载均衡功能，无法做到是否可用性的检查；在服务器宕机时，部分用户会受到影响。**\nl Windows NLB**：**是 Windows 的一个服务。可以做一些基本的检查来判断服务器是否可用，但是无法判断单个服务的状态。\nl Citrix NetScaler**：**智能硬件设备，能检查 StoreFront 服务的状态，根据用户请求主动激活负载均衡状态。\n**B. ****决断：应用程序订阅数据库的高可用** StoreFront 的配置数据都存储在每一台 StoreFront 服务器的本地，然后被复制到服务器组中的其他的系统中。对比之下，用户应用程序订阅信息存储在应用程序订阅数据库中，该数据库可以是本地的 StoreFront 服务器，也可以是推荐的一个专门的 Microsoft SQL Server。\n如果应用程序订阅数据库不可用，以下功能将不可用：\nl 用户不能在管理他们的应用程序订阅；\nl 无法登陆至 Web 方式的 Reciever，但是已经建立起来的会话可以继续正常工作；\n为了防止应用程序订阅数据库成为单点故障点，Citrix 推荐 SQL 的高可用方案：\nl **自动容错的 SQL****镜像：数据库镜像提供了一种比数据库 Clustering 更简单的快速容错方法。数据库镜像技术在每一个镜像点上需要一个标准的 SQL 标准版服务器 License，在加上一个 witness 服务器的 SQL Express License 即可。更多细节可以参考文档：Configuring StoreFront using the Configuration Files.**\nl **SQl Clustering: **微软的技术，不过老实说，相比较 Mirroring 技术配置太复杂，此外，自动容错的过程也更慢。在 License 上，每个 Cluster 节点都需要一个企业版的 SQL license。****\nl **Hypervisor****高可用：**数据库部署在一台虚拟机上，通过 Hypervisor 的高可用来实现。这个技术比镜像或者是 clustering 都要便宜，因为只需要一个 SQl Express License 和一台 SQL Server（需要一个具备 HA 功能的 Hypervisor License）。不过，这个技术容错过程较慢，也仅仅是当 SQl Server 的操作系统宕机时才能启动容错机制。如果数据库服务出现错误是无法被 Hypervisor 层检测到的。\n注意：未来的 StoreFront版本将不会再使用应用程序订阅数据库（Application Subscription Database），相反，预订信息会自动的在 StoreFront服务器组中的 StoreFront服务器中自动复制。\n**C. ****决断：容量规划** 基于扩展性的测试，单个 StoreFront 服务器可以支持的用户数是无限制的，受限制的是在这个服务器上每小时之内用户同时操作的动作。这是因为仅仅当用户执行一个动作的时候，例如在 Receiver 中订阅一个应用程序是，StoreFront 才被使用。当用户连接到所发布的资源时，StoreFront 实际上是 idle 状态的。因此，下面的表格所展示的内容介绍的是没鸟的请求时，或者是每小时的请求数。我们建立了一个前提条件是每用户在每小时之内启动了五个应用程序，订阅了 2 个应用程序，取消订阅了一个应用程序，总共每小时是 8 个操作量。\n注意：上述数字是在仿真环境下测试得来：基于 SSL 的 XenApp6.5，发布了 100+个应用程序，每个用户在 5 秒钟之内完成操作的。\nStoreFront 对 CPU 的数量更敏感，也就是说对 CPU 的消耗更大，而不是对内存消耗更大。推荐的企业 StoreFront 服务器是 4 个 vCPU 和 4GB RAM。\nD. **但服务器扩展性 – **应用程序订阅数据库 应用程序订阅数据库包含了每个用户订阅的一系列资源列表情况。基于测试环境下，推荐的一个储存应用程序订阅数据库独立 SQL 服务器的配置是 4vCPU 和 4GB RAM。\n数据库的增长速度大约是每个订阅 10KB 空间消耗：\n数据库大小 = （用户数 × 每用户的订阅数） × 10KB\n1 个订阅 = 1 个用户订阅一个应用程序，例如，1000 个用户订阅 10 个应用程序就是 100MB。\n桌面控制器 这部分内容主要是介绍 XenClient 部分，请大家自行参见原始文档。\n下期预告：下一期我们介绍最后的部分：Provisioning Services\n","date":"2013-05-02T04:22:36Z","permalink":"https://martinliu.cn/2013/05/02/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbbpart4/","title":"XenDesktop虚拟桌面精品书籍导读(part4)"},{"content":"http://virtualfeller.com/\n","date":"2013-05-02T03:42:54Z","permalink":"https://martinliu.cn/2013/05/02/ask-the-architect-e68ea8e88d90citrixe8999ae68b9fe58c96e5a4a7e5b888e4b880e5908d/","title":"Ask the Architect 推荐Citrix虚拟化大师一名"},{"content":"[nggallery id=18]\n第一次的半程马拉松比赛，跑的非常艰苦，鞋子和脚趾出现严重的状况，中途已经痛的我呲牙咧嘴；烈日艳艳的高温，让整个人都快从脚底板燃烧起来了。到了终点，一个大约坑爹的 1 公里折返跑彻底让人筋疲力尽。\n比赛就是比赛，一旦开始就没有退出，只有坚持到底的人才能收获成绩。\n","date":"2013-04-23T12:41:24Z","permalink":"https://martinliu.cn/2013/04/23/e68891e79a84e7acace4b880e6aca1e58d8ae7a88be9a9ace68b89e69dbee6af94e8b59b/","title":"我的第一次半程马拉松比赛"},{"content":"\n","date":"2013-04-23T11:57:14Z","permalink":"https://martinliu.cn/2013/04/23/bad-thing-will-pass/","title":"bad thing will pass"},{"content":"\n首先我们来回顾一下历史： 上周 Citrix 把经营和支持多年的开源项目 Xen Project 加入到了 inux Foundation，可以说是 Xen Project 的一个新家。可能您还不太了解“Linux Foundation”；访问 FAQ 可获得它的一些基本知识。到目前为止 Linux Foundation 总共支持了 8 个开源软件项目。\n想加入 Linux fondation 的项目还必须满足如下两个标准：\nThe use of open source governance best practices including license and contribution agreement choices in keeping with the ideals of Linux The project must have the potential to fuel innovation in an industry through collaborative software development 我个人认为，这对于 Xen Project 和 Citrix 双方来说都是一个好事，Xen Project 可以获得跟光明的发展前景，Citrix 的商业产品 XenServer 也基本上可以直接从中受益。对 Xen 的处理，Citrix 的做法和处理 CloudStack 是相同的，只是 CloudStack 交给了 Apache 组织。在国外这是一种成熟和成功的商业模式，开源软件项目周边发展出的是生机盎然的生态系统。\nCitrix 的官方新闻 ：Citrix and Industry Leaders Usher in New Era for Open Source Xen //Strong Industry Support Drives Need for Independent Xen Project Initiative Xen Project 官网新闻：Xen is now a Linux Foundation Collaborative Project Linux Foundation 新闻： Xen to Become Linux Foundation Collaborative Project Jim Zemlin （Executive Director of Linux Foundation）欢迎 Xen 的加入： Welcome Xen as a Linux Foundation Collaborative Project 对 Xen Project 做持续贡献的厂商么是这么反馈的： 查看 Xen Project 的旧家： http://www.xen.org/ Xen Project 的新家：http://xenproject.org/ 请记住 Xen 的标志物，功夫熊猫：[gallery ids=\u0026ldquo;52363,52365,52366\u0026rdquo;]\nZDNet 的评论： Xen, Citrix\u0026rsquo;s popular open-source hypervisor, is becoming a Linux Foundation Collaborative Project with the backing of such major technology powers such as Amazon Web Services, Google, and Intel.\narstechnica.comd 的评论：Linux Foundation takes over Xen, enlists Amazon in war to rule the cloud ///Xen virtualization gains support from Amazon, Cisco, Google, Intel, and more.\n","date":"2013-04-23T08:20:59Z","permalink":"https://martinliu.cn/2013/04/23/xen-is-now-a-linux-foundation-collaborative-project/","title":"让Xen Project回家"},{"content":"[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮 Eric [/box]\n桌面虚拟化项目的实施白皮书 《Citrix Virtual Desktop Handbook 5.x》，点击下载。\n智慧的积累靠一蹴而就很难实现，慢慢积累和温故而知新往往是最佳的手段。让我们继续开始《Citrix 桌面虚拟化实施部署白皮书》，这晚我们开讲第二部分的第三单元：桌面层。\n四、 桌面层 Desktop Layer\n设计思想的第三层，也是和用户相关的最后一层，就是桌面层。用户是否能接受桌面虚拟化很多程度上就是在这一层实现的，例如包括个性化、应用程序，以及后台操作系统镜像文件的设计。\n应用程序交付 选择正确的应用程序交付方法会对整个系统设计的可扩展性、可管理性，以及用户感受起到非常大的帮助。基于我们在前几章节的“四、 应用程序数据搜集”，我们可以考虑以下几种交付方法：\nl 直接安装在操作系统镜像文件上：应用程序是基础操作系统镜像文件的一部分；\nl 安装在 Personal vDisk 上：物理是分离的，但是逻辑上是直接安装在基础操作系统镜像文件中；\nl 流化（Streaming）：应用程序被 profiled（XenApp 组件）后通过网络交付到桌面上。应用程序的文件和注册表键值在虚拟桌面的一个容器中保存，但是和基础操作系统镜像文件是分离的。\nl Hosted：应用程序安装在 XenApp 服务器上，用户通过 Citrix HDX 协议远程访问。\n决断：应用程序交付方法 系统架构师应该在基于用户需求、应用程序兼容性，以及其他通过在前几章（“四、 应用程序数据搜集”）搜集上来的应用程序因素基础之上决定采用何种方法来进行应用程序的交付。通常单一的方法是无法满足用户全部的需求的，所以多种方法组合才是最佳答案。但是不管用什么方法，这些交付手段都应当对整个项目的交付复杂程度和后续跟进步骤与以最小的影响。\n下面的表格就是不同的交付方法对系统不同层面的影响：\n除了应用程序交付方法对系统不同层面的应用之外，系统架构师还应该考虑应用程序在不同交付手段上的适用性。下面的表格就是不同应用程序所推荐的部署方法示例：\n上表中需要注意的是最后一种应用程序，我们往往会觉得这种复杂安装和配置的应用程序最好是安装在操作系统镜像文件中，但是最佳实践告诉我们应该安装在 XenApp Server 上，通过 Hosted 的方法发布给用户。\n兼容性 任何一个桌面虚拟化项目都会对一个公司的应用程序交付方法产生巨大的应用。举例来说，许多公司都希望通过在桌面虚拟化中使用流化的应用程序交付或者是 XenApp 交付应用程序来降低升级用户的桌面操作系统的劳动负荷以及提高管理效率。所以在设计阶段我们就要做很多兼容性测试以确定最正确的应用程序交付方法。最重要需要考虑的兼容性需求一般来说包括以下几点：\nl 桌面操作系统的版本：如果操作系统是通过流化安装或者是直接安装在操作系统中，那么应用程序需要考虑和操作系统的兼容性问题；\nl 服务器操作系统的版本：有一些应用程序可能会更合适通过 XenApp 的方式来交付，所以，应用程序是否能安装在服务器版本的操作系统平台上是要考虑的因素；\nl 应用程序本身的架构：应用程序本身的开发平台有可能是 16 位的，32 位的，也可能是 64 位的。16 位的应用程序就不能运行在 64 位的操作系统平台上，例如 Windows 2008Server R2、Windows XP 64bits 等；\nl 互操作性：有一些应用程序如果和某些版本的操作系统共存是会有兼容性问题，例如注册表冲突、DLL 冲突，或者是 ini 冲突。\nl 应用程序流化：应用程序流化到桌面虽然可以简化管理，因为操作系统上不用安装那么多的应用程序了，但是记住有些带有设备驱动程序，或者是使用了 COM+等应用程序就不适合了\n在做应用程序兼容性测试时的三种主要技术手段有：\nl 手动：不言而喻这种方法最消耗时间，每种交付方法都要测试，每种操作系统版本、不同操作系统语言包等也都要验证。手动模式下想要的出应用程序所有方面的测试结果是非常困难的，对应用程序互操作性的测试是几乎测不出来的。而且更多的测试结果是现场使用人员发现的，而不是测试时发现的。\nl 预验证的应用程序：很多应用程序的开发商都会提供该应用程序的兼容性文档和最佳安装方式的文档。参考这些文档会有直接的帮助。此外，Citrix Community Verified 的网站上也有一整系列的由 Citrix 的客户和合作伙伴验证过包括采用流化方法/XenApp/Xendesktop 兼容的应用程序列表。微软公司也提供了类似的应用程序列表：Microsoft Windows 7 Application Compatibility List for IT Professionals；\nl 自动化的工具：Citrix AppDNA 可以快速而且准确的对应用程序的兼容性做出精确的测试，包括测试不同的操作系统平台，测试不同的交付手段，例如 Windows XP、Windows 7、Citrix XenApp、Microsoft App-V，以及 Citrix Streaming 流化交付方式等。应用程序被导入到 AppDNA 时，它会被和数千种应用程序进行兼容性的匹配验证以判断是否有互操作性问题。当发现问题时，AppDNA 会告知问题出自何处，可能的解决办法，以及估计解决的时间。\n上述每种方法的优点和缺点都列在下表中：\n测试做完之后，兼容性的结果就应该填入到之前的应用程序评估表各种以便我们的后续分析：\nl 预运行环境：许多程序都有运行环境的要求，例如 Java、.Net 环境，或者是数据库要求；\nl 程序之间的依赖：例如，需要以 pdf 格式呈现信息的应用程序就需要电脑上安装了 pdf 的阅读器；\nl 16 位的代码：应用程序评估也应该判断是否应用程序包含有 16 位的代码，因为 16 位的代码是不能运行在 64 位的操作系统平台上；\nl Windows XP：确认应用程序是否能通过 Windows XP 的兼容性测试；\nl Windows 7：确认应用程序是否能通过 Windows 7 的兼容性测试；\nl XenApp 6.5：确认应用程序是否能通过 XenApp 6.5 的兼容性测试；\nl Application Streaming 应用程序流化安装：确认应用程序是否能通过流化程序安装的兼容性测试；\n用户分类 通常不是所有用户都需要所有的应用程序，有些程序可能就只有很小一部分用户用的上。所以系统架构师应该做好这个工作，例如如果一个部门的用户都需要的应用程序列表组，我们可以单独做一个操作系统镜像文件。如果只有少部门用户需要使用，那我们建议采用 Personal vDisk 或者是 Streaming 的方式交付应用程序。\n业务特点 l IT 经验：如果 IT 部门已经对某种应用程序交付方式有经验，或者是基础架构已经 Ready 了，那么这种交付模式可能就是合适的方式。例如，如果公司内部已经通过 Microsoft App-V 平台部署过 Streaming 的应用程序，那么 XenApp Streaming 应用程序就应当优先被考虑。\nl 管理需求：应用程序交付的方法很可能严重依赖于应用程序的拥有着。如果应用程序是公司拥有的程序，那么 IT 部门就有责任和义务来维护该应用程序，包括 XenApp 发布或者是 XenApp 流化。如果程序的拥有者是某个下级部门，那么 IT 部门就不方便集中管理，这种情况下应用程序可能就建议安装在 Personal vDisk 上，让部门自己来管理该应用程序。\nl 升级频率：应用程序的升级所需要花费的时间和部门协调也对交付模式的选择有很大影响。如果应用程序经常升级，那么系统架构师就应当选择安装数量最少的交付模式，这样可以减少升级的应用程序数量，以及降低升级的复杂程度。这种情况西 XenApp 交付方式最为合适；\nl 产品 Licensing：如果应用程序没有 License 要求，例如和软件厂商签订了 Site License，那么我们可以将该程序发布给所有的用户也不会产生其他任何成本，将该程序直接安装在操作系统模板里面也能降低交付的复杂性。如果应用程序对 License 很敏感，系统架构师就需要考虑采用一种能够遵守应用程序软件提供商要求的 License 模型。\n技术特点 l 资源使用：如果应用程序对资源要求很高，可能会更合适于直接在虚拟桌面里面直接运行；\nl 技术难点：如果一个应用程序的安装都很复杂，例如需要专门的配置，脚本的运行，或者对其他应用程序有很多要求，我们称之为技术难点。这种情况下，安装在 XenApp Server 上能减少操作系统镜像文件制作的复杂性。\n","date":"2013-04-16T15:29:43Z","permalink":"https://martinliu.cn/2013/04/16/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbbpart3/","title":"XenDesktop虚拟桌面精品书籍导读(part3)"},{"content":"[su_box ] 最近有一篇比较热的文章，中文标题《Forrester：70%的“私有云”根本不是云》；你如果稍微搜索一下，你发现它几乎被转载烂了，但是我看了几篇，真心的担心读者们是否都能正确的理解。写本文，全当是给您的一个阅读帮助。 [/su_box]\n中文版网页点这里 英文版网页点这里\n中文翻译的质量有限，有些概念和逻辑错误，我做了一点点的修订，从而避免误解。\n**【基于 CNW.com.cn 译稿】**如果企业数据中心拥有高度虚拟化的环境，有一个 Web 门户供商业用户申请和访问虚机，再有一种方法可以跟踪有多少资源被使用了……拥有这一切并不能叫做有了一个私有云。\n假如有足够大的容量可以为员工提供他们所需要的任意数量的计算资源，并能够动态地上下扩展或收缩容量，但仍然需要 IT 人员制备好系统的话，那么这仍然不能叫私有云。\n虚拟化和私有云之间的界限是比较模糊的，根据 Forrester 的最新报告，在企业的 IT 高管们所自诩的私有云中，高达 70%的 IT 环境其实并非私有云。“这是个严重的问题。实际上是在做云洗白而已。”Forrester 的云专家 James Staten 如此说。\n为什么说这个问题非常重要? Staten 认为，如果将一个高度虚拟化的环境称为云环境，但它又不具备私有云的一项或多项关键特征，那么 IT 部门就给了用户一个不切实际的期望。假如用户们发现这个环境不能自配置，或者没有弹性资源池而感到不满时，他们就有可能因此而气馁。那么当下一次用户需要实时运行一个虚机时，他们会选择在哪里运行呢? 是 IT 部门给他们的伪私有云? 还是亚马逊的 AWS? 如此一来，IT 部门就无法控制事态了。\n大多数云专家已经对云计算(公有云或私有云)的定义有了普遍的共识，这就是 NIST 提出的五个关键特征。这些特征包括：\n● 用户可按需索取、自服务\n● 泛在的网络接入\n● 共享资源池\n● 弹性扩展资源的能力\n● 拥有可计量的服务\n如果没有这五大特征，那从技术上说就不能叫云。和某些人的想法相悖的是，虚拟化并不是私有云。它只是为云提供动力的一个基本要素，但只依靠它是创建不出一个云的。VMware 的营销经理 Mike Adams 说，私有云必须在虚拟化环境之上综合更多复杂的管理功能，方能满足 NIST 的定义要求。\nCA 的战略解决方案副总裁兼云专家 Andi Mann 给这场讨论踩了一脚刹车。“如果你不符合所有这五大特征，那么你就陷入了语义学纠结中。”他认为真正的问题并不是说符合这五个复选标记的东西就叫做云，而是在于 IT 能否为用户提供适当的服务。“有时候，80%的云都已足够好了，”他说。“用户真正在意的是业务服务。谁会在意你的环境叫什么。你要关心的就是客户，就是业务用户是不是得到了他们需要的资源。”\n也许企业并不需要弹性扩展，因为原本就是静态工作负载。即便不需要弹性的资源扩展能力，它仍然还可以需要云的其他特征——自服务、计费、泛在网络接入和共享资源池。但它在技术上可能并不符合 NIST 的定义。“所以，如果你要想技术上也说得过去，也可以将其称为：高效率的虚拟环境，”Mann 说。\n那么，所有这些云洗白来自哪里? Staten 认为，IT 管理人员基本上对云都抱有恐惧心理。企业内的虚拟化专家通常都处于支配地位; 在需要资源时，他们可以去制备相应的资源容量。而云被视为一种赋予用户自服务和动态扩展资源权力的模式，对 IT 是一种威胁。如果用户可以自己开通了，那还要他们这些虚拟化专家干什么呢?\nStaten 认为，这样想上述问题是错误的。即便有了云，IT 管理人员还是有大量的工作可做，比如需要设置和确保云服务有一个可供用户选择的服务目录，需要完成安全访问协议配置，提供资源可用性和虚拟化组件等。管理人员必须接受这样一个理念：如果他们不这么做，那么用户不论如何还是需要访问和使用他们所需要的资源，这样还是会陷入可怕的“影子 IT”的局面。(Martin 修订)\n我想先对以上的几个关键点和名词做一些解释，从而能让我们更好的理解原文作者的意图。\n\u0026ldquo;cloud-washing\u0026rdquo; \u0026ndash; “云洗白” 这个比喻是说：本来根本什么云都不是！但是还是要狡辩和伪装为私有云。真像是：纯虚拟化环境不等于云\n\u0026ldquo;shadow IT.\u0026rdquo; \u0026ndash; “影子 IT” 这个比喻是说：IT 部门是业务部门挥之不去的阴霾，他们跟没发赶上业务部门需求变化请求的脚本，业务部门的人从来不管你是用的是神马云，你们这帮人根本没有按时的交付过任何东西，甚至于每当想起需要 IT 部门来配合做什么东西，就感到没有指望，啥都需要漫长的等待。\nIT 部门真的是技术不行么？IT 部门真的是干活的人不够么？这个比喻后背后真是的故事：特别是大规模的企业，业务部门所需要的任何 IT 资源和变更都必须通过 IT 自动、半自动或者手工配置实现；小的到开通一个邮箱，重置一次密码；大到新的业务系统的升级和上线；往往 IT 或者业务用户发频繁和密集地发起种种请求时，没有任何一家传统企业的 IT 部门（亚马逊、谷歌这种公司除外，因为它们已经是云计算公司了）能够很有自信地、充分让业务部门满意地完成被要求完成的所有工作。它们为什么完成不了呢？这个就走入了 IT 管理的经典理论，这就是我之前十年工作经验中天天和用户沟通的东西：“保持 IT 系统的稳定，还是接受变化”；为了既能响应业务部门不断的变化请求和 IT 用户的日常需求，IT 部门想到了很好的流程来加以解决，这个流程是什么？它叫“变更管理流程”。举个例子，大型的商业银行一般一周或者两周有一次系统变更日；所有的对 IT 系统的配置和改变，必须提前计划安排好工作顺序，只能在变更日当晚的固定时间窗口中完成，例如晚上 11 点到凌晨 5 点；如果在这个时间段某个工作没有完成怎么办？对不起！没有完成的变更叫做失败变更，你还必须在变更窗前前就把系统回退到未变更前的状态！你现在发现了么？对生产系统是多么严肃的事情！如果你在变更前，没有万无一失的备份计划，你但失误，你就歇菜了；或者你觉得是顺利完成变更了，但是营业厅一开门，IT 的投诉热线就被打爆了，这也不行；变更一但导致生产系统的宕机，轻则 IT 部门的领导引咎辞职，重则数据中心的大领导乌纱帽不保。\n以上讲述的故事可以说是我的亲身经历，就是中国的国情；那么这个文章的出处毕竟是国外的，这几个发话的大佬们都是何方神圣？\nForrester 的云专家 James Staten ：BIO 从 Bio 上看，他好像是 Forrester 的头牌云分析师之一，有 20 年的 IT 从业经验。\nVMware 的营销经理 Mike Adams ：网上查不到它的 Bio，在 VMWare 网站搜索，也只能看到他是http://blogs.vmware.com/vsphere/ 的负责人。网上并没有关于此人的详细介绍，但是我们从 vsphere 的 blog 上在读一下这个产品的定位“BEGIN THE JOURNEY TO A PRIVATE CLOUD WITH DATACENTER VIRTUALIZATION”；这个说法和此大师在文章中说的一样：vsphere 是数据中心虚拟化的一个技术组建，数据中心虚拟化技术是私有云建设的起点。但是它是起点，不是私有云。纯种的服务器虚拟化项目也不是那天就能进化成私有云了。\nCA 的战略解决方案副总裁兼云专家 Andi Mann ：BIO 从 Bio 上可以看出，这大叔才是练家子，人家 84 年从 IT 管理员出身干起；感觉它说的话比较在点子上，并没有去忽悠云；而是从云的本质，也就是 IT 的本质去看，去分析的。也就是“IT 是提供服务和支持的，为的是让用户能够操作和使用业务系统去完成业务工作。” 如果这句话抽象，我可以举个例子：领导需要阅读邮件，他关心的是 IT 能否让我安全的在设备上查邮箱，浏览和回复邮件；当然你能让他在任何设备、任何网络上、任何时间都能完成以上动作，那就再好不过了。银行的储蓄业务柜员需要的是完成一个存、取钱、开销户等相关操作，他关心的是 IT 系统能够正常快速的相应，让客户快速的离开柜台；她根本不关心，网线后面连接的系统是啥做的。\n言归正传：把焦点放到“云”的概念上一点意义都没有！倒不如把心思放在云的价值上；把心思放在私/公有云的建设方案上！我试图从云计算的基础特征上来解读一下云计算对云企业的价值：\n用户可按需索取、自服务：让用户能够更方便的访问（请求、开通和使用）IT 资源和服务，用户无需等待，资源召之即来\n泛在的网络接入：个人觉得这个应该翻译为高速度高带宽的网络接入，这个是外界访问到计算资源的必要条件之一；如果你资源再多，但是出口太窄也没有意义；如果翻译成这样也凑合如果能理解为，在个中网络条件下都能够正常安全的加入到云所提供的 IT 服务上也可以。\n共享资源池： 这个可以提高 IT 资源的利用率，利用率高了，投资就减少了，浪费了低了\n弹性扩展资源的能力：这个可以应付突发的大批量用户访问请求，并且能够自动资源回收，最重要的是这些扩展和收缩的发生都是云系统自动完成的，不需要管理员手工操作\n拥有可计量的服务 ： 这个对于 IT 部门需要向用户收钱的实在是重要；或者对服务提供商更重要，如果国内的用户实在没有这个需求也可以不强求。\n那么，我们清楚了云的标准和价值后，我们需要判断的是什么？我认为是，我们为什么要建云？你在建云的时候，必须要有一个原因；有了这个原因了才有云的价值取向，才能谈到云的需求，才能谈到云的方案。当然，云就是以云的方案和设计理念去建设的，不存在伪云计算最终能进化或者发展成云计算这一说，就像是，猴子长的年纪在大也无法开口讲话一样。厂商也要不要故意误导，用户也不要片面理解。\n在引申一下：云计算和虚拟化究竟有啥关系？我斗胆从云的经典分类上来说 Iaas\\PaaS\\SaaS；从技术上讲，只有 IaaS 和服务器虚拟化有必然联系，其它两种 PaaS 和 SaaS 可以和虚拟化一点必然关系都没有，但是如果他们需要的话，可能可以利用到虚拟化技术的某些优势，但是用非虚拟化技术的架构实现这两种云计算一点问题都没有。网上盛传的“虚拟化是云计算的基石”根本就是一种误解；不过虚拟化的确能帮你做很多事，能帮助你交付很多种的 IT 服务。如果你一定要把他们挂上钩，那么你需要回答的是，你是否要建设 IaaS 云？你的 IaaS 云管理平台是什么，要关注在 IaaS 云计算管理平台的功能和能力上来，看你的 IaaS 是否需要管理多种类型的 Hypersior？是否需要管理到分布在各地的成千上万个服务器？等等。。。从这些需求中才会细化出 IaaS 云管理平台对服务器虚拟化平台的需求。云计算建设是自顶向下的过程，从清晰的概念和建设思路出发，切勿本末倒置，切勿舍本逐末。\n","date":"2013-04-15T17:31:21Z","permalink":"https://martinliu.cn/2013/04/15/forrester-private-clouds-what-is-cloud-computing/","title":"什么是真的云？"},{"content":"[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮 Eric [/box]\n桌面虚拟化项目的实施白皮书 《Citrix Virtual Desktop Handbook 5.x》，点击下载。\n上周一我们介绍了《Citrix 桌面虚拟化实施部署白皮书》的第二部分《设计篇 Design》的第一单元：用户层。今天我们继续往前进，开讲第二单元：访问层的部分。\n三、 访问层 Access Layer\n访问层的设计主要是基于每个用户组和终端设备的移动性需求。\n决断：认证点 让用户在什么地点做认证是管理员的决定，一般而言，有四个认证点：\na) Web Interface：给 XA 和 XD 提供安全访问；\nb) StoreFront：为 Receiver 交付认证能力和资源；\nc) Secure Gateway (Web Interface): Secure Gateway 是一个 Windows 的应用程序，她和 WI 配合工作；\nd) Access Gateway: 硬件\n具体采用哪种方式认证由用户组的移动需求来决定，推荐方案如下：\n决断：预认证策略 如果我们使用的是 Access Gateway，我们就可以选择是否采用预认证策略，这些策略可以是确定终端是否满足某种接入网络前的扫描条件。\n我们可以配置的策略包括测试防病毒软件、防火墙软件、操作系统，甚至是注册表键值。XA 和 XD 可以利用这些策略的检查结果确认后续的动作，包括剪贴板是否开启，打印机映射，甚至是否开启特定的应用程序访问权限。例如，如果用户没有安装防病毒软件，可以配置策略隐藏敏感的应用程序。\n下面的图标从流程上示例策略配置是如何流转的：\n决断：认证策略 l Web Interface, Secure Gateway (Web Interface), or StoreFront: StoreFront 是未来的方向，而 Web Interface 已经是行将就木，所以下面的策略主要是用在 StoreFront 上，当然也适用于 Web Interface\nn 用户名/密码\nn Domain Pass-Through：允许从用户设备上透传 Domain 登录信息，用户登录到加入域的电脑后自动登录到 Store；\nn Access Gateway Pass-Through：用户登录到 Access Gateway 后自动登录到 Store\nl Access Gateway：NetScaler 支持几种不同的认证手段。下面分别列出了几种主要的认证方法，每种方法都可以单独使用，但是在实践中，我们进场组合起来以提供多因素认证。\nn LDAP：轻型目录访问协议是我们最为熟悉的认证方法了，它是一种基于 TCP 协议的目录访问服务，例如 MS 的活动目录就是其中一种实现形式。\nn Radius（aka Token）：Radius 全名是 Remote Authentication Dial In User Service，这是一种基于 UDP 传输协议的安全认证协议。除了认证外，它还提供授权和计费功能。Access Gateway 转发用户输入的用户名和密码给 Radius 服务器，Radius 服务器可以立即检查用户名和密码，也可以转发给目录服务器。\nn 客户端证书：用户登录到 Access Gateway 虚拟服务器后，可以通过本地的客户端证书的属性来做认证。客户端证书通常在用户端的形式是智能卡，或者是 Common Access Cards (CACs)的形式，再通过客户端本地的读卡器来读取信息。\n采用什么认证形式通常都是取决于安全的需求，以及使用什么认证点。下表给出了一个基于安全需求级别的示例：\n决断：会话策略 采用 Access Gateway 作为认证点的用户必须有对应的会话策略来定义用户体验。会话策略的制定是基于 Receiver 在设计阶段制定的。一般而言，首先我们会将设备分为非移动设备和移动设备两种：\nl 移动设备：表达式定义为：“REQ.HTTP.HEADER User-Agent CONTAINS CitrixReceiver”，该语句将移动设备设置为比非移动设备更高优先级以保证移动设备的匹配性。\nl 非移动设备：表达式定义为：“ns_true”，即所有流量。\n更多信息，可以参考 Citrix 公开电子文档：Receiver and Plug-ins\nBTW，另外一种会话策略是采用终端的扫描方法。\n决断：会话 Profile（Session Profile） 每个会话策略（Session Policy）都必须定义一个对应的 Session Profile（姑且翻译成会话配置文件）。这个会话配置文件定义了用户去访问资源时的访问细节。有两种定义到虚拟桌面环境的访问方式的会话配置文件的形式：\nl SSL VPN：传统的 VPN 方式，将网络全部打通。这种方式并不一定十分安全，因为这能导致客户端到内网服务器的攻击访问。\n另外一种办法是考虑是否在 SSL VPN 中开辟一条给客户端网络流量的单独通道。这样通过 receiver 的流量智慧限制在指定的端口，只能访问指定的服务器资源等。\n上述两种方式各有利弊，第一种方式虽然安全性差了，但是可以做客户端流量可以被企业的网络过滤设备，例如入侵检测设备做监视和控制。\nl HDX Proxy：在 HDX 代理方式下，用户是通过 Access Gateway 连接到他们的虚拟桌面和虚拟应用。这种方式下完全没有将内部资源暴露到公网上，此时 Access Gateway 充当了一个微型 VPN 的作用，它仅处理 HDX 的流量。其他的流量，例如电子邮件，又或者是使用者上网的流量都不经过 Access Gateway。\n决断：访问带宽 最后的访问层决断就是要决定虚拟桌面所需要的最大并发网络带宽。其中很重要的一个关键环节就是决定采用 NetScaler Access Gateway 的哪一个平台。\n每个用户所需要的带宽关键还是要看计算的需求。一个时不时才用一下电脑的 ERP 使用者和一个在电脑前屁股都不挪窝的 OA 用户肯定带宽要求是不同的，如果是 CAD 画图的用户那就更不用说了。\n理想情况下带宽的使用情况是通过带宽分析工具来给出来，不过我们还是可以给出一些经验值：\n总带宽的的计算公式可以这样来定义：\n总带宽 = 平均带宽 × 最大并发用户值\n更多细节，可以参考 Citrix 的知识库文章：\nXenDesktop Planning Guide: User Bandwidth Requirements ： XenDesktop Planning Guide: User Bandwidth Requirements\n","date":"2013-04-15T06:52:55Z","permalink":"https://martinliu.cn/2013/04/15/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbbpart2/","title":"XenDesktop虚拟桌面精品书籍导读(part2)"},{"content":"\n原文出处：http://support.citrix.com/article/CTX136751 这篇文章你还不会，你就 out 了！\n概要\n本文描述如何映射默认下被禁用的 USB 设备。\n要求\n当重定向 USB 设备，终端用户必须首先识别 USB 设备，将其映射到会话中。假如设备需要特殊驱动，则驱动必须同时安装在客户机和虚拟桌面代理（VDA）上。如果终端识别驱动，设备在没有驱动的情况下仍可映射，但是 VDA 上需安装驱动以确保工作正常。\n背景\n特定 USB Class 默认下被禁用因为它们主要用于本地工作站，例如智能卡阅读器。\n步骤\n注意!这个修复需改变注册表。错误使用注册表编辑器可能产生严重问题，导致你需要重装操作系统。Citrix 不承诺解决错误使用注册表编辑器的问题。使用注册表编辑器存在风险。确保修改前备份注册表。\n完成以下步骤查找设备的 Class ID 和 Hardware ID：\n打开终端客户机的设备管理器，查找需要重定向的 USB 设备。 右击设备选择属性。注意在 Details 面板上，显示如下图的 Hardware ID 和 Class ID。 在Citrix Desktop Studio \u0026gt; HDX 策略 \u0026gt; 用户中，点击新建USB 设备重定向策略。 点击下一步，类别中选择USB 设备 \u0026gt; 客户端 USB 设备重定向，点击添加，选择允许后确定。 然后，类别中选择 USB 设备 \u0026gt; 客户端 USB 设备重定向规则，点击添加\n点击新建添加允许的 Hardware ID：\n确定后点击下一步，最后应用此策略。\n在终端设备，查看注册表 HKLM\\Software_WOW6432Node*\\Citrix\\Ica Client\\GenericUSB，设置_DeviceRules*值为‘Allow: VID=0911 PID=1844’ 你可以删除deny class rule以使能此 class 的所有设备。但是，为防止非法重定向，增加Allow规则方法更优。\n注意：当增加Allow规则，确保它置于规则列表顶部，使它比规则Deny优先级更高。\n此时在 Desktop Viewer 上可见对应 USB 设备。\n假如点击设备仍不能映射至会话中，尝试手动在 VDA 的注册表中添加允许标记： HKLM\\Software\\Policies\\Citrix\\ICA_Client\\USB\\DeviceRules。 更多信息\n默认值存储于 VDA 注册表的 HKLM\\SOFTWARE\\Citrix\\PortICA\\GenericUSB Type=String Name=\u0026ldquo;DeviceRules\u0026rdquo;，但是，不建议修改此值，因为当 VDA 自检，它首先查看 HKLM\\Software\\Policies\\Citrix\\ICA_Client\\USB\\DeviceRules，再查看本地路径。优选修改规则方法是使用组管理对象（GPO）模板。\n**注意：**你必须修改终端客户机注册表以允许对应的 USB class。\n查看更多: http://support.citrix.com/proddocs/topic/xendesktop-rho/ps-ref-policies-usb-devices.html\n","date":"2013-04-15T06:44:52Z","permalink":"https://martinliu.cn/2013/04/15/xendesktope4b8ade5a682e4bd95e9878de5ae9ae59091usbe8aebee5a487/","title":"XenDesktop中如何重定向USB设备"},{"content":"[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮 Eric [/box]\n桌面虚拟化项目的实施白皮书 《Citrix Virtual Desktop Handbook 5.x》，点击下载。该文档是由 Citrix 全球顶级 Consultant 系统架构师 Daniel Feller, Thomas Berger, Rich Meesters, Matt Brooks, Ed Duncan 以及 Roger LaMarca 等大牛合作完成，它介绍了桌面虚拟化架构设计、方法论、经验总结以及最佳实践等知识，更是包含了一步一步指导手册、真实案例分析以及模板手册等。\n序言：关于方法论 一、 Access 二、 Design 三、 Deploy 四、 Manitain 五、 项目计划\n第一部分：Access 一、 业务驱动力 二、 数据搜集 三、 用户数据搜集 四、 应用程序数据搜集 五、 用户分类\nFlexCast 模型比较 FlexCast 模型选择 六、 应用程序评估 七、 项目管理 Roadmap 项目团队 a) 业务角色 b) 技术角色 第二部分：Design 一、 概况 二、 用户层 User Layer\n终端类型的选择 Receiver 的选择 资源需求 三、 访问层 Access Layer 序言：关于方法论\nCitrix Virtual Desktop handbook 会紧密遵循 Citrix 顾问实施方法论，即如下图所示：\n一、 Access\nAccess 阶段主要提供 Design 阶段所需要的信息，包括：\n业务驱动力；\n数据搜集：包括用户、应用程序、设备以及基础架构；\n用户的分类：用户要根据需要的分类而分成不同的组别，随之应对着不同的 FlexCast 方法论；\n应用程序分类：旧的应用程序应该被删除、应用程序版本应该标准化、非公司程序应该删除，等等这些构成了应用程序的标准化和合理化；\n计划：每个用户组都要根据对业务的影响程度指定不同的实施时间优先级，优先级实施进度结果应该随时更新项目进度和计划。\n二、 Design\n设计阶段主要聚焦在五层的一个方法论上：\n用户层：描述推荐的终端以及所需要的用户功能体验；\n访问层：描述用户层是如何连接到他们的桌面，例如本地桌面是直接连接 StoreFront，而外界用户往往要通过 Firewall 层才能进来，这就涉及到了 FW、VPN 等技术；\n桌面层：主要指用户的虚拟桌面实现技术，即 FlexCast 技术，主要好汉三个主要成分，分别是镜像文件、应用程序，以及个性化内容；\n控制层：如何管理和维护其他层，又分为访问控制、桌面控制，以及基础架构控制；\n硬件层：致力于支撑整个解决方案的硬件物理设备，包括了服务器、CPU、内存、存储设备等；\n三、 Deploy\n按照第二部分设计好的 FlexCast 方式实施。\n四、 Manitain\n主要包含三种不同的活动：\n监控：在虚拟桌面环境设计和实施到生产环境以后，持续的监控是必需的。\n技术支持；\n测试和变更管理：以后会遇到不断的软件和产品更新；\n五、 项目计划\n一个设计详尽的项目计划对项目成功的实施时至关重要的。项目经理要通过项目计划来监控成本、管理项目组成员、跟进项目实施进度等。同时项目进度要及时通告项目组所有成员让大家都知道项目的进度。\n在项目的初期一般只需要做 Access 阶段的计划，这个时段需要多 FlexCast 模式、容量、用户分组等有更多的交接，所以无需做 Design 的计划。如下图所示就是一个计划表：\n第一部分：Access\n一、 业务驱动力\n桌面虚拟化项目的第一步应该是去了解对公司所造成的影响，并且将这些影响定一下来，然后对之以优先级排序。有了这些文字描述管理层和项目管理组才能制定出项目成功实施的标准，设计阶段才能有正确的方法论和架构设计。\n下图就定义了一个业务驱动力的优先级示例：\n二、 数据搜集\n数据搜集阶段负责搜集关键信息数据，包括用户、设备、应用程序，以及基础架构等在下一阶段需要使用的数据。\n有三种方法来搜集数据：\n手动搜集 小型企业有可能通过访问每台终端，或者是远程连接凡是来搜集数据。\n中大型企业一般般都有了 ESD（Enterprise Software Deployment），例如微软的 SCCM 等。可以通过这些平台去搜集应用程序的使用情况等信息。但是 ESD 一般都不能提供应用程序性能需求和实际使用的信息。\n调查表 这也是一个好办法，可以通过管理层去通过行政命令来执行。也可以通过面对面的会议或者是电话沟通来进行；这种方式比手动搜集要显著减少了所花费的时间，但是完成率不高也是一个缺点，不够精确反应实际情况也是一个缺点。\n自动化搜集 这样的工具有很多，一般都能自动化生成报表。Citrix 公司为了帮助用户节省实施成本，和 LanDesk 公司合作，为 Project Accelerator 用户提供了一个 60 天免费试用的 LanDesk FastTack 软件 License。LanDesk FastTack 软件是一个专门为 Citrix 实施方法论开发设计的一个专业信息搜集工具。\n上述三种方法的优势和劣势如下表所示：\n三、 用户数据搜集\n信息搜集表可以参考示例表格：Citrix Virtual Desktop Handbook - Assess Workbook.xlsx\n业务特性 业务特性必须通过业务层的管理人员来手动搜集，无法自动化搜集。包括\nA. 身份\na) 用户名\nb) 部门；\nc) 角色\nd) 业务经理\ne) 所分配的用户组；\nB. 业务\na) 主要的数据中心\nb) 移动性，下表是示例分类\nc) 个性化\nd) 安全性\ne) 关键性\n技术特性 a) 工作负荷\n用户环境 a) 用户 Profile\ni. Profile 类型：包括本地、漫游、强制、第三方、未知\nii. Profile 版本：Windows XP 和 Windows Vista/7\niii. Profile 位置：文件服务器在哪里\niv. 大小：用户 Profile 的大小\nb) 用户数据主目录\ni. 主目录位置\nii. 大小\n客户端硬件，包括以下需要搜集的信息： o Number of CPUs/Cores\no CPU Speed (GHz)\no Memory (GB)\no Disk Size (GB)\no Operating System\no Age of the System (years)\no Peripherals\n本地资源映射，包括以下需要搜集的信息： o Local Drives\no Printing\no Clipboard\no Audio\no COM Port\no USB\no LPT\n四、 应用程序数据搜集\n信息搜集表可以参考示例表格：Citrix Virtual Desktop Handbook - Assess Workbook.xlsx\n身份信息 a) 应用程序名称和版本\nb) 应用程序所有者\nc) 状态\n应用程序技术特性 a) 分配\ni. 使用者数量\nii. 部门信息\niii. 个别用户\nb) 工作负荷\nc) 业务特性\nd) 兼容性\n五、 用户分类\n一旦数据搜集工作完成之后，我们就可以开始准备将用户分成不同的组了，这个时候就要按照 FlexCast 模型的要求去分配不同的实现方式给不同的用户组了。\n我们一般都是按照人物性工作者、分支机构办公人员、移动工作者等方式去区分用户，但是实际上用户的分类远不止这几类，更有甚者，很多用户组都是同时属于上述几个组的。\n最快区分用户的方法就是按照用户的需求不同来分组，一旦将用户的需求区分之后，就可以将这些数据填入 Citrix Virtual Desktop Handbook - Assess Workbook.xlsx 了。\nFlexCast 模型比较 Hosted Shared\nHosted VDI，又可以细分为\na) Pooled-Random/Streaming\nb) Pooled-Static\nc) Pooled/Streamed with Personal vDisk\nd) Dedicated\ne) Existing\nf) Psysical/Remote PC\nSteamed VHD\nLocal VM\nOn-Demand Apps\n下表是关于 FlexCast 整体技术的一个概览：\nFlexCast 模型选择 在 XenApp 和 XenDesktop 之间有很多技术上的区别，但是他们都是通过 HDX 来提供的最佳用户体验。他们的区别如下：\n六、 应用程序评估\n在用户分组完成之后，我们已经有了根据需求不同确定下来的不同的用户组，下一步就是向用户提供他们工作需要的应用程序。下面是建议的三部曲：\nRationalization 合理化\nBusiness Characteristics 业务特性\n兼容性\n七、 项目管理\nRoadmap\n项目团队\n下面的表格示例告诉我们在一个虚拟桌面项目中可以建议的业务角色和技术角色分类。虽然角色有很多种，但是很多角色的存在时间都很短，同时很多角色都由一个人同时完成。项目经理和 Citrix 架构师自然是贯穿整个项目的角色，其他就不一定了。\na) 业务角色\nb) 技术角色\n","date":"2013-04-09T02:19:37Z","permalink":"https://martinliu.cn/2013/04/09/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbb-p1/","title":"XenDesktop虚拟桌面精品书籍导读(part1)"},{"content":"[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 鸣谢：Michael Zhang 的经验分享，有需要的请收藏备用。 [/box]\n刚刚搞定了 POC 环境中一个很诡异的问题。把过程写出来以供大家参考。建议可以把这个设置放到 POC 的实施手册中。 刚开始做 POC 时，我们安装了 XP 的模板，并且安装了同版本的 XenTools，此时 XenCenter 面板上显示虚机的 IP 地址没有问题。但是跑了一段时间后发现，所有的虚机的 IP 地址都显示不出来了，并且 XenCenter 面板上显示 XenServer tools not installed，虚机的内存信息，Disk IO 等信息，都没有显示： 后来重装了模板，重新发布了虚机，一切就 OK 了，此时我认为是原先的模板有问题，所以导致了这个 issue。 但是后来跑了几天，某台虚机又出现了类似的症状，此时我意识到应该不是模板的问题了。然后我就检查了这台虚机的 Service，发现：\n这个 Service 就是 XenTool 的 Service，因为没有启动，所以导致了上述的问题。 但是当我用手工试图重启该 Service 的时候，系统报改 Service 启动时停止，没有给出任何原因。Windows Event Log 里也没看到任何报错。 后来上网查了下，原来是 Windows Event Log 的 Application 类的 log 满了以后，会导致该 Service 启动异常。 看了下 XP 的 Windows Event Log 的 Application 类日志的属性，默认只有 64K：\n我把上面的日志文件大小阀值改成了 1024K，清空 Application 类的 log，重启上面的 Service, 成功，问题解决。\n上述类似的问题我记得也有兄弟曾经遇到过，发邮件出来问过，当时怀疑是 XenServer 跟 VDA 的时间不同步造成，现在感觉也许跟这个原因有关。\n[box color=\u0026ldquo;gray\u0026rdquo; icon=\u0026ldquo;order-check\u0026rdquo;] 欢迎投稿，请发邮件到： liuzh66@gmail.com [/box]\n","date":"2013-04-07T10:27:38Z","permalink":"https://martinliu.cn/2013/04/07/xenserver-tools-not-installed/","title":"解决XenServer tools not installed"},{"content":"[button type=\u0026ldquo;big\u0026rdquo; icon=\u0026ldquo;sign-in\u0026rdquo; url=\u0026ldquo;http://i.youku.com/u/UMzU2OTI4MzY0/videos\u0026rdquo;]点击本按钮，直达优酷视频专辑[/button] [line]\n汽车行业解决方案 思杰制造行业解决方案 金融行业解决方案 呼叫中心场景 Citrix 桌面云解决方案 教育行业解决方案 思杰政府行业解决方案 医疗行业解决方案 营业厅场景解决方案 Citrix 集中运维监控解决方案 OA 解决方案 思杰虚拟化助力翠微中学教育信息化建设 思杰虚拟化为遍布全美的学校师生提供便 [line] [box color=\u0026ldquo;red\u0026rdquo;] 合作伙伴们必看视频，你们不得不懂这些内容，否则跟不上形势：) [/box]\nPoC 标准流程\n2013-03-29 14.02 Citrix MDM solution\n搞定虚拟环境下的 USB 设备\n自由灵活办公【Work Shifting】\n企业统一应用门户 【Unified Storefron\n高管移动办公　【Executive Mobility】\n企业云网络【Enterprise Cloud Network\n桌面虚拟化 【Desktop Virtualization\n云融合【Cloud Convergence 】\nBYOD 工作生活最潮方式\nCitrix Personal vDisk 技术讲座\nCitrix Remote PC 采用 TriScale 技术的 Citrix NetScaler 1\n为什么选择思杰？实现安全移动办公和云\nCitrix 桌面虚拟化之网络解决方案\nCitrix 桌面虚拟化 XenDesktop _FlexCast\nCitrix-VDI-in-a-Box For SMB Citrix CloudGateway Citrix Receiver\n粉笔画动画为您解释 Citrix XenApp 的工作\n演示思杰 TaaS（Tools as a Service）解释\n","date":"2013-04-07T06:06:23Z","permalink":"https://martinliu.cn/2013/04/07/e6809de69db0e8a18ce4b89ae8a7a3e586b3e696b9e6a188e8a786e9a291e694bee9878fe68ea8e88d90/","title":"思杰行业解决方案视频放量推荐"},{"content":"NetScaler Insight Center with HDX insight and Web Insight overcomes the limitations of traditional methods and technologies to fully address the application visibility challenges facing today’s enterprises. Featuring an approach that leverages NetScaler ADCs, Insight Center combines network-based instrumentation – that is both network and application-aware – with an efficient and powerful management system capable of transforming raw data into actionable information.\n在 Citrix TV 栏目搜索 NetScaler Insight ；查询更多的相关资源。\n简单的讲 NetScaler Insight 能做到的是使用业内的专业协议 AppFlow 来监控所有经过 NetScaler 设备的流量。它是一个虚机，能够接收来自多个 NetScaler 的监控数据，实际上在 NetScaler 上打开了 Insight 功能后，它会对 ICA 协议做必要的拆包和封包动作，这样就能够更加详细的看到用户会话的详细信息，能够实时的了解到用户的体验，从而为主动的问题解决和排错打下了好的基础。注意：这个动作只有 NetScaler 设备能做哦！其它厂商看不到 ICA 会话参数。它有两个模块：1)ICA HDX insight ; 2) Web insight；这两个模块能够基本上把所有过 NetScaler 设备的流量截获、分析和报表；未来能够和 XD/XA 的管理工具做直接集成。并且它也能够把分析数据发给其它第三方支持 AppFlow 分析的系统，例如 splunkd 等。\n其它相关资源： http://blogs.citrix.com/2013/03/19/netscaler-insight-center/\nhttp://blog.itvce.com/?p=3101\nhttp://blog.itvce.com/?p=3167\nhttp://blogs.citrix.com/2012/12/07/netscaler-insight-1-0-ga-unleashed/\nhttp://support.citrix.com/proddocs/topic/ni-netscaler-insight-01-map/ni-wrapper-con.html\n","date":"2013-03-28T10:56:04Z","permalink":"https://martinliu.cn/2013/03/28/netscaler-insight-center-e8999ae68b9fe6a18ce99da2e5928ce5ba94e794a8e79b91e68ea7e588a9e599a8/","title":"NetScaler Insight Center 虚拟桌面和应用监控利器"},{"content":"\n前面三四公里总是跑的太猛，最快到了 4：25；跑的速度不太匀。老实说这次是有点太野心了，想创造一万米 50 分钟的个人记录。但是后半程还是没法坚持下来；坚持不下来可能有这样几个原因所知：1）阳光强烈，太晒，太热了；2）后半程爬坡上升海拔的路程有一段。下次试着逆时针方向绕湖跑，让提高海拔的路程放到体力充足的前半程。\n","date":"2013-03-28T07:53:07Z","permalink":"https://martinliu.cn/2013/03/28/two-records-xuanhu-lake-10km/","title":"破两项个人记录"},{"content":"对于 XenApp5 的用户来说你至少需要知道下面两件事情：\nEOF 的时间是 2013-3-31\n关键补丁清单如下\n这意味着，你只能获得越来越有限的支持在这个版本；最好的办法是升级你的应用到 XenApp6.5 版本。如果实在要用，请起码打全了这些补丁。\nHotfix PSE450R07W2K3006 (http://support.citrix.com/article/CTX130483)\nHotfix PSE450R07W2K3027 (http://support.citrix.com/article/CTX131874)\nHotfix PSE450R07W2K3043 (http://support.citrix.com/article/CTX132765)\nLIMITED RELEASE - Hotfix PSE450R07W2K3003 (http://support.citrix.com/article/CTX130466)\nLIMITED RELEASE - Hotfix PSE450R07W2K3004 (http://support.citrix.com/article/CTX130497)\nLIMITED RELEASE - Hotfix PSE450R07W2K3009 (http://support.citrix.com/article/CTX130587)\nLIMITED RELEASE - Hotfix PSE450R07W2K3017 (http://support.citrix.com/article/CTX131022)\nLIMITED RELEASE - Hotfix PSE450R07W2K3029 (http://support.citrix.com/article/CTX132174)\nLIMITED RELEASE - Hotfix PSE450R07W2K3033 (http://support.citrix.com/article/CTX132196)\nLIMITED RELEASE - Hotfix PSE450R07W2K3034 (http://support.citrix.com/article/CTX132245)\nLIMITED RELEASE - Hotfix PSE450R07W2K3037 (http://support.citrix.com/article/CTX132403)\nLIMITED RELEASE - Hotfix PSE450R07W2K3038 (http://support.citrix.com/article/CTX132494)\nLIMITED RELEASE - Hotfix PSE450R07W2K3045 (http://support.citrix.com/article/CTX132809\nLIMITED RELEASE - Hotfix PSE450R07W2K3051 (http://support.citrix.com/article/CTX133221)\nLIMITED RELEASE - Hotfix PSE450R07W2K3052 (http://support.citrix.com/article/CTX133249)\nLIMITED RELEASE - Hotfix PSE450R07W2K3054 (http://support.citrix.com/article/CTX133421 )\nLIMITED RELEASE - Hotfix PSE450R07W2K3056 (http://support.citrix.com/article/CTX133679)\nLIMITED RELEASE - Hotfix PSE450R07W2K3057 (http://support.citrix.com/article/CTX133762\nLIMITED RELEASE - Hotfix PSE450R07W2K3058 (http://support.citrix.com/article/CTX133828)\nLIMITED RELEASE - Hotfix PSE450R07W2K3060 (http://support.citrix.com/article/CTX134027)\nLIMITED RELEASE - Hotfix PSE450R07W2K3062 (http://support.citrix.com/article/CTX134577)\nLIMITED RELEASE - Hotfix PSE450R07W2K3063 (http://support.citrix.com/article/CTX134799)\nLIMITED RELEASE - Hotfix PSE450R07W2K3064 (http://support.citrix.com/article/CTX134829)\nLIMITED RELEASE - Hotfix PSE450R07W2K3065 (http://support.citrix.com/article/CTX135883)\nLIMITED RELEASE - Hotfix PSE450R07W2K3067 (http://support.citrix.com/article/CTX135443)\nLIMITED RELEASE - Hotfix PSE450R07W2K3068 (http://support.citrix.com/article/CTX135887)\nLIMITED RELEASE - Hotfix PSE450R07W2K3069 (http://support.citrix.com/article/CTX135993)\nLIMITED RELEASE - Hotfix PSE450R07W2K3071 (http://support.citrix.com/article/CTX136531)\nLIMITED RELEASE - HDX MediaStream Hotfix HDXFlash110WX86007 (http://support.citrix.com/article/CTX135404)\nLIMITED RELEASE - Delivery Services Console 4.7.3 (http://support.citrix.com/article/CTX132683)\nCitrix 产品生命周期查询一览表：\nhttp://www.citrix.com/support/product-lifecycle/product-matrix.html\n","date":"2013-03-20T10:12:43Z","permalink":"https://martinliu.cn/2013/03/20/xenapp5e8a1a5e4b881e6b885e58d95/","title":"XenApp5补丁清单"},{"content":"[caption id=\u0026ldquo;attachment_52283\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;720\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/03/the_first_half_marathon.jpg) My first half marathon record[/caption]\n本周一，在南京出差，周二一大早，我 5 点就醒了，常识跑一次半马。这是第一次尝试跑两个小时的时间，第一次尝试跑半马的距离。其实前 10 公里还是可以，后十公里还是有点疲劳的，中途休息了四次，每次走大约 1 分分钟左右。很惊喜的看到大部分的路程都在配速 5 分左右，和我设定的五分二十秒目标配速很接近。本次试跑证明了，我身体的耐力跑半马还是可以。打算在半马的基础上提高成绩，争取能把半马跑好再说。下个月四月十四日在苏州的半马比赛很期待，比赛前抽空好好准备争取能轻松完成。跑完后，这几天没有发现身体任何不适，今天早晨跑 5 公里，发现加速比以前有力，似乎经过这次拉练后，身体的体能有所提高。最重要的是：我在没有伤痛的情况下即感受到了体育竞技的乐趣，又达到了强身健体的目的。\n","date":"2013-03-14T12:13:49Z","permalink":"https://martinliu.cn/2013/03/14/my-first-half-marathon/","title":"My first half marathon"},{"content":"[caption id=\u0026ldquo;attachment_52271\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/02/sales-ilt-se-asap-rev07.jpg) sales-ilt-se-asap-rev07[/caption]\n今天参加了 NetApp Accredited Storage Architect Professional Workshop。这个课程偏售前，讲的还是不错，一共 3 天，明天开始做 Lab，实验练习的环境就是在 ONTAP 操作系统中的各种命令；使用官方的模拟器可以很方便的搭建测试环境，模拟器下载地址：https://communities.netapp.com/docs/DOC-1034\n[caption id=\u0026ldquo;attachment_52269\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/02/con01-FilerView.jpg) NetApp 模拟器 Web 访问[/caption]\nNetApp University : http://www.netapp.com/us/services/university/ 更多免费课程还可以在这里注册得到。课程的质量还不错。\n[caption id=\u0026ldquo;attachment_52270\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/02/Introduction-to-NetApp-Products.jpg) NetApp 在线免费课程[/caption]\n","date":"2013-02-26T14:18:43Z","permalink":"https://martinliu.cn/2013/02/26/netappe68a80e69cafe5ada6e4b9a0/","title":"NetApp技术学习"},{"content":"[caption id=\u0026ldquo;attachment_52258\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;640\u0026rdquo;] mac-mini-2012-with-XenServer[/caption]\n今天尝试在 Mac Mini 上安装 XenServer，下面把经验共享一下。我遇到的问题有两个：\n网卡无法识别：使用默认安装盘安装，提示没有检测到网卡，安装无法继续\n网卡驱动植入失败：在按了 F9 加载驱动的时候，没有发现驱动程序，无法继续安装\n安装完毕之后，重启，屏幕上显示一个带问号的文件夹，一闪一闪无法正常启动 XenServer\n经过一番折腾，发现这些点主意一下，应该就没有问题。\n[caption id=\u0026ldquo;attachment_52255\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/02/boot.jpg) 启动 Macmini[/caption]\n在启动 Mac Mini 的时候，在“咚”的一声之前，就按住 ALT 键，否则没法出现上面的屏幕，我用的是 USB 盘启动，所以要选择右侧的图标。\n[caption id=\u0026ldquo;attachment_52256\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/02/boot2.jpg) 进入 menu.c32 菜单[/caption]\n我遵循前人的经验，乖乖到此来禁止 gpt；首先在这里要迅速输入 menu.c32，输入完了就过了，就必须重新关机，重启 mac mini。\n[caption id=\u0026ldquo;attachment_52257\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/02/boot3.jpg) 输入 disable-gpt 参数[/caption]\n进入这个屏幕了，要快速按 TAB 键，否则启动参数无法编辑，输入 disable-gpt 参数的机会就失去了。编辑启动参数的时候，把参数加载第二个\u0026mdash;（三个短横线）前即可，上图我为了拍照在参数之前加了很多空格，其实这个参数和前后要至少一个空格就够了。\n在进入安装的屏幕后，如果是 XenServer6.0.201 的源安装盘，还必须下载 tg3 的网卡驱动，并且用工具打入 iso 文件，这样安装的时候，就可以选择到加载网卡启动，否则 6.0.201 的安装盘即不自带此网卡驱动，也无法正常识别附加的驱动。网卡驱动下载地址为：http://support.citrix.com/article/CTX135328 要把加压后的 iso 文件，再次加压到对应的目录里才行，直接把解压后的几个文件放入目录，安装程序是无法识别到网卡驱动的。如果能正常识别的话，会出现选择框，让你选择 Broadcom tg3。如果是 XenServer6.1 的安装盘，就不需要折腾驱动了，原盘自带了 Broadcom tg3 网卡驱动。下面有两张截图，供必须要使用 XenServer 6.0.201 的人参考。\n[caption id=\u0026ldquo;attachment_52250\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/02/xenserver6.1.jpg) XenServer 6.0.201 with driver[/caption]\n[caption id=\u0026ldquo;attachment_52251\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;]](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2013/02/xs-repository-list.jpg) xs-repository-list 实例[/caption]\n即使你不是安装 XenServer6.0.201，也推荐使用 UltraISO 来把 iso 文件写入一个 USB 盘来安装，因为 Mac Mini 没有光驱，而且这样不用刻盘，更加环保一点。\n最后一个 Tips：这个可能是解决问题 3 的技巧，在安装的最后一个屏幕上，安装程序提示移除 Mac Mini 上的其他所有截至，然后点击回车完成安装。在这个屏幕上要识时务的把安装 U 盘从机器上拔除，然后点击回车来重启 Mac Mini。经过我的验证，拔出 U 盘后好像没有在遇到过闪烁文件夹的重启不了的问题。建议都使用自带 Broadcom tg3 网卡驱动的 6.1 来安装，否则 6.0.201 安装完成之后，一旦打了补丁，还需要下载 for 这个补丁的新版本的网卡驱动，在重新手工打上该驱动，否则网卡会起不起来。\n","date":"2013-02-21T09:24:38Z","permalink":"https://martinliu.cn/2013/02/21/tips-install-xenserver-on-mac-mini-6-1/","title":"TIPS install XenServer on Mac Mini 6.1 "},{"content":"http://hbtc2012.hadooper.cn/download.html\n","date":"2013-01-09T06:24:06Z","permalink":"https://martinliu.cn/2013/01/09/2012-hadoope4b88ee5a4a7e695b0e68daee68a80e69cafe5a4a7e4bc9appte4b88be8bdbd/","title":"2012 Hadoop与大数据技术大会PPT下载"},{"content":"运动总成绩 总距离 79.8 公里 总时长 9.5 小时 共燃烧 5516.4 大卡\n","date":"2012-12-26T14:38:42Z","permalink":"https://martinliu.cn/2012/12/26/e586ace7bb83e4b889e4b99d-e69992e69992e68891e4b889e591a8e79a84e68890e69e9c/","title":"冬练三九-晒晒我三周的成果"},{"content":"\nGetting Ready for Cloud Computing 2013\n[dc]看[/dc]到篇不错的文章，值得分享一下。在最近的三四年里面，厂商都忙着炒作概念，用似云非云的各种虚拟化来对付用户，实际上云计算并没有那么简单，我一直不敢给客户讲，也讲不好的东西就是：对于一个特定的用户，告诉它什么是云？他应该怎么怎么过渡到云？先从那里做起？大致的路径是怎么样的？一旦对应到具体的用户环境里面，以上每个用户的答案都是不同的，感觉没有十足实践经验的人，根本无法和用户达成共鸣和一致。这个和我以前做 ITSM/ITIL 完全不同，在那块领域里面，讲究的是管理的思路和理念，等你做了一些项目之后，你从项目中的总结和提炼，就成了你的炮弹，用在其它新用户身上，用不好，也用不错；管理的学问往往是殊途同归的。而云计算，目前国内真的还属于初级阶段，就像是在 2002 年左右的时候，我们给银行做 ITIL 做服务台一样，对无论是用户和厂商的人来说，还不夸张的说，都是雾里看花。\n[tab label=\u0026ldquo;云计算七大注意事项\u0026rdquo; first=\u0026ldquo;yes\u0026rdquo;]\n[list icon=\u0026ldquo;star\u0026rdquo;]\n检查和评估您的网络 : 如果数据中心不做网络架构的巨大调整，给云平台配置足够强大的带宽资源，上云计算，基本上就是让用户和运维人员都痛苦不堪，不会有啥好结果。 建立鼓励员工进谏的机制 : 识别、评估、选择和实施云计算方案的流程需要提前设计好。在每个阶段和过程里让最终用户、开发人员和管理层都充分的参与意见。 聚焦在立竿见影的运维痛点和功能差距上: 瞄准那些影响最终用户生产力和新上面的应用部署项目上。让云计算的高效和灵活等优势小试牛刀一下，从而验证需求点的准确性和方案的靠谱性。 先尝后买 : 云计算是最着急投胎的，没有必要大干快上，对于数据中心来说也是一个渐进的温和的改良的过程。选定一个足够小的范围，先尝后买，分区分配扩容，放大项目范围。 承载应用（App hosting）和 SaaS 应用不能划等号 : 这根本就是个误解，无须多说。 监控利用率和满意度 : 不管云做的大小，资源都要物尽其用，跟踪最终用户和领导大满意度，与同行用户横向比较数据，找出自己的所处位置和程度。实施反馈机制，让用户驱动云的需求和建设方向。 眼观六路，站足先机 : 市场风云莫测，业务模式层出不穷，这些都不断催熟这云方案。所以广泛关注，收集跟多信息，为云计算建立多个选项，多种选择总是好事。 [/list] [/tab]\n[tab label=\u0026ldquo;英文原文\u0026rdquo;]\nIf you’ve been holding back about moving to the ‘Cloud’, it is time to get onboard the Cloud Computing express.\nNot only has every major research firm published market forecasts indicating that Cloud services are growing exponentially, but we see multiplying customer success stories that clearly illustrate the immediate and measurable business benefits of moving to the Cloud.\nHere are some simple rules you should follow to help you move ahead in the coming year and successfully leverage today’s rapidly evolving Cloud alternatives:\n1. Check your networks: Adopting Cloud solutions doesn’t make sense if you don’t have sufficient bandwidth capabilities. Without adequate connectivity, accessing Cloud services will be like stepping back in time and only frustrate your end-users and executives.\n2. Establish policies that encourage employee input: Develop straightforward procedures for identifying, evaluating, selecting and implementing Cloud solutions. Your end-users, developers and executives are being exposed to Software-as-a-Service (SaaS) applications, Platform-as-a-Service (PaaS) solutions and Infrastructure-as-a-Service (IaaS) alternatives every day. Invite them to recommend those they like.\n3. Focus on your immediate pain-points and functional gaps: Don’t rip out existing applications that work and cost little to maintain. Instead, target those cumbersome old applications that get in the way of end-user productivity and new applications to fill immediate needs.\n4. Start small and try before you buy: One of the greatest advantages of today’s Cloud solutions is that they mitigate many of the risks associated with traditional, legacy applications. Rather than paying for a perpetual license upfront without having an opportunity to test how it will meet your needs, many of today’s Cloud solutions allow you to try them out before you subscribe to them. And, you can start with a small group of users, or a single department, before you roll out the solution across your organization.\n5. Recognize that application hosting doesn’t equal Software-as-a-Service (SaaS): There is a growing number of legacy, on-premise software vendors who are offering hosted versions of their applications on a subscription pricing basis and calling them “SaaS” solutions. Although these hosted applications alleviate some of the operational hassles and reduce the upfront cost associated with traditional software deployment, they still fall short of the fundamental benefits of true ‘multitenant’ SaaS solutions, such as ongoing enhancements and aggregated benchmarks. In addition, the legacy software vendors can’t scale their hosted services if their customers are using varying versions of the hosted application.\n6. Monitor utilization and measure satisfaction: Track how your end-users and executives are using the SaaS apps and other Cloud services. Be sure the utilization levels justify the current subscription fees to prevent overspending. Investigate how your utilization levels compare with other organizations by requesting benchmark information from SaaS/Cloud vendors. Implement feedback mechanisms to ensure satisfaction and generate new ideas. Use data to determine future service requirements.\n7. Stay informed to stay ahead: The Cloud marketplace is changing rapidly from a technological perspective and maturing quickly from a business model point of view. Keeping up on the latest developments may be a challenge, but is also essential to take full advantage of the increasingly powerful solutions being delivered via the Cloud. Maintain an ‘open door’ policy and utilize social networking tools to invite your end-users, executives and others to share information about new services and best practices. [/tab]\n","date":"2012-12-18T16:12:30Z","permalink":"https://martinliu.cn/2012/12/18/2013e5b9b4e79a84e4ba91e8aea1e7ae97e682a8e58786e5a487e5a5bde4ba86e4b988/","title":"2013年的云计算，您准备好了么？"},{"content":"http://www.datamation.com/open-source/top-10-things-ubuntu-is-doing-right.html\n","date":"2012-12-18T15:14:04Z","permalink":"https://martinliu.cn/2012/12/18/top-10-things-ubuntu-is-doing-right/","title":"Top 10 things Ubuntu is doing right"},{"content":"http://searchvirtualdesktop.techtarget.com/tip/Whats-new-in-Windows-8-VDI-licensing-Free-ride-for-Windows-RT?utm_medium=EM\u0026amp;asrc;=EM_ERU_19908957\u0026amp;utm;_campaign=20121212_ERU%20Transmission%20for%2012/12/2012%20%28UserUniverse:%20635116%29_myka-reports@techtarget.com\u0026amp;utm;_source=ERU\u0026amp;src;=5093920\n","date":"2012-12-13T15:28:33Z","permalink":"https://martinliu.cn/2012/12/13/whats-new-in-windows-8-vdi-licensing-free-ride-for-windows-rt/","title":"What's new in Windows 8 VDI licensing: Free ride for Windows RT"},{"content":"[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;52210,52209,52207,52208,52211,52199\u0026rdquo;]\n三亚住着全国各地来度假的人，有在这里旅游的，有在这里度假的，有在这里修养的。洲际酒店是我一直喜欢的酒店，这次赶巧有下榻于此；这里在鹿回头景区旁边，是一个探入大海的鹿头，酒店就坐落在鹿头的脖子部分，所有酒店的两侧都能看到大海，而左右被两座山包夹着。大海一天之中变化着不同的颜色，今天晴空万里，空气好的不得了！想起北京的 PM 值，我都不想回去了，精心准备的 ppt，希望再次打动用户。明天的两大目标：跑 5 公里；打动用户一个都不能少。\n查看大图\n","date":"2012-12-13T14:40:05Z","permalink":"https://martinliu.cn/2012/12/13/e4b889e4ba9ae58d8ae5b1b1e58d8ae5b29be6b4b2e99985e98592e5ba975e585ace9878c/","title":"三亚半山半岛洲际酒店5公里"},{"content":"今天在印度同事的帮助下，又解决掉我一个棘手的问题。这个哥们是个 developer，解决问题很给力。每当他帮忙找出一个原因后，我就感慨，为什么我没有想到？开发人员的思维方式和我们是不同的，他们能找到基础的基础，从哪里开始入手分析问题，往往我们都太聪明了，总是试图找捷径/替代方法/或者绕开问题。\n中国人谈到印度，往往有不屑的态度，可是我真的想不出能有什么理由这么想。看看我们现在如此浮华和虚荣腐败的国家，到处是利益驱动下的虚假繁荣，任凭胡主席和温总理在鞠躬尽瘁地视察民情和整治社会，社会还是依旧那样。环境还在被污染，食品还是一样有毒，物价还是一样的上涨，货币还是依旧的贬值，税赋还是依旧的增加，社保和服务还是不能够的到位，道路还是越来越堵，中石油茅台洋酒还是照样的喝，舆论依然的禁锢愚人，互联网还是那么的和谐\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\n回到印度的话题，我突然到一个问题：现在还有什么软件不是在印度开发的？但从我的公司看，它以平均每年收购两家公司的速度并购，十之八九的被收购的公司的研发工作被部分转移印度做。任凭国内的 developer 你们怎么的叫喊比印度人更聪明，我们的软件业还是照旧，既没有走出去多少，也没进来多少。大多数企业的终极目标也就是去美国上市。即使是国内在大的公司，也偶尔给我们上演一下 3Q 大战的闹剧。无疑印度的软件也在某种程度上是超越国内的。\n","date":"2011-05-10T16:34:59Z","permalink":"https://martinliu.cn/2011/05/10/india/","title":"印度"},{"content":"Remedy 应用的性能优化是一个在系统建设过程中需要长期关注的问题，而不是在上线的前一天晚上去解决的问题，我也碰到过很棘手的性能问题，它确实爆发了，而且恰好在上线前夕爆发；之后感觉除了点背之外，感觉比较遗憾的是：为啥这个性能问题不早点爆发！\n那么如何持续改进 Remedy 的性能？首先是硬件环境的准备情况，是否能在项目开始的第一天，就把开发，测试，生产环境统一装好。而不是到上线的前夕才去动生产环境。甚至于有条件的情况下，可不可以直接在生产环境上做开发，这样做的好处：让生产环境上性能优化的时间周期和机会尽可能的多，尽可能的长。当然这种机会毕竟不多，那么是否可以做到生产环境和开发环境的尽早的同步，也就是说：在开发到了一个小的阶段的时候，生产环境就可能就绪，就可以使用，这样把未成型的系统先部署上去，以便有机会做多次的生产系统性能调优。比较生产系统的性能最优化是项目的一大目标，不能等到最后才去仓促应战。曾经听说某行流程平台上线的第二天就挂了一次，这都是血淋淋的教训。总结一下：尽早的建设生产系统，优化生产系统，把开发好的那部分程序尽早迁移到生产上，长期的追逐系统性能，甚至于在生产环境上对此系统做压力测试。这些工作如果能够做的话，我想在上线日我们一定不会紧张。\n如何追逐测试系统的性能。可以使用 Web profiling 工具如 Fiddler。使用这种工具对某些特定操作持续的测试，把每次的测试结果保存下来，把时间记录到一个表格中。可以考虑测试如下内容：用户登录、打开事件控制台、创建一个事件单、搜索事件单等等，其他流程也类似。保证每次点击的次数都相同。其实从 Fildder 的分析数据中也可能得到很有价值的数据，如：那个 Web 调用的时间消耗最长，那些 Web 资源的请求出错。找出时间消耗做多的调用，就可以有针对性的优化应用了。总之：使用一种工具，在开发的整个过程中持续测试和优化，记录所有测试结果，这样在上线前对系统的性就能有客观参考依据。\n另外要注意 Remedy 系统是一个标准的 3 层架构应用，你需要在系统调优的时候，有这样几种人的帮助：压力测试工具高手、JVM 调优专家、数据库调优专家和 Remed 性能调优专家。还需要参考下列的参数配置。\nMid-tier 优化参数建议 关于 Mid-tier 的一点建议，目前普通使用的 Java 应用服务器都是 Tomcat，我一向是开源软件的粉丝，但是，还是建议如果有条件的话，还是上商业的产品，如 Weblogic 或者 Websphere。这样可以获得能多一点的支持。 鉴于大多数系统还都是用的 BMC 的产品自带的 Tomcat，下面是一些建议的参数配置。\n1-HTTP keep-alive Keep-alive count: infinite (minimum 5000) Connection timeout:90000 ms (minimum 60000 ms)\n2-JVM settings JVM heap：-Xms1024m –Xmx1024m MaxPermSize：-XX:MaxPermSize=256m 以 Windows 系统为例，可以使用 Tomcat 的配置界面工具，配置这两个参数。\n3-Threads configuration of the application server hosting the mid tier maxThreads：500 acceptCount：100\n关于 1 和 3 的 参数文件：tomcat dir/conf/sever.xml 的实例代码： [xml]\n\u0026lt;Connector URIEncoding=\u0026ldquo;UTF-8\u0026rdquo; acceptCount=\u0026ldquo;100\u0026rdquo; connectionTimeout=\u0026ldquo;90000\u0026rdquo;\nmaxHttpHeaderSize=\u0026ldquo;8192\u0026rdquo; maxKeepAliveRequests=\u0026quot;-1\u0026quot; maxThreads=\u0026ldquo;500\u0026rdquo;\nport=\u0026ldquo;80\u0026rdquo; protocol=\u0026ldquo;HTTP/1.1\u0026rdquo; redirectPort=\u0026ldquo;8443\u0026rdquo;/\u0026gt;\n[/xml]\n以上参数配置并不是万能的，只是给出一个优化配置的基础，以此为起点调起来可能会更靠谱。\nFine tuning the mid tier Mid tier parameter or service： Recommended value Enable Cache Persistence：Always on for a production environment Prefetch or preload service： Use prefetch only when a specific set of AR System forms are known. Otherwise, use preload (recommended). Recommended preload procedure： 1.Turn on Enable Cache Persistence. 2.Turn on preload. 3.Allow preload to finish preloading all user facing AR System forms. 4.Turn off preload (allowing statistical service to take over). **arsystem.formhtmljs_expiry_interval **和 arsystem.resource_expiry_interval： Set both parameters to the same value to reflect how often you want the browser to check with the mid tier for updates. In a deployment environment where the AR System applications are not modified, set to 604800 (1 week) or higher. The minimum recommended value is 86400 (1 day). For the new values to take effect, restart the mid tier. Definition Change Check Interval： In a deployment environment where the AR System applications are not modified, turn this off. Otherwise, map this to the frequency of your AR System application modification. For example, if you push changes out every Sunday, set this frequency to 604800 (1 week). arsystem.log_level： Severe. This can also be set through the Mid Tier Configuration Tool\nARS 优化参数建议 打开 ar.cfg 参考一下参数，修改后重启 ARS 服务。\nDelay-Recache-Time:300 ** Max-Entries-Per-Query:2000** ** Next-ID-Block-Size:100** ** Server-Side-Table-Chunk-Size:1000** ** Allow-Unqual-Queries:F** ** Cache-Mode:0** ** Debug-mode:0** ** Submitter-Mode:1** ** CMDB-Cache-Refresh-Interval:600**\n数据库优化参数建议 数据库方面一定要依靠有经验的 DBA，靠他们帮你搞定下面这两条： • Configuring your AR System database server for optimal performance • Diagnosing and resolving issues. 另外如果你是 Oracle11g 的数据库，可以自己动手搞定下面这一条： Oracle 10g/11g database settings are recommended: Cursor_sharing = FORCE 在数据库上做如下操作： [sql] alter system set cursor_sharing=FORCE scope=both; [/sql] 然后在 ar.cfg 里面加入这个参数。 Oracle-Cursor-Sharing: FORCE 然后重启 ARS 服务即可。\n以上参数配置部分参考了 BMC 的官方文档《BMC Remedy AR System Server 7.6 Performance Tuning for Business Service Management 199037.pdf》，感兴趣的话可以去官方站点的文档下载里下载，该文章对以上参数有详细的解释。\n","date":"2011-05-07T10:31:36Z","permalink":"https://martinliu.cn/2011/05/07/let-remedy-ars-fly-2/","title":"让Remedy飞一会"},{"content":"自从 Remedy ITSM 7.6.03 版本发布以后，Remedy ITSM 套件有了一种全新的安装方式“预配置堆栈式安装”，这种安装方法简化了以前从 ARS 开始一个部件罗一个部件的安装方法，它将 ITSM 套件中的所有组件一次性的安装上去。下面讲具体该如何操作。\n什么情况下使用这个安装方式？ A）POC 的情况下 B）客户的生产环境满足下面的需求： • Microsoft Windows Server 2008 (64-bit) (Standard, Enterprise, or Datacenter) with Microsoft SQL Server 2008 (64-bit) (Standard or Enterprise) • Oracle Solaris 10 with Oracle 11g (64-bit) (Standard, Enterprise, or RAC) • Red Hat Enterprise Linux 5 (Update 5) (64-bit) with Oracle 11g (64-bit) (Standard, Enterprise, or RAC) • Microsoft Windows Server 2008 (64-bit) (Standard, Enterprise, or Datacenter) with Oracle 11g (64-bit) (Standard or Enterprise) Note: The BMC Remedy ITSM Suite Precon gured Stack installer supports only Unicode database servers\n这种方式安装了什么组件？ BMC Remedy AR System server version 7.6.04 AREA LDAP Directory Service Authentication ARDBC LDAP Directory Service Data Access Web Services Plugin Simple Network Management Protocol (SNMP) Configuration Full Text Search (FTS) Configuration Approval Server Assignment Engine Email Engine Flashboards Mid-Tier BMC Remedy AR System clients BMC Remedy User BMC Remedy Alert BMC Remedy Developer Studio BMC Remedy Data Import BMC Remedy Migrator Crystal Reports ODBC BMC Atrium Core BMC Atrium CMDB version 7.6.04 Product Catalog version 7.6.04 Atrium Impact Simulator version 7.6.04 BMC Remedy ITSM Suite BMC Remedy Asset Management version 7.6.04 BMC Remedy Change Management version 7.6.04 BMC Remedy Incident Management version 7.6.04 BMC Remedy Problem Management version 7.6.04 BMC Remedy Service Desk 7.6.04 BMC Service Level Management version 7.6.04 BMC Remedy Knowledge Management version 7.6.0 如果你真的不需要安装以上所有组件，请不要使用此安装方法。\n需要什么硬件？ System requirements for Microsoft Windows and UNIX®: • Minimum 12 GB free disk space for the installation directory • Minimum 8 GB free space for local database and remote database • (For Red Hat Enterprise Linux® only) Minimum of 2.5 GB free space in the /tmp directory or /tmp file system. • (For Oracle® Solaris only) Minimum of 2.5 GB free space in the /var/tmp directory or the file system. • 3 GHz dual processor • Minimum 3 GB RAM during installation; 8 GB RAM during runtime; 8 GB main memory for optimal performance • (When 6 GB UNIX systems are used) Make sure that a minimum of 6 GB Swap Space is configured within the system. 如果您的硬件真的低于以上需要，请不要使用此安装方法，否则安装完之后系统可能不能正常运行。\n需要什么人参与？ 需要操作系统管理员和数据库管理员参与 以 Linux+Oracle 为例，可能需要如下环境变量 [bash] export ORACLE_BASE=/u01/app/oracle export ORACLE_SID=remedy export ORACLE_HOME=/u01/app/oracle/product/11.2.0/dbhome_1 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ORACLE_HOME/lib export NLS_LANG=en_US.UTF8 export LANG=en_US.utf8 export PATH=$PATH:$ORACLE_HOME/bin [/bash]\n需要什么安装文件？ 以 Linux+Oracle 的安装为例，需要如下文件：\nlinux.x64_11gR2_database_1of2.zip linux.x64_11gR2_database_2of2.zip jdk-6u25-ea-bin-b03-linux-amd64-27_feb_2011.bin BMCRemedyITSMSuitePreconfiguredStack7.6.04.Linux.tar.gz\n需要安装多长时间？ 大约 1.5 个小时左右，是的没有夸张，这个时间是在一个 DELL E6400（64 位，8GB 内存）的笔记本上测得的，如果你有更好的硬件，相信可以更快，这应该是史上最快的 Remedy ITSM 套件安装速度，如果你也成功通过此方式安装，请留下评论留下下你的安装时间和系统配置情况。\n参考以下操作步骤 安装之前需要根据网卡的 MAC 地址先申请一个 Lic，接着基本上都是点 Next，即可完成安装 [imagebrowser id=8]\n","date":"2011-05-04T15:59:42Z","permalink":"https://martinliu.cn/2011/05/04/remedy-itsm-7-6-04-quick-install-guide/","title":"Remedy ITSM 7.6.04 套件快速安装"},{"content":"很久以前我一直使用的 rpm based Linux，原因很简单，我只要手握一张最新的 DVD，就可以走遍天下都不怕，特别是对 SuSE Linux 的 yast 很依赖，因为它可以帮我解决 rpm 包之间的依赖性。这样工作起来就很简单，基本上是搜索到软件包之后，点击安装既可以搞定所有的软件安装工作。\n来到 Ubuntu 世界的我并不很满意，最近一次的 apt-get update，以失败告终，险些把家里的 PC 的一块硬盘给搞丢了，因为升级失败导致分区表失效了，Win 操作系统不认了。直接崩溃，好在那 Live Cd 模式进入还能勉强看得那个盘里的东西，恢复到移动硬盘，重新格式化该分区，才把文件恢复了。着实让我虚惊一场。\n我比较喜欢一些小的 LAMP 堆栈式安装的 Linux，如 TurnkeyLinux。安装可以在 10 分钟内搞定系统安装。今年家里的宽度升级到 2MB 了，因此带宽上逐渐能满足 Ubuntu 这种从网上升级的需求。下面就是找国内的升级的源了，进过几个月的使用，最近觉得在北京的联通固定宽带的用户，使用 163 的镜像站点速度还是不错的。再次感谢国内的这样的无私奉献的公司，使得在国内的开源用户可以更快更方便。废话说了一堆：）哈哈下面也就是这几条命了的事情。\n第一步，当然要选择近水楼台的 163 了，来参考http://mirrors.163.com/.help/ubuntu.html 的帮助文档，根据你操作系统的版本，更新/etc/apt/sources.list 文件即可，之后你的 Ubuntu 就是从国内的较快的站点上下载包了\n第二步，安装多线程 apt 下载加速工具 apt-fast\n[bash] root@lamp ~# apt-get install python-software-properties root@lamp ~# add-apt-repository ppa:tldm217/tahutek.net root@lamp ~# apt-get update root@lamp ~# apt-get install apt-fast root@lamp ~# apt-fast -v apt 0.7.25.3ubuntu9.3 for i386 compiled on Sep 9 2010 22:22:02 Supported modules: *Ver: Standard .deb *Pkg: Debian dpkg interface (Priority 30) S.L: \u0026lsquo;deb\u0026rsquo; Standard Debian binary tree S.L: \u0026lsquo;deb-src\u0026rsquo; Standard Debian source tree Idx: Debian Source Index Idx: Debian Package Index Idx: Debian Translation Index Idx: Debian dpkg status file [/bash]\n以后你在安装软件包就是用 apt-fast install 了，而不是 apt-get install，至于 apt-get 么，不管你用还是不用，它就在哪里~~~~ 最后一步（可选），如果你还经常要以 cpan 的方式安装 perl 的包的话，那么 163 上不管你用还是不用，他就在哪里，你也可以选择 163 最为 perl 的安装源。安装步骤如下：\n[bash] root@lamp perl/CPAN# pwd /etc/perl/CPAN root@lamp perl/CPAN# cp Config.pm Config.pm.bk root@lamp perl/CPAN# ls Config.pm Config.pm.bk Config.pm~ root@lamp perl/CPAN# vi Config.pm [/bash]\n修改 Config.pm 文件中的 urllist 值，修改成如下即可：\n1 \u0026#39;urllist\u0026#39; =\u0026gt; [q[http://mirrors.163.com/cpan/]], 接下来就可以测试一下了： [bash] root@lamp perl/CPAN# cpan -i XML::Entities [/bash]\n如果你有其他让 Ubuntu 加速的方法，请留言：）\n","date":"2011-04-10T11:11:27Z","permalink":"https://martinliu.cn/2011/04/10/let-ubuntu-fly/","title":"让Ubuntu飞一会儿"},{"content":"ARS 版本 7.6.04 数据库 Oracle11G 和 ARS 在同一台服务器上\n错误现象： ARS 服务不能正常启动\n1 2 3 4 5 arerror.log报 390600 : SQL 数据库不可用 -- 将重试连接 (ARNOTE 590) Sat Apr 02 20:27:41 2011 : Action Request System(R) 服务器 x64 版本 7.6.04 Build 002 201101141059 (c) Copyright 1991-2010 BMC Software, Inc. Sat Apr 02 20:29:51 2011 390600 : SQL 数据库不可用 -- 将重试连接 (ARNOTE 590) Sat Apr 02 20:29:51 2011 ORA-12170: TNS:Connect timeout occurred 排错步骤： 使用 sqlplus 测试登录，返回 TNS 超时错误\n1 2 3 4 5 6 7 [powershell] C:\\Users\\martin\u0026gt;sqlplus ARAdmin/AR#Admin#@ars SQL*Plus: Release 11.2.0.1.0 Production on Sat Apr 2 20:48:35 2011 Copyright (c) 1982, 2010, Oracle. All rights reserved. ERROR: ORA-12170: TNS:Connect timeout occurred [/powershell] 使用 tnsping ars 测试也不成功 ping 本机主机名\n1 2 3 4 5 6 7 8 9 10 11 12 [powershell] ping arsserver Pinging arsserver [fe80::c123:5921:b71b:64fd%13] with 32 bytes of data: Reply from fe80::c123:5921:b71b:64fd%13: time\u0026lt;1ms Reply from fe80::c123:5921:b71b:64fd%13: time\u0026lt;1ms Reply from fe80::c123:5921:b71b:64fd%13: time\u0026lt;1ms Reply from fe80::c123:5921:b71b:64fd%13: time\u0026lt;1ms Ping statistics for fe80::c123:5921:b71b:64fd%13: Packets: Sent = 4, Received = 4, Lost = 0 (0% loss), Approximate round trip times in milli-seconds: Minimum = 0ms, Maximum = 0ms, Average = 0ms [/powershell] 貌似找到原因，修改 host 文件，加入主机名到 127.0.0.1 后面，在测试 ping 主机名成功。 重启 Oracle 监听器服务，再次测试 tnsping 和 sqlplus ，测试都获得成功。 重新启动 ARS 服务，服务被正常启动\n","date":"2011-04-02T13:43:21Z","permalink":"https://martinliu.cn/2011/04/02/ars-start-issue-on-oracle/","title":"ARS启动故障修复案例"},{"content":"今天看到了我保存的一摞 Linux 光盘，这基本上也记录了我所关注和安装过的所有 Linux 的种类。品种繁多。如下：\nCentOS 4.4\nUbuntu 8.4 server\nUbuntu 8.4 desktop\nOpensolaris\nDebian 4.0\nSuSe Enterprise 10.1\nRedhat Enterprise Server 3\nSuSe Linux 10\nMandriva 2008\nCentOS 4.2\nSuSe 10.0 Eval DVD\nMandrake 10.0\nRedhat 7.1\nDerbain 3.0\nFreeBSD 5.2\nSuse 9\nSuSe enterprise linux 9.0\nFedora 4\nRedhat 9\nSolaris 10 x86\nUbuntu 10.10 Desktop\nSLES 10 sp2\n![CD fire](http://martinliu.cn/wp-content/gallery/fatureimage/thumbs/thumbs_Crstal (12).png)总共 50 多张碟片既有 CD 也有 DVD。Linux 这东西最大的特点是更新发展的快，之前硬盘都小，为了安装 Linux 刻盘是最方便的方式，而且多年以前机器还不支持 USB 启动。这么多光盘真的是一大堆的白色垃圾，一直在想废弃光盘该怎么处理的为题，目前好像还没有即能实现废物利用，有环保的处理方法。上周为了在家里的 PC 上安装 Ubuntu 10.10 Desktop，又刻了一张盘，希望这是最后一张 Linux CD，以后考虑 USB 启动安装 Linux 的形式。使用工具软件把 Linux ISO 文件灌注到 U 盘里，在用 U 盘来装。\n推荐两种工具：\nUniversal USB Installer LinuxLive USB Creator [](http://martinliu.cn/wp-content/gallery/fatureimage/Crstal (12).png)\n","date":"2011-03-24T13:12:58Z","permalink":"https://martinliu.cn/2011/03/24/usb-linux/","title":"既要开源，也要环保"},{"content":"Remedy ARS 是全球最大市场份额的产品，是为业内广泛接受的成熟产品套件；虽然他始终是私有的软件产品，但是围绕其周围，还是不断有新的开源工具出现。下面就介绍几种这样的软件。\nARInside is a free open-source utility to create a static html documentation of your AR-Server. If you need something to quickly browse through your workflow, ARInside might be worth a try. ARInside 3.0.2 has some new features, lots of bugfixes and other improvements. Just to name a few:\ndocumentation improvements 64-bit platform support experimental support for Solaris and AIX basic ARS 7.6.x support huge performance plus on big installations 这是一个 ARS 服务器扫描的工具，可以形成一个静态的文档，能够作为一个状态的参考极限，这样方便你对当前的服务器上的所有对象和工作流有个全面的了解。最大的好处是能够统计和技术，而且不用登陆 Dev Studio 了。一图胜千言，下面大家看后就明白它能做什么。\n看后还闲着干嘛，赶紧去下载使用吧。\n其他的关于 Remedy ARS 开源的项目我也在 sf.net 里面大致搜索了一下，下面是个简单的参考清单。\nRemedy Outlook Integration Updated 2006-09-08 The Remedy Integration for Outlook (ROI) synchronizes tickets from any Remedy AR System application to your Outlook task list or calendar.\nRemedy ARAPI PHP extension Updated 2009-07-19 Extension to PHP for integration to Remedy Action Request System. First release will be focused on reading and manipulating data. Later version will give access to arapi-application structure functions.\nJasper Reports data provider for Remedy Updated 2006-08-16 jaspars provides a Jasper Reports custom data source (JRDataSource) compatible with the Remedy AR System. See http://www.mypathworks.com/arslist/Public?id=8ae4b6940c259f32010c3707fbae01bf for more information and usage instructions.\nARSperl Updated 2008-05-06 ARSperl is an integration kit for Perl5 and Remedy ARSystem API. It provides a large subset of the functionality found in the ARS C API\nAR Cache Purge Updated 2009-05-27 AR Cache Purge automates the process of clearing BMC Remedy user cache on client machines. It first checks the registry for the Home folders(s) and then removes the .arf and .arv files. It handles multiple users and home folders on a single machine.\npyARS Updated 2010-12-20 The pyARS python module allows developers to use BMC\u0026rsquo;s ARSystem (Remedy ARS) and Atrium CMDB functions from within Python. Using Python\u0026rsquo;s interactive shell, it is extremely easy to retrieve and modify data entries as well as workflow objects.\nCOM Objects for the AR System Updated 2006-01-10 Coarse (COM Objects for the AR System), provides an automation compatible COM API to the AR System (Remedy only provides a C API and a Java API). It is compatible with VB6, VBA, VBScript, and JScript. Based on the RTL Sourceforge project.\n","date":"2011-03-01T15:46:51Z","permalink":"https://martinliu.cn/2011/03/01/remedy-ars-open-source-tool/","title":"Remedy ARS 开源工具知多少"},{"content":"培训针已获得 Foundation 认证的学员，讲授 ITIL V3 服务生命周期模块的五门中级课程， 包括服务战略、服务设计、服务转换、服务运营、持续服务改进。 课程介绍了服务生命周期各阶段的术语、流程、结构、角色、职能和活动，结合 ITIL 的最佳实践，帮助学员掌握如何提升用户的日常 IT 服务。 课程中还将结合 BMC 的 IT 管理领域领导者优势，向学员介绍 ITIL 的自动化解决方案、以及基于 ITIL 的云计算生命周期管理。帮助广大学员迅速走向管理云端。课程详情\n认证考试： 每门课程学时三天，并包含随堂认证考试。五门成绩均及格即可获得 5 个中级认证以及考取高级认证的资格。\n培训价格（含认证）： 单门课程 10000 元/人 五门课程优惠价格共 32000 元/人\n特别赠送：\n报名五门课程的学员，将获赠云计算网络培训一次。课程介绍 没有通过考试的学员，每门提供一次免费重考。 培训时间： 服务战略：3 月 21-23 日 服务设计：3 月 24-26 日 服务转换：4 月 11-13 日 服务运营：4 月 14-16 日 持续改进：5 月 18-20 日\n培训地点: BMC 上海培训教室（浦东花园石桥路 33 号花旗大厦） 咨询和报名:010-85183688-1883 yuan_yuan@bmc.com Yunlong_jin_cw@bmc.com\n","date":"2011-02-21T04:11:37Z","permalink":"https://martinliu.cn/2011/02/21/itil-v3-bmc-training/","title":"ITIL V3中级认证培训-服务生命周期模块"},{"content":"Why ARS system need full backup and restore 众所周知Remedy ARS上运行的所有程序代码都是在数据库中存储的，几乎所有的程序代码和相关数据都是存储在后端的数据库里的。基于这种特性，我们可以很方便地从数据库层面实现对 ARS 系统的备份和恢复。所谓基于数据库的备份和恢复就是指数据库的全库导入和导出。在这方面Oracle做的很好，他所提供的 imp 和 exp 命令行工具能很好的完成此项任务。 When you may backup BMC Remedy ARS system Database Remedy ARS系统数据库全备份可能会发生在下面的几个时间点：\n在安装过程中，Remedy ITSM套件的安装都是从 ARS 开始一个模块一个模块增加安装的，可以在安装每个新模块之前，做一个数据库备份，用于安装失败情况下的现场恢复 在系统上线前，当系统需要做升级/代码更新等等大规模操作之前可以考虑做一次数据库的导出备份 在做系统迁移的情况下，我们甚至可以生产库迁移到开发机上进行问题的重现，或者代码的修改，或者测试，完成之后再导回生产系统（如果生产系统再次期间处于维护状态的话） How-to 下面是我总结的相关操作步骤参考。\n备份ARSystem数据库 exp aradmin/ar#admin@itil file=c:\\before-patch7.dmp log=c:\\exp.log compress=n statistics=none\n参数解释： aradmin/ar#admin 是 ARS 系统默认的用户名和口令 @itil 是 ARSystem 数据库所在的数据库实例名 file=c:\\before-patch7.dmp log=c:\\exp.log 是导出的数据库文件和日志文件路径\n删除 ARAdmin 用户数据 drop user aradmin cascade;\n创建和授权 ARAdmin 用户 CREATE USER ARADMIN IDENTIFIED BY ar#admin# DEFAULT TABLESPACE ARSYSTEM TEMPORARY TABLESPACE ARTMPSPC PROFILE DEFAULT ACCOUNT UNLOCK;\nGRANT ARADMINROLE TO ARADMIN; ALTER USER ARADMIN DEFAULT ROLE ALL; ALTER USER ARADMIN QUOTA UNLIMITED ON ARSYSTEM;\n导入备份的数据文件 imp ARAdmin/AR#Admin@ars file=c:\\CMDB2010-12-13_13.dmp log=c:\\imp.log fromuser=ARAdmin touser=ARAdmin ignore=y\nCredit to：以上操作步骤由神州太岳工程师李成旗协助编写和测试.\n","date":"2011-02-14T15:05:27Z","permalink":"https://martinliu.cn/2011/02/14/backup-restore-remedy-ars-oracle-db/","title":"在Oracle上备份和恢复 Remedy ARS数据库"},{"content":"《服务建模: 原理与应用》以服务建模为主题，共分 4 部分：第 1 部分介绍了服务建模所需解决的问题，第 2 部分分析了实际应用中的服务建模框架，第 3 部分列举了使用服务建模的案例，第 4 部分则对《服务建模:原理与应用》的中心内容进行了总结，并提出了未来服务建模值得研究的一些领域。\nLearn how to use service modelling to streamline and optimize processes!\nInformation about customer needs, the technical composition of services, and service performance are fundamental to effective service management. Service modelling is a structured approach to utilizing this information to improve the way services are delivered. Consistent application of service modelling provides the automation of processes and timely access to information.\n[caption id=\u0026ldquo;attachment_50942\u0026rdquo; align=\u0026ldquo;alignleft\u0026rdquo; width=\u0026ldquo;201\u0026rdquo; caption=\u0026ldquo;Service Modelling: Principles and Applications \u0026ldquo;]](http://martinliu.cn/2011/02/book-service-modelling.html/couverture_oklwooarsolowb)[/caption]\nService Modelling presents a comprehensive, up-to-date overview of the topic, presented in the context both of business processes, and of requirements stemming from the need to manage network resources. Vilho Räisänen delivers a justification for service modelling, and explains state-of-the-art concepts, frameworks and standards in detail.\nService Modelling:\nProvides a complete and illustrated overview of state-of-the-art concepts for service modelling, covering requirements and frameworks. Includes industry initiatives, conceptual frameworks, and the work of standardisation bodies. Discusses different modelling approaches, and the positioning of modelling of services in service management and in the wider operational context. Sets the modelling framework in the context of business drivers and modelling paradigms. Illustrates principles with real-world use cases, providing both fixed Internet and mobile network examples. Relates concepts to the work of TeleManagement Forum, giving practical examples throughout. Service Modelling: Principles and Applications is an invaluable guide to service modelling for telecommunications and data communications professionals, including vendors, operators, consultants, training organizations, service and content providers, system architects and engineers for IP-based services. Educational organizations, advanced undergraduate and graduate students on telecommunications and networking courses will also find this text invaluable.\n本书的已经翻译为中文版本，本书中包含了针对电信行业的实例模型和介绍，图书内容介绍如下：\n《服务建模:原理与应用》主要内容简介：服务技术的发展，不仅彻底改变了人们原有的生活方式，更从本质上促进了当代社会经济发展方式的转变。《服务建模: 原理与应用》以服务建模为主题，共分 4 部分：第 1 部分介绍了服务建模所需解决的问题，第 2 部分分析了实际应用中的服务建模框架，第 3 部分列举了使用服务建模的案例，第 4 部分则对《服务建模:原理与应用》的中心内容进行了总结，并提出了未来服务建模值得研究的一些领域。 《服务建模:原理与应用》可作为高校信息技术、管理和经济类相关学科电子服务方向的教学用书。也可以作为现代服务企业进行服务建模方面研究的工具书或参考书。\n","date":"2011-02-12T01:17:17Z","permalink":"https://martinliu.cn/2011/02/12/book-service-modelling/","title":"图书推荐《服务建模：原理与应用》"},{"content":"刚才终于把 ARS 装上了。费了我两天的力气终于搞定了。错误其实很简单的，现象很多人都见过，ARS 在安装完所有的文件后，在系统中建完 ARS 的服务以后，会继续启动服务，才能做最后的程序文件导入的相关操作。\n错误的现象是：在启动服务的时，安装程序一直停止在“Starting Remedy ARS services\u0026hellip;.”的屏幕，去 arerror 日志里面可以看到无法连接到 SQL 数据库的错误。\n我的安装错误的原因其实很简单：\n如果是 64 为的 Windows 操作系统，默认的安装路径是 C:\\Program Files (x86)\\目录\nOracle 客户端没有正确的安装\n解决的方法如下：\n修改 ars 默认的安装路径，尽量把它放在一个较短的而且没有特殊字符的路径里，如 D:\\bmc\\\nARS 7.5 sp6 支持的 Oracle 客户端是 32 位的，如果你在 64 位 OS 上安装的是 64 位的 Oracle 数据+客户端（sqlplus），那么默认的这个 64 为的客户端是不能用的，需要安装一个 62 位的客户端，而且需要时 10g 的，此版本也不支持 11g 的客户端；另外在安装 32 位的 oracle 客户端的时候最好也不要在路径中有特殊字符如符号和下划线之类的\nARS7.5 本身是 32 位的可支持程序，所以它所需要的 JDK 和 Oracle 都需要是 32 位的版本。如果你安装的是 7.6.04，就不需要考虑 32 位的问题，由于它本身就是 64 位的程序了，所以 JDK 和 Oracle 都需要使用相应的 64 为的程序。\n","date":"2011-02-10T17:12:30Z","permalink":"https://martinliu.cn/2011/02/10/64-windows-ars-75-install-tips/","title":"在64位Windows上安装ARS7.5"},{"content":"在不同的 CMDB 服务器之间做数据迁移之前一定要注意两点：1）保持两边的 CDM 相同；2）先导入 CI 数据在导入 CI 相关的关系数据。另外就是每个类导入完毕之后要做数据完整性和正确性的抽检。以下使用的工具是 cmdbdriver，该命令初始化和一般性的参数介绍请参考相关文档。\nCI 数据导出示例\nCommand: xexpdt XEXPORT DATA Export instance data from all classes? (F): Classes to export data from: Class and its subclasses, From namespace (1,2) (1): Namespace (): BMC.CORE Class name (): BMC_ComputerSystem Dataset ID (): BMC.ASSET Filename for exported data: C:\\DEMO\\cs-ci Exporting Class BMC_ComputerSystem i=0: namespaceName = BMC.CORE, className = BMC_ComputerSystemExported without errorsExporting Class BMC_MainframeExporti ng Class BMC_PrinterExporting Class BMC_StorageSubsystem CMDBExportData results ReturnCode: OK Status List : 0 items\n到相应目录下面找到导出的文件，导出的结果至少是两个文件一个是 META_FILE 其他的才是 CI 数据文件。\n关系数据导出示例\nCommand: xexpdt XEXPORT DATA Export instance data from all classes? (F): Classes to export data from: Class and its subclasses, From namespace (1,2) (1): Namespace (): BMC.CORE Class name (): BMC_Dependency Dataset ID (): BMC.ASSET Filename for exported data: C:\\DEMO\\REL-DEP.XML Exporting Class BMC_Dependency i=0: namespaceName = BMC.CORE, className = BMC_DependencyExported without errorsExporting Class BMC_AccountOnSystemExpor ting Class BMC_HostedAccessPointExporting Class BMC_HostedServiceExporting Class BMC_InventoryBulkItemsExporting Class B MC_InventoryComputerSystemsExporting Class BMC_InventoryEquipmentExporting Class BMC_InventorySystemComponents CMDBExportData results ReturnCode: OK Status List : 0 items\n到相应目录下面找到导出的文件，导出的结果至少是两个文件一个是 META_FILE 其他的才是 CI 数据文件。\n导入数据示例\nCommand: impdt IMPORT INSTANCE DATA Handle duplicate Instance Ids: (Error/New ID for Dup/Merge/New ID for All) (1-4) (1): 3 Filename containing import data: c:\\demo\\cs-ci_0_0 (导入包含 CI 数据的文件)\nCMDBImportData results ReturnCode: OK Status List : 0 items Total items Processed : 2 Items Imported successfully : 2 Items for which Import failed : 0\nCommand: impdt IMPORT INSTANCE DATA Handle duplicate Instance Ids: (Error/New ID for Dup/Merge/New ID for All) (1-4) (1): 3 Filename containing import data: c:\\demo\\REL-DEP.XML_0_0 (导入包含关系数据的文件)\nCMDBImportData results ReturnCode: OK Status List : 0 items Total items Processed : 1 Items Imported successfully : 1 Items for which Import failed : 0\n导入完毕之后使用 Remedy User 到相应的表格中查找，确认导入的数据是否正确。\n","date":"2011-01-12T05:08:23Z","permalink":"https://martinliu.cn/2011/01/12/bmc-atrium-cmdb-ci/","title":"BMC Atrium CMDB CI数据迁移"},{"content":"当对 CDM 做了定制，并且要在不同的服务器直接做类的迁移的时候，需要把定制过的类都导出，然后在目标机上导入。可以使用的 CMDB 自带的命令行 cmdbdriver 工具。\ncmdbdriver.exe 能支持的参数\nOptions: -u -a -p -l -s -x\u0026lt;INPUTFILE_FULLPATH\u0026gt; -t\u0026lt;PORT_NUMBER\u0026gt; -q\u0026lt;QUIET_MODE_NUMBER\u0026gt;\n登录 CMDBdriver 实例： cmdbdriver -u Demo -p bmc@XXX -s atriumcmdb -t 9988\n登录之后在运行另外用于初始化的两个命令 init 和 log\nCommand: init INITIALIZATION\nCMDBInitialization results ReturnCode: OK Status List : 0 items\nCommand: log Control record: Authentication string () : User name () : Demo Password () : ** Locale[.charSet] () : TimeZone () : Server () : atriumcmdb\n导出类定义的方法实例 Command: xexpdf XEXPORT DEFINITION Export all classes? (F): Classes to export: Class and its subclasses, From namespace (1,2) (1): Namespace (): BMC.CORE Class name (): BMC_ComputerSystem Export all attributes with classes? (T): Filename for exported data: c:\\demo\\BMC_ComputerSystem.xml\nCMDBXExportDef results ReturnCode: OK Status List : 0 items\n使用文本编辑器查看 c:\\demo\\BMC_ComputerSystem.xml 的导出结果\n导入类定义的方法： Command: impdf DEFINITION IMPORT Import Item List: Number of import items (0): Import option : Create/Overwrite (1-2) (1): 2 Filename containing import data: c:\\demo\\cs.xml\nCMDBImportDef results ReturnCode: OK Status List : 0 items\n使用 Remedy User，用 Demo 登录，把语言切换到英文，然后在查 BMC_ComputerSystem 表达，在 custom 2 ～ n 的 tab 页面里面查看哪些导入的属性。或者使用 class manager 查看确认导入是否成功。\n","date":"2011-01-12T04:22:44Z","permalink":"https://martinliu.cn/2011/01/12/bmc-atrium-cmdb-sync-cdm-class/","title":"BMC Atrium CMDB 类定义迁移"},{"content":"Fiddler is a Web Debugging Proxy which logs all HTTP(S) traffic between your computer and the Internet. Fiddler allows you to inspect all HTTP(S) traffic, set breakpoints, and \u0026ldquo;fiddle\u0026rdquo; with incoming or outgoing data. Fiddler includes a powerful event-based scripting subsystem, and can be extended using any .NET language.Fiddler is freeware and can debug traffic from virtually any application, including Internet Explorer, Mozilla Firefox, Opera, and thousands more.\nClientConnected- Exact time that the client browser made a TCP/IP connection to Fiddler. ClientBeginRequest– Time at which this HTTP request began. May be much later than ClientConnected due to client connection reuse. ClientDoneRequest - Exact time that the client browser finished sending the HTTP request to Fiddler. DNSTime - # milliseconds Fiddler spent in DNS looking up the server\u0026rsquo;s IP address. GatewayDeterminationTime - # milliseconds Fiddler spent determining the upstream gateway proxy to use (e.g. processing autoproxy script). Mutually exclusive to DNSTime. TCPConnectTime - # milliseconds Fiddler spent TCP/IP connecting to that server\u0026rsquo;s IP address. HTTPSHandshakeTime – Amount of time spent in HTTPS handshake ServerConnected – Time at which this connection to the server was made. May be much earlier than ClientConnected due to server connection reuse. FiddlerBeginRequest – The time at which Fiddler began sending the HTTP request to the server. ServerGotRequest - Exact time that Fiddler finished (re)sending the HTTP request to the server. ServerBeginResponse - Exact time that Fiddler got the first bytes of the server\u0026rsquo;s HTTP response. ServerDoneResponse - Exact time that Fiddler got the last bytes of the server\u0026rsquo;s HTTP response. ClientBeginResponse - Exact time that Fiddler began transmitting the HTTP response to the client browser. ClientDoneResponse- Exact time that Fiddler finished transmitting the HTTP response to the client browser. Can i find out how long the server needs to process my request ? (ServerBeginResponse - ServerGotRequest) is probably what you want.\nCan i find out how long the request needs to pass through the network? I\u0026rsquo;m not sure that\u0026rsquo;s what you really want to know, but it would be:\n(ServerGotRequest - ClientDoneRequest) - (DNSTime + TCPConnectTime)\n","date":"2010-12-22T07:28:45Z","permalink":"https://martinliu.cn/2010/12/22/fiddler-timers/","title":"Fiddler Timers "},{"content":"为了定义和控制服务和基础设施组件。维持当前计划中、历史的服务和基础设施状况配置信息的准确性 **一、先介绍几个基本概念 **1、配置项（CI） 配置项是正在或将要在配置管理控制下的资产、服务组件或其他。配置项在复杂性、大小、种类有很大不同，从整个服务或系统包括硬件、软件、文档、支持人员到单独软件模块或硬件组件。配置项可以集中或分组管理。配置项可以选择使用既定的选择标准、分组、分类和识别方式在整个生命周期中管理和追溯。其包括： A) 服务 CI 项：服务能力资产、服务资源资产、服务模式、服务包、发布包、验收标准等 B) 组织 CI 项 C) 内部 CI 项 D) 外部 CI 项：包括外部客户需求和协议、供应商发布、分包商及对外服务。 E) 接口 CI 项：端到端的服务，跨越服务提供者的接口 2、配置管理系统（CMS） 为了管理大型复杂的 IT 服务和基础设施，资产和配置管理需要使用配置管理系统 CMS。在指定范围内 CMS 掌握着所有配置项信息。CMS 为所有服务组件与相关事故、问题、已知错误、变更发布、文档、公司数据、供应商、客户信息做关联。 在数据层面 CMS 能使数据库存在多个物理 CMDB 中而后共同组成一个联合的 CMDB。其他数据来源也可以加入 CMS 中。 3、配置管理数据库(CMDB) 所有配置项的信息都包括在配置管理数据库(CMDB)中。配置管理数据库(CMDB)对所有 IT 组件、组件的不同版本和状态以及组件之间的相互关系进行跟踪。在其最基本的形式下，配置管理数据库(CMDB)可能仅由一些纸质表格或一套电子表格 (Spreadsheets)组成。 4、最终介质库(DML) DML 是用来存储和保护所有已授权的被确认版本介质配置项。 他们存储经过质检的主拷贝版本。这个库可以有一个或多个软件库或存放区来存放开发、测试和实时存储文件。他们包含组织所有软件的主拷贝、购买软件的副本及 受控文件的电子版。DML 包含物理的拷贝存储，DML 是发布管理的基础。\n**二、配置管理的目的： ** 1. 确定、控制、记录、报告、审计、验证服务资产和配置项包括版本、基线、组成成分、属性和相关关系。 2.通过服务生命周期管理保护资产完整、配置项等账户。确保只有已授权的组件被使用和已授权变更被执行。 3.通过服务生命周期保护服务资产、配置项的完整性。为了建立和维持一个准确和完整的配置管理系统，确保资产和控制服务、IT 基础设施的配置需求的完整性。\n三、资产、配置管理的活动\n1、规划 2、识别 配置项识别过程： A) 定义和制定标准文件来选择配置项和他们的组件构成 B) 依据标准选择配置项及其组件并记录他们 C) 给配置项分配唯一的标识符 D) 指定每个配置项相关属性 E) 确认每个配置项是受配置项管理来管理 F) 确定每个配置项的责任人 3、控制 必须有效控制信息以维持配置管理数据库(CMDB)的及时更新。一旦某项活动改变了配置项已记录的特征或配置项之间的关系，则必须在配置管理数据库 (CMDB)中记录该项变动。需注意的是：只有变更管理才有权批准对配置项的特征进行变动，事件管理只能改变某个现有的配置项的状态来反映现实状况。 配置管理负责控制组织接收到的所有 IT 组件并需确保这些组件被记录在系统中。硬件可在其已订购或已交付时进行记录，而软件则通常在其被纳入 DML 时进行记录。 4、记录 组件的生命周期可被划分成多个阶段，每个阶段都可以分配一个状态代码，但具体分成几个阶段则取决于公希望记录 IT 基础设施的哪些特征。保持对每次状态变化日期的记录可以提供关于一个产品的生命周期的有用信息，如订购时间、安装时间以及所需的维护和支持。组件的状态决 定了可以对其进行操作的余地。 5、审核和报告 执行审计是为了核实配置管理数据库(CMDB)中记录的信息是否仍然反映了当前的现实状况。这些信息可用来检查和更新配置管理数据库(CMDB)。 在下列情形下需要执行审计： A) 在建立了新的配置管理数据库(CMDB)之后； B) 建立配置管理数据库(CMDB)一段时间之后； C) 重大变更之前或之后； D) 灾难恢复之后； E) 其他任何方便的时候。 审计也可以随机地或在配置经理认为配置管理数据库(CMDB)中的信息不正确时进行。如果配置管理系统与审计工具之间存在关联，则可以每天生成针对某个相 关领域的审计报告。在发现差异时，不应该允许审计工具自动更新配置管理数据库(CMDB)。所有的差异都表明变更管理流程可能被忽视了，所以应该对这些差 异进行调查并通过变更管理对这些差异进行追溯性处理。 三、配置管理管理报告 配置管理流程的管理报告可能包括下列信息： a) 有关流程质量的信息； b) 在审计中发现的记录与实际情形不符的次数； c) 发现未经批准的配置的次数； d) 出现已记录的配置不能被找到情形的次数； e) 审计中发现的有关配置项属性详细程度方面的差异； f) 处理信息记录请求所需的时间； g) 超过给定事件或变更次数的配置项的列表； h) 有关 IT 基础设施的结构和组成的统计信息； i) 有关 IT 基础设施发展情况及其他方面的信息； j) 有关改进措施的总结、报告和建议，例如，针对由于业务、技术、市场价格和其他相关变化所导致的配置管理追踪记录的配置项的范围和详细程度的变更所提出建议； k) 有关实施流程所耗费的人力成本的清单。\n四、配置管理的绩效指标指标 a) 闲置许可数量; b) CMDB 错误导致变更失败的数量; c) 未授权配置数量; d) 配置项文档错误导致变更失败所引起的事故数量; e) 因为 CMDB 错误导致违反 SLA 的数量; f) 无相应配置项刷新的变更请求数量; g) 不精确配置项百分比; h) 客户满意度 ;\n五、与其他流程的关系\n转帖学习一下。\nFrom http://blog.amteam.org/standard/A1159174.html\n","date":"2010-12-20T03:01:40Z","permalink":"https://martinliu.cn/2010/12/20/itil-v3-asset-configuration/","title":"[ZT]ITIL V3 服务转换篇 之 资产和配置管理"},{"content":"\n最近听说有些公司的 IT 部门已经发文，要求公司员工所使用的电脑必须尽快安装 360 软件。嗯，这还真是一个法子，值得推广哈哈哈\n","date":"2010-11-06T09:59:01Z","permalink":"https://martinliu.cn/2010/11/06/qq-v-360/","title":"如何阻止员工上班时间聊QQ的免费解决方案"},{"content":"经过几天的奋战，我们终于在中秋月圆之夜，在黑山扈的百望山脚下为客户成功地安装了 Remedy ITSM 7.6.03 每当安装程序一次次挂死、安装程序界面不正常显示、安装不完全、安装失败，都让在场的人达到抓狂的后期，无语~~ 这里总结一下这几天的失败安装的血泪史，供后来人参考学习。\n版本的确认：所有操作系统，JVM，JDK，数据库，数据库客户端，和以上软件的位数都需要查明，都需要在 Remedy 的兼容文档中一一确认。\nAIX 操作系统的字符集：需要同时安装中英文的 UTF8 字符集。安装方法 smitty，需要有操作系统的安装盘，安装完成之后，locale -a ，需要能看到 ZH_CN, ZH_CN.UTF-8,EN_US, EN_US.UTF-8 这四种字符集缺一不可。否则无法以中文方式安装成功，也无法让操作系统已中文 utf8 来启动 AR 服务。\nXManager 需要安装在于 AR 同一网段的 Windows 服务器上，例如 Mid-tier 可能安装在 Windows 上，并与 AR 在同以网段，那么安装程序最好在该服务器的 Xmanager 的客户端中安装，从哪里连接 AIX 服务器并运行安装程序。如果不在同一个网段，安装程序很有可能安装了一半或者无名的消失，安装进程会立刻中断，需要把系统推到重来。\nAIX 系统上 font server 的安装：使用 netstat -na|grep 7100， 如果没有结果则需要从 AIX 的光盘中在 AIX 的服务器上安装 font server 和相关的包，并且启动它。如果不装的话，remedy 安装程序可能界面显示不正常，或者不显示。\nOracle 上众多僵尸进程：如果在安装 CMDB 或者 ITSM 套件的时候，安装界面挂死或者消失，这会是 Oracle 服务器上产生上百个僵尸进程，这些进程会吃光 Oracle 服务器的所有物理内存。我们的 oracle 服务器的 16GB 内存被吃光之后，ITSM 安装界面几乎停止，20~30 分钟才能安装完一个定义文件。解决方法是：随时监控 Oracle 服务器的内存使用情况，当出现内存被僵尸进程吃光的情况，可以考虑使用 IT 行里无人不知的无敌重启方案，重启 Oracle 服务器的操作系统，从启动 Oracle 数据库实例，重启 ARS 服务，然后再次安装 Remedy ITSM。\nRemedy 安装之备份：如果是在 AIX+Oracle 的数据库上安装。Remedy 还是非常绿色的软件，需要在安装完 AR，CMDB，ITSM 套件后各做一个 Remedy 安装文件目录的备份，在 AIX 上可以把这个文件夹 tar 起来备用。Oracle 数据库还是非常容易备份的，使用 imp 和 exp 命了就可以搞定，具体语句咨询 DBA。切忌在安装 CMDB 和 ITSM 之前一定要对 Remedy 系统的安装文件和数据库做备份，一旦安装失败，可以恢复文件，恢复数据库，排错后重新再来。\n","date":"2010-09-22T13:51:14Z","permalink":"https://martinliu.cn/2010/09/22/install-remedy-ars-itsm-on-aix-oracle/","title":"八月十五月儿圆，我和兄弟们装AR"},{"content":"随着云计算和虚拟化的来临，IT 架构愈加复杂，老一套的 IT 管理方案只能监控静态的基础架构。老一套的 CMDB 和 BSM 给运维无法带来实质性的帮助，需要能够具有自适应、自学习 IT 环境的能力，管理工具需要对 IT 环境的变化有感知，有学习功能，否则无法对业务故障的处理给予应有的支持。转帖自学一下这个文章，老外从 IT 架构的历史讲起，横跨跨服务保证和 CMDB 等领域，讲的还是很不错的。 The Significance of the VMware Integrien Acquisition While it may seem that with Integrien VMware has acquired yet one more piece of the puzzle (a puzzle whose final form no one knows), this acquisition is perhaps one of the most significant if not the most significant that VMware has done. To understand the significance of this acquisition, one has to step back and examine a bit of history in the Systems Management business.\nFor as long as there have been computers, operating systems and business critical applications, there has been monitoring of these items to make sure they were working (available) and performing well for their constituents. In the early days of the computer industry (through about 1982) computer systems were vertical monoliths where a customer would buy “an accounting system” and that purchase would include hardware, systems software, and applications software. All of this usually came from one vendor so there was one throat to choke when it did not work.\nStarting with the delivery of the PC, then Ethernet LAN’s and Novel Netware, and finally Windows Servers and the Internet, the industry reorganized along horizontal dimensions. A computer system was now a multi-layer cake and you could buy each cake from one of many vendors whose products were largely interchangeable with each other, and compatible with adjacent layers. So you could buy an Intel based server from one of N vendors, put either Linux or Windows on it, but a Java applications server from one of N vendors on that and then buy applications from thousands of different vendors.\nThis horizontal layering of the industry was heavily promoted by Microsoft and Intel (who “owned” two key layers of the cake), and also ushered in the tremendous innovation and price competition that continues to drive our industry today. Moore’s Law says that microprocessor performance doubles roughly every 18 months or so, and with those increases in price/performance come the more for less mentality that we have all become accustomed to.\nWith this freedom of choice at every layer of the cake however came problems. The first problem was complexity. There were now too many cooks in the kitchen which meant that there were both too many and not one single throat for the CIO to choke when something went wrong. The management software industry reacted to this by inventing a marketecture, Business Service Management (BSM). The idea behind BSM was to identify the key business services that applications or combinations of applications delivered to users (the ability to enter and order and ship the resulting product is a business service as is the ability of a consumer to transfer funds from one banking account to another), and to then map all of the software and hardware infrastructure that this business service depended upon and to manage that collection of linked resources as an entity.\nWhile Business Service Management sounded like a great idea, it in fact ended up as a miserable failure. The reasons were:\nThere were many applications for which it was just too hard to measure their performance (in response time terms). Web applications turned out to be pretty easy, but fat client Win32 applications written to proprietary client/server protocols turned out to be very hard. It turned out that for most enterprises, more than half of the business critical applications were in the hard pile (fat client/Win32) and less than half were the easy web applications. Many BSM frameworks relied upon scripts and synthetic transactions to measure response time and end user experience. However this approach failed for many enterprises due to the large number of applications that comprised a business service and how rapidly these applications were changing. For example if synthetic transactions were used to measure the performance of a set of transactions, and a company had 500 business critical applications (not a very high number – some companies have thousands), and each application was updated once a year, then that would translate into 10 updates a week for the monitoring scripts. The same is true for most passive monitoring approaches that rely upon templates to identify transactions in applications protocols. There are many products that can measure the response time of transactions from the perspective of the web server by attaching physical or virtual appliance to a span port on the switch that services the web server. However all such products require configuration to understand what set of granular http request/responses combine to create a transaction of interest. Maintaining these configurations across hundreds of applications and thousands of transactions proved to be a major impediment to instrumenting their service level in any kind of a broad and systematic manner. It turned out to be a nightmare to identify the hardware and software that supported each business service. This gave rise to the need for Configuration Management Databases (CMDB’s) that were supposed to get populated with the hardware and software assets and their relationships to each other. The effort to put in place a CMDB and to maintain it turned out to doom the CMDB projects and the associated BSM projects at many companies. The BSM vendors were unable to evolve their products at the same rate as the innovation of the vendors who contributed products to the layers in the cake. New devices (laptops that were not always connected), new protocols (ICA, VOIP), new operating systems (Linux), new languages (Java, C#), and new user interfaces (first the browser and then rich Internet applications) all occurred at a pace that no one vendor could keep up with. When the BSM vendors got overwhelmed by innovation, vendors of point monitoring solutions stepped in to monitor the newest layer or item in a layer. This lead to a proliferation of monitoring tools which were not integrated with each other. When a problem occurred even if one had a BSM product and a CMDB it still horribly difficult to know exactly what path the failed transaction took through the entire hardware and software infrastructure. The BSM tools were rarely aware of every element of the stack and the tactical monitors that had been bought to fill in the cracks were not integrated with the BSM tools nor each other. In summary we entered the age of virtualization and the cloud with both BSM and their supporting CMDB’s having failed at monitoring and managing a static infrastructure where applications and services largely stayed on dedicated hardware. In other words, before virtualization and the dynamic data center it was impossible for anyone in IT to see a problem and get told in a deterministic manner exactly where the problem was and how to fix it.\nThe Impact of Virtualization and the Cloud\nSince holistic end-to-end monitoring of business services was essentially broken (or not attainable) before virtualization, it is reasonable to assume that virtualization and the cloud will only make this problem worse. This will occur for the following reasons:\nVirtualization increases workload density and the dynamic operation of workloads. This will require both continuous mapping of application to infrastructure dependencies and more more frequent (near real time) collection of performance data. Just the requirements for real time mapping and real time data completely overwhelm existing monitoring systems. Hyperic has a good blog on this point here.\nInferring application performance from resource utilization statistics becomes impossible. This was possible on physical hardware, but on hardware that is shared via virtualization it no longers works. Hence the need for Infrastructure Performance Management solutions that measure Infrastructure Response Time. We expect Infrastructure Performance Management solutions from vendors like Akorri, CA Technologies (CA Virtual Assurance), Virtual Instruments, and Xangati to form the foundation layer of whatever will replace BSM.\nApplication will now get moved from cluster to cluster and ultimately from data center to data center (private cloud – hybrid cloud – public cloud). APM solutions will need to track the applications no matter where they go, and seamlessly work across different IP networks. Leading virtualization aware APM solutions like those from AppDynamics, BlueStripe, and New Relic meet these needs today and will likely form the APM layer of whatever replaces BSM.\nAll of the above together combine to create one new result for Systems Management. That new result is that in the general case it will be impossible to deterministically do root cause in a dynamic environment. This was explored in detail in this post.\nThe Significance of the Integrien Acquisition\nThe Integrien acquisition by VMware is significant because it means that VMware has recognized that only a dynamic, statistical, self-configuring, and self-learning approach can keep up with the rate of change in these new dynamic IT environments. The self-learning approach simply means that you feed the system the metrics that get collected about the system and it figures out which ones are important, how the metrics are related to each other, and lets you know when anomalies have occurred.\nThis acquisition is all the more significant because this is not garden variety technology. There have only ever been three companies this this space. ProactiveNet was acquired by BMC a few years ago. Netuitive has been around since the late 1990′s and it took the company until the mid 2000′s before the product had matured into something that really just worked when you plugged it in. Integrien is a fairly recent entry in this field and is now part of VMware – which leaves Netuitive as the only remaining independent player.\nThe New Dynamic BSM – Service Assurance\nSince the old BSM is dead due to a brittle and difficult to update technology approach it is reasonable to ask what will replace it. The answer is most likely a set of Infrastructure Performance Management tools (Akorri, CA Virtual Assurance, Virtual Instruments, Xangati) integrated with a set of next generation APM tools (AppDynamics, BlueStripe, New Relic) vis these self learning technologies. When this occurs, we will have a system that adapts on its own to changing conditions in the environment leaving IT staff available to interpret results (and not raw monitoring data). We will also have taken an important step towards dynamic service assurance which was discussed in detail in this post.\nUnderstanding and Evaluating these Technologies\nFor most IT professionals either they or someone on their staff can digg in and understand how the technologies that they use work. However unless you have an advanced degree in statistics and/or mathematics you are not going to be able to dig an and decide for yourself based upon how these products work which one you should choose. Rather what you should do is apply the following criteria in making your selection:\nDecide exactly what you want the product to do for you. These products are extremely flexible. You can feed them every alarm that is generated by all of your monitoring solutions and let them sort out the good ones from the bad ones. Or you can feed them revenue per minute for one key business application and let them figure what causes degradations in revenue per minute.\nMake sure that the product has connectors to what you already use to collect metrics from your systems. These products are not in the data collection business (with some exceptions). They rely upon other products to collect data from them. They must therefore be interfaced with your existing monitoring solutions.\nHow hands off and plug and play will the product be in practice? This is the key criteria to the long term value of such a solution to your enterprise. Previous attempts at statistical approaches (neural nets) failed because the product had to be “retrained” every time conditions changed. Make sure that the product you select can automatically select and weight the inputs that it bases decisions off of and these these decisions are automatically updated over time. Self-learning needs to be a continuous thing, not just a one time or periodic thing.\nMake sure that the product can handle time based (time series) as well as event based data. Performance metrics tend to be time based, but many performance problems are caused by configuration changes which are events. Make sure that the product can cross-correlate configuration change events with performance degradations.\nCarefully assess the scale of the solution. This means how many inputs can the solution take per unit of time. Right now most of these solutions operate at 15 minute or 5 minute intervals. Monitoring a dynamic system may require intervals of 10 or even 5 seconds (or perhaps even real time continuous streams of monitoring data).\nSummary\nSelf-learning performance management solutions like Integrien and Netuitive are going to be absolutely an essential part of the migration to dynamic data centers and IT as a Service. Once these dynamic data centers scale out to the thousands of applications in a typical enterprise, and scale up to address the most performance critical applications, the rate of change in the environment will be too high for legacy tools and manual administration to be able to keep. up. These automated self-learning approaches will be the only way in which IT Operations will be able to stay on top of these new environments while staying within staffing and budget constraints.\n","date":"2010-09-17T18:46:09Z","permalink":"https://martinliu.cn/2010/09/17/zt-bsm-dead/","title":"[ZT] Old BSM is dead"},{"content":"上图为大型用户环境下 Remedy ITSM 的部署架构，作为本安装步骤参考模型。所不同的是，如下配置步骤只应用了一个最上面的负载均衡器，每个 Web 对应连接一个 ARS 服务器，简化掉了中间放在 ARS 前的负载均衡器。\n第一步 安装前的准备工作。 确定 Remedy ARS 的服务别名，例如“AtriumCMDB”。在所有的 Web 服务器（Mid-tier 所安装的服务器）的 host 文件中加入一条 Ip 地址解析，例如：\n此 ARS 服务别名指向的是该 Web 服务器所对应的 ARS 服务器，例如：Web1 中 AtriumCMDB 对应的 ip 为 ARS1，Web2 对应 ARS2，Web3 对应 ARS3，以此类推。\n第二步安装第一台 ARS 服务器 默认所有的 ARS 都安装了数据库客户端程序，如果是 Oracle 数据库，ARS 上的客户端程序的大小版本号必须和远程数据库的大小版本号完全一致。Windows 平台的 Oracle 客户端只支持 32 位的程序。在所有 ARS 服务器的 host 文件中加入一条 Ip 地址解析，例如：\n此 IP 地址为每台 ARS 自己的对外提供 ARS 服务的 IP。ARS 上安装完 JDK 之后，开始安装 ARS，安装过程中服务器别名输入 AtriumCMDB，其他的选项都按需要配置，所有有关服务器端组件、服务端口、密码、安装路径的信息都要做详细记录，用来安装 Server Group 中其他成员使用。安装完第一台服务器的 ARS 之后，申请 Remedy License，打 License，包括其他所有 CMDB、ITSM 相关应用模块的 License，打完 License 后导出成文件备用。ARS 安装成功之后，顺序安装其他应用，顺序时 CMDB 》ITSM 其他。安装完毕后，通过 Remedy User 来确认所有应用功能是否正常。\n**第三步 **配置第一台 ARS 服务器为 Server Group 中的管理服务器 配置方法参照，ARS Configuration Guide 中的 Server Group 的相关章节。配置完毕之后打开 Server Group 的 Log，从启动 ARS 服务之后，查看该 Log 看 Server Group 工作是否正常。\n第四步 安装 Server Group 中的成员 ARS 服务器 准备工作参考第一台 ARS 服务器。运行 ARS 安装程序，选择 Server Group，选择输入 AtriumCMDB 别名，选择共享的数据库，其他参数与第一台保持一致。安装完毕之后。使用 ARS 自带的 Sample 应用新增一个 city，在 ARS1 上查询 ARS2 上新增的记录。同样参考的 Server Group 的相关章节，对 ARS2 进行配置。在 ARS2 上查看 Server Group 的日志，确认该 ARS 已经加入了以第一台 ARS 为管理服务器的群集中。为第二台 ARS 服务器打 License。在确认第二台 ARS 服务器成功加入之后，安装 CMDB 应用。安装完毕之后，在第二台 ARS 服务器上，使用 Remedy User 客户端，打开 CMDB 的相关表单进行新增和查询操作；然后在 ARS1 上检查操作结果，保证两边一致。安装 ITSM：直接把第一台 ARS 服务器的 ar.cfg 文件覆盖到第二台 ARS 的 ar.cfg 上，一定要修改第一台 ARS 服务器主机名的哪一行，把它修改为第二台 ARS 的主机名。复制第一台 ARS 的 ITSM 安装目录到第二台 ARS 的相同路径中，重启 ARS 服务。查看 arerror.log 文件看看 ARS 启动的是否正常。在第二台 ARS 上使用 Remedy User 确认 ITSM 应用是否工作正常，如果一切工作正常，则第二台 ARS 服务器安装完毕。按照相同的方式安装其他的 ARS 服务器。\n第五步 配置每台 ARS 的 ranking 按照 ARS Configuration Guide 中的 Server Group 的相关章节配置每台 ARS 服务器处理不同后台工作流的 ranking。\n第六步 安装配置所有 Web 服务器的 Remedy Mid-tier 安装 Remedy Mid-tier 软件，都指向相同的 ARS 服务别名 AtriumCMDB，当然该别名被解析为它所对应的 ARS 服务器的 IP 地址。使用浏览器测试每台 Web 服务器，保证 Remedy Mid-tier 都能正常工作。\n第七步 配置 F5 负载均衡 配置 F5 的分发策略，按不同 ARS 服务器的用途，来分别不同的用户请求。考虑管理和接口功能的 ARS 负担少量的用户交互。开发一个 jsp 的程序部署在 Mid-tier 的 shared 目录中，用它来判断 Web 所对应的 ARS 的可用性，以此作为唯一判断条件来分发用户请求给可用的 web 服务器。\n","date":"2010-08-09T01:08:31Z","permalink":"https://martinliu.cn/2010/08/09/remedy-lb-midtier-server-group-configure/","title":"Remedy Server Group及负载均衡配置参考步骤"},{"content":"这个产品被重命名为 OTRS Help Desk，从名字上看出它变的更加成熟，更加符合 ITIL 了。OTRS 界面是很土的，比 RT3 差很多，一直以来我都被它完善的 ITIL 概念所吸引而无暇顾及它丑陋的界面，这个版本将在界面和新的功能上给我们更多惊喜。下面是 3.0 时代的第一个 release notes，偷懒一下，英翻中的工作让 google 代劳了。\nRN 原文：http://lists.otrs.org/pipermail/announce/2010/000133.html\n时间已经到了 一个全新的欢迎开放源码 OTRS 的世界领先的新一代帮助台解决方案。新的 OTRS 的帮助台 3.0 主要版本附带了一个全新的图形用户界面上完全重新设计信息的基 础 架构。您将受益于更快获取相关信息，具有较高的透明度和增加在日常工作效率。 OTRS 的帮助台 3.0 设计的基础 上与来自不同行业的电力用户访问种类繁多以及在与用户体验领先的专业机构密切合作。今天我们很自豪地介绍美妙的结果：\n最值得关注的新功能如下：\n（1）用户为中心的图形用户界面，在一个戏剧 性的转变从结果重新设计一个全面的，但一个更强大的静态和动态的应用程序使用的，类似的 Ajax，XHTML 和优化的最先进的技术状态的 CSS。\n（2）新工单和文章指示器 - 这一新的功能已被两票和文章一级执行。它允许在一个表面上是为代理人在 票或任何更新的文章水平检查，以检查新的和未读文章。您将受益于增加透明度和减少响应时间。\n（3）优化全 文搜索 - 新的搜索功能，您可以灵活定制的方式来浏览信息库。选择新的搜索功能提供了从单一的搜索字符串的搜索范围，复杂的多字符串布尔搜索行动，包括 各经营者。您受益于完全可定制的搜索根据您的需要。\n（4）工单缩放视图 - 关于 Ajax 技术让代理商来显示实时链接的信息结构复杂，同时让代理商目前的工作环境为基础的重新设计。这些公司会受益于增加的方向，提高工 作流程效率。\n（5）全局工单一览 - 知名的 OTRS2.4 全局工单概述已经得到了优化，以达到增加跨活动。根据不同的使用情况和您的代理人的喜好，他们可以轻松地更改机票概览布局根据自己的特殊需要。期权是小型，中型和大型，每个细节提供了不同程度的信息。\n（6）可用性 - 包括重新设计的共同普及标准条 WCAG 和炜也让弱能 ARIA 的用户能够更好地互动与 OTRS 的服务台。美国康复法案第 508 条已经实现。\n（7）新客户界面 - 客户网络前端可集成到您的组织机构内部网，并充分考虑重新设计的桌面帮助系统集成。\n（8）存档功能 - OTRS 的 3.0 现在提供一个新的归档功能。有了你分开存档受益于搜索，并增加结果显示花了时间却缩短。\nGoogle 的翻译效果不佳，请直接看官方发布说明。另外此版本为 beta 版本，OTRS 并不建议用于生产环境。\n","date":"2010-08-03T05:04:46Z","permalink":"https://martinliu.cn/2010/08/03/otrs-300-beta1/","title":"OTRS 3.0.0 beta1 发布"},{"content":"\n课程适用于 Remedy AR 管理员和开发人员，讲授 AR 系统的功能、架构、日常运维和创建应用。 学员可以选择课后参加上机考试，获得BMC Certified Administrator: BMC Remedy AR System 7.5认证。不参加考试的学员将会获得结课证书 点 击查看详情\n课程目标\n认识 AR System 7.5 的用途和优势 认识 AR System 7.5 的架构 使用 Remedy User 和 Web 浏览器创建和查询请求 使用 Remedy User 和 Web 浏览器创建 AR 系统报告 使用 BMC Remedy Alert 和 Web 接收通知 描述 BMC Remedy Administrator 工具的基本维护任务 了解 AR 系统的访问控制概念 了解不同的 AR System 角色 理解 AR System 的系统架构 了解 AR System 的开发工具 权限管理和 AR System 许可管理 使用 Administration Console 执行统一的管理任务. 使用 Developer Studio 创建 AR System 对象 创建 AR System 表单, 控件和 菜单来满足业务需求 创建 AR System active links 创建 AR System filters 创建基于时间的 escalations 定制一个 web 的应用 使用 log 日志来评估性能和识别性能问题 了解 AR System 最佳实践\n参加前提：无 授课语言: 中文 培训价格: 7500 元/人 （BMC 合作伙伴价格 5250 元/人） 认证考试价格：3500 元/人 （可选）\n日程： 北京：8 月 16 日- 20 日 上海：8 月 23 日- 27 日\n联系我们: 010-85183688-1883 Yuan_yuan@bmc.com AP_education@bmc.com\n","date":"2010-07-30T06:28:19Z","permalink":"https://martinliu.cn/2010/07/30/bmc-training-schedule01/","title":"BMC课程通知: BMC Remedy AR 7.5 管理员培训"},{"content":"\n下载 ITIL v3 核心概念介绍，脑图版：http://www.box.net/shared/fve6vvasvt\n这份资料对于新手学习，或者 ITILv3 老手做参考都比较适合。为了为一些朋友突破一下语言的障碍，我把它翻译成了简体中文版，使用开源软件FindMind进行的翻译。\n文档下载 正在翻译中，稍后提供中文完整版本。翻译状态：\n服务策略 100%\n服务设计 100%\n服务转换 0%\n服务运往 0%\n服务持续性改进 0%\n","date":"2010-07-29T03:25:35Z","permalink":"https://martinliu.cn/2010/07/29/itil-v3-mindmap/","title":"ITIL v3 MindMap脑图"},{"content":"Cacti 是我最喜爱的一个网管软件之一。网站http://cactiez.cactiusers.org/ ；该网站的主人吧 Cacti 嵌入到了 Linux 的安装光盘中，实现了 Cacti 的一键式安装，这正是我所关注的关于开源应用的重要的一个步骤。我称之这是在解决开源软件应用的“last mile”问题。开源软件的潜在用户往往有这样几个特点：\n技术力量弱，有些可能根本就不知道什么是 Linux，什么是 open source 需求相对明确和简单 无法获得中文的技术支持和培训 CactiEz 让人能在 30 分钟之内上手开始使用 Cacti，从根本上解决了整套软件的安装和配置工作。\n英文版下载地址：http://cactiez.cactiusers.org/\n中文版下载地址：http://linux.chinaunix.net/bbs/thread-1049886-1-1.html\n","date":"2010-07-23T01:46:33Z","permalink":"https://martinliu.cn/2010/07/23/cacti-easier/","title":"Make Cacti more easier"},{"content":"From 《Step by step to build a CMDB》步骤 17-规划 CMDB 数据填充\n本文描述填充过程的任务 3 到任务 4：\n任务 3 映射 CI 和数据源 现在拿出您的 CI 清单，并把每一类 CI 与具有相关信息的数据源映射起来。一个简单的电子数据表格，像图 17.2 一样的就足够了。有更复杂数据需求的大一点的企业可能需要多个数据页或者通过 CI 分类来连接到不同的数据页。\n这项工作的最终目标不仅是识别用以填充 CMDB 数据源，而且还识别了流程和平台的接触点，有些平台对数据填充是有影响的。这项工作也是至关重要，用来定义数据调和规则，定义数据优先度，这些会在下面的步骤，任务 7“建立调和规则”中用的。 工具映射如下图 17.2 所示，包括了每一个 CI 类，相关的属性，相关的关系数据，和数据源。 图 17.2 Ci 和数据源之间的对照关系图样例 您可能会发现一些 s 数据源之间的重叠，特别是 CI 库存清单的属性数据。这些数据通常包括唯一物理特性和 CI 的地点的说明 ，例如：型号、序列号、地点和所有者。此信息可能被存储在其他多个地方，它们也可用于 CI 数据填充的来源和日常维护的来源。 多种的资产和库存清单数据来源可能包括如下：\n审计（资产清单或者配置发现数据库；无代理和有代理方式） 资产管理系统 采购系统和许可证管理 财会系统（采购或者收货） 合同管理系统 变更管理系统 其他财务应用和系统 任务 4 访问数据源环境 为了确保数据质量，你应该访问所有的数据源环境，而不仅仅只是 CMDB，还包括连接工具和相关技术，要逐一访问查看每一个数据源。在这里，“进来的是垃圾，出去的就是垃圾”这个俗语是适用的。CMDB 项目的成功可能依赖于对系统或者基础架构的更新，以适应网络流量和数据量，还依赖于确保每一个数据源的数据质量。\n当你规划 CMDB 数据填充的时候，要自问这样几个问题，是有关外部映射数据源质量的：\n现在那些信息在那里、怎样被存储的？ \u0026ndash;数据库、电子表格、Word 文档？ 当前环境中有没有审计（发现）工具、软件分发、配置管理或者采购系统，用来自动的跟踪和存储这些信息？ 或者数据时被手工地收集和更新的？ 这些系统是基于开放标准还是私有技术的？ 这些系统的厂商有没有标准化的工具？或者 CMDB 厂商？ 需要被继承的数据源的物理位置在那里？ 在 CMDB 和数据源之间，通讯的方式是双向的还是单向的？ 还要考虑有关映射数据源性能相关的问题：\n就当前的数据源来说，现实的性能、容量和可靠性是怎样的？ 系统上当前的活动状况怎样？ 活动用户数 其他并发继承此数据源的工具 备份、病毒扫描、报表或者数据挖掘的日程 审计工具（配置发现或者库存清单）扫描或者排队日程 其他任何将影响性能的事情 硬件和当前环境是不是能完全满足今后数据迁移所需要的附加工作量和空间需求？以及满足对于以后的日常数据同步？有没有对今后几年里增长率有做过计算？ 是不是需要考虑要满足什么约束或者特殊权限？ 厂商是否在与他们数据库集成方面有建议的最佳实践？（使用热备的生产机来降低作业压力） CMDB 周边的数据集和连接技术是什么？ 网络环境中物理的限制（带宽、距离等）是否会有影响？ 当前的版本是多少？在以后的六个月或者一年里是否有升级的计划？有哪些好处？ 为当前的解决方案是否得到了足够的资料来负责架构、排错以及连接系统的维护？ 通过尽早的回答这些问题，就可以避免后续可能出现的性能问题，那些问题会影响项目的成功。如果数据源不太可靠，而且数据质量和性能方面是有问题的，这个时候，可以回到这些数据的关键利益相关者那里，与他们讨论，并确定这是否会影响到使用方面的关键需求。如果没有，需要把这部分数据需求从 CMDB 项目计划的第一阶段中展示放弃。这里最重要的是第一阶段的合理部署，实施结果能够获得用户全面的适应。然而，如果这些数据依然是比较关键的需求，那么需要与数据所有者，和收益者各方进行沟通，并引起各方的高度重视，共同确定一个解决方案。\n","date":"2010-07-20T11:35:44Z","permalink":"https://martinliu.cn/2010/07/20/cmdb003/","title":"规划CMDB数据填充-003"},{"content":"From 《Step by step to build a CMDB》步骤 17-规划 CMDB 数据填充\n本文描述填充过程的任务 1 到任务 2：\n任务 1 再次回顾 CMDB 范围 现在进行现实检验。你能否确实交付在第 2 阶段即“定义需求和创建 IT 服务模型蓝图”中定义的 CI 范围涉及的相关数据？你在 CI 数据一旦交付以后，能否有足够的资源来维护整个系统和所有数据？这些都是重要的问题，因为您所选择的 CMDB 解决方案，可能很容易地就超越了您需要的范围，超出了你可以能容易维护的程度。\n在规划 CMDB 数据填充时，您的思想应该是“少即是多“。先学会走再跑。让 CMDB 的首次推广得到充分验证后在考虑扩大范围。您需要帮助保持 CMDB 的团队和 CMDB 数据用户的积极性。同时避免项目范围的蔓延，否则可能破坏的实施的效果，以及用户对新的解决方案的接受度。\n请谨记这样几个考虑因素，从而来帮助您始终专注于那些核心需求上，并能对关键的限制作出反应：\n成本 – 每个人都必须面对业务现实，包括预算和费用的现实。因此，在您的 CMDB 项目预算范围里，对主要需求排列优先级。如果出现新的想法，那么也只是在新的预算来下了以后才考虑。 时间 \u0026ndash; 您可能需要在给定的时间内实施 CMDB，来使您企业在此方面的业务需求得到满足，如 Sarbanes-Oxley 法规，或支持一个非常关键的新流程。当您计划了 CI 数据填充的顺序后（后面介绍的这一步），不仅要对 CI 数据排优先级，而且还要明确时间的限制。 实用性 – 如果没有足够的资源用来实施和维持 CMDB，以满足 CMDB 要求，那么您可能需要缩小实施范围，以便您可以在您实际有限的资源里运作项目。你还可以考虑分两个阶段进行实施，把非关键的要求放到第二个阶段中。 外部强加的优先事项 – 有些业务的运作，例如企业治理、数据保护和信息自由，可能会影响您既定的优先次序。您可以通过分阶段实施 CMDB 数据填充来减少外部因素的影响。如果你没有从一开始就计划足够的时间来达成最后期限，那么你可以尝试投入更多的资源来克服时间上的限制。然而，还要意识到，以后你要申请更多的资源，没有资源的保证，你可能无法充分管理好项目。 所有权 – 有时 IT 资产的负责人并不属于 IT 组织。如果资产所有者决定不参与的 CMDB，这会严重限制了 CI 数据内容的提供。您可以提供 CMDB 部分功能的有限的访问给他们，用来消除他们顾虑，并参与进来。 地区 – 地理区域上的边界，可能会限制建立企业范围的 CMDB。由于地理或行政上可能的边界，我们可能听过“最好再也不要从总部传来这样神经质数据库方案”。最好预防这种情况的办法是，尽可能早的让所有地区的相关人员参与到 CMDB 项目里来。 组织架构 – 很多企业把 IT 划分成为清晰地、各自为政的独立部门，通过这种方式来对 CMDB 里的不同范围负责。例如：通信部门的人可能是一个单独的组织结构，他们可能拒绝参与到项目中来，因为他们觉得这超出了他们的控制范围。这时候就要让其他的 IT 组织参与其中，让每个人都知道谁是项目负责人。 当你计划你的 CMDB 数据填充的时候，越能专注于关键受益人的需求，就越能够达成项目的业务目标，就越能让您的项目顺利。您需要就已经确定的 CMDB 范围，与所有的利益方沟通它可能的影响和效果。收集他们的反馈，并对有必要方面做进一步讨论。\n任务 2 识别 CI 使用在第 15 步即“设计 IT 服务模型蓝图”中设计的 IT 服务模型蓝图为基础，来生成用于 CMDB 数据填充的 CI 以及相关属性和关系数据的清单。这个清单的细节应该到数据字段级别，以便，你能够识别并且映射一个或者多个数据源到特定的 CI 数据。 例如，如果你把一个实际的服务器 CI 的属性和关系数据都列出清单，你就可以找出一些现有的能提供属性数据的数据源，可能包括库存管理的数据库和发现或者网络管理工具。但是另外一些数据字段可能没有现成的数据源。你将在第 18 步“选择自动化 CMDB 数据填充工具”中用到以上差距分析。或者您可能决定使用手工的方式来填充和更新这个字段，这里还需要仔细的考虑到数据的负责人，和在 21 步“建立 CI 生命周期管理流程”中需要支持的流程。 至此，你需要专注于用来满足项目目标的要求。在步骤 11 到 14，你定义了与其他流程的结合点，明确的 CI 需求。专注于那些能直接对流程收益人产生直接影响的 CI 数据。\n","date":"2010-07-20T11:25:18Z","permalink":"https://martinliu.cn/2010/07/20/plan-cmdb-population-002/","title":"规划CMDB数据填充-002"},{"content":" What\u0026rsquo;s new in 3.8+?\n清晰易用的图形界面 仪表板 Dashboards 流程单关系图 Ticket relationship graphs 与 PGPemail 无缝集成 Seamless PGP support for email 富文本编辑 Richtext editing (WYSIWYG) 预定义用户首选项 Per-user preferences for common options 单据按日历 feed：Calendar feeds for ticket due dates 标记单据 Bookmarking tickets 新的邮件设置 New email delivery settings 更容易的升级工具 Easier upgrade tools 性能提高 Loads of performance improvements and bug fixes 发现 RT 比 OTRS 的界面好的太多了。不过这俩比较起来，OTRS 更正式，更符合 ITIL，主要是它有 ITSM 模块，这个模块里面内置了 IM，PM，CM 和 SLA 管理，值得一提的是它也包括配置管理模块。不过 OTRS 的界面和 RT 比起来就不是难看一点了。初步体验了 RT 一下，主要感觉是，界面太直观了，所有方便操作近在咫尺，系统的易用性降低了使用和配置的复杂性。对于不追求 ITIL 的中小企业，应该很值得试试 RT。\n","date":"2010-07-18T13:54:54Z","permalink":"https://martinliu.cn/2010/07/18/rt3-request-tracker/","title":"RT3 Request Tacker或让你摆脱束缚"},{"content":"头等大事是有关于 OCSNG 很快就要出 UTF8 多语言支持版的 Windows 采集代理程序。新闻如下： ** 新版 windows 采集代理被彻底重写，它将包括下面的新特性：**\n全 Unicode 代理，多语言 UTF-8 支持 Native 32 and 64 bits agent BIOS AssetTag 收集 硬盘序列号收集 部署返回码收集 全 HTTPS 支持 Socks 4 、5 HTTP 代理支持 FTP, FTPS 和 SMB 包部署支持 二进制插件支持 另外，是一本新书的发布，这是我见到的第一本系统介绍 OCSNG 的图书。可能是由于我写过一些相关的 post，该书的出版社发邮件给我，想请我 review，并写写书评。处于对 OCSNG 和 GLPI 的喜爱，忍不住诱惑，就答应了。很快的我得到了这本书的电子版。虽然没有时间看完，浏览了几章后，还是可以说这本书写的是非常实用。特别是对系统的安装、配置、部署和使用都从系统管理员的角度写的非常到位。书上没什么废话，文字写的比较随意，很易懂的随意。可喜的是该书还捎带着把 GLPI 也给介绍了，包括如何与 OCSNG 做集成配置，以及 GLPI 的主要功能说明。对于这种偏门的开源软件系统能有如此细致使用的介绍实属难得，更何况我对 OCSNG 和 GLPI 的网站文档本身就不敢恭维。这里提供一个样章供参考 \u0026ldquo;Introduction to IT Inventory and Resource Management\u0026rdquo;\n最后，还是期待新版 OCSNG 的 Window 采集代理程序能早点发布吧。期望它发布之时我有时间做这样一个虚机，以便分享给各位感兴趣的人。规划如下：\n基于 Fedora 10 安装 OCSNG_UNIX_SERVER-1.3.2. + glpi-0.78-RC2 做一定系统的基本优化，配置 OCSNG 和 GPLI 的集成 期望该虚机能应用于实际的网络环境中 ","date":"2010-07-16T19:03:17Z","permalink":"https://martinliu.cn/2010/07/16/ocs-inventory-ng/","title":"OCS inventory NG 两三事"},{"content":"\n期待多时的 3.0 版本终于出现了，刚刚升级上来，还没有体验到她的新功能，先换上了最新的皮肤，看上去字体和布局都非常舒服。简单就是美，希望 WordPress 能够越来越好。它真可谓用户体验的典范之作！\n","date":"2010-06-20T11:13:44Z","permalink":"https://martinliu.cn/2010/06/20/upgraded-wordpress-30/","title":"Upgraded to Wordpress 3.0"},{"content":"还有很多企业依然在寻找 IT 服务管理的方法论 还有很多企业依然在让内部开发团队打造 ITSM 流程平台 也还有很多企业在购买的成熟的 ITSM 管理平台套件上大搞研发和定制 也还有很多外国企业在拼命保持使用 ITSM 产品开箱即用的功能来减少开支和加快投资回报 也还有一些外国企业在尝试 ITSM 的 KFC，BMC Remedy OnDemand，连系统也不建设了，直接拿标准的就来用吧。 回顾国内的 ITSM 用户，往往在探索期里花的时间和金钱成本太大，推广标准化 ITSM 的理念需和 ITSM 系统平台建设同行；目前国外的工具和 ITIL 标准已经够标准、成熟和进化了，我们的标准化理念也争取迎头赶上吧 Reduce Service Support Costs Quickly with BMC Remedy OnDemand\nView Full Screen\n","date":"2010-06-07T17:55:46Z","permalink":"https://martinliu.cn/2010/06/07/bmc-remedy-ondemand/","title":"BMC提供ITSM洋快餐"},{"content":"From 《Step by step to build a CMDB》步骤 17-规划 CMDB 数据填充\n目标\n在这一 CMDB 关键的步骤中，会为 CMDB 的初始化 CI 数据填充，做精细的计划。需要考虑到所有 CI 数据，把不同 CI 类型对应到不同的数据集中，安排正确的顺序将这些数据集 CMDB。其中定义对应的规则来调和重复数据是很重要的，不仅在 CMDB 初始化数据填充阶段重要，在以后的日常维护过程中也是非常重要的。做出了本阶段的详细规划后，这样在第 18 步即“选择自动化 CMDB 填充工具”时，就能考虑需要什么样的配置发现和自动化工具了。\n实际上，把数据填充到 CMDB 中是非常基础的工作，必须事前做好充分的数据范围和类型的分析。对于一个典型的 CMDB 数据填过程来说，将需要做如下工作：\n建立里项目程碑和高阶项目计划，以及配套的支撑数据库和操作流程。 安排项目启动会议，单周或者双周的项目进度沟通会。 识别子项目（每个数据集分为一个子项目），建立每个子项目的目标和需求清单。识别和制定项目工作活动内容，确定项目的工作流程，并且按照项目计划排程所有活动。包括： \u0026mdash;并行开展项目（用户界面定制，DSL 数据填充）； \u0026mdash;串行开展项目（发现工具，数据调和，等等） 为每个子项目分配项目负责人，让他们来负责汇报项目的进展、问题升级和下一步的工作。 为所有项目参与人员建立一个开放的沟通平台，包括所有内部、外部人员（邮件组方式，数据库、通报） 为可能出现的紧急事件预留至少 10%的时间和预算的缓冲。 自动配置采集工具是一种很好的数据填充和数据维护方式，您也会在某种发现工具的诱惑下，在很短的时间里，就采集到了大量的数据。可是您还是需要注意：一个被填充了大量数据的CMDB并不意味着是一个好CMDB。一旦您建立和填充了CMDB，您就将需要对它进行积极地维护。如果CMDB中存储着很多超出用户需求的数据，即使在最好的情况下，您也是对这些无用的数据做大量无谓创建和维护工作，这是一个巨大的浪费且没有意义的事。而在最糟的情况下，如果你所填充入CMDB的数据，在后来是没有被及时更新和维护的，那么当用户使用到这些质量低和不精确的数据数据后，就会对CMDB失去信心，这样也对 CMDB在企业里的推广和应用造成一定阻碍。\n按照您在第二步-“定义需求和创建 IT 服务模型蓝图”中的需求，来设计和部署 CMDB。从你的服务模型蓝图出发，来识别 CI，把他们分组到各个数据集中。识别每个数据集应该对应的数据源，把每个 CI 类型和相关数据源对应起来。并且按照既定的 CMDB 数据导入的工作顺序，来规划不同数据源中数据。最后，把以上所有规划和设计用文档记录下来，包括识别重复数据的调和规则等。\n在这一步里，您必须专注于 CMDB 所需要的范围，交付可实现的东西，而非可能的东西。在敲定最终的规划之前，你需要组织分析会议进行仔细地计划。\n","date":"2010-06-04T06:13:20Z","permalink":"https://martinliu.cn/2010/06/04/plan-cmdb-population-001/","title":"规划CMDB数据填充-001"},{"content":"下面是我在过去 ITSM 项目实施中的一些经验和体会：\nITSM_implement best practice\n下载\nCredit：本 ppt 的原版为《the 60 second guide to Enterprise Innovation》\n","date":"2010-06-01T16:37:51Z","permalink":"https://martinliu.cn/2010/06/01/itsm-implement-best-practice/","title":"ITSM实施精要-只讲2分钟"},{"content":"来自：Jonathan Markworth（CompuCom Systems 有限公司管理顾问，探讨联邦数据库的优点）\n使用一个具有单一的、全知的、万能的和自维护功能的工具，来管理 IT 基础架的方方面面信息，是否是最好的方案呢？使用一个能做所有工作的全集成平台，来替换您积累下来的所有管理工具是否是最佳方式？现实情况是，大多数组织都已经实施了几十种应用程序、工具、实用程序、数据存储、硬件平台和管理框架，它们一起运行着一个或更多的 IT 服务管理功能。它们中的每一个应用都有自己的数据库，对当前环境中的一些关键管理功能提供信息支持。在 CMDB 应用场景中，这些工具相关的数据库中，其实也包含了大量关键的 CI 属性，这些属性可以用于识别 CI 之间的关系。重要的问题是，如何利用现有的投资和资源来建立一个底层共享的数据库，比如一个 CMDB。\n一种方法是“集中存储和管理”，从这些数据源中导出 CI 的唯一标识、属性、以及关系，然后都整合到一个数据库中。但在经过了一段很长的时间后，这种方案所产生的数据将很难维护，因为伴随着数据源数量的增长，整套系统的维护会变的愈来愈复杂。\n另一种方法是“建立联邦的 CMDB”，建立一个核心 CMDB，用来整合所有配置项的唯一标识、核心属性和关系数据，为所有需要它的 IT 流程随时提供配置数据，而不需要对所有数据进行集中式地复制。用联邦的模式，让 CMDB 持有所有 CI 及其核心属性数据，然后再连接到其他相关的数据源；如服务台事件单、服务水平协议、甚至其他监控的管理控制台界面。通过正确地部署，联邦模式可以使得企业的 CMDB 能横跨所有的个 IT 组织，如果需要的话可以对既有的相关系统进行分阶段的实施，这样不仅可以让 IT 组织能够继续日常业务，还不会带来什么干扰。\n摘自 BMC 软件公司公布的 VIEWPOINT “CMDB 的潜力—驾驭新的 IT 现实”，CMDB 为主题的文章。\n","date":"2010-05-31T03:53:06Z","permalink":"https://martinliu.cn/2010/05/31/federation-cmdb/","title":"联邦的CMDB–神话/现实/需求/还是策略？"},{"content":"[singlepic id=84 w=320 h=240 mode=watermark float=left] 挑战 1：沟通成本大 项目的参与沟通方可能很多，最多的情况下，可能包括：网络部门、系统部门、安全部门和各个业务部门。沟通的内容主要是配置采集的实施技术方式。其中采集的安全性，风险分析是最重要的部分；在部门多的情况下，面对多种选择的时候，逐一给项目各方说清所有方案，特别是讲清楚利弊是非常耗时的。在充分沟通了所有技术可能性之后，才能做出倾向性选择。逐一这是第一轮沟通，搞清楚了倾向性而已。\n挑战 2：决策成本大 特别是银行等金融企业，安全性要求特别高。安全风险方面的建议往往是最重要的，他们的建议对配置采集工具的实施具有决定性意义。在各方都充分理解了配置采集工具的架构和安全性之后，就是拍板定夺了。这种逐级的审批和决策是需要较长的周期。\n挑战 3：前导时间成本太大 在前导时间里，可能还没有部署正式的 ADDM 采集服务器。在这个阶段里，要配置网络，让以后的采集服务器能够处于能够扫描到所有目标服务器设备。还可能需要在每台服务器上配置相关的准备工作，主要是坚持主机的操作系统的账户、采集协议和安全配置等是否满足配置采集工具的要求。这写工作是一个群众性运动，需要让所有的系统管理员配合。此项工作的设计人员设备多，最好能尽早的开始。\n挑战 4：用户的期望太大 用户对配置工具的期望主要是集中在深度和细度方面。其实这也不为过，只是在实施的过程中，最好还能把发现工具的一下特有的功能和特殊推广给用户。如软件和硬件的 EOL 信息，一些开合即用的报表和图形化展示功能，全文搜索等等功能其实都可以给客户带去意想不到的价值 。\n","date":"2010-04-26T12:24:24Z","permalink":"https://martinliu.cn/2010/04/26/cmdb-addm-tool-implement-good-practice/","title":"CMDB配置采集工具部署之4大挑战"},{"content":"厦门持续的阴雨，这样的天气已经持续很久了，看来清明和谷雨前后没有什么好天气了，说实话不太适应南方这种鬼天气，比较怀念上周 6 北京的大晴天。今天的心情同天气一样，郁闷原因不说了。\n匆忙吃过早饭，乘船来到岛上来寻找一处安静的地方，目的很简单啊，无聊出差的周末工作，还能做什么？今天感觉除了工作就是发呆了。在岛上七拐八拐的稍微溜达了一下，稍微逛了两个小店。想找一个地方能够提供舒适的桌椅、户外的环境，当然还有咖啡和午饭了。\n最后还是落脚在 Naya，院落里有只有墙边的两个桌不淋雨，其他的都被雨水浇的稀里哗啦的。点上一杯咖啡，打开电脑开始工作吧。背后桌上的猫引来一些游客的观赏和拍照，烦！难得找个清静的地方，带上耳机，许巍熟悉的老歌旋即缭绕耳畔。趁没有人惹猫咪，我对它咪咪了几声，它没反应，我继续。过了一会我发现它走到我的长椅上，蹲在那里，正在看我，这猫看来也很无聊，需要人的陪伴，它也让我想到了某人。我摸了几下它的头，它很享受的眯上眼；这又让我想起了，小时候我样的那只大猫，比它颜色白。它坐的位置正好在我搭在椅背上的衣服后面，游客这下彻底看不到它了，我也可以安心地继续了。发文感谢一下这只猫义务陪伴我可爱的 MIMI。今天主要的工作内容是 CMDB 解决方案需要和差距分析。\n","date":"2010-04-18T06:50:02Z","permalink":"https://martinliu.cn/2010/04/18/naya_cat_weekend/","title":"Naya-猫-周末"},{"content":"\n21 世纪最缺的是人才，在 ITIL 项目中更是重要。特别是 CMDB 项目，项目团队人员构成是呈金字塔型。\n最顶端的人是 Project Executive Board“项目执行委员会”，简称 PEB，它就像是一个公司董事会；它对 CMDB 项目的目标、预算、工期、项目变更等负责。PEB 人员数量应愈少愈好，不过下面的个角色也是缺一不可。首先，要请至少一个 C level 的人加入，比如数据中心的 CIO。其次，关键利益干系人，它们是 CMDB 的价值的主要承载者，叫好和批评项目成果的都会是它们。然后是 CMS/CMDB 系统的负责人，它们对 CMDB 的规划、维护和之后的发展最重要。最后是项目实施资源的主要提供方领导，说白了他就是出人出力的部门，今后项目的执行和实施都靠他们。所以 PEB 的人数在 4 人左右。他们是相关部门的领导。我在最近的项目实施中，也遇到了几个问题，需要去找客户的老板来拍，也就是找到 PEB 的人决策。其实之前也听到其他同事在项目过程中，曾经感慨道“客户的领导还真辛苦，大事小情都需要替下面做决策，他们的脑袋真禁拍！”。国内的管理者的确挺辛苦的，毕竟所带领的团队都还比较的年轻，这也是国内 IT 管理的成熟度低的一个体现。\n金字塔下面的人就是都是我们的天天加班、做牛做马的辛劳工作的实施人员了。没有规矩不能成方圆，实施团队的技术素质和构成、团队沟通等都是至关重要的。对项目的质量，项目工期都有非常重要的影响。金字塔下面的兄弟姐妹都是一条船上的人，大家要互相配合才能完成项目的各项工作；在这个过程中没有一个船老大也是不行的，船老大就是项目经理。对 CMDB 的项目经理的要求可不低，重要有以下几点：\nPlanning skills IT service management background Previous involvement in building a database ITIL Manager’s certification Ability to make decisions Capabilities to motivate staff Ability to blend a team Strength of character to lead a team Capacity to present results and status of project to sponsors and stakeholders Self-motivation Ability to communicate instructions to the project team (from step by step to build a cmdb) 项目实施工程应该具备很多的必要素质。CMDB 产品是一个复杂的应用系统，必须有人对它的技术细节非常熟悉，包括应用安装、配置和客户化。这个技能应该是核心中的核心，对产品利用的好，就能减少二次开发的工作量，就能最大发挥产品的原本功能，从而规避项目风险。产品的二次开发技能也是另一个必要因素，这是由于中国用户的特点决定的，对于任何一个大型的 ITSM 项目，国内没有不对产品做二次开发的。程序开发技能也很重要，Java/JSP 开发人员是必须的，他们还需要懂得 html、xml、sql 等技术。如果能在有操作系统和数据库专家就在好不过了，在系统出现性能故障，系统需要全面备份和恢复的时候，数据库专家和系统专家的参与能让事情经行的更高效，更快，不至于由于系统不可用导致的窝工。系统能更安全，能更放心的使用和开发。下面的一些技能是充分条件，包括 ITIL 认证、ITSM 流程的知识背景和项目经验。\nCMDB 项目对实施人员的要求是很高的，实施前要选合适的人；想要追求高品质的项目质量，就需要网络业内的专业的实施专家顾问、有经验的项目经理和合格的项目实施工程师。从这个角度上讲，21 世纪 ITSM 项目最缺的可见是 CMDB 人才；呵呵这纯粹是我的笑谈，不过您要组建一个 CMDB 项目团队的话，挑选人员的时候请务必擦亮眼睛。\n","date":"2010-04-15T16:04:28Z","permalink":"https://martinliu.cn/2010/04/15/cmdb-project-need-talents/","title":"21世纪最缺的是什么？"},{"content":"\n今天在厦门看了一次电影，是 3D 版的，总的来说影片非常好看，可谓是老少皆宜的佳品制作。可惜 3D 眼镜还是太沉了，脖子看完了很痛。红色皇后的真残酷，还有白色皇后的真伪善，还有很多卡通角色的搞笑，包括最后于怪龙的决斗。整个片子内容饱满而有趣，丝毫不觉得拖沓和无聊。让我又一次的回到童年的感觉。清明节前后真不是出游的好季节，厦门整日阴沉着天，只能当是休息了。\n","date":"2010-04-04T14:23:17Z","permalink":"https://martinliu.cn/2010/04/04/alice-wonderland/","title":"Alice in Wonderland"},{"content":"[singlepic id=34 w=320 h=240 mode=watermark float=right]不经意间听到的让我深思的一段对话。 甲：咦，这个功能是什么时候加的？ 乙：哦，我也不知道还有这个功能 丙：那是我加的 甲：需求是谁提的？ 丙：他们那天给我打了一个电话说需要这个功能\n都说 ITSM 项目是非常难实施的项目，成功率低；特别是 CMDB 项目，实施难度大，失败案例比比皆是。首先我觉得 ITSM 项目的实施有它的特殊性，特殊在于实施顾问对客户需求的理解，在于实施顾问对 ITIL 最佳实践的经验，在于对产品工具的把握。其中任何一个环节拿捏不准都会到导致需求的泛滥、需求混乱、需求的飘忽不定。\n可见需求管理是项目实施和执行的灵魂，失去了对灵魂的掌控，需求讨论会就将可能进入走火入魔的地步，需求各方争执不下，整个会议室炸开了锅，每个人都争抢着发言，我的脑也几乎要眩晕；我说的这一点也不夸张，没见过只能是你的幸运。\n需求管理包括需求的分析和整理，应该是有层次的，在不同的层次里讲不同的语言，达成共识的讨论结果。层次可以分为这样三层\n业务需求\n用户需求\n功能需求\n所谓业务需求是说站在公司的高度，从最 high level 角度描述需求之所在。它的语言像是项目使命的宣言，指出为什么要做这个项目，项目的价值点落在哪里。最概况的项目范围。业务需求告诉我们：为什么会有这些需求。\n用户需求是指从项目利益相关人的角度出发。逐一描述各个业务操作环节，这些业务操作由每个可独立执行的条目为单位，每个业务操作中说明业务规则、输入和结果。切忌在这一阶段就进入详细的功能界面或者功能操作上细节的任何讨论。原因很简单：我们在这里还没有进入技术实现环节，依然在以客户或者系统使用者的角度来描述它的需求。系统用户和客户是不需要理解每一个页面跳转和鼠标点击的意义的。在我的经验看来客户在这里最容易陷入技术细节讨论的泥沼，反而可能浪费需求讨论的时间，可能导致项目的延期，需求点难以确定。用户需求告诉我们：用户的需要什么。\n功能需求则需要告诉我们：为了能满足用户需求，我们的系统是怎么做的。这里将用技术的语言，进入系统层面说明系统应该怎么做。功能需求最终将导出概要设计和详细设计。\n业务需求的满足=用户需求的满足+功能需求的满足；用户需求是能推倒出功能需求的，用户需求和功能需求可以是一对一、一对多和多对多的关系。\n以上三个需求是有层次的并与客户递进沟通的产物，既然是沟通，那么在每个层次上都伴随着矛盾、争论、妥协。在任一层次上理不出头绪时，一定要追溯到上一层，通过上一层来指导解决。但是这往往也是很难把握和执行的，最终最可能的结果是在以上三个沟通层次中都伴随着需求的变化、需求的扩大、需求的混乱。甚至于进入了测试阶段还能产生出新的需求和理解的偏差，谁人能不说“需求变更”是项目实施的鬼见愁呢？\n如何解决这个“鬼见愁”？一方面需要时刻对项目预算和时间资源保持清醒的头脑，项目实施比较是那时间和金钱换需求。还有就是通过项目变更委员会来控制需求变更。\n","date":"2010-04-02T14:59:12Z","permalink":"https://martinliu.cn/2010/04/02/project-failed-by-requirements-change/","title":"项目实施之鬼见愁@需求变更@"},{"content":"今天是项目计划提交后的第二天，客户方项目经理对项目的推迟表示感到非常吃惊，期望能让我们给出一个合理的解释。其实这也同样的超出了我的预料，难道软件项目管理和运作都是所谓的人月神话么？\n[singlepic id=22 w=320 h=240 mode=watermark float=left]在我看来 CMDB 项目的实施和运作有是有可能分阶段、逐步地交付项目成果的。简单的来说首先交付的当然是 CMDB 和配套发现工具系统本身，丑媳妇不要怕见公婆，把这个不加粉饰的原型系统拿出来，让项目各方包括最终用户来试用和评估。接着按照 CMDB 配置数据的来源的不同，把数据顺序的导入 CMDB，并且开展数据的调和工作，完成基础数据的初始化。在基础数据的基础上，需要对 CMDB 服务模型加以验证，选取重点的系统来验证，让系统经理和 CMDB 相关用户也参与进来，用事实和数据讲话，对模型和工具做最终的确认。这个其实是一个小范围内的推广，它的经验可以直接应用于下一个阶段。接下来是对其他所有被采集对象的普遍扫描和 CI 数据同步，在这个阶段里还需要实现 CMDB 和所有 ITIL 流程的集成，ITIL 流程是 CMDB 的主要消费者 ，这个集成往往是两家不同的产品，这种情况下，如果集成的效果欠佳，CMDB 的实施成果也会打折扣。最后结尾的交付物可以是 CMDB 的审核和报表等产品。\n正如 ITIL 的实施一样，没有两个国内公司的 ITSM 实施是相似的，就像国内不存在两片相同的树叶一样。那么国外的树叶又如何呢？从 ITSM 实施方面来看，相同的树叶在国外还是非常多的。相同的原因在于，往往用户选择了相同的产品如 Remedy ITSM 套件，往往由于定制化的人力成本很多用户也在尽量避免对产品的定制，如果通过配置可以实现的需求，绝不定制或者开发。我们也应该多走工业化标准生产的道路，少以中国特色为借口来实施个性化二次开发。\n","date":"2010-03-30T14:00:01Z","permalink":"https://martinliu.cn/2010/03/30/phase-roll-out-cmdb-implement/","title":"掀起CMDB的盖头来"},{"content":"[singlepic id=4 w=320 h=240 mode=watermark float=right]今天终于移师厦门开发中心，这意味着我所经历的史上最长 CMDB 需求分析基本告一阶段，也意味着 CMDB 的构建、集成、定制和 测试工作也徐徐拉开了大幕。\n回忆前三个月所做的的需求分析工作，虽然各项调研和讨论工作进行的缓慢，不过细致的工作最终还是换回了令人满意的成果，起码我是这么认为。\n需求分析的过程是对需求的重新整理、重新定义和梳理。项目的立项并不意味着项目目标树立的精准，项目范围控制的合理。实际需求可以在实施的初期阶段来重定义，从新分析，着觉得不是浪费时间。而且这一点对于中国用户至关重要。国内很多项目都是资金或者预算驱动的，先有需求，通过需求推到出项目的价值，在通过项目的投资回报率申报项目预算的过程在国内是很少见得。国内的项目往往是有多少钱需要花，那么大家在来看，如何把需求花到极致，达到最大的产出。这也是很多需求分析做的贪多、贪大、求全的根源，这样做的好处是在一个项目周期内就把需求实现的尽善尽美（愿望是这样），坏处是：可能导致厂商和服务商的服务成本超支，从而造成的项目质量降低，从用户角度来说一次性接受一大堆的系统功能，负担重，接受度低，同时客户满意度低，项目满意度差。\n我认为较好的最佳实践还要抓项目的主要目标，抓需要实现的主要价值点，抓重点放弃那些可做可不做的功能。懂得放弃的人才懂得获得。把所有的功能需求做成能够分批、分期上线的成果；确保让系统用户能 buy in 每一个阶段性成果，不要奢望给用户带来革命性的提高，由于那样也意味着，你对他们当前工作方式的影响是巨大的，没有用户愿意接受巨变。\n需求分析时，从技术上讲，对会议组织人要求很高。需要此人能非常熟悉 CMDB 项目实施的方法论，需要此人能够非常熟悉产品的各个功能点，需要引导有效的需求分析会议。在白板上尽可能多的画图，用 Visio 或者 ppt 等工具尽量多的讲解各种架构图、功能图、流程图具有事半功倍的效果。不管会议上您可能收到怎样的抱怨、抵制、反对；stakeholder 的反馈将是你最宝贵的收获。没有互动和反馈的需求分析会是相当无聊和浪费时间的。切忌在大型的企业中，要慎重地计划每一次需求分析会，理由也很简单，企业组织越大，沟通的成本也越高。需求分析沟通的效率和成功完全取决于 CMDB 项目执行的方法论，取决于分析引导人的各种项目背景经验，还取决于对客户状况了解和上手的速度。\n","date":"2010-03-29T15:19:20Z","permalink":"https://martinliu.cn/2010/03/29/cmdb-requirement-analysis-practice/","title":"CMDB需求分析之最佳实践"},{"content":"[singlepic id=35 w=320 h=240 float=left]在最近的一年里，我基本上忙于 CMDB 的工作，没有什么业余时间来看看 OpenNMS 的情况。其实 OpenNMS 是最初引入我深入了解开源软件世界的东东。时隔 1 年之久，我上一篇关于 opennms 的文章是它是 1.6.1 版本，刚才查了一下，它最新的稳定版本是 1.6.10.\n看似它这一年里发展的比较慢，这让我感到些许地失望，大概地看一下一堆相关的 release notes。功能性的变化如下：\n新增和增强了一些 monitor 的和功能，主要有 http，dns，ldap，ssh，jmx 等，从最初的 snmp 采集，都这些采集功能；采集能力的增强是它这样的无代理监控程序永远的话题 UI 的功能的增强了一些 SNMP 采集仍然是他的主要能力，在这方面也有了一些改进 新增了一些网络设备品牌的支持 阀值配置也有改进 总的来说，作为一款能够采集各种 snmp mib 信息，能够出好看的性能报表，能够作为统一的告警事件平台，能够有简单易用的 UI，OpenNMS 做的显然是非常不错的。至今还行它还没有提出什么云计算相关的话题，可见他们还是一般比较稳健发展，不爱赶时髦的人。希望他们能做的更好。\n对于我的这个 blog 来说，之前写的 OpenNMS 和网管相关的东西比较多，以后可能会越来越少，就此和 OpenNMS 做一个总结。以后本 blog 可能会和目前做的 cmdb 和 itsm 相关这些内容为主了。\n","date":"2010-03-28T05:37:04Z","permalink":"https://martinliu.cn/2010/03/28/opennms-161-1610/","title":"OpenNMS 1.6.1 to 1.6.10"},{"content":"还是不能下决心把 blog 彻底迁移到国内的免费 blog，所以在此选择新的地方来安置它。最后决定这次把它放到美国的一个收费空间中。之前使用免费空间的时候，多是美国的免费空间。这次也走上了收费空间之路。不过昨晚和一个博友聊了一下，觉得.cn 域名真的是个没有前途的域名。所以我也不知道 martinliu.cn 能走多远，所以我还是秉持着一颗平常心，不烦不燥，翻墙并快乐着。毕竟 blog 是以娱乐为主，能看到 martinliu.cn 在线一天，也是个乐子。\n","date":"2010-03-27T07:09:42Z","permalink":"https://martinliu.cn/2010/03/27/martinliucnblog/","title":"重整旗鼓"},{"content":"\n","date":"2010-01-09T11:07:36Z","permalink":"https://martinliu.cn/2010/01/09/avatar/","title":"AVATAR"},{"content":" 目前磁盘存储市场上，存储分类（如下表一）根据服务器类型分为：封闭系统的存储和开放系统的存储，封闭系统主要指大型机，AS400 等服务器， 开放系统指基于包括 Windows、UNIX、Linux 等操作系统的服务器；开放系统的存储分为：内置存储和外挂存储；开放系统的外挂存储根据连接的方 式分为：直连式存储（Direct-Attached Storage，简称 DAS）和网络化存储（Fabric-Attached Storage，简称 FAS）；开放系统的网络化存储根据传输协议又分为：网络接入存储（Network-Attached Storage，简称 NAS）和存储区域网络（Storage Area Network，简称 SAN）。由于目前绝大部分用户采用的是开放系统，其外挂存储占有目前磁盘存储市场的 70%以上，因此本文主要针对开放系统的外挂存 储进行论述说明。 表一：\n[singlepic id=97 w=570 h=250 float=]\n今天的存储解决方案主要为：直连式存储（DAS）、存储区域网络（SAN）、网络接入存储（NAS）。如下表二：\n[singlepic id=98 w=533 h=352 float=]\n开放系统的直连式存储（Direct-Attached Storage，简称 DAS）已经有近四十年的使用历史，随着用户数据的不断增长，尤其是数百 GB 以上时，其在备份、恢复、扩展、灾备等方面的问题变得日益困扰系统管理员。 主要问题和不足为：\n直连式存储依赖服务器主机操作系统进行数据的 IO 读写和存储维护管理，数据备份和恢复要求占用服务器主机资源（包括 CPU、系统 IO 等），数据流需要回流 主机再到服务器连接着的磁带机（库），数据备份通常占用服务器主机资源 20-30%，因此许多企业用户的日常数据备份常常在深夜或业务系统不繁忙时进行， 以免影响正常业务系统的运行。直连式存储的数据量越大，备份和恢复的时间就越长，对服务器硬件的依赖性和影响就越大。 直连式存储与服务器主机之间的连接通道通常采用 SCSI 连接，带宽为 10MB/s、20MB/s、40MB/s、80MB/s 等，随着服务器 CPU 的处理 能力越来越强，存储硬盘空间越来越大，阵列的硬盘数量越来越多，SCSI 通道将会成为 IO 瓶颈；服务器主机 SCSI ID 资源有限，能够建立的 SCSI 通道连接有限。 无论直连式存储还是服务器主机的扩展，从一台服务器扩展为多台服务器组成的群集(Cluster)，或存储阵列容量的扩展，都会造成业务系统的停机，从而 给企业带来经济损失，对于银行、电信、传媒等行业 7×24 小时服务的关键业务系统，这是不可接受的。并且直连式存储或服务器主机的升级扩展，只能由原设备 厂商提供，往往受原设备厂商限制。 存储区域网络（Storage Area Network，简称 SAN）采用光纤通道（Fibre Channel）技术，通过光纤通道交换机连接存储阵列和服务器主机，建立专用于数据存储的区域网络。SAN 经过十多年历史的发展，已经相当成熟，成为业 界的事实标准（但各个厂商的光纤交换技术不完全相同，其服务器和 SAN 存储有兼容性的要求）。SAN 娲 ⒉ 捎玫拇?宽??00MB/s、200MB/s，发 展到目前的 1Gbps、2Gbps。 网络接入存储（Network-Attached Storage，简称 NAS）采用网络（TCP/IP、ATM、FDDI）技术，通过网络交换机连接存储系统和服务器主机，建立专用于数据存储的存储私 网。随着 IP 网络技术的发展，网络接入存储（NAS）技术发生质的飞跃。早期 80 年代末到 90 年代初的 10Mbps 带宽，网络接入存储作为文件服务器存 储，性能受带宽影响；后来快速以太网（100Mbps）、VLAN 虚网、Trunk(Ethernet Channel) 以太网通道的出现，网络接入存储的读写性能得到改善；1998 年千兆以太网（1000Mbps）的出现和投入商用，为网络接入存储（NAS）带来质的变化 和市场广泛认可。由于网络接入存储采用 TCP/IP 网络进行数据交换，TCP/IP 是 IT 业界的标准协议，不同厂商的产品（服务器、交换机、NAS 存储） 只要满足协议标准就能够实现互连互通，无兼容性的要求；并且 2002 年万兆以太网（10000Mbps）的出现和投入商用，存储网络带宽将大大提高 NAS 存储的性能。NAS 需求旺盛已经成为事实。首先 NAS 几乎继承了磁盘列阵的所有优点，可以将设备通过标准的网络拓扑结构连接，摆脱了服务器和异构化构架的 桎梏；其次，在企业数据量飞速膨胀中，SAN、大型磁带库、磁盘柜等产品虽然都是很好的存储解决方案，但他们那高贵的身份和复杂的操作是资金和技术实力有 限的中小企业无论如何也不能接受的。NAS 正是满足这种需求的产品，在解决足够的存储和扩展空间的同时，还提供极高的性价比。因此，无论是从适用性还是 TCO 的角度来说，NAS 自然成为多数企业，尤其是大中小企业的最佳选择。 NAS 与 SAN 的分析与比较 针对 I/O 是整个网络系统效率低下的瓶颈问题，专家们提出了许多种解决办法。其中抓住症结并经过实践检验为最有效的办法是：将数据从通用的应用服务器中分离出来以简化存储管理。\n[singlepic id=99 w=410 h=220 float=]\n由图 1 可知原来存在的问题：每个新的应用服务器都要有它自己的存储器。这样造成数据处理复杂，随着应用服务器的不断增加，网络系统效率会急剧下降。 图 2\n[singlepic id=100 w=398 h=168 float=]\n从图 2 可看出：将存储器从应用服务器中分离出来，进行集中管理。这就是所说的存储网络（Storage Networks）。 使用存储网络的好处： 统一性：形散神不散，在逻辑上是完全一体的。 实现数据集中管理，因为它们才是企业真正的命脉。 容易扩充，即收缩性很强。 具有容错功能，整个网络无单点故障。 专家们针对这一办法又采取了两种不同的实现手段，即 NAS（Network Attached Storage）网络接入存储和 SAN(Storage Area Networks)存储区域网络。 NAS：用户通过 TCP/IP 协议访问数据，采用业界标准文件共享协议如：NFS、HTTP、CIFS 实现共享。 SAN：通过专用光纤通道交换机访问数据，采用 SCSI、FC-AL 接口。\n什么是 NAS 和 SAN 的根本不同点？ NAS 和 SAN 最本质的不同就是文件管理系统在哪里。如图：\n[singlepic id=101 w=455 h=223 float=]\n由图 3 可以看出，SAN 结构中，文件管理系统（FS）还是分别在每一个应用服务器上；而 NAS 则是每个应用服务器通过网络共享协议（如：NFS、CIFS）使用同一个文件管理系统。换句话说：NAS 和 SAN 存储系统的区别是 NAS 有自己的文件系统管理。 NAS 是将目光集中在应用、用户和文件以及它们共享的数据上。SAN 是将目光集中在磁盘、磁带以及联接它们的可靠的基础结构。将来从桌面系统到数据集中管理到存储设备的全面解决方案将是 NAS 加 SAN。\n","date":"2010-01-07T05:20:06Z","permalink":"https://martinliu.cn/2010/01/07/what-is-das-nas-san/","title":"图文阐释-DAS-NAS-SAN"},{"content":"CMDB 的价值点分为两类：硬收益和软收益。从硬收益的角度，CMDB 的用户可能会让你来描述 CMDB 对他们的价值点。下面的几个轶事可以作为收集 CMDB 可能为你的企业带来价值点的几个方向：\n把IT环境的可视化带到更高程度 \u0026ndash;一领先的制热和冷却系统供应商指出，他们始终无法很好的理解一个计划外停机时间对用户所造成影响。例如，当只有25个用户受到了网络中断问题的影响，IT部门必须通知用户群中的全部100个用户。这会导致一个客户满意度低的反馈。CMDB使该公司能够理解配置项之间的关系，并确切地知道在任何确定时刻什么用户会受到影响。现在用户间可信的沟通能够来自于各个IT部门，并且使IT成为业务不可分割的一部分。 按业务目标来安排系统变更的优先度\u0026ndash;大型设备制造商不得不关闭了其所有的系统，后来发现不知道哪些服务器应该先启动。CMDB使公司能区分关键业务元素的优先度，确保减少计划外的停机时间，无形中降低了收入损失的风险。 减少软件许可证的费用的同时确保用户和服务器能整体的满足许可证遵从性 \u0026ndash; -的半导体制造商开展了一个审计，结果另他们感到震惊：该公司支持在为大量已经报废的服务器支付支持和维护费用。实际上，该公司关于报废资产的数量已经长期和实际不符了。CMDB有助于该公司发现这一问题，并重新分配预算资金，以更好地支持现有的基础设施。 为加快服务器整合提供更深层次的资产和关系信息 \u0026ndash; 一大型的金融服务提供商注意到，在其行业的公司通常在一个较短的时间内，会进行几次成功并购和整合。对于如何整合所有的IT部门是一个重大挑战（有时是次要的），他们往往是停留在相互隔离的工作状态下。然而，使用CMDB的公司就能够有效地集成新的收购，从而节省资金和为公司内部建立统一的IT业务形象。 IT要实现CMDB的硬收益，一般通过降低以下对象的相关成本来实现：人、第三方服务、软件、硬件和设施。这些方面的价值点可以通过财务方面的分析报表来反映出来。 CMDB能够实现的价值还包括哪些很难衡量的方面，例如下面的例子解释了这些软价值：\n服务台 \u0026ndash; CMDB可以从提高事件和问题处理和解决效率和效果的方面来体现出硬利益的成效。还可以认为，CMDB使这种改善更可行，往往服务台技术员从尖锐的客户那里来收集信息是一项非常不快的工作，CMDB可能会提高支持人员支持客户的效率，提高客户满意度。另外，通过为服务团队提供更好的信息，你可能使用较低技术水平的工作人员来完成的相同水平的服务工作，降低在工资成本上的成本。 变更管理 \u0026ndash; 通过CMDB这个流程得到了很大的提升，更完善的风险评估，提供更多的信息来评价类似类型CI在过去时间里的变更成功率，并能更好的理解变更CI与其上游和下游其他基础设施组件的依存关系。其结果可能是使企业用户对IT所提供给他们的服务感到更满意，但这是难以像硬效益一样的量化的。 连续性管理 \u0026ndash; CMDB的变成了持续管理的记录源泉。拥有了能准确的、更新的描述IT环境状况的信息后，灾难恢复被大大地简化了，这提高了整个组织的信心。这是一个明确的好处，但也不是那么容易量化。 与业务的影响与和谐 \u0026ndash; CMDB使CI依赖关系能被更深入的了解。这种理解大大简化了连接CI到依赖于IT基础设施的业务流程或者服务的过程。使IT与业务更紧密的和谐是至关重要的，例如提升响应速度和让业务具有更好的竞争优势，但对比硬利益它也可能是难以量化。 以上内容参考了BMC出版的\u0026laquo;step by step to build a cmdb\u0026raquo;;以上软效益对于不同的企业而言可能是不同的，总的来说前两条是显而易见的，你也可能有更好的关于硬效益和软效益的总结和期望。如果有的话一定需要在项目建设前，或者初期阶段中，与CMDB项目相关的利益人和用户做细致的价值点讨论和确认是非常关键的。更进一步价值点的确认也更进一步的指导了CMDB项目实施的方案。BMC Atrium CMDB通过其完备的功能，以及那些以CMDB为核心而建立的ITSM流程应用，能很好的为企业用户实现以上的相关效益。 ","date":"2010-01-01T05:23:06Z","permalink":"https://martinliu.cn/2010/01/01/cmdb-value-points/","title":"CMDB Value Points 价值点"},{"content":"Martin Liu\u0026rsquo;s blog move to 72pines. I will see how long I could still here. Let\u0026rsquo;s say 6 months.[fergcorp_cdt_single date=\u0026ldquo;1 June 2010\u0026rdquo;]To do list[add] I\u0026rsquo;d like to blog more about C-Bank CMDB project implement.[add] I hope I could have sometime for playing with open source software, like opennms, zenoss, otrs, etc\u0026hellip;[del] All of duplicate blog post will be deleted from some of my old blog site, including blogspot, chinaunix, msn space etc\u0026hellip;To be continued\u0026hellip;.\n","date":"2009-12-31T09:26:10Z","permalink":"https://martinliu.cn/2009/12/31/at-end-of-2009/","title":"At end of 2009"},{"content":"如果拥有个人博客，并且拥有个人域名，正在租用一个小服务商的虚拟机，那么你的网站可能已经无法访问，由于域名为注册被封，或者由于服务商的机器干 脆被连窝端而无法访问。如果你是我的 blog 的读者的话，我想你已经发现，我的 blog 已经无法访问两天了。我已经可以想象今天的国内互联网上，国内的自 由博主们，已经是哀鸿遍地了！！！更有甚者成，我国之互联网正进入全球最大的局域网时代。对垃圾网站的严打可以，但是打到这个程度，究竟打击了谁，我相信那些害群只马一定会转移到国 外，继续他们的活动。所以，倒霉的还是很多自由博主，还是那些提供小型博客服务的小服务商。我想新浪、搜狐、百度他们的 blog 的注册量这几天肯定在节节 攀升吧~那就透着乐吧，我想他们肯定在唱“我们的生活充满了阳光~~~~”国内博客的行业亟待实名制管理，自由博主们也需要阳光。我的博客还无法还原两个 月的内容丢失，阴霾笼罩着我。\n","date":"2009-12-30T15:41:53Z","permalink":"https://martinliu.cn/2009/12/30/e59e83e59cbee7bd91e7ab99e79a84e6ae89e891ace59381-e4b8aae4babae58d9ae5aea2/","title":"垃圾网站的殉葬品-个人博客"},{"content":"港片也能这么拍的如此严肃，港人爱国，武打片打到这么痛楚，普通人普通情感才感人，师徒，父子，领袖和革命党，朋友，夫妻，宏大的历史背景下，平常市井生活里，对最关心的人，关心到底有多少，想爱趁早多一点！\n","date":"2009-12-24T13:49:39Z","permalink":"https://martinliu.cn/2009/12/24/e58d81e69c88e59bb4e59f8e/","title":"十月围城"},{"content":"Remedy 的开发人员或许熟悉这个邮件列表，ARSlist.org；如果没注册的话，一定需要注册一下啊，不为别的，学学英语，看看其他人都聊什么，有什么问题总是不错的。下面这个段子就是最近我看过的最扯的讨论。关键词：Remedy, 职位， OH 州，辛辛那提，Developer，伊拉克，ARS 6.3, ARS 7.5, ITSM 7.5, 巴格达， AK 47，武器，活动链，过滤器，阿富汗，薪水，简历，顾问\u0026hellip;\u0026hellip;. engoy！！！！\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;Job: Permanent - Lead Remedy Developer - Cincinnati, OHDear List,\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;1\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-Merry Christmas!Title: Lead Remedy DeveloperLocation: Cincinnati, OHDuration: Permanent (Relocation is offered)Start Date: 2-4 WeeksMust haves:- 5+ Years experience with Remedy- Experience with 7.x- Stable Resume (No Consultant Resume’s) (Client does not like job hoppers and will reject)subtitle: As a senior developer, the individual will create, design, develop, test and implement Remedy applications and workflow enhancements from business requirements, in accordance with the corporate procedures and standards. This individual may also serve as a business analyst or project manager on select projects and may train Remedy users as required.Additionally, the individual will be responsible for the daily administration, maintenance, monitoring and support of all Remedy applications, servers and reporting in a high-available 24x7 environment. The individual is expected to evaluate Remedy application patches, enhancements and new releases as necessary.ITIL certificationCMDB designProject Management and SDLC experienceBusiness requirements gatheringRemedy Integration with other technologies and systemsRespectfully,Joshua KitchenSenior RecruiterKforce Federal937.449.1749 officejkitchen@kforce.comhttp://www.govtrecruiter.comGreat People = Great Results®\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;2\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- Stable Resume (No Consultant Resume’s) (Client does not like job hoppers and will reject)My 2 centHaving been a Consultant for 8+ years (Remedy Developer for 13+ years), and then taking a Full Time Remedy position with a local company, the value I bring to the organization is huge. As I have seen a lot, traveled the world, assisted a wealth of customers with numerous ITSM and bespoke applications, have a breath of experience that most “Stable” Remedy developers do not have. If there is a seasoned Developer/Consultant that is ready to settle down and eliminate traveling, your client should really rethink their definition of “Stable”, because a Consultant is not a “Job Hopper”Doug\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;3\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;Joshua,- Stable Resume (No Consultant Resume’s) (Client does not like job hoppers and will reject)Really! What planet is your client from? I would think most consultants would be glad to MILK a project for ALL its worth. But that would be bad business for the employer. So projects tend to adhere to budgeting constraints.It is not the consultant’s fault that many Remedy projects end on or ahead of schedule. Unless he/she has worked TOO hard. Apparently your client does not want THAT GUY.\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;4\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;As my last \u0026ldquo;Permanent\u0026rdquo; job was for an \u0026ldquo;UNStable\u0026rdquo; company that Disappeared one month end of last year,I couldn\u0026rsquo;t have said it better myself\u0026hellip;spot on Doug!Happy Holidays To You and Yours!\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;5\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;Read between the lines dudes :-)We need a Lead Remedy developer who has the experience of a junior/trainee Remedy Administrator, and who is willing to work at the wages of a gas station attendant.. No expenses paid. Must be willing to work late hours - no overtime.. Must have had his first job as a gas service attendant for at least 5 years..;-)Joe\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;6\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;You guys give ol Josh a break, he is just relaying what his customer wants… If any consultants want to apply for that position I bet you can send an updated resume to accommodate getting to the interview. I think that it’s funny though that some employers do not realize anything about this product or the way that it is developed or administered. But I guess that is what recruiters are actually for right?\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;7\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;Hey Tommy,We just like to have harmless fun sometimes :-) We know (at least most of us) Josh for a while as well as the fact that recruiters / employers sometimes have no clue what they are talking about. Time and again I have come across employing interviewers question me about the implementation of ITIL as if it were a physical product. Its nothing new.Yes not so hard to update a resume to make it like you were on a \u0026lsquo;stable\u0026rsquo; job and not a \u0026lsquo;job hopper\u0026rsquo;. Technically if I were to do that, it would look like I worked for just 2 companies over the 12 years I have worked with Remedy. I had to do just quite the opposite when I started looking for consulting gigs, and name every customer my old company had as a different project so that it would look more like a \u0026lsquo;job hoppers\u0026rsquo; resume.Its just a wrapping paper. At the end of the day you are the real stuff - what you know or do not, and can do or cannot, makes the difference to a smart employer (if they exist).Joe\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-8\u0026mdash;\u0026mdash;\u0026ndash;Did you notice the slight jab at the end of the note? I just wanted to get in a shot. It drives me crazy that there is such a disconnect between the hiring manager and the HR team in most companies.One of my favorite job adverts had the perfect candidate as being aged 21 – 25, Bachelors degree and 6+ years experience in a corporate environment. The math just didn’t add up unless you started your degree plan at before you were 13.\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;9\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-As recruiters who have filled numerous Remedy positions in IRAQ and elsewhere we have tried to always be responsive to the needs of the client and the realities of the talent pool. The external recruiter\u0026rsquo;s role does not stop with the resume.With respect to the current thread, there is a real clue re the client\u0026rsquo;s mind set and/or lack thereof, when they use the word \u0026ldquo;Permanent\u0026rdquo; in their job description. How do you spell \u0026ldquo;law suit?\u0026quot;There are no \u0026ldquo;permanent\u0026rdquo; jobs out there._ Contract positions or_ Employee positions\u0026hellip;Time for a reality check. We expect to be looking for \u0026ldquo;Senior Remedy Engineers\u0026rdquo; for both Afghanistan and Iraq\u0026hellip;Anyone interested?Happy HolidaysSincerely,Jeff GlaserINVIZCORP703-729-3382\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;10\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-Do the Afgan and Iraq positions come with weapons training? Haven’t fired a Mark 19 in a while but I’m sure the mechanism hasn’t changed would love to renew the qualification though lol\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;11\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-Someone actually mentioned age as a desirable quality in a job posting? That would be discriminatory.\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;12\u0026mdash;\u0026mdash;\u0026ndash;If you had issues with the weapon.. would you check active links or filters to see why it’s not firing?\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;13\u0026mdash;\u0026mdash;\u0026mdash;-Lol Is it Friday already?!?! That was a pretty good one.\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;14\u0026mdash;\u0026mdash;\u0026mdash;-Active links, since the trigger is executed by the user action.Rick\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;15\u0026mdash;\u0026mdash;\u0026mdash;-But that weapon is an automatic so you would need to check filters as well if the first round went off but then misfired on the next firing order. Maybe even check API logging of the belt stopped feeding correctly.\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;16\u0026mdash;\u0026ndash;I would have an escalation throw out a grenade every 5 minutes. RUNIF: weapon jams.. JI’d stick around Tommy since you already had weapons training… unless, of course, you trained with Dick Cheney..\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;TTTT_\u0026mdash;\u0026ndash;___/\u0026rsquo;\u0026rsquo;\u0026rsquo;\u0026rsquo;\u0026rsquo;\u0026rsquo;\u0026rsquo;\u0026rsquo;\u0026rsquo;\u0026rsquo;(__O] \u0026mdash;\u0026mdash;\u0026mdash;-__ ____/]_\u0026hellip;\u0026mdash;\u0026rsquo;\u0026rdquo;\u0026quot;\u0026quot;_ \u0026ndash;\u0026rsquo;\u0026rsquo; Q _@|\u0026rsquo;\u0026rsquo;\u0026rsquo; ._ ___=\u0026mdash;\u0026mdash;\u0026mdash;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;| ..\u0026ndash;\u0026rsquo;\u0026rsquo;| l L |_l || ..\u0026ndash;\u0026rsquo;\u0026rsquo; . /-_j \u0026rsquo; \u0026lsquo;| ..\u0026ndash;\u0026rsquo;\u0026rsquo; / , \u0026rsquo; \u0026lsquo;|\u0026ndash;\u0026rsquo;\u0026rsquo; / ` \u0026lt;br /\u0026gt;|\u0026rsquo; \\ -- \u0026lsquo;-.\u0026rsquo;. /\u0026rsquo;-./\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;17\u0026mdash;\u0026ndash;You could also add in an exclusion in the Runif clause just to be on the safe side If $USER$ != “dchene1”Nice AK. You know I think that symbol art is coming back en vogue,\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;18\u0026mdash;\u0026ndash;What would be the client type? Unknown?\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;19\u0026mdash;\u0026ndash;Client type would be terrorist or freedom fighter depending on who was holding the UI.Escalations would be no good unless you happened to be testing something when the enemy was in line with the weapon that was firing at the given time or interval!Filters would be no good because of the network lag between the client and the server by the time the result computed fire, the target had moved out of the kill zone!Sorry guys and girls but always ends up with some grunt holding the weapon and firing the trigger.Rob\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;20\u0026mdash;\u0026ndash;Your right Rob. The \u0026ldquo;grunt\u0026rdquo; part.As it turns out Joe was spot on about the position \u0026ldquo;gas station attendant\u0026rdquo;.I haven\u0026rsquo;t see the wage that was offered, since I worked with the old UNIX client.Remember\u0026hellip; that was before we had Active Links\u0026hellip;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;21\u0026mdash;\u0026ndash;You could have actions like Change Fields (of fire), Open Window (for grenades), and Call Guide (for arty).Rick\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;22\u0026mdash;\u0026ndash;Don\u0026rsquo;t forget to include an active link guide for autofire.\u0026lsquo;threats\u0026rsquo; \u0026gt; 1 AND \u0026lsquo;LastThreatEliminated\u0026rsquo; != \u0026ldquo;Yes\u0026rdquo;SQL Statement Set FieldSELECT MIN(TargetDistance) FROM CURRENT_BATTLEFIELD.FIELD_OF_FIRE WHERE TARGET_STATUS=\u0026lsquo;ALIVE\u0026rsquo;SET FIELD \u0026lsquo;ThreatDistance\u0026rsquo; = $1$If \u0026rsquo;threats\u0026rsquo; \u0026gt; 1PERFORM-ACTION-PULL-TRIGGER \u0026ldquo;\u0026lsquo;ThreatDistance\u0026rsquo;\u0026quot;On a serious note. If you\u0026rsquo;re looking for a contract, go for Iraq before Afghan. They\u0026rsquo;re trying to pay people the same amount of money for both places. Left Iraq 6 weeks ago. No way I\u0026rsquo;d go to Afghan for the same pay. (Living conditions are worse, more time off to sit around and do nothing(very boring), and we got almost no incoming at Victory in Baghdad.)As far as the Iraq posting. It says ARS 6.3 but that description is 4 years old. It\u0026rsquo;s 7.1, ITSM 7.0.3. 7.5 is probably never going to happen there. But if you you\u0026rsquo;re looking for a new contract and want to get paid pretty good to learn ITSM 7 and get some experience with 7.1 (that\u0026rsquo;s why I went) then send Jeff Glasser your resume.Jason BessRemedy Developer/ConsultantBess Development Corporation(My position is the one they\u0026rsquo;re back-filling in Iraq right now. I won\u0026rsquo;t lie, it sucked being there. But the $95k tax exclusion, massive paychecks, and experience were unbeatable.)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;The End\u0026ndash;请问 16 楼贴出的是何物？哈哈:)\n","date":"2009-12-24T13:35:26Z","permalink":"https://martinliu.cn/2009/12/24/is-that-a-joke-of-remedy-developer/","title":"老美真的很扯，一个职位的帖子被顶了22次"},{"content":"在 ITIL v3 以后，配置管理进化为“服务资产和配置管理 SACM”，换句话说，资产和配置管理不分家。两个流程应该是融合的。从微观上看资产管理设计到 CI 的所有生命周期状态，而这个服务资产在 CMDB 中出现的状态为整个生命周期中的一部分。\n最好能通过资产管理为统一入口，来完成对 CMDB 中资产的生命周期管理。例如：一台服务器在到货以后，完成资产入库后，就应该在 CMDB 中自动创建 CI，在上架部署了软件后，有配置资产自动采集工具，采集回详细配置信息后，资产状态就自动变为“部署”，当在运行维护中服务器宕机或者维护时，在资产管理中也能看到更新的信息。下面是建议的服务资产的生命周期状态: ","date":"2009-12-13T07:45:00Z","permalink":"https://martinliu.cn/2009/12/13/service-asset-ci-life-cycle/","title":"资产CI的一生"},{"content":"自从 7.6 发布和以后一直没有时间安装，通过最近的几次安装，积累了一些经验，供大家参考。在安装开始之前请一定查看ARS_7500_Comp_Matrixv1001.pdf文档，保证操作系统、数据库、中间件和 JDK 的版本都符合要求。如果是安装生产系统的话，建议把数据库和应用服务器分开，硬件配置也一定参考 Remedy ITSM 安装手册中的建议硬件配置要求。\n最近在 Linux 的虚拟机上做了一次安装，相关细节如下:\nSuse Linux Enterprise server 10 sp2 64 bit Oracle 10G 64bit (10201_database_linux_x86_64.cpio.gz) JDK 1.6(jdk-6u6-linux-i586.bin) 在 Suse Linux 上安装 Oracle 还是比较容易的，可以参考这个安装手册进行，下载。数据库安最好按照成 utf8 字符集，如下图所示：\nRemedy ITSM 套件的安装分为三个步骤：1）ARS 7.5 SP3 的安装；2）Atrium CMDB7.6 安装；3）ITSM 7.6 安装；其中第一步是最重要的，第二步骤如果安装产品目录数据的话时间花费比正常多一点。Remedy ARS 7.5 是最新的补丁包，它修复了 sp2 的很多 bug；是 Remedy ITSM 7.6 安装的必须版本。在安装 ARS 的时候需要准确的导出相关的环境变量，如果环境变量没有或者不够的话，安装程序则无法正确地连接数据库，下面的例子可以参考一下。\n每一步安装完成之后都需要详细查看相关的日志，确保每一步都安装完全正确。在安装完 ARS 之后一定要为服务器添加所有相关 License。\n","date":"2009-11-28T09:29:04Z","permalink":"https://martinliu.cn/2009/11/28/remedy-itsm-76-installation-tips/","title":"Remedy ITSM 7.6 installation Tips"},{"content":"妹妹问：那么 2012 年的奥运会还办不办了？无语\u0026hellip;..这个电影中有很多情节与中国相关，特效不错，这可能是吸引人去电影院看的原因吧。\n这个电影倒是让人对玛雅文化产生了兴趣，有空可以看看。\n","date":"2009-11-23T04:54:19Z","permalink":"https://martinliu.cn/2009/11/23/2012/","title":"2012"},{"content":"看完这个视频之后，还是没搞清楚：它到是一个快速的浏览器，还是一个快速启动的 OS 加浏览器，如果它仍然需要 OS 的话，那么它不过是一个 Redesigned 的 OS+操作系统。说白了就是瘦客户端加肥浏览器的组合吧！您用 Google 的浏览器么？我用了一次就删除了，至今没有尝试装 Google 的操作系统。\n","date":"2009-11-23T04:38:51Z","permalink":"https://martinliu.cn/2009/11/23/whats-google-chrome-os/","title":"What's Google Chrome OS"},{"content":"自打承接了《Step by Step Guide to Building a CMDB (Updated for ITIL V3)》的翻译工作之后，由于平时工作太忙，翻译工程只能在业余时间完成；现在渐渐感到了此项工作的压力，每每想到读者对英文翻译版本读物的高期望和要求时，就愈加感到此项工作责任之重。不过本书对我来说还是一剂很好的补品，对我最近的 ITSM 项目都有直接的借鉴和指导作用。说来此书有很多实用且精彩之处，相信读了英文原版的人更能有所体会。我忍不住想把其中的部分内容提前与你们探讨，这里想与你们分享如下两个内容。\n上图还给所有 CMDB 用户一个清晰地 CMDB 功能点考察点，CMDB 作为业务服务管理的核心，各个厂商其实并没有达成解决方案功能的标准和共识。通常情况下厂商提供的 CMDB 产品的发展和起源有以下几种情况：1）按照 ITIL 中对 CMDB 的需求和标准从无到有开发的标准 CMDB 产品；2）伴随变更流程或者业务影响管理而开发的 CMDB 功能模块；3）伴随配置自动化发现工具而开发的相应 CMDB 功能模块；4）应资产管理或者监控工具扩展而生的 CMDB 功能产品。用户在挑选 CMDB 产品的时候一定要明确 CMDB 的核心功能，除了以上功能外，其他的附加功能可能是 nice to have 的功能，而非必须。本图位于原版书的 134 页，如果您对我的翻译有建议请留言，多谢！\n上表为评估一个 CMDB 产品厂商的综合打分评价表样例。在选择并且评测一个 CMDB 厂商时，需要仔细考察的产品功能共有 8 点。用户需要注意的是一定要搞清楚其中的每一个功能是否是由厂商的 CMDB 产品的相关模块所提供的，如果不是的话需要搞清楚，每个功能是否是 CMDB 的外围或者其他产品模块，或者二次开发实现的。如果是这样的话，这种解决方案可能不是一套集成统一的解决方案，可能出现其他附加非 CMDB 产品的采购，可能在实施阶段付出不必要的集成和开发费用。虽然这些潜在因素在采购和实施阶段可能是隐形出现的。征集上表中相关术语的中文翻译：Weighted ，Weighted Rating Score，Total Weighted Score。有好的建议请留言。本图位于原版书籍的 141 页。\n","date":"2009-11-19T16:32:22Z","permalink":"https://martinliu.cn/2009/11/19/how-to-select-a-cmdb/","title":"CMDB选型解密"},{"content":"二零零九年的第二场雪，比以往的都来的大一点。昨天晚上的大雪让我感到惊喜，今天早晨空气非常好，不过地铁里的人很多。\n","date":"2009-11-10T06:42:20Z","permalink":"https://martinliu.cn/2009/11/10/e4b88be99baae4ba86/","title":"下雪了"},{"content":"这个电影的官方网站是很炫的，但是看后感觉真的不怎么样。http://www.knowing-themovie.com/ 看是感觉有点悬疑，接着又一点点的惊悚，然后算是带点科幻吧，地球被一个太阳的耀斑给毁灭。俩小屁孩被什么人/外星人接到了另外的一个星球上。难道这就是传说中的亚当与夏娃么？\n","date":"2009-11-09T02:52:10Z","permalink":"https://martinliu.cn/2009/11/09/knowing/","title":"Knowing"},{"content":"康肃问曰：“汝亦知射乎？吾射不亦精乎？”翁曰：“无他，但手熟尔。”康肃忿然曰：“尔安敢轻吾射！”翁曰：“以我酌油知之。”乃取一葫芦置于地，以钱覆其口，徐以杓酌油沥之，自钱孔入，而钱不湿。因曰：“我亦无他，惟手熟尔。”康肃笑而遣之。ZT\u0026ndash; 欧阳修《卖油翁》MY VIEWPOINT：IT 管理的好坏与否，不是依靠个体的技术能力和熟悉程度。铜钱上的孔，是衡量能力和筛选智慧的重要工具。智慧获取数据抽取-\u0026gt;分析-\u0026gt;转化的能力和工具。这三个过程中越往后对工具的依赖程度越低。如图所示，“数据包”是从一个层次传递到下一个层次。“智慧”层次具有作出明智决策必需的所有组成部分 —数据、信息和知识。当然，可以在任意层次作出决策，这取决于现有的结果和条件。下面的例子用于说明在各个层次进行决策的过程：　**数据层：**服务台经理发现有二十位客户等待打入电话。他可能会决定临时增加一线客户服务人员的数量，这是根据一条数据制定的决策。　信息层：在另一类似的情况下，有 20 位客户等待打入电话，但这次经理掌握了更多的数据。他知道有一台目前已停机但马上将恢复正常的服务器。在这种情况下，经理可能决定稍后再增加一线客户服务人员的数量，因为他（或她）怀疑这两个问题是相关的。在拥有多个数据源的情况下，经理掌握的信息更多，并将根据可用信息作出决策。　**知识层：**服务台经理发现等待打入电话的客户不断增多，而且某台服务器即将接近满负荷运转。因为她拥有用以说明如何应对此情况的信息，所以可以立即采取适当的行动隔离并解决问题。这个决策是基于知识作出的。　**智慧层：**IT 执行官正在温习上个月的知识，并发现某一供应商提供的几台服务器出了问题。他们将决定要求供应商评估其所有服务器，以确定其他服务器是否会出现同样的问题。这个决策是基于智慧作出的。　尽管这些例子可能过于简单，但它们可作为理解“智慧分层体系”的参考。来源：行业外网\n","date":"2009-11-03T02:25:50Z","permalink":"https://martinliu.cn/2009/11/03/how-to-get-smart/","title":"汝亦知射乎"},{"content":"好消息《Step by Step Guide to Building a CMDB (Updated for ITIL V3)》即将翻译成中文出版。市场里 ITIL 的书越来越多，但是讲 CMDB 的书却一直很少，能讲解清楚 CMDB 建设过程的的书就更少。可是国内 ITIL 用户 CMDB 建设之瓶颈却越来越明显，我们希望有一本好的书作为这项重要工作的参考指南。给此书起一个好的名字是头等大事，目前能想到的书名如下：Step by Step Guide to Building a CMDB 中文书名？(polls)寻求前 100 名投票者，请对以上书名投票，并评论；如果您有更好的书名，欢迎推荐；请在下面留言，请正确填写邮箱，您推荐书名一旦被选用必有感谢送上。\n","date":"2009-10-29T01:48:58Z","permalink":"https://martinliu.cn/2009/10/29/pick-a-book-name-for-step-by-step-guide-to-building-a-cmdb/","title":"选书名"},{"content":"又一个小人物大英雄的美国片。10-1 前后红色电影充斥所有影院，这是近期看过的最好看的一部电影了。比较好的刻画了一个人物的多面性。影片中描写了很多耐人寻味的小概率事件。这个情节比较紧凑，高潮出现在主角被迫送钱。故事结尾他乘坐地铁，带着一加仑牛奶平安回家，看似一个小市民平常的一天。电影海报如下图所示。\n","date":"2009-10-22T14:12:47Z","permalink":"https://martinliu.cn/blog/2009/10/22/small-person-big-hero/","title":"小人物大英雄"},{"content":"下面是两个 Youtube 上的视频，短短 5 分钟的视频就把云计算的相关核心概念解释的很清楚。好像国内吧 Youtube 给屏蔽了，上面的视频可能看不到，Google 真的应该和中国政府把关系搞好，哎~~\n","date":"2009-10-21T04:36:11Z","permalink":"https://martinliu.cn/2009/10/21/what-is-cloud-computing/","title":"何谓云？"},{"content":"Dell is a big company, if you wants to know how DELL does IT management with BMC, please check out this vide form Dell website.DELL 是一个家喻户晓的公司，它是如何做 IT 管理的呢？请查看这段来自 DELL 网站的视频。视频中谈到 DELL 采用的是全套 ITSM 套件，提到很多的是相关流程是如何使用 CMDB 的配置信息的，从一个侧面我们可以看到配置管理的重要性。CMDB 可以看着成熟客户的标志。\n","date":"2009-10-20T03:17:01Z","permalink":"https://martinliu.cn/2009/10/20/how-dell-does-it/","title":"DELL如何管理IT？"},{"content":"If you have no idea about how to build a CMDB, you should check out this document. It come from http://www.bmc.com/products/product-listing/53556216-141391-2117.htmlDownload it: Step by Step Guide to Building a CMDB (Updated for ITIL V3) (pdf)该《手把手 CMDB/CMS 构建指导手册》包括了配置管理数据库/系统建设的所有相关流程、技术和指导性建议。如果你有 CMDB 的建设意向，该手册非常值得仔细阅读。欢迎留下一个反馈，投票或者留言都行。[poll id=\u0026ldquo;8\u0026rdquo;]\n","date":"2009-10-17T09:37:08Z","permalink":"https://martinliu.cn/2009/10/17/step-by-step-guide-to-building-a-cmdb/","title":"手把手教您构建CMDB/CMS"},{"content":"[caption id=\u0026quot;\u0026quot; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;406\u0026rdquo; caption=\u0026ldquo;dmtf.org\u0026rdquo;][/caption]当然是配置项和它们之间的关系，即：CI 和 Relationship。 那么如何规划那些类型的 CI 和 Relationship 需要保存到 CMDB 中呢？可以参考的数据模型是 DMTF 的通用信息模型，它是以面相对象的方式来描述各类 CI 和关系。它是一个工具用来帮你对环境中的各种物理和逻辑的 CI 和关系进行分类，参考这个模型选择一些有用的类（广度），然后在参考它对每个类属性的描述（粒度）。这些类的选择只是一个初步的研究，每个 CMDB 厂商和工具对其实施和参考的力度都不同，也需要看您具体实施的是什么工具。例如：你需要描述银行基金业务系统，你可能选择的 CI 类包括：客户群、业务流程、业务活动、业务服务、IT 服务、应用系统、应用、软件服务器、服务器、网络、存储等；关系包括：组件、依赖和影响。CI 类和关系的选择也基本上遵循够用就好的原则；而且每个类对应的 CI 实例都需要有人负责管理维护，需遵循，谁负责、谁维护的原则保障其属性的精确性。对于整个 CMDB 来说如果存在没有 Onwer 的 CI 或者关系，如果它是由自动化配置发现工具来更新的；那么它可以存在，如果不是的话，它可能根本就不该存在。所以 CMDB 中保存的数据不是越多，越细越好；而是够用就好，能保证更新就好。由于数据根本就不是免费的，即使国内的人力成本低，也不应该雇用一帮专职更新 CMDB 的人。 综上所述：我们说明了 CMDB 中数据选取和存放的最基本原则和方法，在 CMDB 产品选型过程中需要着重考察产品的数据模型本身和其管理的能力，还包括其 CI 和关系的扩展和定制能力；包括数据类型的支持和界面定制的程度。那么 CMDB 中的 CI 和关系有该如何展现呢？这是 CMDB 系统的另外一个功能：可视化。下面是一个 CI 和关系展示的实例供参考：[http://media-001.yo2cdn.com/wp-content/uploads/266/26670/2009/10/s1-4-blog.swf#swf\u0026amp;width=320\u0026amp;height=320]全屏查看或者下载 Flash 文件第一代的配置展示方式是，纯数据表格方式。第二代具有一种固定格式的图形展示方式，除了那几张视图外，别的需要单独开发。下一代的具有各种视图定制功能，并且支持关系和 ci 的过滤等等。\n","date":"2009-10-05T15:21:24Z","permalink":"https://martinliu.cn/2009/10/05/what-does-cmdb-store/","title":"CMDB中存什么？"},{"content":"趁着国庆长假，我有空吧 Blog 从国外的免费虚拟主机搬回国，搬到了 yo2.cn。原因意外，不知道为啥，访问 martinliu.cn 首页时，总是被重定向到 myfacebook.net 上，访问其它二级页面没有问题。这个问题让我着实抓狂了好几周，国庆前的几周一直在上海出差，比较忙，基本上 9 月九荒废了，别说解决这个问题，就连一篇 blog 也没有时间写啊！想到现在还是没有想清楚，被重定向的原因到底为何？可能是被黑了，可能是被强制添加了广告。不过这个事件也不全是我搬回国的原因，其它原因：\n国内读者居多，从google的统计上可以看出，本blog的主要读者都在国内。 域名已经备案了，上次转到国外的原因是域名未备案 实在懒得自己维护插件和blog本身，我已经把blog模版恢复到了默认模版，插件已经减少到最少，这样blog也可以快一点 实在没有精力维护虚机和域名绑定之类的事，WordPress对我来说可能只剩下一种功能就是Publish，呵呵其它的工作都交给服务商吧。 目前用的是DNSPad的DNS服务，yo2的WordPress服务，他们两个好像都与针对国内电信、网通和教育网的加速功能。那么目前您觉得网站速度如何了呢？方便的话给我一个反馈哦。[poll id=\u0026ldquo;7\u0026rdquo;] ","date":"2009-10-05T09:16:20Z","permalink":"https://martinliu.cn/2009/10/05/bo-ke-zai-ci-ban-jia-hui-guo/","title":"博客再次搬家回国"},{"content":"[gallery link=\u0026ldquo;file\u0026rdquo; columns=\u0026ldquo;3\u0026rdquo; orderby=\u0026ldquo;ID\u0026rdquo;]图片说明：\n十月一日，早晨在阳台上拍摄的空军演习，有8架战斗机 十月一日，早晨在阳台上拍摄的空军演习，有4架战斗机 十月一日，晚上到北京中轴线南端的“永定门”，准备观看天安门的礼花 图片4-6，十月一日,在天桥附近看到的天安门广场的礼花，很壮观 由于照相机有限，拍的不是很清楚，全当留个纪念吧。 ","date":"2009-10-05T04:29:44Z","permalink":"https://martinliu.cn/2009/10/05/guo-qing-l/","title":"国庆掠影"},{"content":"New IT Job: CMDB Manager从此 IT 部门有多了一个职位 CMDB 经理，不过某人的工作量加倍了也没准哈哈，从这个文章中可以看出这并不是一个可有可无的职位，而且 CMDB 的建设和推广，以及管理和其他的 ITIL 流程没有区别，需要结合技术、流程和人老三样，而且要再次改造人们对于配置管理的行为方式和文化了。Role Overview: CMDB ManagerCMDB 经理负责管理和维护您的 CI，工作内容都有了，CIT/CTO 招不招这个人由您。CMDBs reduce costs, automate tasksCMDB 更多的不是一种技术，更多的是流程，联邦技术让您从一个集中的 CMDB 来访问这个多元化多变的世界。CMDB 信息需要多种来源、产品和工具。Top 10 reasons NOT to implement CMDB不去实施 CMDB 的 10 个理由Top Ten Reasons to Implement a CMDB实施 CMDB 的 10 个理由The federated CMDB: Getting past the hype to the good stuff cmdbf 标准的实施在各家产品中尚处于开始阶段，是否大家都会照着做呢。联邦让所有的配置数据更易访问。Logo Mark\n","date":"2009-08-29T16:27:38Z","permalink":"https://martinliu.cn/2009/08/29/martinmarks-for-29th-august/","title":"MartinMarks for 29th August"},{"content":"最近做的一个项目中需要帮用户设计一个 CMDB 的成熟度模型，能够从该模型中持续的检查 CMDB 的建设程度。所以我研究注意了一下的一些书籍，考虑有机会可以买回来研究一下：IT 服务管理的持续改进需要一定的手段实现，这是 ITIL V3 中的一个重要流程。CSF 是关键成功因素，KPI 是关键性能指标，这些都是 metrics 管理过程中需要关注的手段。每个流程都可以找到相应的 CSF 和 KPI。CSF 算是 V3 的新生事物，我想它可能会对 IT 管理质量的衡量和改进带来新的方式。别的不说，我只想说说 KPI 管理方法可能带来的坏处。举个例子：有个公司想通过“事件单数”来考核服务台一线人员的工作。结果当他们在执行了一段时间后，他们发现服务台中有大量重复的事件单，实际上服务台对每个收到的电话都新建一个事件单，并没有做重复事件匹配查找的工作。进一步的也影响了通过重复事件来做进一步的问题管理。从考核管理的角度看，ITSM 的考核指标和体系如何建立的合理，如何才能建立的正确的设计和实施的确是一件大事。否则会有什么后果，我们可以想想三鹿毒奶粉事件，奶粉的蛋白质含量是奶粉质量的重要指标 KPI，营养健康是奶粉的终极 CSF 目标。三鹿真的给了我们一个血的教训啊，想让你的 IT 服务质量如何呢？可以想想三鹿。不过还是需要多多学习所有可能的 CSF 和 KPI，从何设计出确实可行的管理方式。Implementing Metrics for IT Service Management (ITSM)ISBN: 9789087531140Author: David Smith, Micromation CanadaMetrics for IT Service Management (Paperback)by Peter Brooks (Author)Measuring ITIL: Measuring, Reporting and Modeling** ** - the IT Service Management Metrics That Matter Most to IT Senior Executives (Paperback)by Randy A. Steinberg**Step-by-Step Guide to Building a CMDB **by BMC Software; Inc (Author)后来发现了这个 ITSM metrics modeling tools ，觉得这个真的不错。可行性很高。ITSM Metrics Modeling Tool\n","date":"2009-08-29T14:18:33Z","permalink":"https://martinliu.cn/2009/08/29/csf-or-kpi-matrix-itsm/","title":"IT服务管理考核向左走向右走: CSF OR KPI?"},{"content":"吃成都小吃，看国宝熊猫，成都茶馆喝茶，果然是去了就不想走的地方。\n","date":"2009-08-07T03:50:03Z","permalink":"https://martinliu.cn/2009/08/07/51-to-chengdu/","title":"今年5.1去成都休假"},{"content":"新疆之行照片集，路径北京 乌鲁木齐 喀什 乌鲁木齐 布尔津 喀纳斯 布尔津 乌鲁木齐 北京http://picasaweb.google.com/liuzh66/Xinjiang看不到的访问这个链接：http://www.flickr.com/photos/41222865@N03/\n","date":"2009-08-07T02:18:02Z","permalink":"https://martinliu.cn/2009/08/07/xinjiang-is-good-place-kanas-is-best/","title":"我们新疆好地方，最美是喀纳斯"},{"content":" [caption id=\u0026ldquo;attachment_491\u0026rdquo; align=\u0026ldquo;alignleft\u0026rdquo; width=\u0026ldquo;150\u0026rdquo; caption=\u0026ldquo;welcom to martinliu.cn thanks!\u0026rdquo;][/caption]That is what I was dreaming about for almost half year. You can not even understand my blog had been closed, because it took me 4 times to got my doman name registered. Finally I did it by myself. Cheers! I\u0026rsquo;d like to put it on page foot.\n","date":"2009-08-01T14:33:32Z","permalink":"https://martinliu.cn/2009/08/01/got-martinli-dot-cn-icp-registered/","title":"关于ICP备案申请审核通过的通知"},{"content":"July 15, 2009 – BMC Software has announced that it is leveraging Amazon Web Services to provide a single, unified management solution meant to give customers control over existing internal IT assets and external cloud infrastructures, according to a company release.http://www.information-management.com/news/amazon_bmc_software_cloud_computing-10015748-1.htmlBTW: it seems the IT management is as important as infrastructure.\n","date":"2009-07-16T13:34:31Z","permalink":"https://martinliu.cn/2009/07/16/bmc-and-cloud-computing/","title":"BMC and Cloud computing"},{"content":"最近的一些 CMDB 项目和测试中都用到和测到了自动发现工具，很多用户对此的理解和看法还不是很到位。**首先：“自动化配置和关系发现工具是什么？” **它是 CMS 工具集当中的数据采集工具。 从产品名称上看，往外都带 DDM，它是 Discovery Dependency Mapping 的缩写。意思就是帮你发现 CI 和 CI 之间关系的工具。很多用户的各种 IT 管理工具都可以自动发现网络、服务器和应用的配置项以及之间的关系，那么为什么还需要在购买一个新的发现工具呢？其实发现工具解决的真实发现工具不统一和发现数据不统一的问题，更重要的是它可以发现配置项之间的依赖和影响关系。对于一个数据中心来说，变更会经常发生，那么一套应用运行了一段时间之后，你很难准确的说出它都连接了那些其他相关的设备，很难理解它当前的部署状态。我们希望发现工具能帮我们更好的洞察当前 IT 基础架构的构成，应用对设备的依赖，底层 IT 服务对业务的影响。**其次：“它是如何工作的？” **它的工作原理和其他所有的管理软件也没什么太大的差异。基本上讲有两种技术：无代理发现和有代理发现；三种产品形式：纯粹无代理扫描方式、纯有代理方式和混合方式。无代理采集必须依赖被采集设备的开放协议，常用的采集协议有：snmp,wmi,telnet,ssh,jmx,http 等。往往需要在被采集设备上配合一定的账号和权限。采集动作往往是定时、周期性或者触发式执行。扫描结果返回一个数据库中，准备向 CMDB 同步。再次：“它是 CMDB 必须的工具么？”对于下面几种情况我个人认为它是一个必的工具：1）数据中心用户，服务器和应用成百上千套，变更每周都会进行，新业务系统增长快。CMDB 需要使用它来自动更新配置项信息。2）应用多是多层的复杂应用，CI 之间依赖关系复杂，物理连接图已经不足够用来做影响分析，CMDB 需要它来自动化维护配置自己的关联关系，通过它可以减少进 70%的手工工作量。从国外的一些项目经验上来看，50%的 CMDB 用户并没有使用配置自动发现工具，他们使用的配置数据多是监控管理系统中已有的，CI 间的关系靠手工维护。最后：“它是如何与 CMDB 同步的？”有些厂商的 CMDB 是从发现工具上起家的，所以他们本来就使用的一个库，没有同步问题。有些厂商的发现工具是整合的其他产品工具或者收购的，他们自己的同步就需要一定得数据模型了。通过数据模型来解决数据字段映射的关系，一般来讲 CMDB 中会有数据模型 CDM，发现工具同步的时候就以该模型为准，把 CI 和关系经过一定的过滤条件同步到 CMDB 中。不同厂商的发现工具和 CMDB 如果需要同步的话，需要满足起码这样几点需要：CMDB 必须有标准的数据模型来做数据映射；需要有某种数据集成和同步的工具来连接两个数据库；CMDB 中需要具有强大的数据调和功能来处理发现工具带来的数据。\n","date":"2009-07-15T03:45:03Z","permalink":"https://martinliu.cn/2009/07/15/cms-cmdb-and-discovery-tools/","title":"CMS/CMDB 配置管理系统和发现工具"},{"content":"\n** » 下载本指南** （中文版）《云计算基础设施和体系架构指南》** » 下载本指南** （英文版）《Cloud Computing Infrastructure and Architecture Guide》\n» 更多 Sun 白皮书、指南、蓝图 (英文版)\n","date":"2009-07-14T05:34:26Z","permalink":"https://martinliu.cn/2009/07/14/cloud-computing-infrastructure-and-architecture-guide-from-sun/","title":"Cloud Computing Infrastructure and Architecture Guide-From SUN"},{"content":"After 2 crazy months, I finished the longest PoC. This is for CCB CMDB testing. We are fightting with CA,HP,IBM and Utrual Power. It has 3 rounds, took me almost 3 month to finish.Today, I finally got have a chance to do something for my blog. I finally move to a new hosting and attached martinliu.cn domain name on it. Wordpress was updated to 2.8.1 with new theme. I love this theme for three reasons: 1)自动全屏显示； 2)大气；3)自带弹性的调整 options。Now the only concern is MySQL space is only 50 MB. As far as I can tell it could be enough for my 2years blog. So, keep posting and happy blog.\n","date":"2009-07-13T05:13:19Z","permalink":"https://martinliu.cn/2009/07/13/martinliu-dot-cn-is-back/","title":"martinliu dot cn is back"},{"content":"Enjoy the movie and music\n","date":"2009-07-06T03:43:41Z","permalink":"https://martinliu.cn/blog/transformers-revenge-of-the-fall-theme-music/","title":"Transformers-Revenge of the Fall-Theme Music"},{"content":"Now, I am here at ByteactHosting. My blog was moved into this free web hosting.Free Web Hosting Plan\n800MB 1GB (1024MB) of webspace 30GB of monthly transfer 10 MySQL databases 10 Addon domains 10 Addon subdomains 10 Parked domains POP E-mail account (catch-all) Direct FTP access PHP support NO FORCED ADS! It is close to the last one I bought from http://www.paangood.com/otherhost.php.总的来说这是一个非常好用的免费主机，Wordpress的安装只需要点3次Next就完成了。后台管理中可以安装多种开源的程序，有blog、CMS、BBS、B2B、CRM等很多流行程序。目前基本上感觉和使用国内的付费主机没太大差别。 ","date":"2009-07-04T14:47:23Z","permalink":"https://martinliu.cn/2009/07/04/byteacthosting-free-hosting/","title":"ByteactHosting-free hosting"},{"content":"上面是 ITIL v3 的定义，CMDB 的定义和 v2 没有变化。可以看出 CMDB 是一个存储配置记录的数据库，非常多的用户一拍脑门“不就是一个数据库么！我们也可以自己开发一个的。”。这样的情况下，IT 组织的不同部门都可能会各自立门户，开发自己的配置管理信息库；例如：资产管理、终端分发和管理、机房管理等等。数据重复、数据不一致、配置信息不对称；无法得到跨部门和系统的报告。所以 V3 提出了 CMS 系统，它是 CMDB 系统的下一代管理系统。CMS 系统需要 具有对现有信息资料的兼容性，CMS 的建立不能忘记过去；一定要集成已有配置信息。错误一：配置信息是一个独立的配置管理系统，由专人负责数据的更新和维护，手工的管理和维护所有数据。错误二：最配置管理就是要做的细，我要管理到机房中的每一根网线，CI 的属性需要设计的非常多，越细致越好。错误三：我们自己有开发人员，我们有 CMDB 的需求，那就开始做吧，先看法着看看，不就是一个数据的增删改查么！！配置管理或者说 CMDB 的建设可以说是目前，国内 ITIL 用户共同的瓶颈。ITIL 项目中实施最多的三个流程是：Incident Management、Problem Management 和 Change Management。已经实施完毕以上三个流程的用户问的最多的一个问题是：一个故障单、问题单或者变更单一定要和 CI 想关联么？在解决处理的时候寻找目标 CI 或者根源 CI 是必须的么？如果 ITIL 是一种公共语言的话，那么 Incident Management、Problem Management 和 Change Management 等所有流程都是句式或者时态。而 CI 则是主语或者宾语，您觉得没有主语或者缺少宾语的句子，会传递怎么的信息呢？\n","date":"2009-07-04T05:44:02Z","permalink":"https://martinliu.cn/2009/07/04/cmdbe5ae9ee696bde79a84e587a0e7a78de8afafe58cba/","title":"CMDB实施的几种误区"},{"content":"\n回顾或者实施 ITILv3 时，可以去下载一下术语表，http://www.get-best-practice.co.uk/glossaries.aspx 以上网站有原版中英文和其他语言的文档。术语表适用于对 ITIL 有一定了解的人，是受过 ITIL 培训的人或者正在实施 ITIL 的人的案头参考读物之一。我桌上有中英文打印版各一份，拳不离手，曲不离口。另外 ITIL 实施切忌本本主义和教条主义，需要注重实效和对标准的遵从。\n","date":"2009-07-04T05:43:08Z","permalink":"https://martinliu.cn/2009/07/04/itil-v3-e69cafe8afade8a1a8/","title":"ITIL v3 术语表"},{"content":"\n德克虏伯大炮：特点射程远，能 360 度旋转，能把上下调整仰角，炮弹的辐射面积非常广，操作复杂，需要高技能的操作手。操作弹性大。安装部署需要时间长，对环境改造多。\n清红衣大炮：射程短，只能朝一个方向发射，炮弹的打击面基本固定，操作简单，对操作者技术要求低。操作弹性低。 部署配置工作少。\n在 IT 管理工具的选择中，您是选择克虏伯式的超级人间大炮，还是选功能操作简洁的红衣大炮？真是一个两难的选择啊！\n用户必须自己认真思考需求，却对不建议的做法：\n将“德克虏伯大炮”买回家后，发现功能太复杂，接着把它定制成，操作简单的“清红衣大炮”。李鸿章很支持“师夷长技以制夷”，同理购买国外复杂管理套件而不去学习其中的管理方式方法，反而拘泥于自己对概念简单的理解也是成问题的观念。 把“清红衣大炮”三下五除二部署在家后，发现功能限制太多，集成几乎没有，失望的埋怨开源社区，坐观其他人的开发和参与。开源其实赋予你了无限的对开源技术应用的弹性，唯一要求就是有能力参与和进入社区的开发。 ","date":"2009-07-04T05:39:11Z","permalink":"https://martinliu.cn/2009/07/04/e5beb7e5858be8998fe4bcafe5a4a7e782aevse6b885e7baa2e8a1a3e5a4a7e782ae/","title":"德克虏伯大炮VS清红衣大炮"},{"content":"最近在 CCB 的测试中有一项是住系统登陆页面的压力测试。我一直就很担心是否能通过压力测试，因为一个同事告诉我上次他的结果是 80 就不行了。总结一下，我这次成功的原因主要就是两个地方：1）设置 Tomcat 启动和最大内存使用都是 1500MB2）修改 server.xml 中关于连接数等参数(回头贴出我的那些配置内容)我的服务器配置如下：Dell 2950 1C4 核，8GB 内存，单块 136GB 硬盘，Windows2003 系统，JDK1.6，Tomcat 5.5.21另外，我一直以为 Loadrunner 需要真实 Lic 文件才能用，没想到的是，我随便在网上搜了一个也能用，真是神奇啊！ 不过还是反对盗版哈哈:)\n","date":"2009-07-04T05:37:57Z","permalink":"https://martinliu.cn/2009/07/04/tomcate58e8be58a9be6b58be8af95-e68cbae4bd8f200e5b9b6e58f91/","title":"Tomcat压力测试-挺住200并发"},{"content":"Tomcat Configuration 查看一下可以配置的参数设置 JVM 的参数 Setting JVM Options for TomcatEdit the /usr/locat/apache-tomcat/bin/catalina.sh file and add the JVM options to the JAVA_OPTS environment variable.JVM Option Value Description-Xmx 4g The maximum Java heap size.-Xms 4g The initial Java heap size.-Xmn 1g The size of young generation.-XX:+UseParallelGC – To use parallel garbage collection for scavenges.-XX:PermSize 50m The initial size of permanent generation.注释：上面两个 4g 的值，我没试过，我用 8GB 内存 windows 的机器 1.5GB 能启动，超过了 Tomcat 服务就启动不了了。配置 Tomcat Connector AttributesEdit the /usr/locat/apache-tomcat/conf/server.xml file and add the attributes listed in Table 3 to the Connector element.下面是个例子供参考Tomcat Configuration Attribute Value DescriptionThe maximum number of request processing threads to be created by this connector, which therefore determines the maximum number of simultaneous requests that can be handled. If not specified, the default value for this attribute is 40. If an executor is associated with this connector, this attribute is ignored and the connector executes tasks using the executor rather than an internal thread pool.maxThreads 3000The maximum queue length for incoming connection requests when allpossible request processing threads are in use. Any requests received whenthe queue is full are refused. The default value is 10.acceptCount 2000The number of request processing threads that are created when this connectoris first started. The connector also verifies that it has the specified number ofidle processing threads available. This attribute should be set to a value smallerthan that set for maxThreads. The default value is 4.minSpareThreads 500The maximum number of unused request processing threads that are allowedto exist until the thread pool starts stopping the unnecessary threads. Thedefault value is 50.maxSpareThreads 2000Set to “true” if you want calls to request.getRemoteHost() to perform DNSlookups in order to return the actual host name of the remote client. Set toenableLookups false “false” to skip the DNS lookup and return the IP address in String form instead(thereby improving performance). By default, DNS lookups are enabled.上面的值比我实际使用的大，我的 200 并发测试通过了，硬件配置见前一帖。\n","date":"2009-07-04T05:36:03Z","permalink":"https://martinliu.cn/2009/07/04/for-tomcat-benchmark-testing/","title":"For tomcat benchmark testing"},{"content":"\n这里的 theme 都比较干净和简洁http://www.nodethirtythree.com/很可惜的是 blog.ubuntu.org.cn 不能自己更换 theme，所能使用和选择的是固定的一些，都不好看，幸亏还 WordPress 默认的皮肤还在，否则真是不确定我还能用这里的 WordPress。总之还是感谢网上有这么好的免费资源。\n","date":"2009-07-04T05:34:15Z","permalink":"https://martinliu.cn/2009/07/04/free-wordpress-themes/","title":"Free WordPress themes"},{"content":"ITIL 在国内的实施也有 8 年之久，就我看过和做过的项目中：service desk 是最多实施的工具，它包括 IM/PM；还有 Change Management；用户们还可能会常常认为，Release Management 可以和变更流程可以混在一起搞。服务台一般先上，有的变更流程先上，服务台的共同特点还有 PM 一般形同虚设。就我所见所闻的项目和用户来说，CMDB 没有那家能建的好用的好；CMDB 的建设的缺失似乎成了所有 ITIL 用户的通病，应该也是想重点突破的瓶颈。ITIL v3 发布后，CMDB 成了 CMS 中的一个数据库；而且，CMS 中包括不止像 CMDB 这样的配置信息数据库，其实任何保存配置信息的数据库都算在 CMS 系统内。既然是一个系统，所以它就不光包含数据还包含一套配套工具集合，通过这套工具，维护和使用配置信息。CMS 为其他所有 ITIL 流程提供基础的配置信息。它的结构如下图所示：[caption id=\u0026ldquo;attachment_435\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;658\u0026rdquo; caption=\u0026ldquo;配置管理系统\u0026rdquo;][/caption]如果说上面这幅图比较还是比较抽象的话，那么请见下图：[caption id=\u0026ldquo;attachment_436\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;714\u0026rdquo; caption=\u0026ldquo;CMS is a set of tools based on all configuration data\u0026rdquo;][/caption]从上图中我们看到，CMS 系统一共可以分为四层。上三层是核心 CMDB 数据库和相关配套工具，最低层 Data 层则是是所有配置信息的基础来源。从 ITIL v3 的角度来说，只建设一个集中的 CMDB 数据库来存储所有的 CI 信息是不够的，CMS 系统中必须能够包含和处理所有企业已有的各个系统中的配置数据。换言之，CMDB 建设的局限性在于，它只是配置信息数据化，或者说电子化的第一步。当前依然有很多企业雄心勃勃的上马 CMDB 项目，不过切记在规划时，一定先好好阅读一下 ITIL v3 中和 CMS 相关的内容，适当调整项目的目标和预期总是好的，也可以规避一些项目风险。\n以上的一些是我对 CMS 建设的一些认识。如果要落地到项目上还不许经过一个痛苦的过程，那就是产品选型。选项的过程中可以注重一下几点：\n可视化：配置项和之间的关系按拓扑形式展现 标准化：软件、硬件配置项都有完整标准的CTI信息 归一化：与现有各种配置管理系统核心共存同时CMS保持一份完整的户口记录，任何CI都有ID 集成化：CMS中的数据以图形或者裸数据等形式供其他相关消费者流程或者人员使用 联邦化：CMS核心数据库中不保存动态变化的配置信息（DB的最大连接数，网络设备所使用的syslog服务器地址），这些信息通过联邦管理让用户从其他相关的工具系统中查看到最新的数据。 最近可能还会接触一下CMDB的项目，其他经验总结待续。 ","date":"2009-03-01T13:40:16Z","permalink":"https://martinliu.cn/2009/03/01/stop-to-build-cmdb-for-your-it/","title":"Stop to build CMDB for your IT - CMS是怎样炼成的？"},{"content":"这是一个令人赞叹的僧团在默默中延续佛陀的慧命 天下僧人的心愿在他们身上逐步实现此片献给大家使我们大家进一步了解修行的道路和它深远的意义 \u0026mdash;-引自视频中\n","date":"2009-02-14T03:16:03Z","permalink":"https://martinliu.cn/2009/02/14/zte8bebde5ae81e6b5b7e59f8ee5a4a7e682b2e5afbae583a7e59ba2e5ae9ee5bd95/","title":"[ZT]辽宁海城大悲寺僧团实录"},{"content":"（原文於 2008-04-08 發表於 http://blog.roodo.com/ystuan/archives/5830995.html）\n這個音檔的授權是姓名標示-非商業性-相同方式分享 2.5 台灣，跟我的網誌一樣。\n下載 ogg 格式：Born_to_MISrepresent_EP2.ogg 下載 mp3 格式：Born_to_MISrepresent_EP2.mp3 前往存放在 Archive.org 上的頁面：Born to MISrepresent EP2，有更多資訊以及格式。\n內容摘要：\nOpenNMS 1.3.11 版發佈，並宣佈與 Hyperic 就雙方的產品進行合作。這項合作的推手是一個雙方的共同客戶。Hyperic 的 agent 預料將可和擁有強大平台但是拙於 agent (agent-less)的 OpenNMS 形成良好互補。（自 1.3.10 版就開始跟 Hyperic Agent 進行整合，最近 OpenNMS 版本號已跳升至 1.5.90 ） Tarus 的 blog 有更多細節：The Year of Integration\nHyperic 跟 OpenNMS 的初步整合，可線上收看 Integrating Hyperic HQ and OpenNMS（瀏覽器需支援 flash 格式播放）\n當 OpenNMS 遇上 SFLC ：前一陣子 Tarus 跑去 Ask Slashdot ，嚷嚷說 Cittio Watchtower 使用 OpenNMS 的程式碼當然可以，但是使用的方式違反了（程式碼採用的）GPL 授權。\n想也知道，跑去 Slashdot 一定會引來關注，他也尋求軟體自由法律中心（Software Freedom Law Center，SFLC）的協助。但是，SFLC 服務對象僅限於非營利機構，結果呢，SFLC 決定以成立一間新的律師事務所(Moglen Ravicher LLC)的方式，來服務支持自由軟體的營利機構， OpenNMS Group 因此成了 Moglen Ravicher LLC 的第一個客戶。\n喔，不用猜， SFLC 的新聞稿直接告訴大家，兩塊招牌底下都是同一群律師，事務所的所有利潤會回饋給 SFLC 。（嗯，其實我們也可以說 OpenNMS 有兩種，一種是 opennms.org - 社群，一種則是 opennms.com - 主要參與者所開的公司 OpenNMS Group。）\n筆者已經在 FLOSS Weekly 聽過 Eben Moglen 談 GPL 3.0 ，這次為多瞭解另一位大咖 Dan Ravicher （其實只是想搞清楚他的姓怎麼唸\u0026hellip;\u0026hellip;），找到了 Dan 談 GPL 3, Patents and Other Current Issues ，都很棒，推薦給大家，尤其是後者，其實 Dan 還回顧了 GPL 的誕生，解釋了 RHEL 的 subscription model 為何不違反 GPL 但又可以約束客戶（超意外收穫！解答了筆者幾百年前的疑惑）\n照例 Tarus 也在他的 blog 提到整件事：OpenNMS, Eben Moglen and Cittio\n","date":"2009-02-04T04:52:02Z","permalink":"https://martinliu.cn/2009/02/04/e7b6b2e692ad-born-to-misrepresent-e7acace4ba8ce99b86efbc9ae795b6-opennms-e98187e4b88a-sflc-efbc8ce582ace7949fe4ba86-moglen-ravicher-llc/","title":"[網播] Born to MISrepresent 第二集：當 OpenNMS 遇上 SFLC ，催生了 Moglen Ravicher LLC"},{"content":" In childhood, I was playing firecrackers everyday in the Spring Festival. The new year\u0026rsquo;s eve is the only chance for me to lit it again, I felt I like a 10 years child.\n","date":"2009-01-27T10:44:29Z","permalink":"https://martinliu.cn/2009/01/27/my-firecrackers-for-beginning-of-the-year-of-ox-2009/","title":"My firecrackers for beginning of the year of ox 2009"},{"content":"It\u0026rsquo;s Chinese New Year\u0026rsquo;s Eve right now. The Chinese lunar new year came, it\u0026rsquo;s \u0026ldquo;The Year of the Ox\u0026rdquo;. I think you may like the above cute little ox and fortune; I hope you all the best. There are some pics I took tonight.\nhttp://picasaweb.google.com/liuzh66/ChineseNewYearSEve\n","date":"2009-01-25T17:23:30Z","permalink":"https://martinliu.cn/2009/01/25/welcome-to-the-year-of-the-ox/","title":"Welcome to The Year of the Ox"},{"content":"\nToday I installed gOS on my laptop; openSuSE did great work for me 3 years. I\u0026rsquo;d like to play some new things. So, check my new desktop out.http://picasaweb.google.com/liuzh66/GOSIf you go its wetsite http://thinkgos.com/, you will see it talks lots of cloud. It\u0026rsquo;s interesting, but it is not the reson i chose it. Ubuntu 8.04 is inside gOS. So, it time to learn a new linux system. I neve use a Derbin based system, I\u0026rsquo;m not sure it could run for me how long.\n","date":"2009-01-24T15:50:18Z","permalink":"https://martinliu.cn/2009/01/24/gos-looks-green/","title":"gOS looks green"},{"content":"记得以前看过一本描写 Bill Gets 的书，他上中学的时候，在河滨中心通过一个远程终端，连接到某大学的计算机系统，输入程序代码，并且得到代码在远程电脑系统中的输出，输出好像是在屏幕上出现的，或从打印机上输出的。我基本上忘了那电脑系统的名称，不过它的特点基本上是这样的：当时电脑系统很少，可能全世界上也没有多少台功能全面的电脑；用户使用的特别像是一种计算服务，由于终端设备根本没有技术能力，当时还没有个人电脑；接入方式根本不是 tcp/ip 更不是 internet，当时还没 internet。在学习了云计算的一些概念之后，我迷惑了，这个时尚的技术，怎么越看越眼熟啊。IBM 的主机系统可谓是当今电脑世界的恐龙化石级产品，他是一个活化石基本的技术，在经历了开放系统时代之后，我们即将进入云计算时代，我总感觉云计算是一种技术路线的复古。主机系统和第一代电脑系统最相似，区别是可以通过 TCP/ip 网络，和开放系统通信了。最为一种新兴起的技术，我试图 follow http://www.johnmwillis.com/来学习云计算，遗憾的是从 08 年初以来并没有仔细听他所有的 colud cafe；这个老兄在把 blog 改名为 IT Management and Cloud Blog，真可谓是一高产的 blogger，这哥们每天能发四五个 post，强啊。最近找时间听了一段 cloud cafe，我发现到目前为止还没有一个能让大多数人都认同的云计算的概念，基本上对云计算的感念方面有两道三种说法。可以看看 http://en.wikipedia.org/wiki/Cloud_computing 参考这上面的说法也只能有一个模糊的感觉。看看电脑技术打发展历程：最早的电脑系统，主机系统，开放系统，群集，网格，云计算。前一段时间看过一个非常抢眼的标题“以后世界上将只有 5 台电脑”。SaaS 是一个比较火热的和云计算相关的技术，我认为它像是在 web2.0 发展到一定阶段后 Web 应用的一个发展，这方面的强者为 salesforce 之流。Google 和 Salesforce 不同的是，Google 提供网上 office 套件的同时，还开发他的平台，并提供与之配套的 SDK。Amazon 不提供应用也没有 SDK，他只提供平台，平台上包括基本的计算和存储服务。Google 和 Amazon 说起来算是基础架构作为一种服务。抛开云计算本身不谈，用户使用和访问的方式并没有发生变化，在任何一个 web 浏览器存在的地方都能使用或者管理到云计算。客户端的计算和存储能力再次此退化到零，这不能说不是计算机技术发展的返祖现象吧！哈哈～～我也快糊涂了！\n","date":"2009-01-19T07:32:50Z","permalink":"https://martinliu.cn/2009/01/19/e4bb8ee4ba91e8aea1e7ae97e88194e683b3e588b0e7acace4b880e4bba3e794b5e88491e7b3bbe7bb9f/","title":"从云计算联想到第一代电脑系统"},{"content":"本安装手册为纯命令版，如果有什么疑问清参考官方安装手册，或给本贴留言。[install yum on your Linux box]选择任意 Linux 系统，安装上 yum 工具，在命令行测试 yum -v[testing internet connection with those two URL]测试是否能上网，用浏览器分别打开这两个网址\nhttp://www.martinliu.cn/2007/12/13/opennms-yum-install/ http://yum.opennms.org/repofiles/ 先别关闭这两个网页。[Install opennms 开始安装: yum install yum-fastestmirror rpm -Uvh http://yum.opennms.org/repofiles/opennms-repo-snapshot-rhel4.noarch.rpm yum list opennms yum install opennms [ post-install and config] 开始配置： export OPENNMS_HOME=/opt/opennms vi /var/lib/pgsql/data/pg_hba.conf 1. 注释掉其中所有可用的行，加入下面三行local all all trusthost all all 127.0.0.1/32 trusthost all all ::1/128 trust /sbin/service postgresql restart /usr/java/jdk1.5.0_15/bin/java -version $OPENNMS_HOME/bin/runjava -S /usr/java/jdk1.5.0_15/bin/java $OPENNMS_HOME/bin/install -disU -l /usr/lib/jni:/usr/lib [ startup opennms and login ]启动登录： /etc/init.d/opennms start http://localhost:8980/opennms username and password are admin/admin click Admin / Add Interface, input a ipaddress and press Add button OK， I have get oepnnms 1.6.1-1 installed on my home pc, I hope you good luck and have fun. ","date":"2009-01-11T02:33:12Z","permalink":"https://martinliu.cn/2009/01/11/161-1-opennms-quick-install-guide/","title":"opennms 1.6.1-1 quick start guide"},{"content":"This list is from SourceForge.net. You may have the question: How do we adapt open source? My answer might be you just should use them as much as you can. The world is facing economic crisis, you have to saving your budget. How do you deal with that? It\u0026rsquo;s time to think about OSS now.1. Shine J2EE Framework 开发框架http://j2sos.org/http://sourceforge.net/projects/shine-appShine is a Java-J2EE Application Framework/JWMS(Java Web ModelService)Framework/MVC Framework/Service Oriented Framework. Shine Includes Ajax Lib/Server API/J2EE Architecture. Shine Supported JSF/Spring/AspectJ/Struts/Hibernate/ZK-Ajax/\u0026hellip; www.J2SOS.org\n7-Zip 解压缩软件http://sourceforge.net/projects/sevenzip7-Zip is a file archiver with the high compression ratio. The programsupports 7z, ZIP, CAB, RAR, ARJ, LZH, CHM, GZIP, BZIP2, Z, TAR, CPIO, ISO,MSI, WIM, NSIS, RPM and DEB formats.3. ADempiere ERP Business Suite 企业资源管理方案http://sourceforge.net/projects/adempiereADempiere Business Suite ERP/CRM/MFG/SCM/POS done the Bazaar way in an open and unabated fashion. Focus is on the Community that includes Subject Matter Specialists, Implementors and End-Users. We are a community fork of Compiere.4. Notepad++ 文本编辑器，我用了一次就把其他类似的都卸载了http://sourceforge.net/projects/notepad-plusNotepad++ is a generic source code editor (it tries to be anyway) andNotepad replacement written in c++ with win32 API. The aim of Notepad++ is to offer a slim and efficient binary with a totally customizable GUI.5. ffdshow tryouts 多媒体解码http://sourceforge.net/projects/ffdshow-tryoutffdshow is a DirectShow filter and VFW codec for many audio and videoformats, such as DivX, Xvid and H.264. Over 70 bugs have been fixed, codecs have been updated, and support for a few new formats has been added in the tryouts. Vista is now supported.6. DVDStyler 播放器http://sourceforge.net/projects/dvdstylerDVDStyler is a cross-platform DVD authoring application that makes possible for video enthusiasts to create professional-looking DVDs.7. PostBooks ERP, accounting, CRM by xTuple 企业应用套件http://sourceforge.net/projects/postbooksFree open source ERP, accounting, CRM package for small to midsizedbusinesses. ERP client runs on Linux, Mac, and Windows (built with opensource Qt framework). Business logic resides in PostgreSQL database.International ERP, accounting, and CRM tools.8. Zenoss Core - Enterprise IT Monitoring 企业级 IT 监控http://sourceforge.net/projects/zenossZenoss Core is an enterprise network and systems management applicationwritten in Python/Zope. Zenoss provides an integrated product formonitoring availability, performance, events and configuration acrosslayers and across platforms.9. Azureus BT 下载客户端http://sourceforge.net/projects/azureusAzureus: Vuze is a powerful, full-featured, cross-platform bittorrent client and open content platform.10. ZK - Simply Ajax and Mobilehttp://sourceforge.net/projects/zk1ZK is Ajax Java framework without JavaScript. With direct RIA, 200+ Ajaxcomponents and markup languages, developing Ajax/RIA as simple as desktop apps and HTML/XUL pages. Support JSF/JSP/JavaEE/Hibernate/.., and Ajax script in Java/Ruby/Groovy/Python/..11. phpMyAdmin 数据库管理工具http://sourceforge.net/projects/phpmyadminphpMyAdmin is a tool written in PHP intended to handle the administrationof MySQL over the Web. Currently it can create and drop databases,create/drop/alter tables, delete/edit/add fields, execute any SQLstatement, manage keys on fields.12. MinGW - Minimalist GNU for Windows 最小的 Windows 版 GNUhttp://sourceforge.net/projects/mingwMinGW: A native Windows port of the GNU Compiler Collection (GCC), withfreely distributable import libraries and header files for building nativeWindows applications; includes extensions to the MSVC runtime to supportC99 functionality.13. Ares Galaxy p2p 客户端http://sourceforge.net/projects/aresgalaxyFilesharing-Bittorrent p2p client connected to TCP supernode/leaf networkand UDP DHT network. Ares features a built-in directshow media player, apowerful library manager, shoutcast radio support and can be used to hostp2p Chatrooms.14. SMPlayer 多媒体播放器http://sourceforge.net/projects/smplayerSMPlayer is a complete front-end for MPlayer, from basic features likeplaying videos, DVDs, VCDs to more advanced features like support forMPlayer filters, edl lists, and more.15. PhpGedView 家谱管理http://sourceforge.net/projects/phpgedviewPhpGedView is a revolutionary genealogy program which allows you to view and edit your genealogy on your website. It has full privacy functions, can import from GEDCOM files, and supports multimedia. It also simplifiesfamily collaboration.16. FileZilla 多协议文件下载客户端http://sourceforge.net/projects/filezillaFileZilla is a cross-platform graphical FTP, FTPS and SFTP client a lot offeatures, supporting Windows, Linux, Mac OS X and more. FileZilla Server isa reliable FTP server for Windows.17. Hyperic HQ Enterprise Monitoring 系统监控http://sourceforge.net/projects/hyperic-hqEnterprise monitoring and management for web apps on Linux, Mac, Unix \u0026amp;Windows. Auto-discovers 70+ technologies incl. hardware, networks,virtualization, and apps. Includes: monitoring, alerts, remote diagnostics,and control actions from web console.18. Audacity 音频编辑器http://sourceforge.net/projects/audacityA fast multi-track audio editor and recorder for Linux, BSD, Mac OS, andWindows. Supports WAV, AIFF, Ogg, and MP3 formats.Features include envelope editing, mixing, built-in effects and plug-ins, all with unlimited undo.19. OrangeHRM - Human Resource Management 人力资源管理http://sourceforge.net/projects/orangehrmOrangeHRM is an Open Source Human Resource Management System that covers Personnel Information Management, Employee Self Service, Leave, Time \u0026amp; Attendance, Benefits, and Recruitment. Tags: HRM, HRMS, HCM, HRIS, EHRMS, Human Capital Management20. FreeNAS 最简单易行的 NAS 设备http://sourceforge.net/projects/freenasNAS (Network Attached Storage) server supporting: CIFS/SMB, FTP, NFS,RSYNC, SSH, AFP, Unison, UPnP, Webserver, iSCSI protocols, local and MS AD authentication, SoftRAID (JBOD,0,1,5), disk encryption, S.M.A.R.T, WebGUI. Requires only 32MB on DOM.21. Maxima \u0026ndash; GPL CAS based on DOE-MACSYMA 数学工具http://sourceforge.net/projects/maximaMaxima is a fairly complete computer algebra system written in lisp with anemphasis on symbolic computation. It is based on DOE-MACSYMA and licensed under the GPL. Its abilities include symbolic integration, 3D plotting, and an ODE solver.22. DeSmuME 任天堂模拟器http://sourceforge.net/projects/desmumeDeSmuME is a Nintendo DS emulator.23. Openbravo ERP 企业资源计划管理应用http://sourceforge.net/projects/openbravoOpenbravo ERP is a Web based ERP for SME, built on proven MVC \u0026amp; MDDframework that facilitate its customization. Already in production,Openbravo ERP encompasses a broad range of functionalities such as finance, supply chain, manufacturing \u0026amp; much more24. FreeMind 构思管理工具http://sourceforge.net/projects/freemindA mind mapper, and at the same time an easy-to-operate hierarchical editor with strong emphasis on folding. These two are not really two different things, just two different descriptions of a single application. Often used for knowledge and content mgmt.25. aTunes 音乐播放和管理器http://sourceforge.net/projects/atunesaTunes is a powerful, full-featured, cross-platform player and manager,with audio cd rip frontend. Currently supported formats are mp3, ogg, wav,wma, flac, mp4, ape, mpc, mac, radio streaming and podcasts.OSS 应用的常见现象：1）在某电信构思的招标的答疑过程中，我被问道：你们的系统能支持 Linux 么？我回答：能支持 RHEL 4，5 , SLES. 哦，那你们就说说能支持通用 UNIX 系统了，我们需要能运行在 RHEL，或者 RedFlag 上。\u0026raquo;越来越多的用户考虑把 IT 管理系统安装部署到 Linux 平台上，并且认为这就是一种 UNIX 系统，他们以前在商业 UNIX 系统上的管理也使用经验都能适用于 Linux 系统。2）一次用户告诉我他们实在是不能使用 Tomcat 做为中间件，来运行我们的应用系统，他们必须用 BEA。因为他们只有 BEA 的中间件的管理员，没有 Tomcat 的管理员。如果上报一个带有 Tomcat 的系统的话，安全部门不会审批的，因为安全认证还没通过，Tomcat 从安全部门的角度讲安全性低。\u0026raquo;把 BEA 的管理员不当 Tomcat 的管理员是人员任用的严谨还是浪费？为什么商业应用比开源应用安全？其实用户自己人也说，这都是制度，他们也无能为力，IT 变革势力似乎种弱于工作惯性。对于中小企业来说，应用某个开源技术难度应该比大企业要小很多。不过大型企业在很多方面也逐渐有，主动应用开源技术的趋势。这在我以前的 post 中也提到过。从人才的角度和当今的形势看，社会上的 linux 高手，开源大师其实是越来越多，在经济不景气的当下，开源技术的应用从任何角度上看，可能企业都应该放它到议事日程上了。 ","date":"2009-01-07T10:18:18Z","permalink":"https://martinliu.cn/blog/top-25-oss-projects-on-06-jan-2009/","title":"Top 25 OSS Projects on Jan 2009"},{"content":"上周一周都在广州，为中国最大的直销企业 Amway 做“Remedy Administration Part 2\u0026quot;的培训，这个培训是我今年第 5 次做；本周用户还给公司发来了感谢信，可见此次培训也是本年效果很好的一次。其实本月对我来说是一个培训月，第一周在新加坡接受一产品培训“BMC Configuration Automation For Network”；第二周在北京给‘中国人寿’做 ITIL v3 Foundation 的企业内训；第三周在广州，就是这个 Remedy 的培训。ITIL v3 培训和 Remedy 培训是两个不同类型的培训，一个是最好实践 IT 管理方法论的培训；另外一个是 Remedy 系统管理和开发的课程。一个注重理论的讲解，另外一个是注重实际操作的介绍。不过从讲师的角度来说，培训的准备和整个过程的控制都是殊途同归的。**准备篇**对整课程内容的整体把握是至关重要的，必须对每一个 module 的内容谙熟于胸，这样才能控制整个培训课程的节奏，才能对时间做到从容地分配。特别是 4 ～ 5 天的培训，把所有的课程从头到尾贯彻为一个整体，不失课程的整体性，让学员有整体感，不觉得你教的内容没有逻辑、琐碎是非常重要的。所以需要在准备课程的时候就想好，每个 module 之间的衔接方式，要准备好 review 的问题，从这些问题中总结上一个 module，平滑的过度到下一个 module，增加课程内容直接的衔接，可以提高学员对内容的整体理解和掌握。\n**领导篇**特别是做企业内训，企业方的领导如果能至开幕词那是最好不过了，他够让学员再次明确培训目标和培训的纪律等，给学员一定的学习压力，能是整个课程进行的有利保证。总的来说领导在此时应该帮忙唱一出黑脸，下面讲师讲的红脸就可以开始演出了。**教室篇确认教室中的投影仪和其他设施都就绪。对于需要上机操作的培训来说，最好每一个都有一台电脑，电脑的硬件和软件配置都最好相同。确认硬件配置足够能跑虚拟机环境，至少 2GB 内存以上。虚拟机软件和培训用虚拟环境的部署是比较费时的一个工作，对于 15 个学员的课堂，至少需要半天时间准备。对于企业来讲，有条件最好不好在自己的办公室进行，应该到一个远离办公场所的环境进行；宾馆会议室、城外的培训中心或者度假村都是非常好的选择。实例篇对于 ITIL 课程的讲解来说实例的引用是至关重要的，实例可以是以前的项目经验，工具的经验，一个社会现象，甚至是一个小的故事或者笑话都可以。对于这种外国人总结的理论，人们初次学习就像是“外国人听京剧”一样。语言的 gap 是客观存在的，很难在短短几小时内，把别人总结了几年甚至十几年的经验给讲明白。客观的讲：每个讲师都只是演绎了一个自己的版本，为了保证这个版本的正确性，一定要阅读原版 ITIL v3 的出版物，把其中的实例最好能联系到中国国情，中国特色的例子。例如 ：需要讲明白KPI（Key performance indicator ）和 ** CSF（Critical Success Factors）的区别，我引用了三鹿奶粉事件的案例，蛋白质含量是一个 KPI，如果只关注这个指标，而生产出了对 BB 有害的奶粉了，那么这种质量管理是很可怕的。对于 IT 管理来说也一样，某个流程没有 KPI 是不行的，然而没有 CFS 那可是万万不行的，process owner 或者 IT 管理经理需要看到流程的 CSF 中的至少一项或多项得到实现和落实，需要两手抓，两种指标都合格。在 Remedy 培训的课程中，我改变上来就对系统的 over view 介绍，而是从一个 HelloRemedy 程序入手，保证所有人在 5 分钟之内都开发出了一个具有增删改查四种操作的应用，学员对 Remedy 的开发流程一下子就有了了解，和以前的编程经验一下就联系起来了，对课程中 lab 的兴趣一下就提高了一大截。**辅助文档篇**一定要高估你的学员的学习能力，大多数人都是勤奋好学的，特别是看上去相对年轻的学员。课堂的内容往往不能满足他们一周的求知欲。对于 ITIL v3 的培训，可以提供给学员最新的英文和中文的 ITIL 术语表各一份，我还给学员提供了 ITIL v3 Quick Reference Guide，这些内容可以帮助对课本内容学习和认证考试的准备。对 Remedy 的培训，我提供了 Remedy Action Request System 7.1 最新的所有产品文档，release notes，install guide 等等。能更多提供相关的文档是充实课程内容的一个辅助方式。**课堂管理篇**签到表的管理也是很重要的，一般需要让学员知道，最后的结果会发给他们的 HR。课堂时间的管理主要是根据课程内容的进行来自由安排，在每一个 Break 和 Lab 的时候都需要用最醒目的方式，告知开始和结束的时间。我的最佳实践是，电脑接上投影之后，使用屏幕扩展显示的方式工作，在 ppt 的演示配置中设置，把演示内容投影到第二个显示设备上。这样你就有两个可以工作的桌面，两个独立的桌面，在投影仪显示的那个桌面上，用白底黑字醒目的提示 break 或者 lab 的其实时间。原本的桌面你还可以上网或者备课用。工具技巧篇基于上一个技巧，还需要强调的是：电脑接上投影之后，才可以在桌面的显示属性的设置中看到第二个显示器，并且在这时候才能启用投影作为第二个显示器，把桌面扩展到投影上。如果显卡支持的话，一般在投影上显示的分辨率还是可以调节的，这就避免了桌面切换和桌面与投影支持分辨率不匹配的麻烦。在得到一个扩展桌面之后，投影会显示一个你空白桌面，背景图片和你的本机相同。这样在打开 PPT 之后，你在放映设置的菜单里就能看到相关对屏幕设置的选项；重要的是两个选项：1）投影的第二个显示器；2）显示演示者试图。第二个技巧是我以前的 Manager 教给我的，这个演示者视图是一个和 ppt 内容不同的视图，如图所示。我觉得有两个好处，一是在这个视图上有计时器，能知道你讲了多长时间，二是能看到 ppt 的注释部分。另外一个工具就是带激光的翻页器。它使你能够站在任何一个你觉得舒服的地方讲解，试着走到学员中间去讲解，是一个不错的方式，这样能让学员听的更清楚，而且也能让你容易融入到学员中。如果你也想使用这个工具的话，记得在电脑包中记得带一个没有拆封的备用电池。我的翻页器，如果使用激光指示过多的话比较费电，所以我一般都多带一节电池。课程考核篇中国人都比较重视考试，考试的压力能很好的驱动学员的学习。在上两个培训中都有考核的部分，一个是 ITIL V3 的官方认证考试；另一个是考核是我设计的。为了配合 Amway 的培训考核需求需要，由于这个培训是不提供试卷考试的，我就设计了一个对 Lab 结果的评估作为考试内容。所以学员在最后一天把 lab 的结果导出成一个文件中交给我，我从课程的几个方面来评估他们的结果，给出一个具体的分数。反馈篇在课程进行的过程中，可以向学员，特别是用户方培训的负责人征求反馈意见，及时了解学员的接受程度和期望。通过这些反馈信息，对后面的课程进行方式和内容做合理的调整。从而保证最终学员和用户对课程的满意。对于讲师来说，课程各个内容的质量可以看做是 KPI，而用户的反馈和最终认可就可以看做是 CSF 了。说白了作为讲师而言，咱不能让人觉得白花了钱。以上是我最近的一些培训经验总结，如果您也有类似经验和经历，欢迎交流和分享。\n","date":"2008-12-27T08:21:11Z","permalink":"https://martinliu.cn/2008/12/27/training-tips/","title":"Training tips"},{"content":"上周给“中国人寿”做了 ITIL V3 Foundation Training， 这是一个定制的企业内训，包括 3 天的理论学习，一天的‘BSM 机场模拟沙盘演练’，最后一天进行 ITIL V3 Foundation 认证考试。总的来说培训的效果还是非常不错的，学员基本上都能够理解和掌握 ITIL v3 的基本理论；在随堂的模拟考试后，能够针对一些题和我做非常深入的讨论。BSM 机场模拟沙盘演练对于这群基本上比较年轻的学员来说成了一个非常热烈的培训环节，培训教室温度和气氛都比较热，一轮游戏跑下来以后，有些人就已经是满脸通红了；可见沟通也是一件力气活 :) 从学员们填写的反馈表的结果显示，他们对我的平均满意度是 4.35；呵呵这证明经过多日来的备课准备和以前的项目积累还是比较有效的，相信下次能够比这做的更好。\n那么：什么人是需要参加 ITIL V3 培训的？我觉得 IT 部门的所有相关人员，都是有必要参加 ITIL v3 的基础培训，部分流程核心人员和管理人员需要继续参加更高级的培训。除非你认为：不需要应用 ITIL 作为 IT 服务管理的理论，而是应用的其他方法论总之 ITIL 作为当今的“good practice”，通常它还是非常推荐一种武装思想的必备武器。ITIL 培训还应该是整个实施过程中的一部不可缺少的部分，不同规格和内容的培训需要在不同阶段提交给组织的各个层面。有时候一些组织结构或者管理方法的调整和改进，一方面需要高层领导的大力关注和重视；更重要的是保证这个改进和改革的步伐能持续不断的推进下去。关于 ITIL 理论的持续性学习，其实企业内部也可以自己组织，可以对当前运作的或即将实施的特定的流程，进行回顾。主要是把定制和客户化之后的流程、角色、PKI，CFI 等概念和涉及的流程工作说明做进一步深化。培训的组织可以是不举一个的，process owner 应该和 service manager 一起运作和制定这些培训，确保企业内相关流程的有效性和效率。[poll id=\u0026ldquo;8\u0026rdquo;]相信企业运用了更多的 ITIL 之后，还可以总结出更多自己的经验。初级阶段应该是缓慢上升的过程，当 ITSM 达到一定的成熟度后，在应用其他未实施流程，应该会更快。 今天还发现了一个不错的 ITIL Blog ，分享一下 http://itservicemngmt.blogspot.com/\n","date":"2008-12-14T11:00:42Z","permalink":"https://martinliu.cn/2008/12/14/itil-v3-traininig-for-china-life/","title":"ITIL V3 Traininig For China Life"},{"content":"如果你了解 OCS Inventory NG 的话，您可能会发现这个问题，在家里用 adsl 上网，可能访问不到这个项目的网站，所以要想下载这个项目的软件，可以去 sorceforge.net 下载。10/28/2008 OCS Inventory NG Server 1.02 RC3 发布了 Patch1，Patch1 主要是修复了一些数据库创建和更新的问题，具体的内容如下所示：\nOCS Inventory NG 在 sorceForge 的下载网址 http://sourceforge.net/projects/ocsinventory/**15 September 2008 GLPI 0.71.2 发布 **这也是一个 bug 修复的版本，没有新增什么功能。修复的问题如下所示。\n#1094 Auth Method Change if old one does not exists #1109 Clean update for end_warranty_buy on search system #1110 OEM Computer selection problem on licenses #1111 Keep reminder and bookmark when author is deleted #1112 Bookmark creation right problem #1113 Mail formatting #1114 Clean log on cartridge / consumable #1115 logout with noAuto for auto logged users #1119 Mailgate followup import problem due to author check #1120 Cartridge restore bug #1121 Clean Ignore process in software dictionnary #1122 Correct stats computation #1131 Search engine problem for plugin field which need group by #1133 Bug on database connection error\n","date":"2008-11-27T05:15:26Z","permalink":"https://martinliu.cn/2008/11/27/ocs-inventory-ng-102-rc3-available-and-glpi-0712-available/","title":"[项目更新] OCS Inventory NG 1.02 RC3 available and GLPI 0.71.2 available"},{"content":"当 OTRS 遇到 OpenNMS **OTRS meets openNMS! **OTRS 和 OpenNMS 发布了新的集成手册 http://www.opennms.org/index.php/OTRS_Integration 这个 Web Service 的接口应该能做方便的集成了，没有试过，总之 OpenNMS+OTRS 应该是不错的组合，黄金搭档送给你，到~~**The SIRIOS 2.2 modules for OTRS 2.3 are released **SIRIOS 2.2 模块发布了。我一直以为SIROS是非开源的项目，今天才知道它也是开源的哦，有空试试看。这个是专门为安全管理定制的，主要是去管理企业的安全事件。自从 2008-08-05 **OTRS 2.3.1 (Bora Bora) **发布之后，又发布了两个版本，2.3.2 和 2.3.3，这两个版本都是 2.3.1 的 bug 修复版，功能上没有增加。OTRS 2.3 中重大的改变如下：\n# \u0026ldquo;Performance, Performance, Performance!\u0026rdquo; 系统性能提高_ Data base- \u0026amp; code-improvements increase lead to a general performance gain of up to 20%._ The support of an indexed full text search has been added. The feature is disabled per default because additional disc space is needed. The expected performance gain is 50%._ Reduced reloads by using AJAX technology_ Instead of an ongoing recalculating of the escalation time during the run time, it is only recalculated when it changes due to an event in OTRS. It is then being stored in the ticket object which allows a direct access of external reporting tools to the data base as well as a more efficient reporting on escalations. This will also lead into a substantial performance improvement.# Search Functionality 搜索功能_ Support of logical expressions: ticket-, customer- and FAQ- search supports logical expressions, utilizing the AND, OR and ! operators as well as structuring expressions with parentheses._ Search for ticket numbers by using the Browser OpenSearch feature (OpenSearch format)._ Search for ticket titles in the agent ticket search form and in the generic agent._ Search for ticket close time in the agent ticket search form and in the generic agent.# Ticket Zoom \u0026amp; Ticket Move 工单伸缩和移动_ Expand/Collapse of articles: the article view can be expanded to display all articles at once. The current article will remain in focus, and the preceding, or following articles will be displayed._ Structured article tree - The article tree has been changed to a table._ Printing of articles has been realized._ The ticket title of linked tickets are displayed in case of a mouse over action._ Merged tickets are displayed crossed out._ Multiple files can be attached while moving a ticket using the ticket move mask.# Ticket FreeText \u0026amp; FreeTime opportunities_ When splitting a ticket, all FreeText and Free Time data will be copied to the new ticket._ Ticket Free Time fields can be declared as mandatory._ A URL can be configured that takes the value of a FreeText Field and displays it as an URL link in the ticket._ Added X-OTRS-TicketTime and X-OTRS-FollowUp-TicketTime.# IMAP, IMAPS, POP3 \u0026amp; POP3S support 对以上协议的支持_ With OTRS 2.3 IMAP, IMAPS, and POP3S is supported to fetch mails from your MTA.# Security 安全方面_ In case of a lost password, OTRS is sending an e-mail to the user with a \u0026ldquo;password reset link\u0026rdquo;. After clicking this link the new password is sent to the user in a second e-mail.# Notifications \u0026amp; Escalations 通知和升级_ All agents that have a read permission on a certain queue can be selected for notification._ An escalation view has been added that displays all tickets sorted by their remaining time to escalation.\n","date":"2008-11-19T17:40:56Z","permalink":"https://martinliu.cn/2008/11/19/otrs-project-news-update/","title":"[项目更新] OTRS project news update"},{"content":"OpenNMS 1.6.0 (Stable) Released似乎每年的 10 月以后我就会进入一个超级繁忙的状态，很长时间没有更新 blog 了，今天姑且转载一个 OpenNMS 的发布说明吧。OpenNMS, the world\u0026rsquo;s first enterprise-grade network management platform developed as 100% free and open software, has released version 1.6.0. This is a stable, production release that incorporates nearly three years of development.以上算是 OpenNMS 的广告语大家看看就是，需要注意的是一个企业级的产品实施费用是从很低的门槛一直到企业级的花费的。和其他的企业级解决方案的实施没有区别，差异在于，一个不同的许可证类型，此为开源许可证是也。\nThe last production version, 1.2.0, was aimed to compete squarely with Hewlett-Packard\u0026rsquo;s OpenView Network Node Manager product. This release builds upon that work to expand the reach of OpenNMS to other parts of the OpenView family as well as to provide an open source alternative to products such as Tivoli\u0026rsquo;s Netcool.以上是 OpenNMS 的精神所在：OpenNMS 一直在叫嚣这和 OpenView, NetCool 较量；这足以说明了它的勇气，和发展方向，它的创始人 Tarus 从一个人单枪匹马开始，到现在有一般人 inhouse 开发这个产品，自己全世界出差，如果说没有实现和商业产品的抗衡的话，我个人觉得他起码实现了一个所有开源参与者的梦想“为需要自己的人工作，为自己工作”OpenNMS 1.6.0 sports a redesigned user interface, a number of scalability improvements and increased integration with other products. OpenNMS now runs on Windows, in addition to most flavors of Linux, Solaris and Mac OS X.上面说的是新版的用户界面重新设计了，目前我还没有时间安装，回头装好了一定上图片，新版的稳定性得到提高并增加了和其他产品的集成。现在 OpenNMS 也能在 Windows 上运行了，在我看这是早晚的是，它是个纯 Java 的应用，移植不是什么难事，不过我不推荐在 windows 上完开源的产品，有点不伦不类的感觉，而且从原生态的 Linux 环境中才哪呢个够获取开源的全部优势。One of the major additions to the platform is the Alarms subsystem. OpenNMS can receive events from a number of sources, such as SNMP traps, syslog, TL/1, and custom scripts. A key can be configured for each event that will allow it to be turned into an alarm. Thus if a device is generating multiple, identical events, their number will be reduced into just a single alarm. This greatly reduces the amount of event \u0026ldquo;noise\u0026rdquo; that operators see.上面说告警子系统现在是增强了。OpenNMS 能收到像是 snmp trap，syslog， TL/1 和自定义脚本发来的告警事件。某种键值能被设置，让一个事件能被出发成一个警报。报警事件经过了压制和降噪处理，较少了重复报的数量。In addition, automated actions can be performed on alarms. For example, events that signal problem resolution, or \u0026ldquo;up\u0026rdquo; alarms, can be matched with \u0026ldquo;down\u0026rdquo; alarms to automatically clear them. Event workflow can be built into the system by using these automations to manage the alarm list, thus freeing up the operators to focus on the most important issues.另外，对于一个警报来说，可以和一个自动化的动作配合，例如某些 up 事件能去清除对应的 down 事件。While OpenNMS contains a robust automated discovery system, when managing tens of thousands of nodes it is often preferred to allow an external system to determine what OpenNMS is to monitor. Thus OpenNMS 1.6.0 contains a new \u0026ldquo;model importer\u0026rdquo; feature that allows node, interface and service information to be imported directly into the system using data in an XML format. One company uses this method to manage over 70,000 devices with a single instance of OpenNMS.同时 OpenNMS 现在的自动发现系统非常强大哦，档管理一万个节点的时候，OpenNMS 往往倾向于使用一个外部的系统来决定什么是需要 OpenNMS 监控的。在 1.6 中包括这样一个新功能‘模型导入’，他能把 xml 格式的节点和端口数据自己导入到 OpenNMS 系统中。曾经一个公司用这个方法管理这 7 万个节点，都在一套 OpenNMS 系统内，好家伙~~也就是说这个功能有了之后，你就可以不用一个节点的去发现了，往往有些机器发现的那会正好不在线，那就漏掉很多的机器了。Data collection saw many improvements as well. With the proper hardware, OpenNMS is able to collect over one million data points every five minutes. This data can be from SNMP (versions 1, 2c and 3), JMX, HTTP, or NSClient. The collected data can be exported via the web user interface. Reports showing the highest and lowest values for a particular set of data points (Top N Reports) can also be created, and 1.6.0 contains a vastly improved thresholding system. Thresholds can be generated on individual data points, combinations of data points, as well as a \u0026ldquo;relative change\u0026rdquo; such as when a value shows a sudden increase or decrease.数据的采集方面也有很多增强。利用一个合适的硬件，OpenNMS 能够每 5 分钟把超过一百万的数据采集点采集一遍，要是采集稳定的话，这还是比较快的了。被采集的数据点可以使来自 snmp v1,2,3, JMX, http, nsclient。 采集来的数据能通过 web 界面到处了。这还是不错的功能，能有可能做一些系统之外的自定义报表了。自带的报表功能能够定制 TopN 的报表。OpenNMS 现在的阀值管理系统也得到了增强。能为某一个数据点设置，也能为一组数据采集点，同时有了对 \u0026ldquo;relative change\u0026quot;的管理，也就是某个数据忽高忽低的管理，也即是某些瞬间的异常增的很高或降的很低。OpenNMS was originally designed for network service monitoring, and that functionality has been increased as well. New monitors for such things as Windows services are now available, as well as more advanced synthetic transactions. The Page Sequence Monitor was created to monitor a complete web-based transaction, while the Mail Transport Monitor determines the full round-trip availability of a mail service.OpenNMS 天生是监控网络的。新增了很多 monitor，例如 windows 服务监控，模拟交易监控。页面序列监控器用了监控一些列的 web 交易处理行为，还能通过 Mail Transport Monitor 来确定邮件服务的可用性。Probably the biggest change was the development of distributed monitoring. Using a small Java webstart application installed on a remote system, OpenNMS is able to monitor service availability from the point of view of the remote system. Combined with the Page Sequence Monitor one can measure the user\u0026rsquo;s experience when visiting a website from various remote locations.最大的变更在这个版本中是‘分布式监控’，使用一个小的安装在远处的一个主机上的 Java Webstat 应用，opennms 能过过这个监控服务点看到远程的系统上采集的数据。结合页面序列监控功能，它可以实现这样的功能：在南北方，网通电信的网络中找四个点安装这个程序后，模拟从不同网络位置监控某个 web 网站上一系列功能页面的可用性。这就是所谓的模拟交易管理，是 Web 应用管理方面中当下不可缺少的环节。As OpenNMS was designed as a platform, there are numerous ways for external applications, both open and proprietary, to integrate with it. There is a new Trouble Ticketing API that allows for two-way communication between OpenNMS and a number of external ticketing systems such as Jira, Concursive (CentricCRM) and OTRS.像 opennms 这样的平台，可以提供给开源或者商业外部系统的接口。通过这些 api 的双向接口，你可以把报警事件送到外部的工单管理系统(事件管理流程平台)中，例如 Jira, Concursive (CentricCRM) and OTRS.、These are just a few of the new features available in 1.6.0. As always, OpenNMS is 100% free and open software. Please check it out and let us know what you think. We hope you enjoy using it as much as we enjoy creating it.嗯，终于读完了整篇的发布说明，你能相信，它都发布了这么久了，我只有在周五晚上抽空仔细读完么。这周简直是太忙，天天加班，还有天天处理不完的状况。今天的一个教训就是“软件系统之间的集成不是简单能搞定的，需要小心，小心在小心”\n","date":"2008-11-14T14:57:36Z","permalink":"https://martinliu.cn/2008/11/14/e58f91e5b883e8afb4e6988e-opennms-160-stable-released/","title":"[发布说明] OpenNMS 1.6.0 (Stable) Released"},{"content":"这就是全新的 ITIL v3 的模型个人觉得吧 ITIL 四个字母放在中间不如把 Service 放在中间，原因很简单，所有流程和原则都是围绕服务展开，V3 是一个关于服务生命周期管理的最好实践集合。\n不管你是否学过 ITIL v3，你需要了解的核心基本概念包括：Good practices, service, service management, function, roles, process, process model, RACI, generic roles。 想初步了解这些概念的话可以先看看 ITIL V3 的术语表。上图是一个最高 level 模型，告诉了 V3 的架构，要进一步细化的话,下面的这张图是我见过的最能说清楚整体框架，并且能点到为止的模型图。如果你觉得这个图形还是过于复杂，理解起来还有些困难的话，你需要看看下面的内容。下面是我整理的 ITIL v3 概念快速参考：大流程套小流程Service Strategy// Service strategy, demand management, service portfolio management, financial management 共 4 个流程Service Design// service level management, service catalogue management, availability management, information security management, supplier management, capacity management, it service continuity management 共 7 个流程Service Transition// change management, service asset and configuration management, release deployment management 共 3 个流程Service Operation// Event management, incident management, request fulfillment, problem management, assess management, [functions] service desk, technical management, it operations management, application management 共 5 个流程加 4 个职能，术语表中也吧 Function 翻译成功能，我觉得不妥，职能应该更贴切一点。Continual service improvement// 7-step improvement 共 1 个流程所以 v3 一共是 20 个流程加四个职能。比较一下 V2，V2 有 10 个流程和一个职能，内容增加了一倍。如果系统的学习的话最好还是上一个正规的培训。现在正规的 v3 培训也不贵，而且一般认证考试也不难。V3 和 V2 主要的不同点\n对service的重新定义 **对Service management ****的重新定义 ** 更强调processes是****闭环系统 ITIL从此进入Good practice时代 Generic Roles概念 ： process owner, service owner, process manager ","date":"2008-11-04T22:56:57Z","permalink":"https://martinliu.cn/2008/11/04/itil-v3-study-notes-2/","title":"ITIL V3 Study Notes (2)"},{"content":"I think the following open source software resources could be helpful to you.本页面上是我认为可能对您有用的资源连接，目的是让您能以最小的时间和精力代价来体验开源软件。使用一个虚拟应用可能是一个比较方便的途径；有些开源应用做的非常体贴用户，软件提供 ISO 文件下载，通过这个 ISO 文件甚至能一键安装，在一个物理和虚拟的硬件上试用这个软件了。\nVirtual Appliances / 虚拟应用 Asset Management 资产管理 OCS Inventory v1.02 RC1＋ GLPI v0.70.2，Download , 下载地址和虚拟说明。 IT Service Management \u0026ndash; Help Desk \u0026ndash; Ticket tracking system, OTRS2.6.6+OTRS::ITSM 1.0.94, Download , 下载地址和虚拟应用说明。 Network monitoring system: Zenoss 2 , it was made by Zenoss, not the newest version; download, 下载网址。 OpenNMS 1.5.91, download it from SourceForge; they like to keeping this vm appliance update. Download 下载网址。 ISO Appliances / ISO应用 Cacti + Nagios + nTop = CactiEZ OSSIM is a open source security management suite. download, 下载网站 Network appliance: Vyatta could be firewall, router, gateway, dhcp server, etc\u0026hellip; download, 下载网站 Slax is a USB Linux, install in on usb key within 10 minutes, run it on any where, download Slax for CD 下载 FSF mail listWelcome to the Free Software Supporter, the Free Software Foundation\u0026rsquo;smonthly news digest and action update. ","date":"2008-10-29T03:43:35Z","permalink":"https://martinliu.cn/2008/10/29/some-old-stuff-for-sharing/","title":"Some old stuff for sharing"},{"content":" ","date":"2008-10-27T13:32:49Z","permalink":"https://martinliu.cn/2008/10/27/e585abe8bebee5b2ade6a3aee69e97e585ace59bad-e7baa2e58fb6e5b2ad/","title":"八达岭森林公园-红叶岭"},{"content":"No matter Bill says how friendly M$ Windows is. It is eating more and more my free disk space. Toady I figured out some tips for releasing disk space. In Windows file explore, you can not see the folder size without checking on property. So you may need a tool, something like FolderSizes. FolderSize helps me to know more about my heard diver. It shows me there is a folder \u0026lsquo;System Volume information\u0026quot;, this folder is 6.20GB big. What the hell is that??? I can not even see it in file explore. Then I check on Folder Options, here are so many hiding options for you. In order to take out that big folder, I unchecked \u0026lsquo;\u0026ldquo;Hide protected operating system files and folders\u0026rdquo;, then the folder shows up. But I can not open it sine I really wants to know what hell is been hidden in that folder. A error message box popup up\u0026quot;Assess is denied.\u0026quot; WOW this is my laptop, I am not able to access the folder. Is this a M$ asset? In FolderSize, I can go inside this folder; it has so many files. Everything in this folder looks like patch file. I have no idea where and when it went down my computer; or this dame OS made it. Now I\u0026rsquo;m deleting these files and folders in folder \u0026lsquo;System Volume information\u0026quot; from FolderSize. Another error message box popup up; it says \u0026ldquo;Cannot delete XXX000.ps1: It is being used by another person or program\u0026rdquo;. Kidding me? Does anyone share this laptop with me at this moment? Fortunately I have openSuSe, I issued rm -rf command after booted into openSuse. Now 6.2GB space was released.\nWithin FolderSize, one more fat folder was identified out, It is \u0026lsquo;\u0026lsquo;C:\\Documents and Settings\\LocalService\\Local Settings\\Application Data\\Google\u0026rsquo;. I have Google Desktop on my laptop, but I did not use Google desktop search too much, but it take me near 2GBs space. I realized Google desktop indexed my whole hard drive anyway. I have to uninstalled Google Desktop and deleted that folder. Now I got more 2GB space.M$ Windows also did anther favorite for me to created a fat pagefile.sys. It is 3.5 GB; Big~~ isn\u0026rsquo;t it? My laptop have 4GBs physical RAM, but XP only use 3.5GB. As same 32bit OS, openSuSE does use all of 4GB. Since I am short of free space, pagefile.sys was changed to 1.5GB. SO, 2GB spaces was saved.In XP file system, there are some files can not be deleted. I bet you do have some files like that. Those files are already useless, but you can\u0026rsquo;t get rid of them. ForceDel.exe can delete them all. This tiny tool saved me more then 1GB space.6.2+2+2+1=11.2GBThere are more screen-shots, please check out: http://picasaweb.google.com/liuzh66/Mis and comment.Ok now I\u0026rsquo;m be able to create at least two VMWare machines for my work. I hope those tips are helpful for you.In this week, I\u0026rsquo;m so busy on a Bladelogic product POC testing for CCB which is one of the biggest bank in China. At evening, I usually had to study on ITIL v3 stuff in order to get myself ready for a upcoming training next month. But tonight I\u0026rsquo;d like to take time off of the work.XP 磁盘空间节省偏方\n","date":"2008-10-24T00:52:53Z","permalink":"https://martinliu.cn/2008/10/24/ms-windows-is-eating-your-hard-driver/","title":"M$ Windows is eating your hard driver"},{"content":" I have Christopher T. Kuhn Blog\u0026rsquo;s RSS feed in my blackberry. That\u0026rsquo;s the way I following with OTRS project. Christoper do the best job to explain new features and updated s. I did not try out OTRS FAQ 1.5.3 yet, but it look great from Chrisopher\u0026rsquo;s post.知识库、解决方案库或者 KB 的建设往往被人们忽视，对它的选择也是见仁见智。不过可能也有标准，就像你选择你最喜欢吃的水果一样。你最喜欢吃的水果就是：一年四季你到超市见到就想买的，一年四季都想吃的，而且必须是营养丰富有益于健康的。OTRS FAQ 1.5.3 新版的 FAQ 出来后，OTRS 有了真正的 Knowoledge Base； 虽然依然是一个简单版的 KB，不过已经具备了作为一个 KB 应该具有的 6 个主要功能。\n**所见即所得的编辑方式 **创建包含图片和丰富文字和是的知识库或者FAQ条目。 **脚本导入工具 **可以导入已有的一些经验文档、操作规章手册等已有知识文档。 **关键字连接 **增加知识库的可搜秀性 **FAQ报表 **通过一些定期的报表计算出每一个知识库条目被查看的频率 **TOP10文章列表 **在知识库浏览界面中显示被浏览次数做多的前10篇 **知识审批流程 ** 你可以定义一个审批的流程，审批后的内容可以被显示在内部、外部或者公开区域。 目前我还没有时间测试这个知识库，相信应该是个不错的东西，相关测试截屏请拭目以待。如果你已经测过也请留步，留言告诉我你的体验。 ","date":"2008-10-19T13:01:34Z","permalink":"https://martinliu.cn/2008/10/19/otrs-faq-153-you-have-six-reasons-to-use-it/","title":"OTRS FAQ 1.5.3 : you have six reasons to use it"},{"content":"关于 ITIL V3 的简单网上已经有很多，我是从 ITIL V2 Foundation 认证升级到 V3 的，由于目前做的 ITSM 的项目还都是 V2 的内容。随着公司的产品逐渐想 V3 上靠，并且很多已经通过了 V3 认证了；所以自己必须好好在看看 V3 的内容，所谓温故而知新，我也希望能尽早把 V3 的内容都消化掉。下面的一些列帖子是我最近的一些学习笔记，也本着把后书读薄的目的，希望这些笔记能帮我把思路整理好。ITIL V3 的核心出版物有五本。如果有 ITIL v2 相关的理论或者实践经验 ，而且英文好的话建议直接从网上购买或者下载这五本书开始学习。不过过程可能会比较漫长，效果很难预测。我现在学的是一个公司的 ITIL V3 Foundation 认证培训的教材，这本书好在他其实整合了上面五本书的所有核心内容，而且通过实际用例来解释理论。它是本考试认证用书，所以上面还有考试辅导方面的内容，如考点提示之类的。对我来讲业余时间能很快把 V3 的内容过一遍，这本书应该在好不过了。\nITIL 认证和其他 IT 认证没有什么本质区别。整个学习和认证架构是一个金字塔，在最顶端的当然是 OGC，在最下层的当然是你了。OGC 之下的是 APMG，APMG 是 OGC 官方的唯一授权认证和考试机构，它可以授权一些组织成为 ITIL 的培训机构和考试机构。所以向认证的第一步就是找一家 APMG 授权的培训机构去培训了，接下来的认证考试可以有培训组织帮助联系。如下图所示：如果你没有 ITIL v2 的认证的话，你就是从上图的第三个框开始你的认知之路。http://picasaweb.google.com/liuzh66/ITILV3Training1/ITIL 和 ISO20000 的关系？ITIL can be implemented without ISO/IEC 20000, but ISO/IEC 20000 cannot be achieved without ITIL.服务定义举例：Let’s use the analogy of the difference between a supermarket and a restaurant.Both places are visited for purchasing food. At the supermarket, clients buy a product or a set of products with which they have the capability to create a meal. They go home, they prepare the food, and they serve dinner to their guests. Conversely, at the restaurant, the clients are buying the complete Service, the capability and resources to create the meal, as well as the overall experience of dining.Function 的定义：It is important for us to understand the definition of function.A function is defined as a team or group of people and the tools it uses to perform one or more processes or activities. Functions are self-contained units of organizations, with their own capabilities and resources.举例没有 Function 的组织结构的特点：The challenge most IT organizations face is that they are structured with a single focus on functions.The functional organization in IT is typically aligned to the technology, for example: Network, Mainframe, and so on. IT came by this honestly, as each technology type requires specialized resources and capabilities to manage, thus meeting the definition of a function.However, when these same functions do not have clear understanding of their roles in processes and service delivery, it leads to “functional silos”, where work is completed without clear knowledge of the impact of this work on the quality of services.Process models help avoid this problem with functional hierarchies. These process models improve cross-functional coordination and control. Well-defined processes can improve productivity within and across functions.Role 举例：As an example of roles and functions, the Technical Management department or function can perform the role of Problem Analyst when diagnosing the root cause of Incidents. This same department or function could also be expected to play several other roles at different times, such as assessing the impact of Changes, that is, the Change Management role.The scope of the role and what triggers the role player to play that role are defined by the relevant processes and agreed by their Line Manager.流程的特点：You can remember these characteristics by breaking them down into a mnemonic such as MSCR — Mary Sells Custom Rings.\n","date":"2008-10-19T11:55:10Z","permalink":"https://martinliu.cn/2008/10/19/itil-v3-study-notes-1/","title":"ITIL V3 Study Notes (1)"},{"content":"Link：Open Source and Cloud Computing(开源与云计算)From above post:开源的成功有几个关键元素：1.许可证要允许和鼓励再发布、修改乃至发展分支；2.一个体系结构要使程序能被作为组件在任何可能的地方重用，以及可以被扩展，而不是被替换来提供新功能；3.低门槛，让新用户轻松上手一试。4.低门槛，让开发人员构建新的应用与大家分享。\n个人认为：使用云计算的用户并不一定是租用土地的佃户；佃户把自己的收成都给了地主，自己剩下的少的可怜。云计算的用户会愿意付出多少成本给地主是可以计算的，计算的原则就是‘保证自己的利益、安全等’。\n","date":"2008-10-16T13:09:16Z","permalink":"https://martinliu.cn/2008/10/16/open-source-and-cloud-computinge5bc80e6ba90e4b88ee4ba91e8aea1e7ae97/","title":"Open Source and Cloud Computing(开源与云计算)"},{"content":"Now this forum is open for registration. Please feel free to post any of your idea or question. I hope you will have fun.http://www.martinliu.cn/forum论坛开张了:) 欢迎加入我的开源论坛！\n","date":"2008-10-06T08:05:07Z","permalink":"https://martinliu.cn/2008/10/06/welcome-to-my-oss-forum/","title":"Welcome to my OSS forum"},{"content":" 这个论坛软件看似还不错，而且号称简单、快速和优雅，比较吸引我。我的 blog 后台是 Wordpress 的，所以理论上讲可以和这个软件很好的集成，这可能是最吸引我的一个地方。对于本开源软件博客而言，是否需要增加论坛这个功能呢？其实本博客还是一个多作者博客，我邀请了几个开源的朋友供稿，不过他们也应该比较忙 :) 其中的两个朋友也有自己的论坛，分别是 www.itnms.net 和 www.zenosscn.com 。对于国内的很多朋友而言，可能论坛是一个更好的沟通方式，泡论坛已经是很多朋友上班中不可缺少的内容。考虑一下开设论坛的利弊。好处应该是会带来更多站点交互。坏处还没有想好，目前能想到的可能是：需要花更多的时间打理本站，还有就是抵御论坛的垃圾。总之还没想好是否增设论坛功能，如果您有什么意见和看法也请告诉我。[poll id=\u0026ldquo;7\u0026rdquo;] [poll id=\u0026ldquo;6\u0026rdquo;]\n","date":"2008-09-23T04:58:47Z","permalink":"https://martinliu.cn/2008/09/23/should-i-open-a-forum-on-my-site/","title":"Should I open a forum on my site?"},{"content":"Peoples always love whatever Google\u0026rsquo;s invention, I am using Gmail and GTalk every day too. But I think I couldn\u0026rsquo;t say I like google anytime. That\u0026rsquo;s just because Chrome. It was installed on my laptop yesterday. I\u0026rsquo;m trying it out when I access any of my google services (Gmail, Reader, Doc, etc\u0026hellip;). There are some App shortcuts are already on my XP deskdtop. Base on one day experience of Chrome, I\u0026rsquo;d like to talk about reasons I don\u0026rsquo;t like Chrome. I has not tested it too much at present, just few comments below:\nChrome\u0026rsquo;s Name: I still do not figure out how to pronounce this word, someone says it sounds like a man perfume; I do thinks so. But it\u0026rsquo;s ok for a name of software, I don\u0026rsquo;t care about too much what it called. FireFox is cool name, everyone know it.Crash Continually: It proved Chrome browser is on early stage. For me, I won\u0026rsquo;t any software on my laptop send out any piece of information which I don\u0026rsquo;t know or couldn\u0026rsquo;t understand. So, I will never turn on crash report option for any software. It is still crashing frequently, I might will not use it any more; or install it.**Bookmark on top: **My laptop has supper wide screen, so all of bookmarks are listing on the left side of Firefox/IE. I like to access bookmark from left side of screen. It is on the top and just below the address bar, I have to close it.ADs in Gmail/anywhere it could be: In Firefox, I get really few AD showed up. Nobody love ADs, but Google can not do with our AD.Without Add-ons: It is so important for extending the usage of your browser. Add-on makes a browser to do more jobs as you wash for. I can list some add-ons of Firefox, they are very helpful and I must have all of them.I thinks Google really good at marketing. it crashed into browser marketing, its ambition knows no limits. All in all, Chrome is not a good enough to be my default browser; Fixfox will keeping do this job for me. Chrome is a ok software, it is no offence to Googl\u0026rsquo;s fans.\n","date":"2008-09-05T05:10:15Z","permalink":"https://martinliu.cn/2008/09/05/do-you-like-chrome/","title":"Do you like Chrome?"},{"content":"Are you running a open source project? If so, you may wash for this awards. Have you every vote for someOSS on InfoWorld? After I check out all of those lists, I realized there are some great softwares I still don\u0026rsquo;t know. For sure you are leveraging oss power, you may go with some champion projects.Best of open source productivity appsThe InfoWorld Test Center\u0026rsquo;s picks for the top free and open source productivity apps include office suite, Web browser, image \u0026hellip; August 4, 2008Best of open source developer toolsThe InfoWorld Test Center picks the top free and open source RIA platform, Ajax framework, business rule management system, \u0026hellip; August 4, 2008\nBest of open source storage softwareThe InfoWorld Test Center turns up the top free and open source offering for network and online backup, network attached storage, \u0026hellip; August 4, 2008Best of open source enterprise applicationsInfoWorld Test Center picks the best free BPM, CRM, ERP, e-commerce, business intelligence, project management, application \u0026hellip; August 4, 2008Best of open source for collaborationThe InfoWorld Test Center picks the best for social networking, wiki, blogging, and groupware August 4, 2008Best of open source in networkingThe InfoWorld Test Center chooses its top picks for IP telephony, VoIP monitoring, log analysis, Wi-Fi scanning, server and \u0026hellip; August 4, 2008Best of open source platforms and middlewareInfoWorld Test Center picks the top free and open source operating systems, desktop and server virtualization, database, \u0026hellip; August 4, 2008Best of open source in securityThe InfoWorld Test Center picks the top free and open source firewall, IPS, network gateway, password cracker, penetration \u0026hellip; August 4, 2008\n","date":"2008-09-04T08:13:52Z","permalink":"https://martinliu.cn/2008/09/04/best-of-open-source-software/","title":"best of open source  software [InfoWold OSS AWARRDS]"},{"content":"在 IT 管理领域里，商业软件厂商中有自称 Big 4 的集团：CA，HP，BMC， IBM；在开源软件项目中也好像有自称“开源 Big 4”的集团，他们是Groundwork、Hyperic、Qlusters 和 Zenoss 公司。商业厂商向用户推出自己的产品的时候，往往都会打着一些比较大的概念和幌子，说“我们是 IT 管理的 Total Solution”；潜台词是我们的产品非常多，可以满足您所有的需求，而且只要您选择了我们，我们能保证所有的产品模块之间是无缝集成的。事实上的确如此，商业厂商凭着后台开发团队的强大，还有本地服务商的支持，在解决方案的集成性上的确没有什么问题。对于开源软件来说，由于每个软件都在各自为政的状态下独立发展，即使是彼此之间的功能有着某种衔接和集成性，在多数的情况下也往往是各自独立发展；没有考虑到彼此的组合和集成。不过换一个角度看，既然是开源软件，人家把源代码都全开放出来了，如果你想做两个开源软件的集成的话，从技术的角度上说，没有任何障碍；对比商业的闭源软件产品来说，似乎他们又在这方面有着与生俱来的优势。\n开源的 IT 管理软件中有非常多的种类，就拿网管软件来说吧。我的 blog 上介绍了很多，其中很多的软件都是功能非常重复，而各有千秋的。要想组合一个纯开源的整体 IT 管理解决方案不是不可能的，需要的是对一些比较精华的软件系统有所了解，并且了解他们之间集成的方式和实现功能。在此基础上做出合理的组合，方能搭建出一个整体的方案。\n由于现在 ITIL 已经成为了大家耳熟能详的“GOOD PRACTICE”，这是 08 年 V3 之后的一个转变，V3 提出之后，它就以一种亲民的身份，自称自己不再是“BEST PRACTICE”了。既然是要攒一个“开源 IT 管理整体解决方案”，同时为了保持本方案具有一定的理论高度 ;) 选择 ITIL 作为理论依据当然是不会错了呵呵～～ 不好意思今天心情比较好，废话实在太多，抱歉，下面将开始方案书写了。\n本方案将兼顾 ITIL 中的两大块：IT 交付和 IT 支持。我所选取的是 OpenNMS, Hyperic HQ 和 OTRS 来分别支撑 IT 交付和 IT 支持者两个部分。OpenNMS 和 Hyperic HQ 组合来完成网络和系统监控，它们为可用性管理、性能（容量）管理和服务水平管理提供支持和实现，注意这里说的是为这几个流程提供支持的工具，这些工具本身并不是流程工具。OTRS 完成事件管理、问题管理、配置管理和服务水平管理等流程，OTRS 本身是一个工单跟踪管理系统，他现在的 ITSM 模块以及发展到 1.1 的版本了，同时自称是 ITIL 兼容的软件。\nIT Delivery\nOpenNMS 和 Hyperic HQ 的功能定位有所不同，在这里选择他们俩来作为监控网络和系统的平台由一下的一些理由。OpenNMS 是 agentless 的监控软件，它的网络自动发现功能非常好使，而且现在能支持越来越多的网络设备，对于国内的华为等厂商的设备需要做一些定制后才能监控，否则只能看到标准的 mib2 的信息。最新的版本也能支持分布式的管理功能，也就是 remote monitor 的模块。我没有让 Zenoss 入选网络监控的一个重要原因是，OpenNMS 是纯开源软件项目，它的所有功能都是可用的，而且它是 Java 程序，配置文件大多是 xml 文件。对支持非常大量的网络设备和端口，你需要有的是对 Tomcat 和 Java 应用的调优能力，和通过 OpenNMS 的邮件组来解决 bug 的能力。OpenNMS 里面有非常好的告警事件管理功能，它本身是一个非常好的事件平台，事件升级、报警、过滤等功能都有。而且现在 OpenNMS 已经能和 Hyperic HQ 做事件集成，Hyperic HQ 的报警事件能传递到 OpenNMS 中，这就意味着 OpenNMS 可以作为一个统一集成的事件管理平台，在这里对集中管理所有类型的告警事件。HQ 是一种 Agent based 的监控软件，对于系统监控而言，很多商业厂商的软件功能都无法很好的做到单一代理的技术，当然我认为 BMC 的 Patrol 是例外，它的单一代理技术是我见到最好的。HQ 的单一代理技术意味着，通过在一台服务器上部署一次代理程序后，其他的工作就都转到 web console 上了，在那里，你可以配置代理对各种资源的管理，它的代理能发现非常广泛的基础架构应用：Web， midtier, DB 等。由于 HQ 是一个商业开源的软件，所以它对商业基础架构软件的平台支持的非常好，能支持目前流行的所有基础架构软件包括各种商业的操作系统、数据库、中间件；当然它对开源的软件也能够监控。监控参数很多，配置容易，有开放的接口提供功能扩展开发。从 OpenNMS 和 HQ 的各种图形上可以很好的评价和监控和各种 IT 服务的质量。OpenNMS 中的界面中最多的就是对某个节点或者上面的某个服务可用性的计算。\nOpenNMS 和 HQ 实现和完成的功能能为 IT 交付中的：可用性管理、性能管理和服务水平管理提供实时的数据支持，OpenNMS 作为总的事件平台，同时它还监控所有的网络设备。HQ 用来监控所有重要业务服务器，那些边缘的非重要的业务服务器或者是客户端设备也可以交给 OpenNMS 来管理，它的无代理监控，对这些设备也能管理的不错。\nIT Support\nOTRS 本身是一个非常不错的工单跟踪系统，它在加载了 ITSM 模块之后，就把 ITIL 的很多精髓理论做了很好的诠释和实现。对于很多大型企业用户而言可能会笑话 OTRS 的简陋，不过实施 ITIL 的过程，我觉得应该是：把当前的繁杂工作，按照 ITIL 的几个流程简化梳理的过程，每个流程完成比较单一而纯粹的目标；流程之间又能有一定的集成就可以了。对于 OTRS 的研究，我目前也处于安装和读管理员手册阶段，没时间细看。选择 OTRS 的一个最重要原因是，今年也开发了一个事件集成模块，它能通过这个模块与 Nagios，openNMS，OpenView，Tivoli 等监控产品做事件集成，也就是说告警事件能自动在 OTRS 中生成事件单，而 OTRS 的事件管理模块就负责吧入站的事件单自动化的分配给相关的技术支持人员受理解决。详情请参考 Automated System Monitoring with OTRS Download这个白皮书是在 OTRS.com 的网站上下载的，我当初怀疑这个事件集成模块是否是开源的软件，所以在Christopher T. Kuhn 的 Blog 上问他了一下，他向我确认该模块是开源的，并提供了下载地址。从技术路线上来说 OTRS 是实现了服务台的功能，并且实现事件、问题、配置和 SLA 管理；从界面上看它对这些流程的支持是比较简洁的实现，你完全不能把它和商业的服务台软件来比较。不过实施 ITIL 的道路，我觉得应该是丰俭由人的，我相信一定会有人走简洁路线的。想想 Apple 的产品，它的设计无比的简洁，它简洁并不丑陋，而且还很 cool，很流行。\n由于这个方案攒的还是比较匆忙，而且技术上没有实际测试和验证，本文旨抛砖引玉的提出一些思路和想法，未经详细推敲，欢迎提出您的建议。\n","date":"2008-08-23T15:17:05Z","permalink":"https://martinliu.cn/2008/08/23/open-source-total-it-management-solution/","title":"Open Source Total IT management Solution"},{"content":"配置管理的项目可以从 CMDB 的建设开始，也可以从配置管理的流程建设开始。我在一些配置管理的项目中发现了一些用户容易犯的错误有很多。先说说配置管理，做 ITSM 的项目，往往 CMDB 的建设，或者配置管理流程大多不会非常重视，往往作为一种辅助性的环节在项目中得到实施。例如 ITSM 项目一上来就做服务台，然后是变更管理流程和其他流程；在一些后续的资产管理的项目中 CMDB 的到重视并建设。其实配置管理流程和 CMDB 是 ITSM 项目中非常重要的一环，它建设的效果对整体效果有乘法放大的效果。CMDB 的主要功能我认为有两点：\n提供唯一、精确的配置信息库，让所有IT团队的人都明确IT管理配置项范围，有了它所有人都起码能清楚“我管理的东西是什么有哪些？”。都说ITIL的语言是IT管理的共同语言，那么配置信息就是这个语言的主语和宾语；从这里可以看到，如果我们没有这样一个准确的配置信息库，我们彼此之间的沟通会出现多大的误解和迷惑。我在用户现场做项目的时间比较多，耳闻目睹很多沟通障碍；这些障碍不是沟通方式和技术造成的，而是大家没有能从一开始就说清楚“谈论的CI对象到底是什么” 实现一定程度上的业务影响分析。往往都是有IT部门牵头做CMDB，后期也主要是IT部门用。有效的业务影响分析能力，可以彻底提高事件管理的有效性。一般用户可能会有一个集中Event Console，从这个console中事件一般是以生成的时间先后顺序查看和处理的。最差的事件管理方式就是这种“先进先出”的处理应对方式。如果你能说清楚，发生事件的对象（配置项）对业务系统的影响程度，那么你就能够做到按照这些事件的优先级别来处理；事件的优先级就是该事件对业务系统所造成的影响的严重程度。需要做到业务影响分析，就必须做业务模型梳理。每一个业务服务和业务流程也是配置项，IT的人也需要能理解业务。 下面列出一些常见错误，这些错误发生在企业做ITSM项目的前后都有可能，不过多是在实施ITSM项目之前，或者上CMDB工具之前，或者过程中。1）目标不明确，实施结果无法衡量 Goal所谓目标不明确，并不是说没有目标，而是说：目标定的不太合理。不合理的原因有一下几种：目标过大、目标过于模糊、过于教条、拘泥于ITIL的书本、和实际的工作联系不紧密、没有衡量和控制的方式。在一定的项目时间周期内，总结之前配置管理的问题，作出一个切实可行的配置管理数据库建立目标应该不难，主要以使用为主，不要拘泥于细节。2）配置项信息混乱，信息结构无序 Scope这里的“信息结构”是说CMDB的CI配置项信息查看应该是立体的有结构的很直观的数据信息。在访谈的过程中，有些用户在讨论过程中认为配置项组成的信息结构应该是网状的。其实现实中的IT基础架构组件的确是以网状的形式相关联的，这种想法非常实际。不过人们都太偏重IT了，遗忘了IT部门的最终使命“为企业交付各种业务服务”。业务服务就是CMDB数据金字塔的顶端部分。从IT部门提供的业务服务开始来梳理和建立CMDB配置库是一种“自顶向下”有效方式，是IT部门做CMDB配置管理过程中，与业务部门沟通的“翻译机”。自顶向下的方式需要业务部门的配合，或者IT部门内有精通业务的强人。通过这种方式做出了的CMDB，CI之间的构成方式，从宏观上看：屏幕的投影是树根型的，立体的看是金字塔形的，业务系统模型是树根的根部，是金字塔的顶端部分。微观上看，局部可能是网状的，或者是星型的。没有业务服务作为头部，很难说出CMDB的scope究竟是多大，很难说清楚哪些CI可能会在CMDB中出现。3）配置信息随意堆积，纠缠于过多的CI属性 Level每一个CI都可能具有非常多的属性，成功选择的标准是：够用就好，精简是王。很多用户都存在的误区就是“复杂比简单好，越复杂越放心”；大多数用户在项目初期的需求整理的时候都觉得，需求提的越全面，越好，越保险。这种心情是可以理解的，毕竟ITSM项目的周期和投入通常都是非常多的。不过对于配置管理来说却，万万不能有这种想法；否则，CMDB的维护和审计的工作量将非常巨大。一个信息量过载的CMDB，就是一个不可用的配置库。一个只有10个属性的CI和有50个属性的CI展现在你面前的时候；你找到你所关心的信息花的时间上看，前者是后者的1/5时间。属性一定要精简，特别是CMDB从零开始的用户。在设计的初期一定预留属性扩展的可能性。4）疏于配置信息的准确性和实时性 ** update**CMDB一旦建立了之后，所有用户一定要对CMDB使用起来，要为CMDB提供反馈。最终使用配置信息的人，如果发现信息不准确，需要及时报告配置经理。配置经理需要及时维护。配置经理最重要的职责是，确保每一个大小变更实施完毕之后对要对相关CI做更新。你可以没有正规的变更流程系统去跑变更单，不过我所看到的是很多企业即使没有实施ITSM项目，其实他们手工变更单的流程跑的有板有眼，一点都不差。美中不足的是，变更后的结果没有地方更新和反馈。而CMDB就是这样一个变更结果反馈和汇集的目的地。在大家都频繁使用CMDB，并且每一个大小变更都更新CMDB的完美情况下，CMDB中的信息会随之时间的流逝，愈来愈精确，愈来愈完善。5）拘泥于工具的功能，忽略了最终目标 Tool我看到的最多的工具是MS Excel，也有使用自开发系统的，可有自开发系统最终丁不住在转向商业工具的 :( 无论何种工具，假如在一个正确的事实和使用的策略下，我觉得都是可以获得CMDB建设的成功的。一个好的工具还是有必要的。在选择一个成品工具或者开发一个CMDB工具时，需要考虑工具的几个方面。工具应该参考或者借鉴某种国际标准，这里的标准是指某种通用模型标准 Common Data Model (CDM)，例如DTMF的 Common Information Model (CIM),或者WMI等。好的工具需要能和其他ITSM流程紧密结合，特别是事件管理、问题管理和配置管理者三个流程。如果这三个流程是建立在某种工具平台之上的，那么CMDB的信息最好能无缝的整合的流程的处理过程中。 ","date":"2008-08-15T14:24:25Z","permalink":"https://martinliu.cn/2008/08/15/e9858de7bdaee7aea1e79086e4b8ade587a0e4b8aae79a84e8afafe58cba/","title":"配置管理中几个的误区"},{"content":"可惜 yo2.cn 开张的太晚了。否则我的 blog http://www.martinliu.cn 就可能在这里了，先注册一个好的名字 opensource.yo2.cn 先呵呵～～ 如果有需要请和我联系，不想浪费这么好的 blog 地址。\n","date":"2008-08-10T12:03:17Z","permalink":"https://martinliu.cn/2008/08/10/e5bc80e6ba90e8bdafe4bbb6e79a84e883bde9878f/","title":"开源软件的能量"},{"content":"中午后去超市购物；超市的人可真多啊，大家都在采购备战晚上的奥运哈哈。我也买的毫不手软啊，西瓜、王老吉、可乐、牛肉、蔬菜等等！回家后，先炖上一锅牛腩萝卜汤，昨天立秋，今天贴贴秋膘有不迟。准时 5 点就开始收获在电视机前。等待开幕式的开始。开幕式终于开始，虽然视觉上的冲击性不强，不过还是完美的展示了中华文化的精髓。通过四大发明的展示，以东方人含蓄和细腻的手法，把吾国浩浩汤汤 2000 多年的历史优美的展示与全球世人面前。地球村的创意我觉得非常好，最后刘欢站在最上方高歌一曲，挺好。兴致最好的时候牛腩汤经过几个小时的熬制，也香气扑鼻了，呵呵来上一碗，继续看总之真个文艺演出，文化气息十足，可圈可点之处也很多；唯一担心的是怕老外们理解不了。现在终于看到中国代表队在姚明的带领下，正缓缓入场；中国体育健儿的队伍可真大啊！！！中国加油!!! 哈哈忍不住了，我也在 blog 上喊一嗓子吧，明天奥运的战幕就缓缓拉开了，希望他们拿更多金牌为国争光。现在中国队走到了中场，期待圣火点燃的那一刻吧。顺便说一句，有人说中国队的服装配色有点借鉴了‘西红柿炒鸡蛋’的色彩，呵呵有点象，的确有点象，而且那时我的拿手菜:) 今年北京的天气，好的是，天公作美，真的憋住，愣是没有下雨；不好的是，桑拿的程度太高了。场内入场的所有运动员，从电视上可以看出都已经是大汗淋漓了，都在等待圣火。烟火，有事一波烟火，整个鸟巢像是个火锅一样，再次沸腾一次。中国画，由所有运动员参与绘制的一副巨画放到了场地中央，这幅画可谓整场的一个核心线索，这可能是老谋子的 idea 吧，和拍电影的道理一样，需要有一个线索贯穿始终，像是 ice age2 里的那颗坚果。不知道以后会把它放在那，细看这画很不错，写意，非常写意，还有点点现代气息。刘淇开始讲话了。不禁回想起，我在看圣火采集实况转播时候的激动心情，他在希腊的采集圣火的神殿哪里也发言了。LP 说他在这发言可谓捡了一个不小的便宜，前人种树后人乘凉啊!!胡锦涛主席宣布“大会开始！！” :) 呵呵，有一波强烈烟火，太 cool 了！！ 奥运会旗入场了，八人举着会旗缓缓入场，8 人都是奥运的元老人物。现在看到那些在场地周边，做分割线的 MM 们好像不用再跳跳跳的欢迎了，这些 MM 已经在入场式的时候跳了快 2 个小时了，体力不行还真去不了啊，辛苦辛苦了！哈哈！！护旗手开始升会旗，不得不说中国的护旗手世界上最 cool，赞一个！！在赞一次天工吧，到现在为止，一滴雨都没下，真给面子啊！张怡宁右手抓五环旗开始宣誓，她表现的很腼腆：）黄利庭代表裁判员宣誓，慷慨激扬，强！！我看时间一定要拖到 12 点整了，不行我先把这个 post 发布一下啊，一定要讨到八月八的这个好彩头。发布 edDONE 继续，很大很强的一个烟火在鸟巢上空喷出，绚烂啊！！许海峰手持火炬入场，开幕式的最大悬念缓缓揭开了。啊！点燃了高敏的火炬～～～转给李小双，继续跑，传给第四个占旭刚，跑～～这第五个张军该是最后一个了吧，都快是最后一分钟了，我和 LP 都猜，最后一个是谁呢？刘翔？？第六位了陈中，跑～第七个了，孙晋芳，第八个该是最后一个吧？继续跑～过 0 点了。火炬在晚上看，真好看，最后一个李宁了，被吊起来到空中，很高，很高，继续升高～～ OH my god ，升到最高处，绕嘴上圈，在空中跑，创意啊！！！赞！！！画卷在他下面缓缓打开，画卷始终在他身后，缓缓打开，太强了，弓虽！！！牛啊～～～李宁依然在空中认真的跑着，要绕场一周了，看来，不知主火炬到底在哪里啊？？到了，主火炬终于出现了，点 ing。。点了一个导火索，导火索螺旋上升，圣火熊熊绽放在北京夜空～～全城烟火一起点燃，烟火到达等顶峰。一个五环的烟火呀！！我坐在家里可以听到隆隆的烟火声，家里的视野不好，无奈啥也看不到！刚才急奔向楼顶，想看一眼最后的绚烂，可惜到了楼顶的门口发现，门已被锁，而且上了封条了。外面的烟火声还是有，心里一个字痒啊～～～不过无奈总是难免的，我的奥运开幕式实况转播也要结束了。动态奥运奖牌榜\n","date":"2008-08-08T15:52:40Z","permalink":"https://martinliu.cn/2008/08/08/2008-beijing-olympic-game-introduce-china-to-the-world/","title":"2008 Beijing Olympic Game introduce China to the world"},{"content":"Please download it here A paper from Open Management Consortium This is a paper from \u0026ldquo;2008 Ottawa Linux Symposium\u0026rdquo;. It will give you a nice insight about some great NSM projects. It is talking about OpenNMS, Zabix, Zenoss, GroundWorks and Hyperic, those might b the hottest projects around NMS field. If you are looking for a open source network and system monitoring solution, or you are testing one of them; you should check it out. I got this paper from Open Management Consortium.Sometimes, people might spend too much time on testing different projects; I know this is a kind of fun. But eventually they only got lots of comments about manny project. They still did not realize the value of open source. The best way to adpat open source is that you just pick one nice project and keeping to use it for months at least. I have a net admin frind who I had since helped to setup Cacti for all of his network devices. He don\u0026rsquo;t know so many NSM projects, but he really engoy Cacti. With Cacti, he can do a easier and better job then before. So, are you going to still watching open source world? Let\u0026rsquo;s get start your real open source journey.\n","date":"2008-08-04T09:26:57Z","permalink":"https://martinliu.cn/2008/08/04/systems-monitoring-shootout/","title":"Systems Monitoring Shootout"},{"content":"很久没有更新这个 blog 了，本来想保持每周一帖的频率，不过最近总被一些事情所耽误了。今天终于有空闲坐下来写点什么了。昨晚无意间发现了这个叫做 UnWakeAble 的 Theme，稍微看了一下马上就更换到这个主题了。这个主题有几个地方非常吸引我：它有自己的配置选项；能配置成 2 或者 3 栏的形式；提供 3 种内置的风格可以切换，这个太空船的黑色风格太吸引我了。我想在没有时间写正经 post 的时候，用有限的时间调整一下界面风格也不错呵呵，虽然之前曾经发誓，要把主要 blog 时间都放在提交高质量项目介绍和评论上，不过通过这个 blog 做适当的娱乐还是未尝不可的呵呵:) 可能是对 Wordpress 了解的很多了，用的也越来越多了，现在觉得它也可以作为一个公司内部的知识库来使用，知识库有可以说是一种特殊的 CMS 内容管理系统，它能方便用户查询和浏览相关的知识条目。昨天看了一下 wordpress 的 roadmap，它以后可以提供更多的 api，甚至于下离线的编辑内容的功能，我想这些都可以是外部系统和它集成的很好的接口。我说的外部系统可以是：IT 管理的服务台系统，现在很多厂商的服务台都有现成的 KB 模块，不过把知识条目放到 wordpress 这样一个外部的系统中还是很有优势的。关于把 wordpress 用作 CMS 内容管理系统的一些考虑您可以看看这个post今天去西四的广济寺，途中经过了潘家园市场、虹桥市场、天坛北门、天桥、西单等。途中的景色令我可以说是非常吃惊，奥运真的把北京改变了很多。潘家园门口兜售和田玉的巴郎子（新疆人对少数民族的一种称呼，其实是维吾尔语‘小青年’的意思）没有了，随处摆的地摊也没了，随处乱扔的白色快餐饭盒没了，在路边拉黑活的黑车也没有了。虹桥市场门口的路上以前总能看到的那些专门向老外乞讨的人也没有了。天坛北门的街道两旁真是很干净啊，垃圾、墙上的办证都没了。天桥哪里更是变化巨大，以前道路两边破烂的小卖部都没了。西单更是夸张啊：过街天桥附近打扫的人真多啊，而且以前扫大街的人都是自动化了；没人在骑着老式的保时捷垃圾车，取而代之的是等自动扫街的电瓶清洁车。北京变了，北京准备好了。呵呵我也喊两句口号吧！甚至于我在考虑，开幕式那天晚上，我去哪里看焰火。我里永定门的距离不算远，听说那是放烟火的中轴线上的最南点，暂时把这作为我的 plan A 了。我也很想知道，你奥运期间如何度过呢？[poll id=\u0026ldquo;4\u0026rdquo;] [poll id=\u0026ldquo;5\u0026rdquo;]\n","date":"2008-08-03T07:45:41Z","permalink":"https://martinliu.cn/2008/08/03/this-post-is-too-later/","title":"This post is too later"},{"content":"Slax - your pocket operating system Slax How to\n","date":"2008-07-04T14:31:15Z","permalink":"https://martinliu.cn/2008/07/04/running-linux-from-any-machine-without-installation/","title":"Running Linux from any machine without installation"},{"content":"If you have no idea, you should read this post \u0026ldquo;Google spotlights data center inner workings\u0026rdquo;.There are some notes I took as blowing.Google Infrastructure:\nclusters of 1,800 servers are pretty routine. an ordinary Google search query that involves 700 to 1,000 servers puts 40 servers in each rack Google has 36 data centers across the globe; Google has more than 200,000 servers; growing every day. Google largely builds its own technology. to treat each machine as expendable; Google prefers to invest its money in fault-tolerant software. NOT hardware fault-tolerant. Google uses ordinary hardware components for its servers, it doesn\u0026rsquo;t use conventional packaging. Google required Intel to create custom circuit boards. As to the servers themselves, Google likes multicore chips, those with many processing engines on each slice of silicon. three core elements of Google\u0026rsquo;s software: GFS, the Google File System, BigTable, and the MapReduce algorithm. Google helps with** a lot of open-source software projects** that helped the company get its start, these packages remain proprietary except in general terms. GFS stores each chunk of data, typically 64MB in size, on at least three machines called chunkservers; master servers are responsible for backing up data to a new area if a chunkserver failure occurs. The largest BigTable instance manages about 6 petabytes of data spread across thousands of machines. On any given day, Google runs about 100,000 MapReduce jobs; each occupies about 400 servers and takes about 5 to 10 minutes to finish. 总结一下上面的东西：Google不是买的成品服务器，而是去Intel定制的芯片自己攒的，特别喜欢使用多核的cpu，由于他们的程序都适应与多线程并行计算的方式。一个群集有1800个服务器是非常平常的。Google大概有二十万个服务器，每40个放在一个机架上，分布在全球36个数据中心。Google不使用商业的服务器包括数据库等软件，一来造价太高，二来无法满足扩展性的需求。Google使用了很多的开源软件项目，事实上它们就是站在开源软件的肩膀上发家的；GFS，BitTable等都是它们常用的。广泛使用软件容错技术。传统商业公司和google的不同： 从硬件到软件基本都使用现成的商业产品。基础架构中的每个环境都是钱堆出来的。用钱来节省时间，不过google的时间和金钱的节省都是值得学习的。 在容错技术上硬件HA技术用的最多，群集中的服务器数量不多。 不同业务系统之间几乎是孤立的。从数据库到web到关联的网络设备都是一套独立的系统，甚至于按业务系统划分运维的团队。 系统的扩展性比较小，对核心部件：如核心应用服务器或者核心数据库服务器的扩展，垂直扩展比较多，追求单机的多CPU，高主频，高内存。而另一方面：在这些系统上的压力测试和性能调优工作异常的痛苦。 饱受被商业软件公司绑定之苦，如果数据库、应用服务器等出了产品的bug，厂商提供fix一般都需要一定的时间周期-时间代价比较高，原厂的现场技术支持服务金钱代价也比较贵。 从高层看：CTO、CIO、CEO没有正视开源技术。只要预算允许，引入和采购业内流行的商业技术似乎是永恒的明智之举。开源软件技术应用的有不过很少。 从基层看：工程师可能有足够的某项开源的技能，不过没有适当的渠道能反应到上层来提议使用该技术；如果在下面擅自使用了某种技术，非常担心出了IT事故后对后果的承担。开源技术对技术人员只是一个爱好而无法应用与自己的日常工作中。 特别是中国用户对最新潮的IT技术永远保持着极度的热情，不管是硬件和软件买就买最先进的，数据中心的机房最后成为博物馆，新老系统很难整合资源。把基础架构的彻底改变寄希望于未来的某种技术革命，实际上技术变革已经悄悄发生了好几波了，怎么管理现状怎么就是越来越艰难，越来越花钱呢？走中国特色道路真的值得提倡一下了。 Google的这些特点真是引人入胜，任何企业都无法复制；而且也不可能复制，它毕竟是一个商业公司而不是一个开源项目。如何使用现有的技术和人员来打造出你自己的完美基础架构呢？现实中这么多的role model已经证实了很多技术都是可用的，完美的境地也不是空中楼阁。如何集思广益并多多引入开源技术和人才可能是一个需要斟酌的题目。[poll id=\u0026ldquo;3\u0026rdquo;] ","date":"2008-06-21T07:01:58Z","permalink":"https://martinliu.cn/2008/06/21/google-infrastructure/","title":"What is Google Infrastructure?"},{"content":"哦不是中暑:-)而是发烧；夏天就要到了，监控服务器的主板温度和风扇是否工作正常有变的比较重要起来了。今天发现一个文档 Monitoring Temperature and Fan Speed Using Ganglia and Winbond Chips 这个是一个不错的文档，值得参考一下。文章是写如何在 Ganglia 中实现对主板温度和风扇的监控。以前也有人问过我这个问题“Ganglia 的监控图上为什么没有温度也风扇的图”；相信您看后就知道怎么回事了。下面是我对关于温度和风扇监控的一点想法：\n主板的芯片能提供这些数据的访问给操作系统 操作系统上有sensors这个命令工具用来采集这些数据 有合适的脚本分析上面命令的输出数据转换成能被监控工具（ganglia， cacti，nagios， opennms）采集的格式等 往往这两个参数并不是监控工具的默认采集数据，所以需要扩展采集工具的采集集合，收集并保存这些数据。 在监控工具如Ganglia中显示这些数据，当然如果有自动报警功能就好了，可以及时通知管理员给服务器消暑：） Ganglia是最好的网格或者群集的监控软件，不过当你用它的使用也要注意到下面这个问题：What does Ganglia not provide?Ganglia does not attempt to address service monitoring or reporting (unlike Nagios). So far, we have not come across a single monitoring solution that addresses all of our needs effectively.上面所说的服务监控是说，它的特点不是想Nagios和OpenNMS那样对服务器系统做非常全面细致的监控，它默认的监控指标比较少不过对于监控网格或者群集这种数量巨大的对象来说这些比较经典的指标也够用了，特别是对服务器的可用性，CUP、RAM，网络资源利用率和工作负载等数据的采集也比较够用了。如果你使用它来监控数量不是很多服务器的话，你可以使用它的可扩展性加入任何想监控的KPI。我最喜欢的还是它能把服务做分组，而且垂直的方向上可以加N层的嵌套；这种组织方式能比较好的适用于业务系统众多而复杂的数据中心。 ","date":"2008-06-15T15:50:31Z","permalink":"https://martinliu.cn/2008/06/15/monitoring-temperature-and-fan-speed-using-ganglia/","title":"盛夏严防服务器中暑"},{"content":"\n在我做任何比较之前还是先看看 Wiki 上对一系列网管监控软件的比较，源网页地址在 http://en.wikipedia.org/wiki/Network_monitoring_comparison\n上面一共列出了 12 中不同的开源软件，从 13 个方面以矩阵的方式来做比较。\nNagios 和 Cacit 都是比较老牌的开源网管软件；OpenNMS 是稍微点出现的项目，它集成了前两者的部分优点，界面是 Java 的界面，后台的自动发现机制非常的方便。Zenoss 是一个比较年轻的项目，所谓长江后浪推前浪，它是纯 python 语言编写的一个软件，架构非常的不错，而其界面做的非常好，面向对象编程的理念处处可见。从根上可以看出它们的主要编程语言各有不同，这也决定了它们的特点和发展方向的不同，这里仅以此作为一个见到的比较和总结。其实我想写一个更好的比较表，如果您感兴趣的话请留言，我们可以一起做一个更好的比较。\n","date":"2008-05-31T05:52:22Z","permalink":"https://martinliu.cn/2008/05/31/zenoss-opennms-comparison/","title":"zenoss opennms comparison/比较"},{"content":"现在我坐在清华主教学楼里等待这个自由软件大会的开始。Zeuux 社区组织在发一些免费的书籍和及时贴。我也领了几个，在笔记本上贴了三个：1）GNU\\Linux inside2)GNU 牛头3）GNU\u0026amp;Linux the dynamic duo。这次也将会见到 Richard Stallman，听听他今天能讲点什么。现在会议还没有开始，已经有很多学生来此等候，好像 GPL v3 的 T 恤比较强手，很多学生都在找自己的号。为了获得 Richard 签名的人可以购买一本他的文件，附送一件这样的 T 恤，会后即可获得签名。发现www.gnu.org网站的速度非常慢，几乎打不开，通往自由的路其实是艰难的:P写在活动之后：现在已经是晚上 11 点，我坐在电脑前上网，把今天活动的收获整理一下。我做的第一件事情是把我的 blog 的标题改了，logo 随后在改。从“LiuZheng\u0026rsquo;s OSS Blog” 到 “LiuZheng\u0026rsquo;s Free Software Blog”。Richard S.的一席话对我来说可谓醍醐灌顶了。我以前把 Linux 和 open source 软件都看做就是自由软件，可谓是一叶障目不见泰山。Richard 今天把他对 GNU 所作的所有相关工作都做了一个回顾，并解释了 Linux 其实是 Gnu-Linux 的一部分而以，还介绍所谓开源软件的真实来由。这也让我能更加理解他彻底不同意 Sun 开源策略的原因。Linux 的发展和产生依赖于 Gnu 项目下的所有自由软件，Richard 认为如果 Linux 的发明人没有在当时创造出 Linux 内核的话，一个 GNU free operation system kernel 也早晚会产生。我认为 Linux 的产生也是有他的必然性，它是在软件发展历史上应运而生的；由于它站在了前人的肩膀上，能整合所有相关的自由软件，从而风靡一时，甚至声明远胜 GNU。Richard 认为开源软件是商业公司利用自由软件谋利的一种手段，open source 这个词在商业公司市场宣传的运作下，声势也掩盖了 GNU。我发现其实我的一些认识也一直受到潮流的影响，如果我是和 Richard 站在同一条战线的话，我可以说彻底的被潮流带到沟里去了。总之 Richard 给我一个清楚的自由软件的发展脉络。他几乎是一个斗士，坚定的认为：任何一个软件用户都要保护自己的自由，彻底的抵制任何私有软件；他把 MS，RealPlay，Adaobe 等商业软件批斗的非常狠。到结束时，他穿上他那标志性传道士的行头就地化身为自由软件教堂的一个圣徒，来呼唤和号召大家一起行动起来加入自由软件的行列。说实话我作为一个商业软件的从业人员，站在我个人立场上我很难说我是否要站到 Richard 的行列里，很难做到彻底的变成一个自由软件的卫道士。虽然现在可以说立场还是糊涂的，不过总算头脑边的清醒了，我应该会以这样的头脑来静静看待软件世界即将到来的变革吧！\n","date":"2008-05-31T04:59:24Z","permalink":"https://martinliu.cn/2008/05/31/zeuux-free-software-summit-tsinghua/","title":"Zeuux Free software summit @Tsinghua"},{"content":"我准备安装的版本是 ganglia-3.0.7 ， 参考的安装文档是http://www.linuxsir.org/bbs/thread309837.htmlrpm 的安装会比较省事。rpm 安装都会很正常，不过在 Suse 下面需要注意一下两点：\ngmond和gmated的启动脚本不是rpm包中默认装上的那个，那个脚本适用于redhat linux；下载源码编译之后在gmond/ gmated/的文件夹里有后缀为 .SuSE的哪两个文件才对。 rpm吧gmated的web界面默认安装路径是/var/www/http/ ，SuSE下的apache的路径是 /srv/www/htdoc/；安装完后copy或者连接过来 配置： gmond.conf 更具我参考的安装文档产生这个文件的命令是 gmond -t \u0026gt; /etc/gmond.conf；rpm安装包中有这个文件，如果需要恢复到默认状态可以使用这个命令。 gmated.conf 是服务器端的主要配置文件，详细阅读一下源码包中的那个html文件对这个文件的配置会有帮助 安装过程中出现的问题如下：在启动gmond的时候启动失败，debug一下可以看到下面的错误。sles:~ # gmond \u0026ndash;debug=9slurpfile() open() error on file /sys/devices/system/cpu/cpu0/cpufreq/scaling_max_freq: No such file or directoryudp_recv_channel mcast_join=239.2.11.71 mcast_if=NULL port=8649 bind=239.2.11.71Error creating multicast server mcast_join=239.2.11.71 port=8649 mcast_if=NULL family=\u0026lsquo;inet4\u0026rsquo;. Exiting.在所有虚拟机（host-only 网络设置）上都遇到这个错误。一次一个NAT网络的虚机上正常至今觉得这是一个网络的问题，还没有想出正确的配置和解决方法。如果您有什么好建议请留言。 ","date":"2008-05-24T02:15:27Z","permalink":"https://martinliu.cn/2008/05/24/ganglia-install-and-configure/","title":"Ganglia install and configure"},{"content":"http://www.datacenterknowledge.com/这个网站还是不错，有很多关于数据中心的知识。它应该主要是收集业内在该领域里新咨询，先收录一下，回头慢慢学习。这个 vido 我觉得也可以学习一下。IBM 和 Google 结成联盟开展企业云计算方面的研究，可能会建立“IBM-Google cloud ” 这个云会运行在 Linux 上，使用 Xen 做系统虚拟和 Apache Hadoop。同时 Google 和 IBM 都有自己巨大的数据中心，还不知道它们将来的研究成果会运行在谁家的设备上，让我们拭目以待。Tips：有些网络视频比较大，在线看如果网速比较慢的话可能不能正常浏览。很多下载视频的工具好像都是要收费注册的，否则只能下载 60％。我发现的一个方法是，把视频网址输入到这里 http://www.techcrunch.com/get-youtube-movie/ 它会给你生成一个 http 的下载连接，点击后一般的 http 下载工具就能下整个视频了，之后用视频浏览的软件查看，正在缓慢下载上边的视频。不知道你有什么好方法或者是工具可以推荐呢？http://youtubedownload.altervista.org/ 是我现在所使用的，不过下载的太慢了，不能支持多线程下载。\n","date":"2008-05-12T00:57:06Z","permalink":"https://martinliu.cn/2008/05/12/enterprise-cloud-computing/","title":"Enterprise cloud computing"},{"content":"A) Download 10201_database_linux32.zip from Oracle website.B) Download 10gR2_openSUSE102_introduction.pdf and ora.rpm from ftp ftp.novelŀcomC) Install Oracle, following quick steps:1. Install openSUSE 10.2 with \u0026ldquo;C/C++ Development\u0026rdquo; selection.2. Download and Install orarun package.3. Enable and set password for newly created user oracle by orarun.4. Set updated kernel parameters by executing /etc/init.d/oracle start.5. Download and unzip Oracle 10gR2 Database SW.Edit file database/install/oraparam.ini to add \u0026ldquo;SuSE-10\u0026rdquo; to line #39.6. login as user oracle and run Oracle Universal Installer \u0026ldquo;database/runInstaller\u0026rdquo;.Troubleshooting:1) installer error:\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;oracle@Martin:/database\u0026gt; ./runInstallerStarting Oracle Universal Installer\u0026hellip;Checking installer requirements\u0026hellip;Checking operating system version: must be redhat-3, SuSE-9, redhat-4, UnitedLinux-1.0, asianux-1, asianux-2 or SuSE-10PassedAll installer requirements met.Preparing to launch Oracle Universal Installer from /tmp/OraInstall2008-05-08_09-11-56AM. Please wait \u0026hellip;oracle@Martin:/database\u0026gt; java: xcb_xlib.c:52: xcb_xlib_unlock: Assertion `c-\u0026gt;xlib.lock\u0026rsquo; failed.\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;Solution :\nexport LIBXCB_ALLOW_SLOPPY_LOCK=1 run runInstaller again 2) 在安装完成末期,需要root用户运行两个脚本，完了之后，我遇到一个错误对话框，点击过去之后好像没有发现安装失败，安装目前正常More SQL scripts:http://cs-netlab-01.lynchburg.edu/courses/Oracle/SQLPlus.htmSQL\u0026gt; CREATE TABLESPACE AMP2 DATAFILE \u0026lsquo;/opt/oracle/oradata/orcl/AMP.dbf\u0026rsquo; SIZE 200M;Tablespace created.SQL\u0026gt; CREATE USER AMP IDENTIFIED BY ca12342 DEFAULT TABLESPACE AMP3 QUOTA UNLIMITED ON AMP;User created.SQL\u0026gt; GRANT CONNECT, RESOURCE TO AMP;Grant succeeded.SQL\u0026gt; GRANT CREATE SESSION, CREATE TABLE TO AMP;Grant succeeded.How to start oracle em manully?可能出现的错误如下，没有ORACLE_SID的 环境变量, 可能网络地址和环境发生变化,比如主机名修改等.oracle@Martin:/product/10.2/db_1/bin\u0026gt; ./emctl start dbconsoleTZ set to PRCEM Configuration issue. /opt/oracle/product/10.2/db_1/localhost_orcl not found.oracle@Martin:/product/10.2/db_1/bin\u0026gt; ./emctl start dbconsoleTZ set to PRCOC4J Configuration issue. /opt/oracle/product/10.2/db_1/oc4j/j2ee/OC4J_DBConsole_localhost_orcl not found.修正方式:oracle@Martin:/product/10.2/db_1/oc4j/j2ee\u0026gt; cp -R OC4J_DBConsole_Martin.bmc.com_orcl OC4J_DBConsole_localhost_orcloracle@Martin:/product/10.2/db_1\u0026gt; cp -R Martin.bmc.com_orcl/ localhost_orcloracle@Martin:~/product/10.2/db_1\u0026gt; bin/emctl start dbconsoleTZ set to PRCOracle Enterprise Manager 10g Database Control Release 10.2.0.1.0Copyright (c) 1996, 2005 Oracle Corporation. All rights reserved.http://Martin.bmc.com:1158/em/console/aboutApplicationStarting Oracle Enterprise Manager 10g Database Control \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. started.\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;Logs are generated in directory /opt/oracle/product/10.2/db_1/localhost_orcl/sysman/log启动了后访问: http://localhost:1158/em/手工启动Oracle实例的方法1) sqlplussqlplus /nologconnect sys/manager as sysdbastartup2) rcoracle需要修改如下几个文件：/etc/oraInst.loc /etc/oratab / /etc/sysconfig/oracle /opt/oracle/product/10.2/db_1/bin/dbstart /usr/sbin/rcoracle 修改这些文件中的路径等信息知道 rcoracle start 命令不出错为止。 ","date":"2008-05-08T01:51:16Z","permalink":"https://martinliu.cn/2008/05/08/install-oracle-102-on-opensuse-103/","title":"Install Oracle 10.2.01 on OpenSuSE 10.3"},{"content":"\nThis is my second virtual appliance, it suppose to work for production. This is a 100% open source solution for inventory/asset management, it including OCS Inventory NG and GLPI. I encourage you to deploy it in your school or company.\nAbout virtual appliance / 关于此虚拟应用\nOpenSuSE 10.2 (root password is martinliu) LAMP+Perl OCS Inventory v1.02 RC1 GLPI v0.70.2 bridged network You can download it from below.\nDownload it 下载 This source is not available any longer. I will offer it by DVD. 这个地址已经无法下载，请关注我即将推出的 DVD 版虚机。\nThanks BigYue.com for donated upload space. 感谢**BigYue.com**的空间。\nRun Server / 运行管理服务器（\u0026gt;=2GB RAM）\nun-zip the image on a computer which will be network with for any managed nodes to upload inventory information. This host machine should have at least 2GB RAM.\nDownload a wm player and install it.\nOpen virtual machine and power on.\nAt top of boot screen, you will find the ip address of this vm I assume you have a DHCP server on network. Otherwise you have to configure network manually for this vm.\nAccess to the home page (http://IP_address_Of_vm/) which I made it for you. On this page, there are login information and entry points.\nNow you have a full function asset management solution up an running. You will configure security for the whole system before you do more work with it. You should change the password for root and mysql. Mysql have a blank password. After you done this, you must re-configure database connection for both OCS Inventory NG and GLPI accordingly. Please refer to administration guide.\nDeploy Agent / 安装部署代理\nFor any Unix-like system : you will manually install on each of target computer. Following the installation guide from OCS inventory NG. For MS windows system: You can do manually installation too. Also you could distribute agent via AD domain policy automatically, all target machines must logon the AD domain at least once in order to get agent package installed. Agent is running as a windows service if it is installed properly; inventory information will update timely to the server. The Agent package can be copied to a USB key. You can use it for collecting inventory information for off-line computers, or a computer which you wont have any piece of OSS installed on it. I\u0026rsquo;m kidding, I guess you love to run OSS on any of your computers, PS: the more the better. Management Asset / 管理 IT 资产\nSynchronize inventory data from OCS Inventory NG to GLPI. GLPI can do it at interval that you set hourly or daily. Those two OSS are just easy to use. You will still read some necessary documents on their web. 请阅读尽可能多的使用手册 As long as you use this virtual appliance, I can see your smile face. Don\u0026rsquo;t forget give me comment below and let me know how many nodes do you manage. Enjoy and have a lot of fun. Support / 支持 This virtual appliance comes with ABSOLUTELY NO SUPPORT. I will try my best to support you, but questions are not guaranteed for a quick answer. I strongly recommend you will go to open source community when you run into any error. I believe you can get support and might help others too. If you improved this virtual appliance, I am looking forward to see your share. I\u0026rsquo;d like to hear any good idea from you.\nNotes:\nFrom wikipedia: Comparison of open source configuration management software ","date":"2008-04-28T02:01:06Z","permalink":"https://martinliu.cn/2008/04/28/deploy-asset-management-solution/","title":"Deploy asset management solution"},{"content":"这周我在繁密的出差当中，偶尔能用 Blackberry 看一眼邮件，不过完全没有可能回答读者任何问题。最近这两周有愈来愈多的博客读者给我发了邮件，问我了一堆问题，我很希望能给他们一个好的答案，不过这种可能性太小了，尤其是在这样的时间里。通过他们焦急的情绪，我忽然想到这个问题：如何获得开源软件的相关支持？其实这也是我的一个问题。于是乎我想到下面的一些东西。**搜索 **是最主要的一个途径，你会发现很多一般问题都能获得答案，仔细选择和尝试不通的关键词**邮件组/论坛 **每种开源软件都有这两种或者至少一种用户支持方式，其实这是用户互助的方式，用户之间的帮助往往更快。这些就是社区的载体，有些邮件组比较活跃，有些论坛比较活跃；例如：OpenNMS 的邮件组就非常活跃，我订阅了其中的几个子项，问出问题往往能得到很快回复，其实 OpenNMS 的人每周有不人负责回答问题；Cacti 的论坛就相当好，那里也是用户直接互相同享模板的主要地点，解决问题的功能也相当好。很多国内中文论坛也非常好，推荐一个http://www.itnms.net/ 更多的还需要你自己去发现。**线下用户团体 **我参加国 BLUG 的线下活动，感受非常深刻，当你面对很多来自不同背景不同技术特长的 OSS 认识的时候，找到合适的高手并不是困难的事。不要躲在网络后面捣鼓开源软件，走到现实世界来享用它吧。**商业支持 **有些开源软件有两个网址 oss.org 、oss.com；往往.com 网址上有商业支持的说明，商业和开源并不矛盾，更具你的需求购买商业支持也是一个非常现实的方式。**聪明问问题 **如果你遇到问题，首先要学会正确描述问题，问题的描述信息包括：软件版本、运行环境、出错情景，以及其它任何关键或者有用的信息。很多软件都运行在某种技术堆栈的最高层，下层的环节包括 OS、DB、Web、Php 语言等；你应该清楚如果是这些环节出错，那么你该去响应的社区求助，要问对人，不要问错人，也不要问傻问题。**友好的交流 **每当我遇到一些开源高手的时候，幸运的是他们非常的 nice，我可以轻松的问任何问题，无论简单、还是复杂。技术思想的沟通应该是一种愉快和友好的体验，保持一种谦虚正常的心态，这是自身素质和修养的表现。**语言 **对所有非英语人士，英文是必须要会的，英语不灵的话需要好好补习补习。**支持我的读者 **推荐通过留下 comment 的方式问你的问题，发给我邮件我很容易忽略，而 comment 是我必须处理的。如果我有答案的话，我会在 3 内给出回应；超过 3 天的话表明，很可能我目前还没有一个合适的答案。在留下问题的同时，一定多面出击寻找答案，别在这守株待兔。**关于此博客 **定义如下：技术型、记录型、日志型、开放型和共享型。对我自己来说，它是我记录研究开源软件的一个载体，是我向需要这方面信息的人分享的一个窗口。它不具有任何商业性，不承诺提供任何程度的支持。通过这个博客有相投兴趣的人也能相互交流。\n","date":"2008-04-24T16:48:12Z","permalink":"https://martinliu.cn/2008/04/24/e5a682e4bd95e88eb7e5be97osse694afe68c81efbc9f/","title":"如何获得OSS支持？"},{"content":"I made a OTRS 2.2.6 virtual machine for anyone who wants to test both OTRS and OTRS::ITSM. It was built on OpenSUSE 10.2, including OTRS 2.2.6 and OTRS::ITSM 1.0.94. OTRS::ITSM implements ITIL (R) focused IT service management. OTRS::ITSM 1.0.94 is still on Beta, you might have some bugs when using this virtual machine. Please download from my box.net, if you have an comment please just let me know. I\u0026rsquo;d like to invite you to improve this virtual machine if you have any good ideal.\nDownload it from here 点此下载。 This source is not available any longer. I will offer it by DVD. 这个地址已经无法下载，请关注我即将推出的 DVD 版虚机。\nThanks BigYue.com for donated upload space. 感谢**BigYue.com**的空间捐助。\nCredentials 登录密码如下\nOpenSuSE 10.2 : username / password is \u0026ldquo;root/ca1234\u0026rdquo; MySQL : username / password is \u0026ldquo;root/ \u0026quot; OTRS : admin username and password is root@localhost/root Run 运行压缩文件中的虚拟机\nDownload and install VM Player, the machine should have 1GB RAM at least.\nUn-zip OSS.rar in a partition, freespace must be 2.5+ GB.\nDouble MartinLiu.cn.vmx and power on this machine.\nClick \u0026ldquo;keep\u0026rdquo; and OK button when you get a popup box。\nThe network connection of virtual machine is \u0026lsquo;bridged\u0026rsquo;. You will see the ip address of this virtual machine at 5th line one the top of boot screen. NOTE: you should have DHCP server on your network.\nAccess 访问虚拟机\nSSH to it. Agent login page: http://ip_address/otrs/index.pl Customer login page: http://ip_address/otrs/customer.pl Tips of OTRS installation 安装经验\nApache should have perl mod, configure perl for apache before you install OTRS. 这是一个 Perl 写的程序，所以在安装之前最好吧 apache 上的 perl 配置好，确认 apache 能运行 perl 的东西 Make sure your database accepts packages over 5 MB in size. Increase max_allowed_packet in my.cnf to 20MB. 修改 my.cnf 中的 max_allowed_packet 参数到 20MB，否则 ITSM 的包安装有问题。 OTRS 需要一写附件的 perl 包的支持，手头最好有操作系统的安装 dvd 或者直接从网上安装。 Usage 用途\nYou can use it for any purpose, if you need any support you will contact OTRS。你可以用于任何用途，本博客不提供技术支持，请联系 OTRS 的邮件列表。 ITIL training, OTRS::ITSM implements ITIL (R) focused IT service management. 可以用于 ITIL 的培训，它能演示：incident management, problem management, configuration management 等。 This virtual machine comes with ABSOLUTELY NO WARRANTY. DO NOT USE it for production. 仅供测试使用，切勿用于生产环境。 If you like OTRS, you may try Request Tracer\n今天一个网友告诉我另外一个开源的类似系统Request Tracer ，有空的话回头也试试。\n","date":"2008-04-21T02:16:20Z","permalink":"https://martinliu.cn/2008/04/21/open-source-ticket-request-system-otrs-226/","title":"Open Source Ticket Request System - OTRS 2.2.6"},{"content":"最近两周最吸引我的 TAG 是这个词“cloud computing”。在我前一个文章中稍微展望了一下云计算的前景“云计算吧电能转化成计算能力，然后向用电一样的来使用，我们甚至不需要使用 PC 这样的个人信息话设备来管理我们的信息，所有的信息和信息的处理都在云上发生”。在了解了更多的信息之后，这些可能实现，但是这种巨变需要时间，而且可能是很长时间；清醒之后不得不佩服 Google 在这方面的宣传。理性认识云计算的简单方式，扫扫盲：\n阅读一下wikipedia对‘cloud computing’的解释 听听John Willi的两个Podcast 多看看非google来源的信息：） 读读这个GRIDtoday的文章 \u0026ndash; \u0026ldquo;Clouds are Looming and We Love It\u0026rdquo; 很多厂商都在参与这个热点，open source也要加油，期待开源在这个领域的发展。 ","date":"2008-04-18T15:05:23Z","permalink":"https://martinliu.cn/2008/04/18/clouds-are-coming/","title":"Clouds are coming"},{"content":" Ganglia 是一个用来监控群集和网格计算环境的软件。它是可以扩展的分布式监控系统，它基于多播协议，数据存储和传输的格式都是基于开源的标准：XML/XDR/RRDTool/APR/Apache/php 等。\n应用 Ganglia 的几个理由：\n在一个点上监控包含很多服务器的群集，单个 cluster 内服务器的数量比较多，需要从整体看某个 cluster 的可用性和性能，也要能看到单独某个机器的运行情况。 监控分布式的 cluster 环境，例如跨网段和地域的灾备的环境。 需要监控系统能分 N 级的查看方式，以银行为例：北数据中心\u0026ndash;\u0026gt;网络银行业务\u0026ndash;\u0026gt;个人网银系统\u0026ndash;\u0026gt;web server 群集\u0026ndash;\u0026gt; WebSvr001；可以按业务逻辑和系统架构逻辑。 需要 724365 的监控整个系统，能得到可用性、性能和容量等方面的报表。 应用 Ganglia 的几个好处：\n监控能力的无限扩展，被管理服务器数量达数千个甚至根多。 纯 web 前端，apache 和 php 的应用页面方便定制 强壮的系统结构，并且具备可以任意扩展采集数据 KPI 的特点 适合高性能计算或者网格计算环境。 Ganglia 应用需要注意的方面：\n在每一个节点上需要部署一个代理程序，考虑到对代理配置的变更的工作量，在部署代理之前，需要彻底的分析需求，尽量减少部署过程中配置变更带来的多于调试的工作量。 部署后期的变更工作，如果比较频繁的话将导致后台维护工作量增大，可以考虑使用一些开源的软件分发和自动化配置管理的工具。这些配置的初始化工作可以与 OS 的安装部署工作一起考虑。 它被很多大学和专业机构研究并使用，所以有非常多的专业文档可以参考，哪行文档多分析了 Ganglia 的系统架构和特点，多系统的原理介绍的非常细致。下面是我收集的几个关于这个软件的文档请参考。并且在它们的网站上也可以看到很多相关的资源连接，都是非常好的实施方面的详细文档。\nIf you need more detail please take look those documents below.\n","date":"2008-04-16T09:41:06Z","permalink":"https://martinliu.cn/2008/04/16/using-ganglia-for-cluster-and-grid-monitoring/","title":"Using Ganglia for cluster and grid monitoring"},{"content":"There is what I got from http://appengine.google.com/\nI read a post last night, Developers, start your engines Even I am not a developer, I definitely look forward to sing up appengine. . But I can not have it, that\u0026rsquo;s pity. Let\u0026rsquo;s see how to create a \u0026lsquo;hello world\u0026rsquo; appp on google appengine.Let me see your app on google. See more on http://appgallery.appspot.com/Google App Engine 是一个开放的应用运行平台，它提供给你的应用无限的扩展性，并免费的在后台运行。记得以前和同事曾经有过一个话题“GOOGLE 的基础架构是怎么搭建的？”，google 的成功和它对基础架构资源的结构方式是密不可分的，大家都想知道这个秘密。不过现在好像你不需要模仿并拥有一个相同或者相似的了，你有可能免费访问并使用了。Google 把它定义为一种服务，和邮件服务好像没有任何区别。IT 基础架构实现和提供的是计算资源，而以后随着‘云计算’等技术的实现，使用这种资源可能会想使用电一样方便。不需要拥有发电厂，你的电灯依然会亮。\n","date":"2008-04-10T05:23:44Z","permalink":"https://martinliu.cn/2008/04/10/do-you-have-a-google-app-engine/","title":"DO you have a google App Engine?"},{"content":"6yeas ago, I had a open source talk with my friend Tom Chen. The topic was \u0026quot; does oss suppose to work for large enterprise for mission critical business?\u0026quot; Until last week, I thought I found answer by myself; the OSS does works for bank business in China. During last week, I deployed my company\u0026rsquo;s product on CCB\u0026rsquo;s machines. Those machines are part of e-banking system, 1/4th of them are on Redhat Enterprise Linux 4 update6. As we all know CCB is one of big four bank in China, those Linux machines are running Apache for web-tier of e-banking system. A 160MB installation image was ftp to every managed nodes, untar it then ran a same install script. I felt Linux boxes took less time then other HP-UX boxes, they are similar servers I mean similar hardware. Actually CCB have many Linux servers all over the country then I touched at this time.I had a business travel in Urumchi lat year. I met another bank customer there. When we were talking about what kind of OS they have. They impressed me very much. They said part of servers are on SuSE Enterprise Linux, they are just virus-free and lower maintenance cost then M$ Windows. They are just use those SuSE Linux to running IBM DB2 database for some bank business. They like Linux, but not use it everywhere. I didn\u0026rsquo;t tell them that is my favorite Linux distribution. Just look back 5 years, I would say more and more companies are using OSS or they are considering have more OSS for their business.Let\u0026rsquo;s get back to my topic: what OSS could be good for you? Do you have confidence for have more OSS for your business system? I think you need to just have the right-size of OSS. You have to figure by yourself. The following are my suggestions:\nOSS adoption might take years, you should have a plan. Starting from one single on-going project, you could migrate all or part of a business system to OSS(Linux for OS, Tomcat for mid-tier, or what every you\u0026rsquo;d like to use) Monitoring the entire IT by same way by 24 hours. You must have availability and performance report for every node. Then you could analyses those history report to figure out if OSS does a good job or not. A incident report of whole IT support org is highly recommended. Having more OSS engineers might speed up the process you move forward to OSS. If you like my thought in this post, you would like to see this old one. ","date":"2008-04-05T14:19:20Z","permalink":"https://martinliu.cn/2008/04/05/get-right-size-of-oss/","title":"Get right-size of OSS"},{"content":"安装我的安装环境是虚拟机下面安装的 CentOS4.4；在安装的时候需要注意的是：在安装选择的时候 PostgreSQL 一共有十几个可选的包，把可能会用到的包都尽量选中，否则就要手工去安装了，手工解决包之间的依赖关系烦啊。从光盘上装的好处就是它自己帮你把用户和启动脚本建好了，安装后需要检查如下两个文件：1）/etc/init.d/postgresql 是否存在；2）/etc/passwd 里面有没有 postgres 用户。启动数据库第一次启动，用 root 用户登录，运行命令：[root@RBA init.d]# service postgresql start ；如果需要数据库在系统启动是就启动的话需要运行：\n检查结果\n数据库管理先切到 postgres 用户 su postgres新建一个数据库 createdb amp新建一个超级用户，需要在 shell 下运行：\n链接到数据库之后，确认以下：\n给用户加一个密码：\n其他参考信息\n","date":"2008-04-03T08:25:44Z","permalink":"https://martinliu.cn/2008/04/03/postsql-basic-admin/","title":"PostgreSQL基本操作指南"},{"content":"开源一般都是谁在玩？我觉得还是开发人员比较多，通常有开发背景的人才会比较轻松的去下载源代码，编译并运行。现在网上有很多能让您轻松搞定开源软件的方法，虚拟技术的发展使我们能更轻松的获取并运行开源的解决方案。向往糖果盒子中放巧克力一样容易。最近我收到了几个OTRS的新版发布的新闻邮件。先说说关于 OTRS 的一些新闻，2008-03-31 发布了最新的一个版本 OTRS 2.2.6 (Ipanema)。这个版本是一个 2.2.6 的安全补丁修复版，修复了一些安全的 bug，同时有提供了另外两种语言的支持：土耳其和越南语；当然 OTRS 是能够支持简繁体的中文的。而且关于语言方面的翻译对照表也是可以自行修改的，可以把流程当中的一些术语翻译成符合你企业实用习惯的名称。OTRS 后台能支持非常多的数据库，包括 Oracle，MS SQL 等非开源数据库，它的核心程序是用 Perl 写的，这些程序运行在 Apache web 服务器上，客户端是用的纯 web 的方式，后台的管理提供 Web 和命令行两种方式。它的安装对于我来说不是很方便，安装文档中并没有写的很详细需要哪行 Perl 的包，apache 上需要安装哪行 Perl 相关的东西；不过您对 Perl 非常熟练的话相信没有这个问题。导致的问题是我在安装了 ORTS 之后，它或者它的某些程序运行不了。总结一下体验开源软件可能的一些步骤：\n安装某个版本的Linux 下载开源软件的安装包或者源码，开发人员可能更多回去下载源码，编译安装 寻找次软件相关的安装文档和攻略，一步一步的照做。 配置系统来满足次软件的安装和运行条件 管理和运行该软件需要的服务，例如MySQL，apache等 运行该软件 继续查看软件的使用文档，学更多内容，体验感兴趣的功能 在这一个过程中可能遇到的问题有： 痛苦与重新安装操作系统，往往系统中的一些包会缺少或者版本不符合安装需求，如果对Linux系统包管理不熟练的话这是最容易出现的问题。 痛苦与对底层支持应用的配置和管理，底层依赖的系统服务可能有数据库、web服务器或者应用服务器等；至今记得我第一次被迫在PostgreSQL中创建数据和用户的痛苦 有些OSS项目文档做的非常好，有些不好，那么安装和配置OSS的过程也可能会非常麻烦；毕竟很多配置文件的修改都需要手工修改配置文件 应用虚拟技术可能是一个比较好的方式，目前我找到两个比较好的网站能提供 OSS 虚拟应用下载的，如下所示。http://www.rpath.com/rbuilder/http://www.jumpbox.com/这两个网站的区别是：JumpBox 是提供开源软件包下载和相关服务的，当然下载肯定是免费的；rPath 不但提供下载而且能给你空间去攒一个你自己的虚拟应用。当然 VWMare 的网站也能提供这些虚拟应用的下载：http://www.vmware.com/appliances/这里不想讨论虚拟技术的好处，不过它确实给体验和应用 OSS 带来很多方便。我第一次下载的虚拟应用是 Zenoss，下载总共花了 10 分钟，下载的过程当中我在看 Zenoss 的文档，下载的虚拟机运行起来之后，我做的第一件事情就是运行自动发现网络设备的命令了。通过虚拟这个桥梁，更加节约了我们体验和应用 OSS 的时间。我想这应该是开源和虚拟共同给我们带来的好处，道理很简单如果你下载并且使用一份包含 Windows 操作系统的应用，而没有给 MS 交钱的话，那么你就是盗版使用 Windows 了。更没有人会给你免费安装配置一套商业应用软件。那么让我们从体验 OTRS 开始把，什么是 OTRS 请参考本博客中的文章。你可以从 JumpBox 下载并运行 OTRS2.2.6，下载地址是：http://downloads2.jumpbox.com/otrs-1.0.1.zip ","date":"2008-04-02T06:46:29Z","permalink":"https://martinliu.cn/2008/04/02/vm-jumpbox-rpath-play-oss/","title":"虚拟让你轻松玩开源"},{"content":"这几天我对 blog 做的做多的工作就是找一个好看的 Theme。由于受blogspot的影响，所找到的都是黑色两列的；后来觉得样式还是太花哨了，花哨的外表和化繁为简的思想不相投啊。简单并不意味着丑陋，想想 Apple 就行了，看看它的产品吧，外观上无不简洁大方。今天对 blog 做了一些简化工作：\n对左侧模块的精简，去掉了不需要的模块，把模块标题字数减少。 删除了所有之前下载的Theme，以后就用Wordpress默认的模板。 删除了不用的插件，把Google sitemap插件装好。 导入以前Blogspot里的文章 删除了站内不需要的文件，数据库和配置。 wordpress默认theme是我唯一只能挑出最少毛病的模板，其他的模板总体来说还是可以的，不过总有至少一个让你不能忍受的缺陷，这也成了删除它的不二理由。回归wordpress默认theme让我更加关注在它本身的功能上，让我更专心在内容质量上，同时降低了以后的升级工作量。联系一下开源软件(Open Source Software)，OSS也都以简为美，简单而开放让OSS绽放了无限魅力。如果没有wordpress的简单开放，那么就没有全球这么多的bloger天天去网上淘好看的theme和插件了；就不会有这么多的开发人员了，他们的创造使得wordpress魅力绽放。OSS基本上都是功能注重型的，开发人员都关注软件的核心功能，OSS的简单开放一定会被人们更加关注。 ","date":"2008-04-01T12:27:26Z","permalink":"https://martinliu.cn/2008/04/01/simple-is-everything/","title":"化繁为简"},{"content":"纪念一下吧~~~从 blogger 搬到此处，真的非了很多的周折~本博客介绍：我曾经有过好多个 Blog，其中最喜欢是 http://lzheng.blogspot.com。在这个 Blog 之前我曾经在 chinaunix.net 上有过两个 blog，一个 okwiner.cublog.cn,后来有专门为 OpenNMS 新开了一个 opennms.cublog.cn； 其实对这两个 blog 更新的还是挺多的，特别是第一个 CUblog。不过后来，还是觉得 google 的 blog 有非常多的功能，就把以前写的好的文章都搬 去 blogspot 了。目的有二，一来是想用一个功能能强大的 blog，二来呢觉得 google 对自己的 blog 的搜索一定会更好，通过 google 可以 能带来更多读者。不过不幸的是去年两会的时候 blogspot 就被封了，期间偶尔也开放过一两。有一次我还以为真的是有恢复了，一夜没睡觉，更新了 blog 的样式准备重新开始继续更新。可是第二天就有访问不了了，其实平时在公司或者在公司的 VPN 上是可以访问的，由于是走的国外的网络；从 blog 流 量统计上可以看出，http://lzheng.blogspot.com的访问量是平均大约每天 12 个，访问者基本上都是从国外和港台地区。不过我觉得我的读者是应该面向国内的，写这个博客的目的还是向国内的中文用户提供开源的信息和技术。所以就申请了自己的域名，购买了一个虚拟机（LAMP），在虚机上安装了wordpress。wordpress 和 blogspot 的内容是可以互相兼容的，把 blogspot 里的文章导出成 xml 文件在导入到这个站点当中，这样完成了 blog 的搬家工程。工程虽然不是很浩大，不过毕竟还是费了一番周折，目的只有一个，以前写的东西有些还是有用的舍不得丢。以后会把我在开源方面的心得和想法都更新到这个博客上，希望能够为您提供一点点的帮助。在这里呢会对开源技术提供全景式介绍，做的力求比较全面内 容。不过我一直以来呢是做 IT 管理这个方向的，所以从我的文章分将有 70%以上是这方面的内容，30%介绍其他内容。不过您如果有其他任何相关的想法也欢 迎和我探讨。\n","date":"2008-03-29T05:08:28Z","permalink":"https://martinliu.cn/2008/03/29/moveback/","title":"搬家成功纪念一下"},{"content":"If you\u0026rsquo;d like to check out release note, please click here. http://support.hyperic.com/confluence/display/DOC/HQ+3.2+Release+NotesI had a quick install on RHEL 5. For some features what I saw, I took some screenshots as bellowing. I hope this helps you to understand what\u0026rsquo;s new in 3.2 and save a little bit time for you if you do not wants to install it. I will describe in Chinese.\nNew Nav menu 新导航菜单 导航菜单的名称变成了：Dashboard \u0026ndash; Resources \u0026ndash; Analyze \u0026ndash; Administration 菜单的风格稍微有一点变化。Analyze 下面可以进入 Alert Center 去查看报警信息。我觉得 3.2 毕竟是一个小的功能增进板，添加了支持 MY SQL 的支持。增强了对 Nagios 的集成。对 Nagios 的集成对它还是很有好处的，由于它自己是 Agent Based 的监控方法，而 Nagios 是 Agentless 的监控方法；集成之后通过它的 web 界面能统一管理，还是挺好的。不过和 Nagios 具体能集成到什么程度，我还没有试过。\nCurrently Down Resources 当前宕机资源 如果所示：各种有问题的资源安装各种分类都显示出来，同实现时什么时间出的问题，持续了多久，点击放大镜后查看相关的报警信息。上图显示的是：HQ Agent 在 w2k3vm 这一 Windows 服务器上没有启动的情况，它报告了包括 hq agent 自身以及所有相关资源的都宕机的情形。同时作为一个监控系统来说，管理员最需要看到的信息可能主要包括两种：1）有那些资源出了问题；2）当前有什么样的告警事件。这里对这两类信息提供了一个非常不错的访问入口。\nLive Exec Data 实时数据获取 HQ-agent 本身只能周期性的采集 matrix，在汇报给管理服务器。实时的数据采集对排错还是非常有帮助的。此功能我觉得是 3.2 版中的最好的增强。它应该是远程的让 agent 去执行一下命令在把最终结果返回到页面上：\nCpuinfo CPU信息 Cpuperc CPU利用率 Df 磁盘利用率 Ifconfig 网卡ip信息 Netstat 网络端口信息 Top Who 这些信息的获取通过agent完成所以和平台无关，即使是Window平台也能收到相同的信息。 HQ Health Check 管理服务器自身检查 一个真正的自监控功能最好能做到对相关指标的报警处理。能设置一些条件，在不正常情况发生的时候报告管理员说出管理服务器那里有问题了。上图可以看出，hq 已经做出了第一步，能采集并且显示很多 HQ 服务器运行的状态信息。\nSummary： 在 3.2 的发布说明中还提到它自身的扩展性也很大的增强，这一点对 hq 来说尤为重要。由于它的结构是基于代理的，当监控的设备和资源都非常多时，hq 管理服务器自身的处理能理将会成为瓶颈，如果它的处理，存储和网络上的任何一个环节出现了问题，整个监控系统就失效了。由于事件有限，目前还留下了一些问题：\nGlobal Alert Disable是在那里设置的？ 报警阀值的设置是否有全局设置的地方？（例如：对所有windows机器都设置一个CPU\u0026gt;80％的阀值） 如果您对以上两个问题有些答案请回复告诉我。关于HQ的其它文章，清在本blog中搜索。 ","date":"2008-02-02T06:02:00Z","permalink":"https://martinliu.cn/2008/02/02/hyperic-hq-32-new-features/","title":"Hyperic HQ 3.2 new features"},{"content":" Well, it is the first time to running a RHEL 5 for me, at same time got zenoss built successfully on it. zenoss-2.1.2 was build from source, the whole process went a while since RHEL is in one of my VMware session; CPU %sy was pretty high during building source code.\nBuild zenoss-2.1.2 The INSTALL.txt file is good enough, my installation how-to can be really sample:\nRead INSTALL.txt add zenoss user start mysql upload zenoss tarball to zenoss home directory login as zenoss untar zenoss tarball then run the following, good luck! Start Daemons: bash$ $ZENHOME/bin/zenoss startbash$ $ZENHOME/bin/zenoss status\nThen I access to Zenoss portal, got this error. HTTP Status 404 - /zport/dmd I reboot the RHEL server, then start mysql and zenoss. Finally, everything goes smoothly. Let\u0026rsquo;s take this nice zenoss portal.On my RHEL, mysql, snmp and python were installed with OS; other packages might installed from zenoss source tarball. I am not sure about this, you could check above to see my install log.Install tips:\nPackage dependence should be consider before you build Zenoss source code. A full RHEL install is a lazy idea to solve this problem; but it is still the best practice if you are new to both Linux and Zenoss. Start zenoss daemons might take one minute or more. If you access to zenoss portal immediately, you could get a HTTP Status 404 error. Before you see balance stone, please be patience. Auto-Discovery of Devices It\u0026rsquo;s time to read ZenossAdminGuide211.pdf; BTW that\u0026rsquo;s a good document. I will go ahead to note down what I did in my testing evn. Please turn to P47, I will go from there. For sure you have something discovered, please read the following tips:\nThe Zenoss machine should have snmp installed, including the following packages: As far as I know net-snmp-utils-5.3.1-19.el5 is a necessary. Without this package, you do not have ability to snmpwalk any device via SNMP protocol; in other word you can not get enough information about that remote device.\nAdd a right network ID, here is a example: snmpwalk at least one snmp-enable device, here is a example: Let\u0026rsquo;s see what I got after done all of above.Zenoss has a pretty good network map, it is a flash map; you can drag things on this map. Before I end this blog, I\u0026rsquo;d like to summary my questions blow:\nBecause my RHEL installation is big enough, I don\u0026rsquo;t know what are dependence packages for Zenoss; no time to list all of them. Does have this list? I\u0026rsquo;ve no idea how to configure snmpd on Solaris. What I did was just modified /etc/snmp/conf/snmpd.conf How to restart snmp daemon for Solaris? Do you have any good blog about zenoss? I will write a Chinese blog after this one to conclusion zenoss installation. Please give a hint if you have any comment. ","date":"2008-01-30T13:22:00Z","permalink":"https://martinliu.cn/2008/01/30/build-zenoss-212-on-redhat-enterprise-linux-5/","title":"Build Zenoss 2.1.2 on Redhat Enterprise Linux 5"},{"content":"很多网络系统管理软件都有 Trap 管理的功能，在系统的安装和配置过程中；验证系统是否能正常处理 Trap 是很麻烦的事情。原因有很多，发送 trap 的设备没有，设备上的 snmp 没有启用，或者设备都正常，到网管系统的网络可能有防火墙吧 snmp 给堵住了。为了方便的测试和配置网络管理监控系统，需要手工生产和验证 trap 的发送和接收。最近偶然在网上发现了这样几个免费（非 OSS 软件）软件工具，可以做这件事。下载的网站是：http://www.ncomtech.com/ 下面吧我所下载和测试的软件做一个小结，希望对您有所帮助：\nTrap Receiver http://www.trapreceiver.com/ 是一个Windows程序非常小，安装了之后会在windows安装一个服务。程序的启动目录是C:\\Program Files\\Trap Receiver\\TrapRcvr.exe 程序界面非常简单，如下图所示： 点击configure按钮后可以做一些配置：Action －－当收到某些特定的trap是出发邮件、声音等动作；logging－－把收到的trap信息按照某种格式记录在文件中；Mibs－－导入目标设备的trap文件，让这个接收器能认识到另外的trap格式。还有其他配置信息也非常简单。 **TrapGen **http://www.ncomtech.com/trapgen.html 顾名思义－这就是一个手工生产和发送trap的工具，是一个命令行工具。example: trapgen -d 192.168.2.3；上图中的第一条和第三条就是用这个命令发出的trap。欲知详细帮助信息，使用\u0026quot;trapgen -h\u0026quot; I/F Spy http://www.ncomtech.com/ifspy.html 是一个网络接口枚举工具，它通过snmp协议去访问目标设备的IFMIB信息，显示所有IFMIB相关信息。 UDP Listen http://www.ncomtech.com/udplisten.html UDP协议的监听程序，是命令行工具，有linux和Solaris版，能用作一个debug工具。 Thingy http://www.ncomtech.com/thingy.html是一个Windows下的GUI工具，能帮你监控三个SNMP指标，采集并做大于等于和小于的逻辑判断然后显示不同的信号灯。 这几个小工具都很小，都能在windows下安装和使用对网络系统监控软件的安装、配置和排错应该有一定的帮助。如果您有什好的小工具也请回复一下本文。 ","date":"2008-01-21T17:34:00Z","permalink":"https://martinliu.cn/2008/01/21/trap-tools/","title":"网管系统的测试工具"},{"content":"多系统/跨平台支持 如下图所示，我安装了并运行了四个代理程序。HQ 的服务器是安装在我的笔记本上的是 Windows XP 平台的。HQ 管理服务器在 windows 下的安装是非常简单的，两分钟就能完成。安装包中包括了 Jboss 和 PostgreSQL。其它三个测试的代理程序分别安装在 OpenSUSE Linux 10.3 （VM），AIX 5.3 和 Solaris 10 （5.10），代理程序的安装过程非常简单，需要注意的是保证代理和管理服务器的时钟同步。否则数据收集和显示的时间会错位。对不同平台的数据采集是不同的，代理能根据操作系统而已采集不同的数据指标；比如 CPU 的监控指标 windows、linux，Aix 和 Sun 都有细微差别。\nDashboard 首页－－仪表盘 HQ 登陆后的首页，第一个感觉是－专业。算是一个 Portal 门户界面。页面顶端是最新的两个报警信息，和水平导航条。右边的模块有：资源搜索、保存的资源图、可用性图和最近增加的平台等。右边的模块有：自动发现、最爱资源，最近报警、控制动作问题资源和监控指标视图等。整体来看：所有的模块都可以配置、拖拽、添加和删除；您可以按照自己的喜好设置布局。对于网管来说：最近报警、和问题资源和监控指标视图应该是非常重要的；通过这些内容可以立刻了解到所关心的资源和服务的整体状况。\n浏览资源 Platforms 平台－－四个监控对象：所显示的是所有被监控对象，HQ 主要是 Agent based 的监控方式，当然也可以通过 snmp 方式监控网络设备，不过这个我没测过它监控网络设备的能力。我安装测试的是 HQ 企业版，所以我只能监控到 4 个被监控对象；当然如果是付费用户的话就可以增加被管理目标的数量了，多话钱是肯定的了；好像 HQ 是按照被监控节点的数量收钱的。测试这个企业版的目的是，浏览一下它所有的功能，下面所说的有些功能是企业版才有的开源版本是没有的。Servers 服务器－－21 被管理服务器：HQ 的自动发现功能不仅能发现到服务器上的基础资源（CPU、文件系统和网络）；还能自动发现被监控平台上的数据库、web 和 App 服务等。这些服务有的是需要一些配置才能采集到数据的，例如对数据库的监控，MySQL 需要在 HQ 服务器上输入一个 MySQL 的用户名和密码（密码不能为空），这个用户需要有能运行 status 命令的权限。Oracle 数据库需要按照 HQ 页面上的提示在数据库实例上，用 DBA 的权限运行一个命令，也建立一个用户。代理程序是通过这个用户通过 JDBC 链接到数据库上采集监控指标的。对于 Apache 来说，是需要配置 Status 模块的。HQ 也算得上是单一代理的监控方式了，这一个特性是非常重要的；和 BMC 公司的 Patrol 产品有些相似。单一代理能很好的降低被监控服务器的额外负担。\n告警事件规则 默认情况下所有 HQ 里没有任何一个报警规则的。不过你可在它的问题资源模块上看到 OOB 次数。OOB 是 Out Of Bound 的简称，意思是超出边界，那么边界在那？边界在 Baseline 上，baseline 会在每几天算一次，它并不是平均值，某个监控资源的实际忙闲程度水平的参考面。例如如果你的 CPU 平时都不超过 30％的话，它的基线可能是 20％，如果某次采样数据是 24％了，OOB 的数量就被加一；它表明该资源的使用异常了，需要引起你的注意了。HQ 企版可以设定固定 fix 阀值，也可以设定动态阀值。所谓让很多企业级用户梦寐以求的动态阀值，其实就是比对 BaseLine 来报警的机制。HQ 的报警规则可以是：例如 CPU 使用率超出 Baseline 的 15％；那么这样 CPU 使用率的报警范围就是动态的了。报警规则的设置可以根据不同的 platform 而定，可以给某了 platform 定义一套默认的规则级应用到所有监控对象上。还能在某个监控对象上设置特殊的报警规则。报警条件可以是多条件的逻辑判断。报警事件可以每次触发时都发出，也可以在某个时间段上持续到达多少次才发出，发出的告警信息可以发给某个人或者某组人，还能在时间内升级等。显然这就是某些用户梦想中的事件压缩、峰值抑制、事件升级等功能。HQ 的企业版还能从事件上触发 Action。\n报表中心 默认的报表好像是有 7 个，可以输出成 PDF，excel，csv 和 html 格式。不得不说的是 HQ 的数据采集方式应该是从 HQ 服务器上向 Agent 发起的，取得了数据后，保存在 Postgresql 数据库中。HQ 服务器端保存了所有数据，不过如果在某个时间端，HQ 服务器不能和 agent 通信的话，这段数据就是空白的。这一点可呢功能和所有其它开源软件都一样。而 CA 的 UDPM 和 BMC 的 Patrol 是不同的，Agent 采集到的数据可以短期的保存在被管服务器端；采集数据的连续性不受网络影响。\n总结 HQ 企业版的功能太强大了，可以与商业软件媲美；单基于 Baseline 的动态阀值报警就是 Big four 所不能提供的。不过企业版是不能用的：虽然能使用到所有功能，不过只能监控 4 个服务器。在浏览 HQ 网站文档的时候，某个功能如果后面有一个红色的星号，那么它就是企业版的功能，需要付费使用了。不过它开源版的功能已经非常不错了，而且有这么优秀的一个框架使用；能支持二次开发和扩展。下次在提供一个开源版的测试报告。\n","date":"2008-01-12T15:26:00Z","permalink":"https://martinliu.cn/2008/01/12/hyperic-hq-engerprise-testing/","title":"Hyperic HQ Engerprise 3.1.4 测试报告"},{"content":"＃１Nessus : 首要的 UNIX 弱点/漏洞评估工具Nessus 是最好的网络漏洞扫描工具之一，此软件最好是运行在 UNIX 上。它被持续不断地更新，有超过 11,000 的免费插件(但是需要注册或者接受 EULA)。主要的特点包括远程和本地的执行安全检查，带有 GTK 图形用户界面的 client/server 架构，一个用来写自己的插件的内置脚本语言。从 Nessus 3 开始停止开源 now closed source，但是他依然是免费的除非你想要最新的插件。查看所有的漏洞扫描器 vulnerability scanners＃2 Wireshark :附着在 Internet 上的嗅探器Wireshark (在 2006 年夏之前名为Ethereal )是一个 Unix 和 Windows 上 fantastic 的开源网络协议分析器。它能让你分析在线的网络数据和捕获的数据文件。你能方便的浏览捕获数据，深入研究到你需要级别的数据包的细节。Wireshark 还有几个强大功能包括，包括丰富的过滤显示语言和能去查看 TCP 链接重建的过程。它能支持几百种协议和网络介质类型。一个需要注意的方面是 Ethereal 现在遭受这很多可远程利用的安全漏洞，因此保持它的更新和提防在非信任的或者敌对的网络上运行它。查看所有包嗅探器 packet sniffers\n＃3 Snort :所有人都喜欢的开源 IDS 这个轻量级网络入侵检测和阻止系统擅长于 IP 网络上的流量分析和包记录。通过协议分析，内容搜索和各种预处理，Snort 能探测上千种蠕虫, 利用漏洞企图，端口扫描和其他可疑行为。Snort 使用一个弹性的基于规则的语言去描述它应该收集或者忽略的网络通信流量，和一个模块化的检测引擎。从此链接产看更多的基本分析和安全引擎，有一个 Web 用户界面来分析 Snort 告警。开源的 Snort 被一些个人、小企业和部门用的很不错。它的母公司SourceFire提供了一个非常全的产品线；具有很多的企业级功能和实时规则更新。它们提供了一个免费的（需注册）的 5 天延迟的规则更新源，你还能在Bleeding Edge Snort找到很多非常好的免费规则。 查看所有入侵检测系统intrusion detection systems＃4 Netcat :网络瑞士军刀这个简单的工具通过 TCP 或者 UDP 网络链接读写数据。它被设计为一个可靠的后端工具：能被直接和通过其他程序或脚本简单地驱动执行。同时，它也是一个功能丰富的网络调试和探索工具，因为它能生成几乎所有类型的你需要的网络链接，包括接受绑定了端口的外来链接。最初版本的 Netcat released 是 Hobbit 在 1995 年发布的，但是不论它是多么的流行也没有被持续。它有时候很难被找到nc110.tgz。利用这个工具的弹性和用途去开发了很多其他的 Netcat 的实现极大的推广了这个工具- 经常的很多现代的功能都不能在原始版本中找到。其中最有趣的是 Socat，扩展 Netcat 去支持很多其它 socket 类型、SSL 加密、SOCKS 代理和更多。它甚至按自己的意图扩展。还有 Chris Gibson\u0026rsquo;s Ncat，提供了甚至更多功能同时能保持可移植性和简洁性。其它流行的 Netcat 包括 OpenBSD\u0026rsquo;s nc, Cryptcat, Netcat6, PNetcat, SBD, 和 GNU Netcat。查看所有 Netcats＃5 Metasploit Framework : Hack 星球 Metasploit 在它 2004 年发布的时候给安全界带来风暴。没有其它什么工具能出现在这个列表的前 15 中， Metasploit 以第五位进入榜单，超过了很多知名的开发超过 10 年的工具。它是一个高级的开源平台。The extensible model through which payloads, encoders, no-op generators, and exploits can be integrated has made it possible to use the Metasploit Framework as an outlet for cutting-edge exploitation research. It ships with hundreds of exploits, as you can see in their online exploit building demo. This makes writing your own exploits easier, and it certainly beats scouring the darkest corners of the Internet for illicit shellcode of dubious quality. Similar professional exploitation tools, such as Core Impact and Canvas already existed for wealthy users on all sides of the ethical spectrum. Metasploit simply brought this capability to the masses. 查看所有 vulnerability exploitation tools如需了解全列表，请参考源列表页面：http://sectools.org/\n","date":"2008-01-04T15:25:00Z","permalink":"https://martinliu.cn/2008/01/04/top-100-security-tools/","title":"Top 100网络安全工具"},{"content":"前言 在 2007 年 ITILv3 推出之后，ITIL 这个概念从最佳 Best practice 实践变成最好 Good practice 实践。从此称呼的转变能够看出 ITIL 思想的普及化、平民化。ITIL v2 已经使用了快 20 多年了，看看如今的 ITIL 的用户，成熟度依旧参差不齐。有的已开始琢磨着如何完善所有 ITIL Support 流程并开展实施 ITIL Delivery 中的各个流程；有的已经在开始实施帮助台并建立事件和问题管理；有的依然处于扫描阶段。在 ITILv3 即将普及的 2008 年，v2 对于各类用户来说还是基础，是最可实施的框架。v2 是 v3 的核心内容，为了及时的升级到 v3，熟练掌握 v2 的概念是当务之急。下个月公司有 ITILv3 升级的认证考试，本系列文章可能算是一个 v2 的复习笔记吧。一图胜过千言，本系列通过对一些经典图形的回顾来复习 v2 的部分概念。由于是看图学话版，所以目标观众是 ITIL 的学龄前儿童呵呵，学习内容是 ITIL Delivery。如果您已经是小学以上水平，请忽略:)\nITIL Service Delivery 介绍 ITIL 的全称是 IT Infrastructure Library，开发于 1980 年；成果要素：Public domain framework 公共领域框架－放之四海皆准；Best practice framework 最佳事件框架－现在成最好事件了；De facto standard 事实上的标准－90 年 ITSM 推广； Quality approach 质量解决方案－IT 质量保障；itSMF IT 服务管理论坛。Jigsaw diagram ～ 锯齿图 OGC 设计了这个图，用此来说明 ITIL 有 5 个主要部分组成；每个部分之间都相互接口并联系着。Service Delivery; the coverage ～服务交付涵盖如图 5 个不同流程。BS15000 Service Management processes ～ BS1 万 5 中的服务流程图示。它涵盖了 ITIL 的所有流程，以控制为中心的增强版。\nRelationship between Change Management, Configuration Management, Capacity Management and Release Management ～变更、配置、能力和发布管理之间的关系。Process improvement model ～ 流程改进模型：发展方针和业务目标，评估、流程改变和指标追踪。\n","date":"2007-12-31T14:13:00Z","permalink":"https://martinliu.cn/2007/12/31/itilv2/","title":"看图学话，学ITIL(v2)系列 之1"},{"content":"一贯喜欢按照 Google 的指引在互联网上穿梭的你，是否发现了下面的这个现象。如果你搜索 itil，无论选择所有网页、中文网页还是简体中文网页；你是否发现了在右边的赞助商连接中，OTRS.org 总是能出现在第四个。OTRS.ORG 是什么？和 ITIL 有什么关系？热衷于开源 ITSM 的我不得不揭示这些答案。\n什么是 OTRS 这是一个开始于 2001 年的开源项目。OTRS 是 Open Ticket Request System 的缩写。它的老家在www.otrs.org；下面是来自它首页的简介：OTRS is an O_pen source _T_icket _R_equest _S_ystem (also well known as _trouble ticket system) with many features to manage customer telephone calls and e-mails. The system is built to allow your support, sales, pre-sales, billing, internal IT, helpdesk, etc. department to react quickly to inbound inquiries. Do you receive many e-mails and want to answer them with a team of agents? You\u0026rsquo;re going to love the OTRS! It is distributed under the GNU General Public License (GPL) and tested on Linux, Solaris, AIX, FreeBSD, OpenBSD, Mac OS 10.x and Windows. The ((otrs)) company provides commercial services (e.g. support, consulting, training, pre-build-systems, etc.) for the OTRS (English and German). Try our demo system to get an impression of this kind of magic.从这个简介中可以看出，这就是著名的‘问题单管理系统’；用来管理用户的电话或者邮件的请求。它能帮你的很快的受理各种问题和查询。比方说很多企业的 IT 支持部门，大多数都是工作在救火队模式下；对于期待问题解决的用户来说，也只能做到把奶喂给会哭的孩子；往往 IT 支持部门分身乏术，好像天天都处于缺奶的状态。对于 IT 支持或者运维部门的挂历者来说，他们也很难说出：我的员工很忙，都忙于什么事情。显然这是一种缺乏管理，缺乏流程的状态；不过要对这种局面进行管理，提高管理往往是非常难。最难的是在跨出第一步：记录，跟踪，处理所有问题。来自 OTRS 的问题：您是不是收到很多 email（或者电话），并且希望通过一个支持团队回答？那么你将爱上 OTRS!OTRS 是一个在 GPL 许可证下被分发的软件，被在 Linux, Solaris, AIX, FreeBSD, OpenBSD, Mac OS 10.x 和 Windows 下测设过。((otrs)) 公司提供 OTRS 的技术支持、咨询、培训、安装等商业服务。由于这个软件是德国人开发的，所以他们提供英语和德语的服务。我跟踪这个项目大概有一年左右的时间，亲眼目睹了它从一个普通的问题单管理系统变为一个兼容 ITIL 的服务台工具的过程。它从 07 年 4 月的它发布了第一个 ITIL 兼容的版本 OTRS::ITSM 1.0 BETA2；这应该也是开源领域里的一个大事件吧，第一个像样的开源 ITSM 解决方案横空初始。按照它官方的声明，它做为 OTRS 的一个重要的插件（我是这么理解的，或者说是扩展模块）能支持 ITIL 中的事件管理、问题管理和配置管理/cmdb。\nOTRS 有哪些功能 详细的功能描述在http://otrs.org/feature/我简单总结以下几点：\n纯Web用户界面支持包括简体中文，繁体中文在内的10＋种语言，能够灵活定制界面，支持附件，支持单点登陆。 邮件接口，支持MIME附件，能自动回复，自动根据邮件头分派邮件，自动邮件提示用户Ticket状态的变化。 Ticket功能，定义不同的受理队列，支持Ticket的锁定、回复、历史、优先级、受理时间计算、批量处理、等待等操作。支持全文检索，工作量和访问列表控制。 系统功能，按照日历时间计算SLA，提供LDAP和SQL数据库认证用户，自定义订单号格式，数据库支持MySQL, PostgeSQL, MaxDB/SAPDB, Oracle and DB2，前端和后台都支持UTF-8字符集 系统架构图 http://otrs.org/images/BigPicture.gif 如何使用 OTRS 下载和安装都非常简单，您可以参考它们的官方文档，文档非常详细，能看出德国人的细严谨的风格。下载网址： http://otrs.org/download/ 文档： http://doc.otrs.org/2.2/en/html/ 安装说明：选择一个文档中支持的操作系统，建议 Linux；如果是新手而且对 Perl，apache 和 mysql 不熟悉，建议直接选择完全安装；下载安装包，参考文档安装，使用。\n后记 OTRS 一个非常经典的项目，德国工艺，德国品质保证～～～ Oops 怎么听起来像是卖假木地板或者家具的广告呵呵！！个人非常喜欢此项目，相信您用了之后不会后悔；真的后悔了也别和我联系哈:-) have fun ～～\n","date":"2007-12-27T02:12:00Z","permalink":"https://martinliu.cn/2007/12/27/otrs/","title":"OTRS.ORG，it is time to check it out；不得不：）"},{"content":"这个功能是是 1.3.2 之后加入的。它解决的问题是：当 OpenNMS 系统和被监控节点之间的网络路径失效了，或者网络链路 down 了，那么 OpenNMS 就需要抑制发送这个节点的告警。例如，如果一个广域网链路 down 了，所有由这个链路连接的远程站点的所有节点就都看起来 down 了。因为你将会得到一个路由器上远端链路无响应的告警，而不需要得到在这个路由器后所有节点 Down 的告警。如果当一个远程节点不响应了，OpenNMS 会测试一下那个远程路由器广域网接口的 ip，通过对这个 ip 的测试 OpenNMS 觉得是否该发出此节点 Down 的告警。OpenNMS 测试的这个节点叫做此节点的 Critical Path IP Address（关键路径 Ip 地址）。给一个节点配置 Path Outage在 OpenNMS 的节点配置上，点击 Admin, 点击 Configure Path Outage，输入对于这个节点来说关键的 ip 地址。点击 Submit 按钮。配置基于规则的 Path outage可以为一组节点配置一个规则。在总导航条上选中 Admin，Configure Notifications，点击 Configure Path Outages，在 Define the Critical Path 下面输入一个 Ip 地址，例如：192.168.0.1（这种格式）；在 Current Rule 下面输入地址范围，例如：IPADDR IPLIKE 192.168.0.*；可以选中 Show matching node list 后的 box，点击 Validate Rule Results 连接；在下面的页面可以查询到受那个关键 Ip 地址所影响的所有节点；最后点击 Finish 按钮完成配置。查看 Path Outage在总导航条上选中 Path Outages，在页面中你可以看到你配置的所有 Path Outages 的规则。这个文章基本上翻译的是http://www.opennms.org/index.php/Path_Outage_How-To 只是觉得这是个不错的功能，所以就大概翻译了一下，希望对感兴趣的朋友们有帮助。由于手头硬件环境的限制，我还没有真实测试过这个功能，如果您对此功能做了什么测试的话，也欢迎和我交流，请留言或者或发邮件给我。\n","date":"2007-12-23T12:20:00Z","permalink":"https://martinliu.cn/2007/12/23/opennms-path-outage/","title":"如何配置OpenNMS中的 Path outage －路径失效"},{"content":"自从 1.3.7 之后 OpenNMS 加入了 Smokeping 功能，取名为 StrafePing。从此 OpenNMS 也成了 Smokeping 的银牌赞助商。\n安装：\nStafePing 做为一个 Poller 默认被安装在 1.3.7 后的软件中，不需要单独安装和配置。\n配置：\n没有单独的配置文件，相关的配置信息需要修改文件： poller-configuration.xml 中的相关部分。需要在 标记中加入需要使用的 Ip 地址范围。启用之后 StrafePing 做为一个被监控的服务显示在这个节点上。\n默认安装 OpenNMS 并不使用这个服务，是为了减小网络流量；推荐根据 OpenNMS 硬件的能力只对部分节点做这种监控。\n使用：\n需要产品 StrafePing 的图形有两种方式。1）在 OpenNMS 首页上，点击右侧的 Resources Graphs，选中产看的机器，在 Response Time 下面的列表中选中需要产看的 Ip 地址，点击 Submit，即可产看到图形。2）在节点产看页面，选中 Resources Graphs，在 Response Time 下面的列表中选中需要产看的 Ip 地址，点击 Submit，即可产看到图形。\n**如何想看懂 StafePing****的图**\n请参考我以前的 blog http://lzheng.blogspot.com/2007/02/smokeping-rttround-trip-time-tcp-tcp.html\n参考 Smokeping 的网站http://oss.oetiker.ch/smokeping/doc/reading.en.html\n","date":"2007-12-21T07:14:00Z","permalink":"https://martinliu.cn/2007/12/21/opennms-strafeping/","title":"如何使用OpenNMS中的StrafePing功能"},{"content":"在 OpenNMS 的邮件组中偶然发现的这个解决方案，利用这个方案你可以用串口连接外置的 GSM modem 来发送短信。这个方案的名称叫做：SMS Server Tools 网址在－\u0026gt; http://www.meinemullemaus.de/smstools/index.html工作原理 －\u0026gt; http://www.meinemullemaus.de/smstools/slideshow/page1.html据说是可以运行在任何平台上，能支持很多设备，不过我没用试过，记录一下日后可能有用。\n","date":"2007-12-14T17:15:00Z","permalink":"https://martinliu.cn/2007/12/14/gsm-modem-alert-sms/","title":"发送告警短信的方法，德国工艺服了"},{"content":"OpenNMS 可以监控可用性和性能参数。下面看看 OpenNMS 监控 Windows 服务器的三种情况。第一种情况：Windows 机器上没有安装 SNMP 服务，在自动发现了这个节点后，它会被加入节点列表，之后它被定期的轮询。如果这个节点断网了，OpenNMS 会报警；同时这个节点的可用性被计算。自动发现还会发现这个机器上的服务。ICMP 是肯定会有的，还可能有 http 等其他的服务；这些服务也会被定时的轮询，如果某个服务停了，这个节点的整个的可用性受到影响。这种情况下该节点的所有服务的响应时间会被 OpenNMS 收集并保持历史数据。第二种情况：安装了 SNMP 服务。先说一下 windows 服务的安全性，默认情况下 public 是默认的只读密码；为了更加安全可以配置其他的只读密码，并指定某些特定的 IP 才能访问这个节点。这个策略在 Windows 的觉策略中很容易实现，或者说建议使用域控制器来管理这个策略，比较方便。假定 OpenNMS 能访问该节点的 snmp 服务的情况下。这些数据会增加：SNMP Attributes；在选择了资源图后，可以看到 snmp 的节点数据和接口数据。进入后可以看到，其实收集 的是一个 tcp／ip 接口上基本的信息：流量，连接数，丢包，错包等。个人认为流量是个最有用的数据，特别是对于一些简单的 web/ftp 服务器也就够用了。第三种情况：我们需要监控到操作系统的性能数据 cpu/disk/RAM 等。就需要安装一个 snmp 代理，这个代理可以提供这些信息，opennms 才能通过 snmp 协议收集这些数据。需要到下面网址下载一个免费的 snmp 代理，当然这个产品也有收费版本：http://www.wtcs.org/informant/download.htm 这个代理很小需要在 windows 机器上安装一下。默认情况下 OpenNMS 的对 windows 采集模板中包含了对 cpu/disk/ram 等数据的采集，等到下一次 OpenNMS 在采集这个机器的时候相关数据就会被显示在节点 snmp 数据下面。这里是通过这个免费的 snmp 代理能采集到的数据：/Program Files/SNMP Informant/standard/mibs/informant-std-tree.txt\u0026ndash;standard(1.3.6.1.4.1.9600.1.1)|+\u0026ndash;logicalDiskTable(1)| || +\u0026ndash;logicalDiskEntry(1) [lDiskInstance]| || +\u0026ndash; r-n InstanceName lDiskInstance(1)| +\u0026ndash; r-n Gauge32 lDiskPercentDiskReadTime(2)| +\u0026ndash; r-n Gauge32 lDiskPercentDiskTime(3)| +\u0026ndash; r-n Gauge32 lDiskPercentDiskWriteTime(4)| +\u0026ndash; r-n Gauge32 lDiskPercentFreeSpace(5)| +\u0026ndash; r-n Gauge32 lDiskPercentIdleTime(6)| +\u0026ndash; r-n Gauge32 lDiskAvgDiskQueueLength(7)| +\u0026ndash; r-n Gauge32 lDiskAvgDiskReadQueueLength(8)| +\u0026ndash; r-n Gauge32 lDiskAvgDiskWriteQueueLength(9)| +\u0026ndash; r-n Gauge32 lDiskAvgDiskSecPerRead(10)| +\u0026ndash; r-n Gauge32 lDiskAvgDiskSecPerTransfer(11)| +\u0026ndash; r-n Gauge32 lDiskAvgDiskSecPerWrite(12)| +\u0026ndash; r-n Gauge32 lDiskCurrentDiskQueueLength(13)| +\u0026ndash; r-n Gauge32 lDiskDiskBytesPerSec(14)| +\u0026ndash; r-n Gauge32 lDiskDiskReadBytesPerSec(15)| +\u0026ndash; r-n Gauge32 lDiskDiskReadsPerSec(16)| +\u0026ndash; r-n Gauge32 lDiskDiskTransfersPerSec(17)| +\u0026ndash; r-n Gauge32 lDiskDiskWriteBytesPerSec(18)| +\u0026ndash; r-n Gauge32 lDiskDiskWritesPerSec(19)| +\u0026ndash; r-n Gauge32 lDiskFreeMegabytes(20)| +\u0026ndash; r-n Gauge32 lDiskSplitIOPerSec(21)|+\u0026ndash;memory(2)| || +\u0026ndash; r-n Gauge32 memoryAvailableBytes(1)| +\u0026ndash; r-n Gauge32 memoryAvailableKBytes(2)| +\u0026ndash; r-n Gauge32 memoryAvailableMBytes(3)| +\u0026ndash; r-n Gauge32 memoryCommittedBytes(4)| +\u0026ndash; r-n Gauge32 memoryCacheBytes(5)| +\u0026ndash; r-n Gauge32 memoryCacheBytesPeak(6)| +\u0026ndash; r-n Gauge32 memoryPageFaultsPerSec(7)| +\u0026ndash; r-n Gauge32 memoryPagesInputPerSec(8)| +\u0026ndash; r-n Gauge32 memoryPagesOutputPerSec(9)| +\u0026ndash; r-n Gauge32 memoryPagesPerSec(10)| +\u0026ndash; r-n Gauge32 memoryPoolNonpagedBytes(11)| +\u0026ndash; r-n Gauge32 memoryPoolPagedBytes(12)| +\u0026ndash; r-n Gauge32 memoryPoolPagedResidentBytes(13)| +\u0026ndash; r-n Gauge32 memorySystemCacheResidentBytes(14)| +\u0026ndash; r-n Gauge32 memorySystemCodeResidentBytes(15)| +\u0026ndash; r-n Gauge32 memorySystemCodeTotalBytes(16)| +\u0026ndash; r-n Gauge32 memorySystemDriverResidentBytes(17)| +\u0026ndash; r-n Gauge32 memorySystemDriverTotalBytes(18)|+\u0026ndash;networkInterfaceTable(3)| || +\u0026ndash;networkInterfaceEntry(1) [netInstance]| || +\u0026ndash; r-n InstanceName netInstance(1)| +\u0026ndash; r-n Gauge32 netBytesReceivedPerSec(2)| +\u0026ndash; r-n Gauge32 netBytesSentPerSec(3)| +\u0026ndash; r-n Gauge32 netBytesTotalPerSec(4)| +\u0026ndash; r-n Gauge32 netCurrentBandwidth(5)| +\u0026ndash; r-n Gauge32 netOutputQueueLength(6)| +\u0026ndash; r-n Gauge32 netPacketsOutboundDiscarded(7)| +\u0026ndash; r-n Gauge32 netPacketsOutboundErrors(8)| +\u0026ndash; r-n Gauge32 netPacketsReceivedDiscarded(9)| +\u0026ndash; r-n Gauge32 netPacketsReceivedErrors(10)| +\u0026ndash; r-n Gauge32 netPacketsReceivedUnknown(11)| +\u0026ndash; r-n Gauge32 netPacketsReceivedPerSec(12)| +\u0026ndash; r-n Gauge32 netPacketsSentPerSec(13)| +\u0026ndash; r-n Gauge32 netPacketsPerSec(14)|+\u0026ndash;objects(4)| || +\u0026ndash; r-n Gauge32 objectsProcesses(1)| +\u0026ndash; r-n Gauge32 objectsThreads(2)|+\u0026ndash;processorTable(5)| || +\u0026ndash;processorEntry(1) [cpuInstance]| || +\u0026ndash; r-n InstanceName cpuInstance(1)| +\u0026ndash; r-n Gauge32 cpuPercentDPCTime(2)| +\u0026ndash; r-n Gauge32 cpuPercentInterruptTime(3)| +\u0026ndash; r-n Gauge32 cpuPercentPrivilegedTime(4)| +\u0026ndash; r-n Gauge32 cpuPercentProcessorTime(5)| +\u0026ndash; r-n Gauge32 cpuPercentUserTime(6)| +\u0026ndash; r-n Gauge32 cpuAPCBypassesPerSec(7)| +\u0026ndash; r-n Gauge32 cpuDPCBypassesPerSec(8)| +\u0026ndash; r-n Gauge32 cpuDPCRate(9)| +\u0026ndash; r-n Gauge32 cpuDPCsQueuedPerSec(10)| +\u0026ndash; r-n Gauge32 cpuInterruptsPerSec(11)|+\u0026ndash;system(6)|+\u0026ndash; r-n Gauge32 systemSystemUpTime(1)最后记得在看看这个许可证文件：Program Files/SNMP Informant/standard/license.txtLICENSE.TXT\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;FREE OF CHARGE SOFTWARE PROGRAM LICENSE AGREEMENT forSNMP INFORMANT STANDARD EDITION (The Software)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;Copyright(c) 2005, Informant Systems, Inc. (www.informant-systems.com), andCopyright(c) 2003-2005, Williams Technology Consulting Services (www.wtcs.org)\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;Product names used in this document are trademarks of their respective owners.* IMPORTANT-PLEASE READ CAREFULLY BEFORE INSTALLING THE SOFTWARE.\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;后面略\u0026hellip;.在安装了 snmp 代理之后，我们可以看到 OpenNMS 可以帮助我们完成 windows 服务器的可用性和性能管理。\n","date":"2007-12-14T11:34:00Z","permalink":"https://martinliu.cn/2007/12/14/opennms-monitoring-ms-windows/","title":"如何用通过OpenNMS监控Windows 服务器"},{"content":"OpenNMS 网站的安装文档：http://www.opennms.org/index.php/Installation:Yum\n下面是我在一个 CentOS4 的机器上按照上面文档安装的。\n[root@jng-hkg-48-dyn3328831 ~]# yum list opennms\nRepository opennms-stable-common is listed more than once in the configuration\nRepository opennms-stable-rhel4 is listed more than once in the configuration\nSetting up repositories\nReading repository metadata in from local files\nAvailable Packages\nopennms.noarch 1.3.10-0.8030.snapshot opennms-snapshot\nDependencies Resolved\n=============================================================================\nPackage Arch Version Repository Size\n=============================================================================\nInstalling:\nopennms noarch 1.3.10-0.8030.snapshot opennms-snapshot-common 5.0 k\nInstalling for dependencies:\niplike i386 1.0.6-1 opennms-snapshot-rhel4 10 k\njdk i586 2000:1.5.0_13-fcs opennms-snapshot-common 46 M\njicmp i386 1.0.4-1 opennms-snapshot-rhel4 43 k\nopennms-core noarch 1.3.10-0.8030.snapshot opennms-snapshot-common 47 M\nopennms-webapp-jetty noarch 1.3.10-0.8030.snapshot opennms-snapshot-common 27 M\npostgresql i386 7.4.17-1.RHEL4.1 update 2.0 M\npostgresql-server i386 7.4.17-1.RHEL4.1 update 3.0 M\nTransaction Summary\n=============================================================================\nInstall 8 Package(s)\nUpdate 0 Package(s)\nRemove 0 Package(s)\nTotal download size: 125 M\nIs this ok [y/N]: y\nlocal all all trust\nhost all all 127.0.0.1/32 trust\nhost all all ::1/128 trust\ntcpip_socket = true\nisten_addresses = \u0026rsquo;localhost\u0026rsquo; (这一行加入了好些数据库启动不了了，去掉就行了，不知原因)\n","date":"2007-12-13T10:14:00Z","permalink":"https://martinliu.cn/2007/12/13/opennms-yum-install/","title":"OpenNMS的Yum的安装方式，安装简单了很多"},{"content":"Zenoss 2.1 Beta 版有什么新功能，看了这部三分钟的电影您就能知道了：http://content.screencast.com/media/c01d3364-2df0-4ccd-90f8-964f9268c326_ee342243-dec3-4aaf-bb9e-c82f06220438_static_0_0_Zenoss Beta 21 Compromised.wmv 这部电影使用了碟中谍的背景音乐，和星际的片尾字幕显示。为了方便大家的观看，下面是片中部分台词赶快进入看看能找到什么？Zenoss 在那，它在哪？就在这，打开门来看看是否有一 Zenoss2.1 bate 正在运行？快来看看这什么东西，干嘛的？这什么玩意？我不确定我能做这事！这是什么？看上去是一个地图么？Google Map，这是 Google Map 么？对啊，是 Google Map ～这些绿色的圆点是什么？来点击一下看看～看上去像是显示了一个数据中心之类的东西！Locations ～哦!你可以拖拽这些东西？是的～这看上去，好像布局是可以配置的？哦 My god！哦你可以单击来选择一个最喜欢的布局？是啊，来看看～哇哦～～看这些黄色的按钮，他们是图标还是按钮？来点击一下看看先！这就来到了事件窗口了～来看看这个网络 map 怎么样？这些玩意还真的是浮动的！！非常 cool！这个小企鹅是个啥？这个可能是个 Linux 服务器～哦，你可以告诉我 windows 服务器是啥，那个是 windows 服务器的图标？哦 My God！！！你可以点击之后看到一个小圈在上面。哇！！是在是 cool！！我喜欢它！！在拍摄这个电影期间没有 Zenoss 的员工受伤，如需更多 zenoss Beta 2.1 的信息请联系我们www.zenoss.com**观后感：*一个貌似比较无知比较神经质傻哥们对 Zenoes 的新特色进行了一番探索，一个开发人员尝试给他做了一个演示。从一定程度上看出 Zenoss 开发人员比较兴奋，从侧面可以看出他们比较 happy 比较喜欢他们的工作，喜欢这个产品。我想这可能是一个产品创造性的主要源泉。开源软件人的创造性大于商业软件，商业软件是金钱驱动的，是商业；我觉得商业软件的开发人员很难把自己的创作性投入产品中，起码在中国是这样。关于 Zenoss 2.1，废话少说最快的体验方法莫过于直接使用它。一种不需要安装的方式是直接下载安装好的 VMWare 虚拟机。你只需要到 VMWare 下载一个 VMWare Player，在下载这个 Zenoss 的虚拟机压缩文件就成：http://nchc.dl.sourceforge.net/sourceforge/zenoss/zenoss-2.1.1-x86.vmware.zip下载并且解压缩后您就可以使用了。它是使用 DHCP 的在启动之后就能在 root 登录的 console 上看到登录的网址，请登录端口 8080 的那一个。登录密码是 admin/zenoss，have fun ～～～功能点评：先请看：http://www.zenoss.com/community/code/zenoss-2.1/zenoss-core-2-1 文中提到的电影下载自本页。我仅仅感受了一下界面并没有深入功能。就界面上讲，我觉得他们做的非常好。界面上的每一块基本上都是可以伸缩和隐藏的，好像在非 IE 的浏览器里显示的更好。主页上的 Dashboard 是可以配置的象 MSN Space 的页面一样的定制方式。Google Map 的引入使人眼前一亮，我曾经在 OpenNMS，Cacti，Unicenter 中尝试 Map 功能;Zenoss 在这个功能上创意和功能都大大超出了其他产品。他的网络地图怎一个 cool 字了得，做到这个份上对于 3 层网络拓扑图来说算是一种很高的境界了。我准备使用的是它的自动发现功能和对 JXM 监控的功能。如果您对这个软件有什么心得的话别告诉我。***后记：_**我仔细看了一下 Zenoss.com 网站，发现两年之内变化还是蛮大的。最大的方面是在它提供的技术支持和服务上。Zenoss Enterprise Edition 的 Zenoss Subscriptions 定价从 66$到150$不等，同时还提供了培训、实施和定制等服务。前一段时间看到的相关新闻中提到了 Zenoss 可以列入 10 大最赚钱的开源软件之一（网管类）。他们的 Zenoss 很 happy，他们公司也很 happy。还真是鱼和熊掌兼得。\n","date":"2007-12-07T03:01:00Z","permalink":"https://martinliu.cn/2007/12/07/zenoss-21-beta/","title":"破门而入Zenoss总部–Break in at Zenoss HQ"},{"content":"常规_ 多用户管理多种用户认证方式（local, LDAP, Active Directory, Pop/Imap, CAS)_ 权限系统_ 分页系统_ 多语言支持（包括中文的 14 种语言支持）_ 搜索模块显示字段列表配置_ pdf 和 cvs 格式导出数控_ SQL 格式保存和恢复_ 数据 XML 格式导_ 出可配置的下拉框系_ 统更新检查_ UTF8 界面_ HTML4.0.1 兼容资产清单_ 从 OCS Inventory NG 导入资产数据_ 计算机资产清单管理以及与设备的连接关系，TOC 总拥有成本_ 管理显示器资产清单管理以及与计算机的关联关系_ 网络设备资产清单管理以及和设备之间的连接(IP, Mac adresses, VLANs\u0026hellip;)._ 打印机资产清单管理以及和计算机的连接关系，耗材，以及耗材使用的阀值报警_ 其他外设的资产清单(scanners, graphical tables\u0026hellip;)，管理和计算机的连接关系_ 软件资产清单管理，许可证和过期时间管理安装物理位置（房间，楼层、、）分配_ 硬件商业和财务信息管理（采购，合同等、、）_ 管理硬件的状态_ 与外部其他应用的接口管理_ 资产清单信息的更改历史管理跟踪_ 跟踪资产清单中各种组件的故障请求单Final userFinal user frontend for intervention demand Mail tracking of the intervention demand feature Interventions history consultation Possibility of adding comments at the request of interventionTechnicians Interventions demands priority management Tracking of interventions demands Mail tracking of interventions Assignment of interventions demands Opening/Closing/Re-opening of interventions Assignement of a real time of interventions Realised interventions history Displaying of the interventions to realise by a technician Displaying of the history of the interventions for a given hardware Posting of the interventions to be realized by technician Posting of the history of the interventions for a given material Management of plannings of intervention统计_ 统计报表，月报，年报_ 全局_ 按技术人员和企业按硬件，位置或者类型_ 按用户_ 按分类_ 按优先级_ 管理企业（制造商，供应商，物流，收货人\u0026hellip;)_ 管理和相关的合同_ 管理联系人_ 管理（租赁，保险和服务等）资产相关的文档和合同_ 文档授权类型管理预约_ 管理资产租赁的预约_ 日历模式的预约用户界面知识库_ 管理基本系统的知识分类条目_ 管理公共的 FAQ报表_ 报表生产可以按照设备的类型、相关的联系人和商务信息Translate from：http://www.glpi-project.org/spip.php?article53\n","date":"2007-11-08T14:16:00Z","permalink":"https://martinliu.cn/2007/11/08/glpi-features-list/","title":"GLPI资产管理系统－－功能列表"},{"content":"GLPI 是一个信息资源管理器。你可以用它来给你公司建立一个资产清单（计算机，软件，打印机、、、）数据库。它的增强的功能可以是管理员的日常工作简单化，例如带有邮件提醒功能的工作跟踪系统等。它最首要的功能包括：1）所有技术资源精确的资产清单。资产的所有属性将被存储在同一个数据中。2）管理流程、维护工作的历史。这是一个动态的应用，它直接连把需要发出支持请求的用户和技术人员连接起来。（注：上文来自http://www.glpi-project.org/spip.php?article43）在 ITpub 上发过一个非常不错的帖子，请点击：http://www.itpub.net/762653.html 这个人是今年四月在他们公司使用的总结贴，对该项目的主要功能介绍的比较全面。本人同期发布的文章：GLPI \u0026ndash;IT 资源生命周期管理\n","date":"2007-11-07T15:29:00Z","permalink":"https://martinliu.cn/2007/11/07/glpi-features-list2/","title":"GLPI资产管理系统－－系统简介"},{"content":"今天是在没有心情搞了。快被 Zenoss 的网站给搞糊涂了。我准备好了一个 Suse10 的机器来装 Zenoss。首先想到的是上http://zenoss.com在下载的页面，我有点差异了，怎么系统兼容表里命名写这有 suse10 的 rpm 包，而下载连接的列表里确只有 redhat 和 centos 的安装包，奇怪！！！！接着看看文档把，发现新的希望：http://www.zenoss.com/community/docs/install-guides/install-on-suse-10/ 看看这文档，乍一看很不错啊，写的步骤非常清晰，大喜。没看完我有纳闷了，他明明也说 Zenoss-2.0.0-0.sles10.i386.rpm 这样一个安装文件啊。算了去 google 搜一下把，看到的帖子都来自 zenoss 的论坛啊，发现满世界的人都在找这个文件，哦，地球人都知道啊 ！还是不死心，去 sourceforge 搜，结果一样，也没有。我昏啊，你们明明写这支持，还有安装文档，为啥就不提供一个下载的连接呢？？？Zenoss 的人你们都脑子进水了么！！呵呵第一次这么说开源的人，这次真的是无奈得很，以前把这种信息的搜寻和 troubleshooting 做为一个乐趣，现在真的没这样耐心了。最终 zenoss 的安装，宣告失败！！ :-)\n1 一晃三个月都没更新这个blog了！！！～～～！！！！继续开源ing ","date":"2007-09-06T09:35:00Z","permalink":"https://martinliu.cn/2007/09/06/zenoss-20-install/","title":"Zenoss 2.0 安装失败：）"},{"content":"\nLinux 硬件是下面的Windows机,软件是openSuse10.2运行在VMWare中. Windows XP 硬件是Dell optiplex 745 安装难度是中 使用简单 能支持中文和多种语言 ","date":"2007-06-15T10:17:00Z","permalink":"https://martinliu.cn/2007/06/15/ocsng-inventory-windows-linux/","title":"OCSNG 代理程序生成的清单扫描信息"},{"content":"下面我将描述如何安装 OCSNG 服务器和客户端.服务器的安装在 openSuse Linux 中,文中将提到 Linux 和 Windows 代理的安装方法.最终能在界面中看到两个节点的清单信息,不过只有 Linux 的哪个会每天更新.This article is talking about how to install OCSNG 1.0.1 on a openSuSE 10.2 system.\nRequirements: You have to meet the following requirements. Apache version 1.3.33 or higher / Apache version 2.0.46 or higher. Mod_perl version 1.29 or higher. Mod_php version 4.3.2 or higher. PHP 4.3.2 or higher, with ZIP and GD support enabled. PERL 5.6 or higher. Perl module XML::Simple version 2.12 or higher. Perl module Compress::Zlib version 1.33 or higher. Perl module DBI version 1.40 or higher. Perl module DBD::Mysql version 2.9004 or higher. Perl module Apache::DBI version 0.93 or higher. Perl module Net::IP version 1.21 or higher. Perl module SOAP::Lite version 0.66 or higher (not mandatory) MySQL version 4.1.0 or higher with InnoDB engine active. Make utility like GNU make.If you can use yast for managing package, I believe you could install all of them within 20 minutes. I won\u0026rsquo;t say more about this. Installing Management/communication Server and Web Console You must have root privileges to setup management server. Login OS as root, then do the following:1)Download install package from http://nchc.dl.sourceforge.net/sourceforge/ocsinventory/OCSNG_LINUX_SERVER_1.01.tar.gz2)unpack itSuse:/mnt/hgfs/win/OCSNG # cp OCSNG_LINUX_SERVER_1.01.tar.gz /rootSuse:/mnt/hgfs/win/OCSNG # cdSuse:~ # tar zxf OCSNG_LINUX_SERVER_1.01.tar.gzSuse:~ # cd OCSNG_LINUX_SERVER_1.01/Suse:/OCSNG_LINUX_SERVER_1.01 #3)run installerSuse:/OCSNG_LINUX_SERVER_1.01 # sh setup.sh+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| || Welcome to OCS Inventory NG Management server setup ! || |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+CAUTION: If upgrading Communication server from OCS Inventory NG 1.0 RC2 andprevious, please remove any Apache configuration for Communication Server!Do you wish to continue ([y]/n)?yAssuming Communication server 1.0 RC2 or previous is not installedon this computer.Starting OCS Inventory NG Management server setup from folder /root/OCSNG_LINUX_SERVER_1.01Storing log in file /root/OCSNG_LINUX_SERVER_1.01/ocs_server_setup.log+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for database server properties\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Your MySQL client seems to be part of MySQL version 5.0.Your computer seems to be running MySQL 4.1 or higher, good ;-)Which host is running database server [localhost] ?OK, database server is running on host localhost ;-)On which port is running database server [3306] ?OK, database server is running on port 3306 ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Apache web server daemon\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+which: no httpd in (/sbin:/usr/sbin:/usr/local/sbin:/opt/gnome/sbin:/root/bin:/usr/local/bin:/usr/bin:/usr/X11R6/bin:/bin:/usr/games:/opt/gnome/bin:/opt/kde3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/opennms/bin)which: no apache in (/sbin:/usr/sbin:/usr/local/sbin:/opt/gnome/sbin:/root/bin:/usr/local/bin:/usr/bin:/usr/X11R6/bin:/bin:/usr/games:/opt/gnome/bin:/opt/kde3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/opennms/bin)which: no apache2 in (/sbin:/usr/sbin:/usr/local/sbin:/opt/gnome/sbin:/root/bin:/usr/local/bin:/usr/bin:/usr/X11R6/bin:/bin:/usr/games:/opt/gnome/bin:/opt/kde3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/opennms/bin)Where is Apache daemon binary [] ?/usr/sbin/httpd2OK, using Apache daemon /usr/sbin/httpd2 ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Apache main configuration file\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Where is Apache main configuration file [/srv/www//etc/apache2/httpd.conf] ?/etc/apache2/httpd.confOK, using Apache main configuration file /etc/apache2/httpd.conf ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Apache user account\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Which user account is running Apache web server [] ?wwwrunOK, Apache is running under user account wwwrun ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Apache group\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Which user group is running Apache web server [wwwrun] ?wwwOK, Apache is running under users group www ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for PERL Interpreter\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Found PERL Intrepreter at ;-)Where is PERL Intrepreter binary [/usr/bin/perl] ?/usr/bin/perlOK, using PERL Intrepreter /usr/bin/perl ;-)Do you wish to setup Communication server on this computer ([y]/n)?y+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Make utility\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, Make utility found at ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Apache Include configuration directory\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Setup has found Apache Include configuration directory in.If you are not using Include directive, please enter \u0026rsquo;no\u0026rsquo;.Where is Apache Include configuration directory [] ?/etc/apache2/conf.dOK, Apache Include configuration directory /etc/apache2/conf.d found ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Apache mod_perl version\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Checking for Apache mod_perl version 1.99_22 or higherFound that mod_perl version 1.99_22 or higher is available.OK, Apache is using mod_perl version 1.99_22 or higher ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Communication server log directory\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Communication server can create detailled logs. This logs can be enabledby setting interger value of LOGLEVEL to 1 in Administration consolemenu Configuration.Where to put Communication server log directory [/var/log/ocsinventory-NG] ?OK, Communication server will put logs into directory /var/log/ocsinventory-NG ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for required Perl Modules\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Checking for DBI PERL module\u0026hellip;Found that PERL module DBI is available.Checking for Apache::DBI PERL module\u0026hellip;Found that PERL module Apache::DBI is available.Checking for DBD::mysql PERL module\u0026hellip;Found that PERL module DBD::mysql is available.Checking for Compress::Zlib PERL module\u0026hellip;Found that PERL module Compress::Zlib is available.Checking for XML::Simple PERL module\u0026hellip;Found that PERL module XML::Simple is available.Checking for Net::IP PERL module\u0026hellip;Found that PERL module Net::IP is available.Checking for SOAP::Lite PERL module\u0026hellip;Found that PERL module SOAP::Lite is available.+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| OK, looks good ;-) || || Configuring Communication server Perl modules\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+WARNING: INSTALLSITESCRIPT is not a known parameter.Checking if your kit is complete\u0026hellip;Looks good\u0026lsquo;INSTALLSITESCRIPT\u0026rsquo; is not a known MakeMaker parameter name.Writing Makefile for Apache::Ocsinventory+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| OK, looks good ;-) || || Preparing Communication server Perl modules\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-++\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| OK, prepare finshed ;-) || || Installing Communication server Perl modules\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-++\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| OK, Communication server Perl modules install finished;-)|| || Creating Communication server log directory\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Creating Communication server log directory /var/log/ocsinventory-NG.Fixing Communication server log directory files permissions.Configuring logrotate for Communication server.Writing communication server logrotate to file /etc/logrotate.d/ocsinventory-NG+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| OK, Communication server log directory created ;-) || || Now configuring Apache web server\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Writing communication server configuration to file /etc/apache2/conf.d/ocsinvent+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| OK, Communication server setup sucessfully finished ;-) || || Please, review /etc/apache2/conf.d/ocsinventory.conf| to ensure all is good. Then restart Apache daemon. |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Do you wish to setup Administration server (web administration console)on this computer ([y]/n)?y+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Apache root document directory\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Where is Apache root document directory [] ?/srv/www/htdocsOK, Apache root document directory is /srv/www/htdocs ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for required Perl Modules\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Checking for DBI PERL module\u0026hellip;Found that PERL module DBI is available.Checking for DBD::mysql PERL module\u0026hellip;Found that PERL module DBD::mysql is available.Checking for XML::Simple PERL module\u0026hellip;Found that PERL module XML::Simple is available.Checking for Net::IP PERL module\u0026hellip;Found that PERL module Net::IP is available.+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Installing files for Administration server\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Creating directory /srv/www/htdocs/download.Creating directory /srv/www/htdocs/ocsreports.Copying files to /srv/www/htdocs/ocsreports.Fixing directories and files permissions.Configuring IPDISCOVER-UTIL Perl script.Installing IPDISCOVER-UTIL Perl script.Fixing permissions on IPDISCOVER-UTIL Perl script.+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| OK, Administration server installation finished ;-) || || Point your browser to http://server/ocsreports to || configure database server and create/update schema. |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Setup has created a log file /root/OCSNG_LINUX_SERVER_1.01/ocs_server_setup.log. Please, save this file.If you encounter error while running OCS Inventory NG Management server,we can ask you to show us his content !DON\u0026rsquo;T FORGET TO RESTART APACHE DAEMON !Enjoy OCS Inventory NG ;-)Suse:/OCSNG_LINUX_SERVER_1.01 #Suse:/OCSNG_LINUX_SERVER_1.01 # /etc/init.d/apache2 restartSyntax OKShutting down httpd2 (waiting for all children to terminate) doneStarting httpd2 (prefork) doneSuse:~/OCSNG_LINUX_SERVER_1.01 #As we can see the installation is successful. If you are running a different Linux, you should input other settings. Configuring Management Server The following is a post-install setup for management server. Y will go through it from a web browser. Open FireFox it is my current favorite browser and point it on URL http://Ip_address/ocsreportsThe first warning message should be this.WARNING: You will not be able to build any auto deployment package with size greater than 2M.You must raise both post_max_size and upload_max_filesize in your php.ini to correct this.Do the following to fix it:# vi php.iniThe default post_max_size is 8M, we are going to increase upload_max_filesize to 12M; Maximum allowed size for uploaded files.upload_max_filesize = 12MWe should restart apache to take it effectRun this command: /etc/init.d/apache2 restartPress F5 to refresh the first web page, this warning is still there. Let\u0026rsquo;s just go ahead to input the mysql \u0026gt; Setting up Agents on openSuse and a Windows Xp client. Download agent packages from internet.Installing a Linux agent:Suse:~ # tar zxf OCSNG_LINUX_AGENT_1.01.tar.gzSuse:~ # cd OCSNG_LINUX_AGENT_1.01/Suse:/OCSNG_LINUX_AGENT_1.01 # sh setup.sh+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| || Welcome to OCS Inventory NG Agent setup ! || |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Writing log to file /root/OCSNG_LINUX_AGENT_1.01/ocs_agent_setup.log+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for previous installation\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Previous installation of OCS Inventory NG agent not found+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for supplied parameters\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+No parameter foundOCS Inventory NG Agent setup running in user interactive mode+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for OCS Inventory NG Agent running method\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OCS Inventory NG Agent can be run through 2 methods:- local: inventory will be generated locally to a file, withoutinteracting with Communication Server. Inventory resultsmust then be imported manually into the server throughAdministration Console.- http: Agent can connect to Communication Server and will interactwith it to know what is has to do (inventory, ipdiscover,deployment\u0026hellip;)Which method will you use to generate the inventory ([http]/local) ?OK, OCS Inventory NG agent will be running in mode ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for OCS Inventory NG Communication Server\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Which host is running OCS Inventory NG Communication Server [] ?localhostOn which port is running OCS Inventory NG Communication Server [80] ?OK, OCS Inventory NG Communication Server is running on host and port \u0026lt;80\u0026gt; ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for TAG administrative information value\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+What is the value of TAG ([]) ?LiuZhengOK, OCS Inventory NG agent will use as ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for PERL Interpreter\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, PERL Intrepreter found at ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for C/C++ Compiler\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, C/C++ Compiler found at ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Make utility\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, Make utility found at ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for dmidecode binaries\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Found dmidecode binaries version \u0026lt;2.8\u0026gt; at ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Compress::Zlib PERL module\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, PERL module Compress::Zlib is available ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for XML::Simple PERL module\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, PERL module XML::Simple is available ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Net::IP PERL module\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, PERL module Net::IP is available ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for LWP::UserAgent PERL module\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, PERL module LWP::UserAgent is available ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Digest::MD5 PERL module\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, PERL module Digest::MD5 is available ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Checking for Net::SSLeay PERL module\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, PERL module Net::SSLeay is available ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Installing IPDISCOVER binary\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Building IPDISCOVER version 3Installing IPDISCOVER version 3 into /usr/sbinOK, IPDISCOVER version 3 setup successfully ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Installing OCS Inventory NG Agent\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Configuring OCS Inventory NG AgentBuilding OCS Inventory NG AgentInstalling OCS Inventory NG AgentCreating OCS Inventory NG Agent symbolic linkOK, OCS Inventory NG Agent setup successfully ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Creating OCS Inventory NG Agent log directory\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Creating OCS Inventory NG Agent log directory .Configuring logrotate for OCS Inventory NG Agent.Writing OCS Inventory NG Agent logrotate to file+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Installing OCS Inventory NG Agent configuration files\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Creating OCS Inventory NG Agent configuration fileCreating OCS Inventory NG Agent configuration directoryWriting OCS Inventory NG Agent configuration fileCreating OCS Inventory NG Agent configuration fileWriting OCS Inventory NG Agent configuration fileOK, OCS Inventory NG Agent configuration files setup successfully ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Installing OCS Inventory NG Agent cron configuration\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+Creating OCS Inventory NG Agent cron configuration fileWriting OCS Inventory NG Agent cron configuration fileOK, OCS Inventory NG Agent cron configuration file setup successfully ;-)+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+| Lauching OCS Inventory NG Agent\u0026hellip; |+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+OK, OCS Inventory NG Agent runs successfully ;-)Setup has created a log file /root/OCSNG_LINUX_AGENT_1.01/ocs_agent_setup.log. Please, save this file.If you encounter error while running OCS Inventory NG Agent,we can ask you to show us his content !Enjoy OCS Inventory NG ;-)Suse:/OCSNG_LINUX_AGENT_1.01 #The installer will install agent and a cron job on target Linux system. The job will launch OCS Inventory NG Agent once a day under root account, that means a update will get into database every day. Now you will see one single node in the web console.-\u0026gt;Installing a Windows AgentOCSNG 1.01 does not support Vista yet, so I tested it on Windows Xp/2K/2K3 and it works very well.You will donwload OCSNG_WIN32_AGENT_1.01_repack.zipUnzip it and run ocsagent.exe. I\u0026rsquo;d like to test a standalone version agent, it is not a service version agent.Double click ocsagent.exe, then you will get a new folder C:\\ocs-ngCreate a batch file in this folder.My scan.bat file as below:OCSInventory.exe /server:Ip_Address_of_server /np /tag:\u0026ldquo;LiuZheng\u0026rdquo; /hkcu /forceIn order to get inventory scan into database, you will double click scan.bat file. Now, you will get one more node in web console. It is a good idea to copy c:\\ocs-ng folder on a USB key. Then you are able to run inventory scan on other Windows machines. If you are going to get update inventory from Windows machines, you have to install OcsAgentSetup.exe agent on them.If you have any issue please add a comment blow or send me a email. I could help you later if I might have any idea.OCSNG现在还没有中文的界面,它的代理和服务器端是支持中文的.如果你在一些中文的操作系统上做了清单扫描,扫描的某些信息在Webconsole中查看的结果可能是乱码.这时候,你可以进入浏览器的内码设置,设置成中文后,你会看到正常的中文显示.这说明它是可以支持多语言的.为了在做资产管理的时候对于用户比较方便,我们可以是用gpli项目. GPLI有中文界面,而且能提供流程支持.GPLI的安装和配置手册待续.这个安装手册用英文写,如果给您带了了不便请谅解,您有什么问题的话欢迎给我留言,谢谢观看! ","date":"2007-06-15T08:06:00Z","permalink":"https://martinliu.cn/2007/06/15/how-to-install-ocsng-101-on-opensuse-102/","title":"How to install OCSNG 1.0.1 on OpenSuse 10.2"},{"content":"我做开源工具测试时,90%以上是在 VMWare 虚拟机中实现的,本人比较懒一直没有学习 Xen 虚拟机的用法,等下次吧,一等要彻底开源是我的一个梦想呵呵!说说这个 All in One 虚拟机的想法,我只是想把所有的我熟悉的工具都安装和配置在一个虚拟机里,这样当有人需要给做 Demo 的时候,我可以很快的做一个分享.如果有朋友感兴趣的话,我可以刻盘他.总的来讲希望能分享一下我的学习成果给大家.第一步:安装虚拟机这个虚拟机我不像使用很多的 Snapshoot,我以前是这么做的,从一个基础的 OS 发出许多分支到不同的工具;这样做的缺点有二:1)特别占磁盘空间;2)不能同时访问多个系统.我选择的 Linux 是 Open Suse Linux 10.2;Suse 的包管理对我来说真的很方便,从安装 DVD 上用 Yast 可以方便安装各种软件,无须考虑包之间的依赖性问题.我选择的是最小图形化系统安装,安装完之后,vmdk 文件的大小好像是 2GB 多.接下来安装的是所有的必须的包,大致如下:Apache,Perl,MySQL,PostgreSQL,rddtool,net-snmp,php,gcc,Kernel-source(for vmware tools)\u0026hellip;等安装完之后用 chkconfig on 命令设置需要自动启动的服务;然后把 apache 等服务逐个启动一下验证是否工作正常.然后安装的是 VMWare tools,这个好像也不是必须,不过还是装上比较好,方便虚拟机和 host 机共享文件.我的虚拟机的版本是 5.5.3workstation 版本.第二步:安装各种开源软件下面可能会是一个很长的 change log1. 安装 OpenNMS 1.3.2 安装方法 设置了 opennms 的自动启动,还没有设置 tomcat5.5.23 的自动启动.2.安装 Cacti **0.8.6j **安装方法, 使用的 poller.php,尝试安装 cactid,安装失败,原因可能是 OpenSuse10.2 好像没有 net-snmp lib 包. 暂时不安装 cactid3.安装 OCSNG 1.0.1 安装方法4.安装 hyperic-hq 3.0.4-389 安装方法, 2007-6-21th5.安装 OTRS 2.2.1-1 安装方法很简单，执行 rpm 安装既可, 2007-7-28th\n","date":"2007-06-15T07:24:00Z","permalink":"https://martinliu.cn/2007/06/15/e5bc80e6ba90ite7aea1e79086e5b7a5e585b7e5a4a7e585a8e4b98ball-in-onee8999ae68b9fe69cba/","title":"开源IT管理工具大全之All in one虚拟机"},{"content":"需求分析如果你开一个公司的话，如果你的公司需要提供人们某些在线服务的话，如果有的 office 需要 200 人同时上网工作的话，如果您在在线业务需要三层结构的话，如果您的服务器需要 7×24 小时监控的话，如果您的 ITsupport 工程是需要同时 照顾 50 个服务器和 200 个最终用户的话，如果您的企业随时收到黑客的攻击的话、、、、、、挑战如果您是公司的总裁或者 CTO 的话，试想您将如何为公司节约成本？如果建立一个可管理的基础架构？如果保证 IT 满足业务的需求？如果相应各种 IT 维护需求？如果降低企业的运行维护成本？、、、、、、开源领域里的可选组件如下外界链接设备\nVyatta路由器，可运行于低端PC，能实现DHCP，DNS，Firewall，NAT，DMZ以及多种路由协议 http://www.vyatta.com/ Asterisk PBX交换机，可以实现VoIP，语音菜单和信箱，软分机，IP电话 http://www.asterisk.org/ OpenVPN 是一个全功能的SSL VPN解决方案 http://openvpn.net/ 应用服务器 Linux 多种版本可供选择和免费使用 Apache、Tomcat、JBoss、Perl，PHP可以建立多层的Web企业 Mysql，PostgreSQL 比较稳定和流行的数据库，能支持双机等功能 桌面机 Ubuntu SuSE 帮助台 ORTS ITIL 兼容的ITsupport服务管理工具，比较好的支持对内部IT支持的流程 http://otrs.org/ SugarCRM 能和SalesForce抗衡的CRM系统，能管理客户信息，销售活动和售后支持活动 http://www.sugarcrm.com/ IT监控管理软件 OpenNMS，Nagios，Cacti、、、网络系统监控，我的blog上还有很多可选项 GLPI ＋ OCSNG IT资源生命周期管理，您需要知道您都有那些设备和资产 Nmap网络扫描，SNORT网络入侵检测，OSSIM等工具帮助网络安全管理 不知道有没有人愿意建立这样一个开源企业？呵呵！！如果您有什么新的想法和补充请一定分享给我。 ","date":"2007-06-12T09:18:00Z","permalink":"https://martinliu.cn/2007/06/12/e5bbbae7ab8be4b880e4b8aae5bc80e6ba90e4bc81e4b89a/","title":"建立一个开源企业"},{"content":"这是一个比较新的产品，提供开源的软件路由的解决方案；他们的目标直指 Cisco 这些大牌网络硬件厂商。它能简单的安装和运行在 32bit 的普通计算机硬件上，实现路由器的几乎所有功能；能支持的硬件平台和路由协议还真不少，请查看 Datasheet；下载 网址在 VMWare 中安装了一下发现它可以完全满足我需求：1）在公司中办公网络建立一个隔离的测试网。2）测试网中提供 DHCP,DNS 服务3）提供 NAT,Firewall4）安装简单，硬件需求低准备在公司实际环境中安装测试，安装和配置信息待续。现在我正在 Vyatta Router 后面的小网内更新这个 Blog。上午的安装过程如下：（硬件准备）测试机一台 Dell Gx620，主板上带 Intel 的内置网卡一块 TP-LINK TG-3269C，网线若干（网络环境）在一台办公网的机器上，寻找一个未使用的 IP 地址，这个地址会分配给 Router 的 Internet 网卡上；然后运行 ipconfig /all 记录下默认网关、默认 DNS 和子网掩码，这些信息会配置到 Router 上。（安装过程）\n下载Vyatta的试用手册 Quick Eval Guide - Boot, Configure \u0026amp; Test the Vyatta software翻到手册的第三页，重新标准出你的网络信息，注意后面的配置跟这里的信息有关。为了简单起见，我就改了对外链接的哪个网卡的IP地址，至于内网么，有什么ip地址范围都无所谓了呵呵 下载刻录Vyatta软件 Vyatta Community Edition 2 - CD-ROM Image 刻录到一张空白CD上 把可好的CD放入机器中，从CDROM启动，这其实是一个livecd。启动过程可以无需关心，看似是一个Linux PE的CD，启动之后用root进入操作系统，root的密码是vyatta。进入后可以查看一下 vi /var/log/dmesg 主要看看你的两个网卡它是否能真确识别。我的测试机是Intel CPU的，不知道AMD的机器是否呢个装，没试过。 其它的配置过程文档中说的非常详细，不用我在多说。 安装之后的小节：Router有两个网卡，在对外的网卡上做了，NAT，firewall，在对内的网卡上做了DHCP,DNS，现在我的笔记本在Router后的小网里，运行ipconfig /all的结果如下Ethernet adapter Local Area Connection:Connection-specific DNS Suffix . : mycompany.comDescription . . . . . . . . . . . : Broadcom 570x Gigabit Integrated ControllerPhysical Address. . . . . . . . . : 00-0F-1F-BB-B2-92Dhcp Enabled. . . . . . . . . . . : YesAutoconfiguration Enabled . . . . : YesIP Address. . . . . . . . . . . . : 10.0.0.150Subnet Mask . . . . . . . . . . . : 255.255.255.0Default Gateway . . . . . . . . . : 10.0.0.1DHCP Server . . . . . . . . . . . : 10.0.0.1DNS Servers . . . . . . . . . . . : 192.168.172.20010.100.112.27Lease Obtained. . . . . . . . . . : 2007年6月12日 11:57:30Lease Expires . . . . . . . . . . : 2007年6月13日 11:57:30总之这是一个非常成功的测试，这个产品真的非常Coooooool！！！！！它让我看到了OpenSource的东西不仅可以在纯软件领域和商业产品有所比较，它还能在硬件领域有所作为。 ","date":"2007-06-09T08:56:00Z","permalink":"https://martinliu.cn/2007/06/09/go-open-sourcego-vyatta-network/","title":"Go Open Source,GO! Vyatta开源软件挺进网络硬件领域"},{"content":"注:本文是我的处女作呵呵,发布在\u0026quot;网管员世界\u0026quot; 三月 B 刊上,原文如下:\n谁来关心核心业务系统——简要比较 IBM Tivoli 与 HP OpenView\n导语：随着 IT 的快速发展，中国用户对先进技术的追逐和应用正日益高涨。回想我们已经建立的这些业务系统。我们不得不用如下几个词来形容：复杂、动态、故障多和管理难。在繁琐的日常运维工作中，来自各个部门的人，似乎又在默契地担负和实现着这样的同一个使命：保持关键核心业务系统正常运转。网络系统监控软件是用来帮助 IT 运维人员，缩短故障解决时间和提高工作效率的有力工具。选购网络系统监控软件的技巧在于对自己的 IT 系统深刻的理解和对管理需求深刻的理解。假设您的用户是通过这样的一个访问路径来查看客户信息：浏览器 àInternetàWeb 服务器 à 中间件服务器 à 数据库；首先标出在这个路径中的每个点上，开发、测试和运行维护等各部门人员是怎样分布的。假设在每一点都有这样的一个自底向上的技术堆栈：网络 à 服务器操作系统 à 数据库 à 中间件 àWeb 服务器 à 客户端。再让各部门的每个相关的人员标出在哪些区间所消耗的时间和遇到的故障是最多的；这些故障是什么？记住把这些信息记录下来，并打印出来，无论如何这样的原始数据都是 IT 管理优化非常好的参照。在得到这样一个管理需求的分布图后，接下来就可以按图索骥来挑选相关的管理平台以及相应管理模块。一个好的监控管理系统并不一定试图监控和管理到技术堆栈中的所有对象，而是在您最需要帮助的核心部分提供有利的支持，为您清晰呈现 IT 系统的这样几个关键因素：可用性、性能和故障状况。记录和分析核心业务系统在这些方面的变化情况是 IT 监控管理软件的主要功能。\nIBM Tivoli 和 HP OpenView 是主流 IT 监控管理套件中的两个重量级角色。它们是两个著名的市场品牌，旗下丰富的管理模块组成了非常全的产品线。选择标准如何确定呢？管理工具提供的管理功能永远超过其它因素，做单纯产品线长短的比较是没有意义的。一个清晰的管理需求定义可以使您能够非常轻松的考察和比较不同品牌的管理产品。由于它们都属于管理平台型产品，管理功能都非常的丰富和全面。本文对这两个产品的介绍和分析，无法面面俱到，所以只能对它们的工作方式、特性和原理等方面做粗略的比较；旨在抛砖引玉，引起读者注意，给您提供若干提示和思路。下面就网络管理和应用系统故障管理（操作系统、数据库、Web 应用等）这两方面来做一个简要的分析和比较。这也是对核心业务系统监控管理的最基本内容。\n**网络管理方面：**IBM NetView 和 HP OpenView Network Node Manager 都是很好的产品，有很多可选的功能模块。众所周知 NetView 产品是当年 IBM 从 HP 购买的，NetView 和 OpenView NNM 算是一对孪生兄弟。后来，它们在各自的家庭里慢慢的长大，成为个性不同的两个产品。如今的 OpenView NNM 在下面的一些方面可能比 NetView 做的更为出色一些：1）很好的支持多种行业标准的管理协议：多个版本的 SNMP、ROMON、Netflow、Ipv6、OSPF、HRSP、CDP 等；2）提供全面的网络管理视图，包括二层和三层的网络拓补图；以及 VLAN 和其它协议视图；3）有效的内嵌事件关联引擎和事件管理配置工具，对用户处理事件和相关事件非常有帮助。OpenView NNM 毕竟是具历史悠久的成熟产品，不过在 IBM 收购了 Micromuse 后；今后可能在网络管理方面,IBM 和 HP 也可以不相伯仲了。网络管理的特殊性在于：只能通过行业标准的管理协议来从这些硬件设备上获得所需要的信息。网络监控系统一般作为网络设备的数据收集器和网络设备 SNMP Trap 的目的地。在多厂商设备的网络环境中，监控系统需要的是对各种硬件设备的兼容性；从实际环境出发，选择更能反映真实运行环境，更易于理解，而且容易使用的产品。\n**应用系统故障管理：**这个管理范畴中包含最多的管理功能和管理模块，它管理操作系统和操作系统之上运行的一切对象：各种数据库、Web 应用、中间件、Web 服务、邮件服务和标准商业应用等。它与实际业务应用系统同时运行在同一个网络环境当中，是它肩负着对核心业务系统的监控。由于这部分的功能最多最复杂，它往往被看作是管理监控的平台或者框架，是监控系统的核心部分。所有管理对象的故障告警事件都汇聚到里，其它各个功能模块都以它作为通讯平台和数据存储中心。Tivoli Monitoring 和 OpenView Operations 就是这样的核心模块产品；它们都有很多其它相关的管理模块，这些模块大多数需要加载到这个核心框架上运行；部分模块是可以独立运行，同时和它们做故障事件集成。用户使用界面、管理策略定制、管理对象轮询、故障事件报警和管理报表等功能都关联到这里。下面将从四个不同角度简单比较一下 Tivoli Monitoring 和 OpenView Operations 的各种特性。\n1**、监控代理的差异** 在监控主机上安装监控代理是各个厂商的相同做法，代理程序运行在被监控主机上和管理服务器通讯；执行各种数据收集任务和管理策略。操作系统代理是最基础的模块；有的厂商可以通过操作系统监控代理程序来实现对数据库、Web 应用、中间件、Web 服务和邮件服务等的监控，有些需要安装和配置多个代理监控程序。\nIBM Tivoli Monitoring\n2**、告警机制的差异** 代理程序在采集和整理实时和历史的监控数据时，需要随时检查各种报警条件是否满足。监控最好能在故障状况发之前，将各种迹象以不同级别的事件精确地、及时地汇总到管理服务器端，以邮件，短信等方式通知到相关工作人员。\nIBM Tivoli Monitoring\n在监控对象阈值设置上可以实现复杂的逻辑。对于某个采集点在某时间点或者时间段上的数值，可以设置它和另外一个数值的几乎所有算术关系的比较；还可以逻辑上和其它采集点的状况做关联。告警条件的定义可扩展到：在给定的时间内、多资源、多阈值的情况。告警条件的判断是在代理程序端完成，最终发送告警事件到管理服务器。能定义在临界值到达时的自动触发处理动作。\nHP OpenView Operations\n告警条件的设置可以对于某个采集点在某时间点上的数值，能提供大于和小于的比较条件；其它的情况可以通过 VB、Perl 脚本来实现复杂条件判断。能设置尖峰持续时长，对有本地重复事件报警抑制功能；代理程序可以在临界值的到来、持续和结束三个不同阶段，定义和发出不同的事件提示；执行不同的故障修复动作。\n3**、用户使用界面的差异** 图形化用户界面是产品选型的重要因素之一，易用性高的用户使用界面可以降低软件的复杂度。IT 管理软件功能的复杂性是很多用户望而却步的一个主要因素。中国用户对报表的需求是比较特殊和苛刻的，往往需要定制和开发特定的管理报表，所以需要详细考察预定义报表和相关开发接口。\nIBM Tivoli Monitoring\n窗口用户界面和 Web 界面保持高度的一致性，用户可以通过 Java 客户端和 Web 浏览器连接到相同的工作区上。Tivoli 用户界面非常像是一个报表分析系统。在工作区中有很多预定义的窗口，能方便的开始系统状态的查看和监控策略的定制。管理平台内置的基于权限和角色的管理也由用户界面得到了实现；分权和分区域管理是很多大型企业环境的必要需求。\nHP OpenView Operations\n图形用户界面能提供业务管理的业务视图，管理员进行面向业务的管理，实现故障定位、分析、跟踪和解决等相关管理工作。用户界面还包括各种预定义的策略模版、工具和报表。多种不同层面的中文管理报表，可以满足客户对网络性能、故障、配置等各方面的管理要求。Web 用户界面和窗口用户界面稍有不同。\n4**、体系架构的差异** 根据企业环境和管理需要的不同，监控系统有时候需要能够跨地域全网监控；有时候也只限于监控某个 IT 中心的核心系统。监控系统有时候和生产系统在同一个网络，有时候又只能部分运行于生产环境。在完成所有监控任务的同时，还要能被用户方便的访问；对网络的适应和防火墙的友好性是必不可少的。\nIBM Tivoli Monitoring\n它的三层管理结构可以实现分布式多级系统管理。内置了基于角色和权限分工的安全机制，所有的权限定义在管理平台中实现。IP.PIPE 协议可以满足跨火墙地址转换的管理需要。同时，IP.PIPE 也对防火墙端口的设置有最小的要求，以适应企业越来越严格的安全规范。\nHP OpenView Operations\n能支持灵活的分布式管理模式；能实现包括对等中心、向阳式和互为备份管理中心等多种方式。用这些架构特点可以保证跨地域和跨广域网统一集中管理的实现。两层的管理结构使得管理架构相对简捷和易于部署。\n上述四点是应用系统故障管理的几个关键部分。其中的技术细节和实现方式和运行细节往往比较复杂。其实任何一个具体的 IT 环境对监控产品都是非常具有挑战性；监控产品也可能在某些环境中无法工作；也可以对系统造负面影响。然而，深刻理解监控管理需求和实际 IT 环境的您则只需要做好对产品功能和架构特性的考察即可；同时将所有其他影响都降低到最小化的可以接受的范围。\nIT 监控管理系统的复杂性和企业对业务应用系统管理需求的动态性，使我们很难简单的总结出一个管理秘笈或者产品技术宝典。IT 管理工作的开展除了选择好用的管理监控工具外，还一定要遵循：“二分工具，八分流程”的二八管理原则。如果您机房中的电缆正像蜘蛛网一样蔓延；您的 IT 运维人员天天都在抱怨的电话中度过；您的硬件维护开支在漫无边际的增长；这是您可能需要学习借鉴一下 ITIL 最佳管理实践模型，对 IT 管理的优化和改革不仅需要各种监控工具的帮助，也需要通过改造管理流程来提高工作效率。总之：核心业务系统不仅需要好的 IT 监控管理工具，也需要 CIO/CTO 来设计和驾驭优良的管理流程。\n","date":"2007-06-07T09:44:00Z","permalink":"https://martinliu.cn/2007/06/07/core-business-hp-ibm/","title":"谁来关心核心业务系统"},{"content":"转载 ITmanagement 的一个文章；全文的部分翻译。个人以为这个文章的把网管的开源工具做了一个小结，英文好的同志请直接访问原文地址：click Here “最高评分的管理管理工具不会使人不得不花未来的钱。来考虑一下这些自由且低成本的开源软件吧。”Leslie T. O’Neill May 24th, 2007\n如果您的公司排名在 Fortune 1000 强和中小企业之间，那么您网络管理的选择形势看似比较严酷。你既不能在小市场上收集一堆拙劣的玩意来组成一个解决方案；你也不能花很多钱买一些真正不需要的高科技产品。这里有一个很好的选择：试用可一个开源的网络管理方案，加专业服务，包括开发和技术支持。\n**Open Source = Flexible ****开源＝灵活性**\n一个开源的解决方案对厂商来说也是非常灵活性的，他们很快地增加新技术的支持，比改进一个私有系统更快。例如：当 Ubuntu 7.04 “Fiesty Fawn”四月份发布之后, Hyperic HQ 在发布的第二天就宣布了对其提供技术支持。\n当谈到开源的网络管理方案时，公司最需要也用的最多的技术莫过与监控功能。不过监控技术在很大程度上已经变成了日用品。通常的，专业化版本的开源 IT 管理软件平台集成多个其他开源项目在一个框架中，象 Nagios 网络监控等；并且加入统一的网络界面；并且提供技术支持服务。另外，他们都想通过强大的社区来提高和改进代码，跟踪 bug 等。\n六个企业级平台\n下面的六个开源 IT 管理都可能用作 HP, IBM, CA 和 BMC 大型管理套件的替代品。每一个都能提供低价的专业服务和免费软件下载。它们的不同支持在与所提供的功能和支持的操作系统\nQuest Big Brother\n这个 Web-based 系统和网络监控产品能支持 Windows, Unix 和 Linux 等操系统, 还有一个通过用户投稿形成的脚本知识库，利用它能容易地定制 Big Brother 取管理你的网络。它的 GUI 是一个不错的特色，使用相同的颜色代码；红色代表不好，绿色代表好。\nGroundWork Open Source Monitor Professional\n2004 年发布，它是最早的企业级网络管理产品之一。它集成了超过 100 种最好的开源项目，包括 Nagios, Apache 和 NMap, 在这个框架之上有添加了很多特有功能，例如 Web-based 用户界面等。Monitor 提供了集中化的监控和管理，管理和监控你的企业网络，包括 Linux, Unix 和 Windows 服务器, 应用, 数据库和网络设备。\nHyperic HQ Enterprise\n瞄准的是一个数据中心，Hyperic 被设计为去监控和管理 Web 应用的所有层次， 包括硬件、中间件、虚拟化、Web 和开放式应用。它还提供基线和趋势分析。它支持 Apache, JBoss, Linux 和更多应用。\nOpenNMS\n这个 Java-based 网络管理工具专注于网络服务轮询，数据采集和事件/告警管理。它目前支持多种开放式操作系统，包括 Linux, Mandrake 和 Solaris,还有 Mac OS X; Windows 系统的支持计划在 OpenNMS 2.0 中实现。\nOpenQRM\n也瞄准了数据中心的管理，OpenQRM 不仅能管理数以千计的 Linux 和 Windows 服务器，还能跟踪计量你的数据中心的使用率和效率。 他还能做自动化基于策略的 provisioning。它也集成了 Nagios 作为监控功能。\nZenoss Core\n基本上都是 Python 写的，这个管理平台提供了服务器、网络设备、OS 和应用的事件管理、可用管理、和性能管理。Zenoss 能运行于 Linux, FreeBSD 和 Mac OS X；它也可以作为一个 Zenoss 虚拟应用运行在 VMplayer 里。\n四个无支持的项目\n这四个项目位于 TOP10 开源网络管理工具中。不象那六个产品，它们不提供商业的服务和企业级的增强功能。但是它们是绝对的 free，而且你可以拥有所有需要的网络健康性检查功能。\nNagios\n这是一个开源的运行在 Linux 操作系统上的主机、服务和网络监控程序。\nJust For Fun Network Management System (JFFNMS)\nJFFNMS 能监控标准的 SNMP (Simple Network Management Protocol) 网络设备，服务器、路由器和 TCP 端口。它工作在 Linux, FreeBSD 和 Windows 2000/XP。****\nBig Sister System and Network Monitor\n这个项目包括了 real-time system 和 network health monitor, 一个 Web 应用框架和一个系统管理应用。\nNetdisco\n这个 Web-based 应用被设计为管理中道大型网络和其中的 SNMP 网络设备。\n相关文章:\n· Interview with Hyperic\n· Top 5 Upstart Monitoring Companies\n· The Advantages of Open Source Management\n· 10 Simple Steps to a Green Datacenter\n","date":"2007-06-01T01:47:00Z","permalink":"https://martinliu.cn/2007/06/01/top-10-nsm-tools/","title":"[转]10大优秀开源网络管理工具"},{"content":"HQ 的网站是一个显的非常商业化的网站；看上去制作的比较精良也比较专业。从 HQ 的官方文档（好像没找到 pdf 手册）中看出它能监控的东西还真的非常多，无论是商业的软件还是开源的都有一大串的 matrix；他们在被监控的及其上是需要安装和运行代理的。所以从这一点上讲和商业软件也没有什么区别，总之看的数据多应该比较好，不过数据收集的多有时候会给监控对象代理太重的 workload。如何安装下载 HQ\\hyperic-hq-installer-3.0.4-389-x86-linux 从 HQ 的网站。这个压缩文件包含：安装程序，服务器端程序（好像包括一个内嵌的 PostgreSQL 数据库），代理程序，服务期端 shell 程序，JRE。BTW:服务器端和代理都是 Java 程序，如果自己配置好 JRE 的话可以下载不包含 JRE 的安装包。Windows 上的代理包是一个 zip 文件，为了方便我都下载的含有 JRE 的安装包。由于是纯 Java 的应用所以服务器端和代理端看似好像都没有任何依赖性要求，只是需要在服务器端安装 xorg-x11-libs 包，否则不能正常绘图，看不到图形。在 Linux 下的安装过程大致如下。mkdir /opt/hquseradd hq -G root -d /opt/hqsu hqtar zxvf hq.tgzcd hyperic-hq-installer/./setup.sh/opt/hq/server-3.0.4/bin/hq-server.sh start注意最好建立一个新的用户为 HQ，服务期端本身需要被非 root 用户安装和启动。另外代理和服务器端都需要特殊的两个端口通信，所以安装完之后必须停止或者配置防火墙；否则不能访问服务器，服务器也不能和代理通信。启动代理之前需要配置好防火墙。试用：总体说 HQ 的安装和配置都是非常简单的，不过他的 Web 界面更是简洁。当代理启动了之后，会自动出现在 Auto-Discovery 下面，点击 Add Resource 按钮将它变成一个正式的监控对象。默认的情况下，代理会收集一定数量的监控指标；大概是可收集数量的 20%左右。当在某个监控对象上（例如 Memory Used）设置了收集间隔之后，服务器端就开始了定时的数据收集，所收集的数据默认情况下用折线图的形式展示。可以根据某个指标建立一个告警，告警的逻辑也相当的完整：逻辑判断，巅峰判断，升级处理；看似能想到的都有了。由于是第一次使用展示没有看的如何建立一个告警规则应用于所有监控对象的。我用 HQ 对我的一个服务器（iis,MS Sql,.net）做了监控，从数据收集和展现效果上来说，真的堪称可与商业软件媲美。使用结论：安装简单方便，在 Linux 下代理端完全无需关照包依赖性。代理配置的安装配置需要一定量的工作，必须配置服务器地址，通信端口等。代理程序对服务器的工作负担还是比较大的，特别是在启动的那几分钟内。代理进程对 CPU 的使用率可以达到 50 ～ 80%，之后就比较低了。对内存的利用一般是 30MB 左右，当然这应该是可以通过降低收集数的数量和频率来降低的。用户界面的使用还真的是很方便，还支持告警信息的 RSS 访问。总之 HQ 是一个开源软件中的重量级选手：功能强，复杂性高，代理程序负担较重。其他使用小结，待续。\n","date":"2007-05-30T04:28:00Z","permalink":"https://martinliu.cn/2007/05/30/hyperic-hq-testing/","title":"Hyperic HQ小测手记"},{"content":"FROM：http://www.zabbix.com/features.phpZABBIX offers functionality that will make your IT resources look more transparent, and it will also help to easily identify performance and availability problems. ZABBIX greatly increases the productivity of system administrators by providing simple-to-use monitoring system.Key features\n开源的方案Open Source solution 能编译运行在多种OS：AIX, FreeBSD, HP-UX, Linux, MacOS X, NetBSD, OpenBSD, Solaris, Tru64/OSF SQL database存储配置、性能等各种信息 Web interface 简单易用的访问 提供实时和历史的监控分析数据 Data 可视化和影射 高性能的监控代理 (UNIX, Win32) 监控 \u0026ldquo;agentless\u0026rdquo; 环境 维护和监控SLA of IT Services 监控 SNMP (v1,v2,v3) devices IT Services 提供IT基础架构（组建/服务/硬件）等和业务逻辑的联系和对应ZABBIX\u0026rsquo;s unique technology allows you to relate your applications and underlying servers or network to a IT Service such as application, location, server, network device, region, etc. This technology allows you to correlate your business to your IT infrastructure and identify the impact of your IT infrastructure to the delivery of business service to your customers.Data visualisationZABBIX provides excellent visualisation of statistical and real-time information, ranging from simple graphs to complex views containing graphs, maps and text information. All graphical information is accessible from WEB interface. The wealth of information available such as the trend analysis (days to threshold), the historical graphs and histograms allow you to make informed decisions about the weaknesses and performance of your IT infrastructure.Application monitoring 应用监控Enterprise applications such as Oracle, WebSphere, WebLogic, Exchange, Apache, etc. can be monitored using SNMP. In many cases, agentless technology can be used, cutting down on the deployment and management costs.ZABBIX agents can be easily extended to perform monitoring of any aspect of your applications. It is matter of writing a shell script which would return required data back to the agent.Server monitoring 服务器监控Virtually all server platforms are supported including but not limited to UNIX, Win32 and Novell Netware. ZABBIX native agents take care of CPU utilisation, memory utilisation, disk usage, network I/O, temperature of CPUs and mainboards, status of processes, etc. All real-time performance data is immediately available by WEB interface.Network monitoring 网络设备监控ZABBIX supports monitoring of Cisco, Juniper, 3Com, Nortel, Foundry and other routers as well as firewalls from Netscreen, Fortinet, Cisco or Checkpoint. Any network devices (routers, hubs, printers, etc) having SNMP support can be easily monitored by ZABBIX.ZABBIX makes possible creation of network maps which give very clear representation of monitored network infrastructure. The maps show network devices, connections, statuses of the devices, and reasons if a device is not available or has any problems.Integration of Fault and Performance Management集成化的故障和性能监控The need to effectively integrate fault and performance management is becoming increasingly apparent to IT organizations seeking to ensure quality delivery of business services. ZABBIX generates real-time notification of threshold violations based on scheduled performance tests. ","date":"2007-05-22T14:53:00Z","permalink":"https://martinliu.cn/2007/05/22/zabbix-key-features/","title":"ZABBIX特点介绍，转自它们的网站"},{"content":"第一次看到这个软件是在 OpenNMS 的邮件讨论组中，他们计划做一个 vmware 的 image 放到VMTN 上 。我在 VMTN 里哪里点击了一下监控管理这一类，一个叫OpenESM 的项目进入了我的视线。它能引起我的注意是因为，它在项目的描述中说:我们理解 ITSM、、、、Check it out! 大致浏览了一下他们的网站，发现他们的目的是在 Zabbix 的基础上作一下优化和开发，加入若干特色：GSM modem 发短信、新报表、SLA 监控等。现在很多项目都有迅速实施的解决方案。对于很多开源项目来说，它们对于新手的相同门槛就是安装。安装上了，不会配置；配置好了，不会用；用上了解决不了问题。我先下载了OpenESM ，一个不算太大的文件 1.3GB。解压缩之后用 VMWare 打开运行，猜出 root 的用户名是 openesm，登陆之后发现它是一个 Fedora 的虚拟机。登陆 OpenESM 的控制台， http://ip/ 接下来就需要去www.openesm.com上下载手册了，否则无法继续下去。照着手册安装代理，在我的两个Windows的机器上。安装需要先下子代理安装包，允许安装命令的时候需要制定自己的主机名和服务器的主机名。在控制台中加入这两个安装了代理的机器，由于是初次使用没用玩自动发现之类的功能。收集了一阵子数据之后，很快发现了很多有趣的数据。最终总结如下\n这是我安装的第一个有代理程序的开源监控软件，感觉在Windows下代理的安装还是比较方便的。比我想象的简单，安装文件只有一个exe文件，装完之后形成一个服务。我记得在查阅文档的时候看到了一文档，上面列出了所有代理程序能收集的数据的表格，说明了什么数据在什么操作系统中支持，那些不支持。它能在多种操作系统上安装，他的安装时说从代码编译安装，windows上不需要，在非windows上就以为这需要安装编译器什么的。这好像并不是特别好。 可用性和性能的数据都能收集。 事件管理功能，能触发action，还没有试过，能触发邮件和GSM短信等。没有试过。 没有试的还挺多，还需要进一步研究。 ","date":"2007-05-22T13:51:00Z","permalink":"https://martinliu.cn/2007/05/22/what-is-zabbix/","title":"What is ZABBIX?"},{"content":"1.1 概述 Opennms 能够帮助 IT 管理部门持续的监控分布式的异构系统和网络设备的运行状态，它可以支持 SNMP 网络管理协议确保管理的扩展性，并且提供非常灵活的定制功能从而有利于管理范围的伸缩。它内置的故障事件管理以提供故障事件的记录和分析的能力，快速隔离非根源事件并迅速发现故障原因。Opennms 良好的设计可以快速部署实施，简单友好的图形界面能够使得用户迅速掌握，从而降低操作的复杂度，提高 IT 管理效率。\n1.2 体系架构 作为一个通用的网络系统故障监控平台，其体系架构应如下图所示：\n**附图 1. ** **Opennms****体系架构**\n我们从下至上对 Opnnms 体系架构作一一的介绍：\nu 被管理对象层，SNMP 代理程序是数据采集和动作执行层。对应网络设备来讲，该层对应与网络设备本身的网络管理功能，不需要在设备上单独部署功能模块；对计算机来讲，该层是运行在目标计算机上的 SNMP 服务，负责采集该系统运行状况、性能等数据，并向管理层汇报。\nu Opennms 监控引擎是实现网络和系统可用性、故障管理的业务逻辑和策略的处理层。他利用特定的轮询策略：从代理程序层收集数据、更新和维护被管理对象状态、执行相关的报警事件通知。\nu 管理对象数据库是网络和系统管理的数据存储层。其中以面向对象的方式保存着网络和系统资源的模型，记录着他们的配置、描述和状态等信息。这些模型和信息是通过 Opennms 网络扫描模块自动建立起来的，并由管理者层自动维护。\nu 图形用户界面是网络和系统管理的数据表示层。他以各种直观、生动的用户界面向用户展示网络和系统中各种对象的关系、配置、状态和故障情况，是优秀的用户接口。\n针对某企业简称 user short name 的环境，其 IT 故障监控子系统的管理框架为：\nu 被管理对象层——启动核心路由器和交换机的 SNMP 网管协议，作为网络设备故障的数据提供源；在所有需要管理的服务器上运行 SNMP 服务，作为监控操作系统故障的数据提供源。\nu Opennms 网络监控服务器——新增一台服务器，部署 Opennms 的监控引擎模块，由该模块对被管理对象层的数据源进行自动的数据采集和翻译采集的结果。并实时发送报警信息。\nu 对象存储库——在和 Opennms 监控引擎安装的机器上安装 PostgreSQL，作为 Opennms 监控模块的对象存储库。\nu 图形用户界面——某企业简称 user short name 管理员可使用任何的 WWW 浏览器连接 Opennms 网络监控服务器的用户界面，使用合适的用户名，在某种适当的权限下查看和浏览网络监控信息、状态信息、可用性报表和性能报表。\n1.3 功能介绍 1.3.1 网络节点自动发现 对象存储库中的信息并不是靠管理员手工输入和维护的，而是由 Opennms 网络监控引擎－自动扫描模块自动从用户的计算机系统中搜索发现出来的。\n**附图 2. ** 网络节点自动发现\n1.3.2 图形用户管理界面 在某企业简称 user short name 这 样的网络和系统中，需要一些友好的监控视图。目的是使得管理员能够通过直观的界面，迅速发现故障，从而在最短的时间内解决故障。该用户界面视图可使得管理 员通过管理工具看到现实世界对象的真实反映，而不是抽象的符号。使用户能够监控整个系统的概貌，系统的大体分布和总体运行状况等。并且决策适当的故障排除 方案，各种界面视图可通过 Intranet 进行浏览查看。\n**附图 3. ** 网络管理员管理主页\n该用户界面的最左边是：Nodes with Outages，表格中列出了最近发生故障状况的 12 个节点，这些节点可能是网络故障，或者是某些网络服务出错等。\n用户界面的中间是：各种网络服务的服务水平报告。它列出了最近 24 小时之内各种网络服务的服务质量水平；其中的网络服务可能包括：网络接口的 UP 时间、Web 服务、DNS 和 DHCP 服务和数据库服务等。\n最右侧的是一些比较常用的功能选项：报警提示信息、节点的性能报表、节点网络服务相应时间报表和自定义的性能报表。\n1.3.3 故障监控 被管理对象的数据采集和状态维护是由 Opennms 的监控引擎模块实现的。每个所管理的所有对象存储在数据库中。可以管理的对象包括：\nu 支持 SNMP 网管的网络设备\nu 部署了 SNMP 服务的服务器上的操作系统\nOpennms 采取统一的通讯方式从这些管理对象上采集可用性和故障信息，信息的采集有两种方式：\nu Opennms 主动地通过 SNMP 协议定期查询被管理对象状态\nu Opennms 被动接收被管理对象发来的 SNMP Trap\nOpennms 得到被管理对象的轮询或 Trap 信息后，根据收到的信息类型、对象原来的状态和网络系统管理的策略和逻辑判断对象的状态是否发生变化。如果发生了变化，则可以按照管理策略采取若干更新操作。\n1.3.4 故障事件管理 当 被管理对象的运行状态发生变化时，就会产生事件。如果该事件是由正常变为故障，则会产生故障报警。事件管理是通过收集、确认事件，对事件进行分类和过滤， 关联不同来源的事件完成对事件的处理和响应。通过事件管理，系统管理人员可以方便、迅速、及时掌握系统运行的故障和警报，及时进行处理，保障系统的正常、 稳定运行。\nIT 系统管理人员所关注的问题，如系统资源出现短缺、数据库连接失败、网络通信中断、主机文件系统溢出等等都会以事件的形式表现出来。\n**附图 4. ** 事件管理控制台\n1.3.5 操作系统监控 Opennms 对各种计算机操作系统的可用性、运行状况和故障的集中监控是通过本身的 SNMP 服务程序完成的。这些 SNMP 代理程序是 SNMP 服务的组成部分。在本次建议的方案中，在所有的被监控服务器上其监控的主要内容包括：\nu CPU 利用率，显示系统、用户、空闲时间的百分比；\nu 虚拟内存(Virtual memory)利用率；\nu 文件系统使用情况，显示磁盘空间使用情况；\nu 监视文件系统的使用率，当使用率超过特定阈值时向系统管理员报警；\nu 监控网络端口的输入、输出、错包，以及端口是否被停用或者删除；\nu UNIX 系统还可以监控\n² Load Average：服务器平均处理量\n² 共享内存\n1.3.6 网络节点配置信息管理 被监控对象节点在数据中的配置信息是 IT 设备的资产信息，每个网络节点都是一个特定的 IT 资产设备。每个节点在数据库中有很多属性字段供选择填写，主要有三类属性信息：\n配置种类信息：配置分类、告警分类、轮询属性和阈值分类。 标识信息：资产描述、厂商、型号、资产编号、操作系统等 位置信息：负责人、部门、楼层、房间、机架编号等 **附图 5. ** 节点资产信息\n1.3.7 全面的节点监控 每个被监控的节点都能被细致的记录和监控。当查看某节点的信息时，有这样几类信息：状态信息、各种网络服务总的可用性、SNMP 属性、各个接口熟悉、最近发生的 5 个事件和最近的故障事件。\n**附图 6. ** 节点监控视图\n在查看某个节点是，界面上的信息分为三类：网络服务可用性报表、当前状态和监控事件信息。在菜单栏还能有很多功能选项：查看故障事件、资产信息、响应时间报表、SNMP 性能报表、重新扫描、节点管理和更新 SNMP 信息。\n1.4 特点和优势 Opennms 在网络和系统管理方面，有非常广泛的用户，特别是中小企业用户，Opennms 具有很多极好的特点：\nu 方便易用的用户管理界面——Opennms 可以提供故障事件视图、节点视图、相应时间视图、性能视图等各种管理视图。\nu 基于 Open Source 协议开发——用户可以按照自己的需求，通过修改软件本身或者软件的源代码来定制。\nu 跨平台管理——Opennms 支持任何能运行标准 SNMP 协议服务的操作系统系统，并且可以从一个单一的用户界面分别管理其局域网（LAN）。\nu 切实可行的事件管理系统——Opennms 通过方便易用的交互式控制台，为 IT 管理员显示关键事件，提供自动的事件响应，可以以电子邮件方式发出事件通知。\nu 方便的集成——Opennms 可以与第三方产品集成。例如 Opennms 可以方便的与 Dell、HP、IBM 等厂商的服务器自带的 SNMP 故障管理软件集成。\nu 2005 Linux World 推荐管理产品 ——Opennms 获得 2005 年 Linux 世界大会的“最佳网络系统管理软件”的荣誉。已经被认定开源软件世界中的最佳网络系统管理软件。\n版权所有，如果转载请著名出处。\n曾被www.vshj.com转载：http://www.vshj.com/Article/2006/200607/Article_97842.htm\n文章中所提到的图片请参阅我的相册。 ","date":"2007-05-08T04:41:00Z","permalink":"https://martinliu.cn/2007/05/08/what-is-opennms/","title":"OpenNMS网络和系统管理简介"},{"content":"**问：OpenNMS 是什么？**答： OpenNMS 是第一个开发在开源模式下的企业级网络管理平台应用。OpenNMS 的目标是成为一个真真的分布式、可升级的网络管理平台，尽管它看似一个 FCAPS 网络管理模型，使之可用于开放源码和商业领域。目前：OpenNMS 专注与以下三个方面：服务轮询 － 检查应用服务的可用性，产生可用性报表。数据收集 － 收集、保存和报表网络信息数据，并设定和触发门限值。事件和提示管理 － 接受事件系统内部的和外部的事件，将源事件提供给强大的故障告警和故障升级系统。OpenNMS Group 是开发和支持 OpenNMS 应用的一个商业性的实体。问：为什么要开源？答： 我们坚信真真的创新不会来自规模巨大的企业。我们还相信网络管理软件领域比 Linux 操作系统更适合开源模式。不像 Linux，网络管理要去监视和控制来 自不同厂商的很多的技术。考虑到每年都有很多新的网络设备面世。商业软件公司并不希望追赶这种更新产品的工作负荷，相反它们只能依赖与它们的通用管理技术 （最小化的通用性）。相反，对于一个开源项目中的每一个人－－厂商、用户或者技术顾问－－都能对项目做出自己的共享，从而保障了这个项目成功的几率。**问：OpenNMS 是用什么语言写的？**答： OpenNMS 主要是用 Java 语言写的。OpenNMS2.0 的目标是：让它成为一个以一堆.jar 文件形式来安装的产品。还有一些非 Java 的部分： icmpd-Java1.4 API 不能理解 ICMP。因为 ICMP 回答请求（ping）是一个最简单的来测试基于 Ip 的网络设备是否可以服务的方法，没有那个网络管理应用程序不用的 它的。将 ICMP 功能分离为一个独立的守护进程的目标是，如果系统中有 ICMP 的功能那么 OpenNMS 就用，如果没有 OpenNMS 就率略它。 OpenNMS 不需要 ICMP 来监控网络设备。数据库－OpenNMS 现在使用 PostgreSQL 作为它的地层数据库，PostgreSQL 是用 C 写 的。OpenNMS2.0 会使用几个能通过 Hibernate 适配器访问到的数据库。rrdtool－OpenNMS 当前的版本实时的选择使用 RRDtool 或 jRobin（Java 会使用 RRDtool）。最终这个选项的默认使用 jRobin，也可以选择使用 RRDtool。**问：OpenNMS 有图形的显示么？**答： 这可能是一个对于 OpenNMS 新人来说最常问的问题：OpenNMS 的图形监控界面在那？简单的问答是我们没有一个这样的地图，如果你想听听我们的解释 请继续往下看。OpenNMS 是被一些经验丰富的网络管理技术顾问开发出来的。HP 的 Openvew NNM 是一个很流行的商业软件，它能生产一个可定制化的网络监控图形。OpenNMS Screenshot\n","date":"2007-05-08T04:35:00Z","permalink":"https://martinliu.cn/2007/05/08/opennms-faqs/","title":"OpenNMS常问问题All-in-One"},{"content":" GLPI 是一个法国的开源项目，之所会了解到这个项目，是由于 OCSNG 的原因。当我安装并使用了一下它之后立刻产生了以下问题：1）它仅仅是一个对现有设备 Inventory 的工具，对新设备的采购和计划无法实现。2）它仅仅是一个技术工具，能提供 CMDB 相关的配置信息数据，相关的流程如何实现：计划，采购，使用，变更和报废。没想到在安装试用了 GLPI 之后着一切都疑问都散去了。那就先讲讲安装过程。环境准备，我的测是环境如下：Dell Inspiron 600M 笔记本（70GB HD, 1GB RAM），由于硬件资源实在有限，所以我喜欢使用 VMWare 作为测试环境。在 VMWere 中安装 SuSE 10.1，最小安装；安装 apache,perl,php,mysql 和其它相关的包，由于 Yast 的包管理实在好用，所以为整个安装过程带来了很多方便。如果您也想测试的这个软件系统的话，最简单的方式则是：找一个物理的机器做 SuSE 10.1 的全安装，这样的安装过程绝对不会有找不到那些依赖组建的问题。软件安装：OCSNG / GLPI 的安装模式都是相同的基本相似的比较简单；再次就不多话了；我猜您可能会碰到的问题有：GLPI 的登陆用户名和密码的问题。所有可以利用的相关文档里好像没用提到这个信息，昏！可能是我的运气不好，的确没找到，不过最终被我猜到：）[登录密码在安装向导的导数第二个页面上]OCSNG 需要安装 Agent，Agent 会在目标设备上做清单扫描，上传 Inventory 信息；它的三层结构可能会是企业级用户的好消息，它还能方便的通过 Windows 域的组策略部署代理，也就是说只要用户登陆域，代理就能顺利安装部署。OCSNG 趋向做全面的客户端管理：inventory、license 管理等方面。从上面的 GPLI 的 screenshot 可以看出和一个笔记本电脑相关的一切。先讲讲它的来由，GPLI 解决的是 OCSNG 的上层问题：计划，购买，部署，跟踪，变更，维护，退休。它管理的是所有业务和流程层面的东西。GPLI 的数据来自 OSCNG 的数据库，它能自动从 OSCNG 中定期更新 inventory 信息。截屏中的电脑是我在我的笔记本上安装了 OSCNG 后，做的首次扫描后的结果，在 GPLI 中配置了和 OSCNG 的集成后，它就变成了一个 GPLI 中的管理数据。可以看到，和一个电脑资产相关的所有硬件信息，软件信息，help desk 请求，文档，链接，注释和变更历史记录等。GPLI 中有对外的 HelpDesk 模块，这能方便最终用户对设备维护的请求。GPLI 和 OSCNG 很好的结合可能做到“IT 资源生命周期管理”，参考文档：http://glpi-project.org/wiki/doku.php?id=en:cyclevie如果对把它们所实现的功能和 ITIL 框架对应一下，或许 IT 服务财务管理，能力管理，配置管理和发布管理等流程能与之能有某些联系。\n","date":"2007-04-30T03:49:00Z","permalink":"https://martinliu.cn/2007/04/30/glpi-it-asset-mgmt/","title":"GLPI –IT资源生命周期管理"},{"content":"最近在网上又发现了一个不错的开源软件，这就是 OCSNG 资产管理软件。他能提供非常好的 Inventory 功能，发现并、更新计算机系统上的软硬件清单信息。下面是从他们的网站上找到特色介绍的信息：\nRelevant inventory 资产清单管理. Powerfull deployment system 强大的部署系统，代理程序软件部署方便宜用。. Web Administration Console 基于Web的管理控制界面. Multiple operating systems support,多操作系统支持 Microsoft Windows, Linux, *BSD, Sun Solaris, IBM AIX, HP-UX, MacOS X. Lightweight bandwith usage: 轻量网络带宽使用，Windows系统的全部清单信息大约5 KB . High performance: 高性能，1 000 000 电脑每天做清单扫描，使用的服务器是bi-Xeon 3 GHz /4 GB RAM. 3-Tier architecture 三层架构设计，支持http/https/xml等协议河标准. 基于有名的开源产品实现， Apache web 服务器, MySQL 数据库服务器, PHP 和 PERL 脚本语言. Web service 提供 SOAP 接口的Web服务访问. Plugins support 通过API提供插件支持. Used with a IT and Asset Management Software such as open source tool GLPI, you will have a powerfull inventory and asset management software with automatic updates of computer configuration, license management, help desk and more.根据ITIL的定义，CMDB是配置管理的主要数据库；其它相关的流程也非常依赖配置数据库；CMDB不一定是一个物理的数据库，它可以是一套数据库的集合。OCSNG能为CMDB提供有效的数据信息。 ","date":"2007-04-29T09:26:00Z","permalink":"https://martinliu.cn/2007/04/29/ocsng-it-asset-management/","title":"OCSNG － IT资产管理软件"},{"content":"Nmap (“Network Mapper(网络映射器)”) 是一款开放源代码的 网络探测和安全审核的工具。它的设计目标是快速地扫描大型网络，当然用它扫描单个 主机也没有问题。Nmap 以新颖的方式使用原始 IP 报文来发现网络上有哪些主机，那些 主机提供什么服务(应用程序名和版本)，那些服务运行在什么操作系统(包括版本信息)， 它们使用什么类型的报文过滤器/防火墙，以及一堆其它功能。虽然 Nmap 通常用于安全审核， 许多系统管理员和网络管理员也用它来做一些日常的工作，比如查看整个网络的信息， 管理服务升级计划，以及监视主机和服务的运行。Nmap 输出的是扫描目标的列表，以及每个目标的补充信息，至于是哪些信息则依赖于所使用的选项。 “所感兴趣的端口表格”是其中的关键。那张表列出端口号，协议，服务名称和状态。状态可能是 open(开放的)，filtered(被过滤的)， closed(关闭的)，或者 unfiltered(未被过滤的)。 Open(开放的)意味着目标机器上的应用程序正在该端口监听连接/报文。 filtered(被过滤的) 意味着防火墙，过滤器或者其它网络障碍阻止了该端口被访问，Nmap 无法得知 它是 open(开放的) 还是 closed(关闭的)。 closed(关闭的) 端口没有应用程序在它上面监听，但是他们随时可能开放。 当端口对 Nmap 的探测做出响应，但是 Nmap 无法确定它们是关闭还是开放时，这些端口就被认为是 unfiltered(未被过滤的) 如果 Nmap 报告状态组合 openfiltered 和 closedfiltered 时，那说明 Nmap 无法确定该端口处于两个状态中的哪一个状态。 当要求进行版本探测时，端口表也可以包含软件的版本信息。当要求进行 IP 协议扫描时 (-sO)，Nmap 提供关于所支持的 IP 协议而不是正在监听的端口的信息。除了所感兴趣的端口表，Nmap 还能提供关于目标机的进一步信息，包括反向域名，操作系统猜测，设备类型，和 MAC 地址。摘自：nmap 中文文档 nmap 首页\n","date":"2007-04-28T11:43:00Z","permalink":"https://martinliu.cn/2007/04/28/nmap-network-mappe/","title":"Nmap — Network Mapper(网络映射器)"},{"content":"Per-install Checklist:\nSuSE 10.1 Linux install CD OpenNMS rpm packages for SuSE Linux JDK 1.5 package Tomcat 5.5.20 package Here we go: Insert install CD into Cd/Dvd rom Do SuSE Linux mini install Logon in OS, run \u0026lsquo;yast firewall\u0026rsquo; to open 8080 tcp port on firewall upload all packages to /opt untar JDK untar Tomcat install postgresql through yast; run \u0026lsquo;rcpostgresql start\u0026rsquo; Export some variables export JAVA_HOME=/opt/jdk1.5.0_09export OPENNMS_HOME=/opt/opennmsexport CATALINA_HOME=/opt/apache-tomcat-5.5.20export PATH=$PATH:$JAVA_HOME/bin Test Java and Tomcat java -version$CATALINA_HOME/bin/startup.sh Modify this file, vi /var/lib/pgsql/data/pg_hba.conf , then run \u0026lsquo;rcpostgresql restart\u0026rsquo; #local all all ident sameuserlocal all all trusthost all all 127.0.0.1 255.255.255.255 trusthost all all ::1 ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff trust install OpenNMS rpm packages; rpm -ivh xxx.rpm $OPENNMS_HOME/bin/runjava -s $OPENNMS_HOME/bin/install -dis $OPENNMS_HOME/bin/install -y -w $CATALINA_HOME/conf/Catalina/localhost restart Tomcat start OpenNMS; $OPENNMS_HOME/bin/opennms start Check opennms status; $OPENNMS_HOME/bin/opennms -v status login web console 以上仅仅是我一个偷懒的方法，可以比较快的部署运行OpenNMS。这种方式的好处如下： Mini安装可以是最快的安装，总共只有几百MB就得到一个Linux操作系统 SuSE的包管理比较好用，配合一张安装DVD，几乎所有软件招之即来，不需要下载任何东西 Java和Tomcat的安装包是从以前的机器上直接把安装目录tar出来的，这也直接解压来用速度比较快。 这个安装方式的缺点： 并不是最优的安装，没用设置服务的自动重启 没用优化PostgreSQL 没用优化Java和Tomcat；ONMS是java应用，性能可能会是个问题 没用对ONMS做任何配置 Post-install Checklist:Change Admin password for ONMScustomize ONMS per your requirementsoptimize Tomcat/Postgresql/ONMS configuration ","date":"2007-04-26T10:47:00Z","permalink":"https://martinliu.cn/2007/04/26/opennms-install-sample/","title":"OpenNMS 安装说明－精简版"},{"content":"从来没用这么期待过一个软件的问世，虽然工具和技术不能画等号，不过它应该是第一个主动与 ITIL 看起，并且靠拢的开源软件。1 下载安装需要下载的软件是 OTRS 2.2.0 BETA2 和 OTRS:ITIL 1.0；后者只是一个压缩包，它包含了所有 ITIL 相关的软件包。此次安装并不顺利，归咎于很多 Apach 上 perl 的配置；安装之后的问题多是其它依赖的软件包不全造成的。2 CMDB说不上它是一个很好的 CMDB，不过用起来到是很方便。在 Admin 里把所有 CI 的类都建立出来后，相关的工作人员就能登陆上来，把相关的 CI 添加尽量。你需要从车轮开始做起，在这里可以说是非常适用，它不想商业软件内置了一堆的预定义的东西。CI 直接的联系关系也可以得到表达。3 其它功能试用中待续\n","date":"2007-04-23T10:51:00Z","permalink":"https://martinliu.cn/2007/04/23/otrs-itil-compatible/","title":"OTRS的第一个ITIL兼容版本"},{"content":"想实现 IT 与业务融合的目标吗？想让 IT 部门踏上自我管理之路吗？想在 IT 规范的丛林里找到清晰的管理思路吗？在 IT 与业务战略融合的过程之中，ITIL（IT 基础设施库）和 ITSM（IT 服务管理）规范将为企业用户提供实现诸多 IT 与业务管理目标的真实路径。1989 年，英国政府商务部在发现企业对 IT 提供服务和自我管理的方式存在混乱认识的问题后，发布了长达 44 卷的 ITIL 规范。目前所实行的第二版于 2001 年发布，容量减至 9 卷。而最新的消息显示，ITIL 第三版本有望于 2007 年 4 月正式发布。在 ITIL 诞生并成长的 10 余年间，ITIL 及 ITSM 理念都经历了巨大的变化和发展，并有望在 ISO 20000 中成为全球标准。目前的 ITIL 既是一个词汇库，也是一系列旨在概括性描述 IT 最佳实践的概念性流程。对企业而言，要使 IT 更有效地实现自我组织和自我管理，兑现 ITIL 对于管理的承诺，是一项足以用“浩大”二字形容的工程。所以，您需要先确定一个起点，并了解目前与 ITIL 有关的 10 项核心内容。** 1. 我能够通过 ITIL 实现哪些过去无法实现的目标吗？如果实施得当，ITIL 可以提高客户满意度、减少 IT 部门中的浪费，并降低运营成本。下面是两个简单的案例：● 在 2000 年，Caterpillar 公司的 IT 部门解决 Web 事件的目标响应时间是 30 分钟，但是该部门达到这一目标的几率只有 30%。实施 ITIL 后，其 IT 供应商达到该响应目标时间的几率提升至 90%，而 Caterpillar 在过去 5 年实现了业务的几何级增长，IT 预算只上升了 1%。● 两年前，Liberty Mutual 的 IT 管理员只有在用户打投诉电话后才能发现某个关键网络应用已停止工作。部署 ITIL 后，管理员可以在故障发生前对应用的运行速度和异常活动进行监视，并且通常可在用户感觉到异样之前解决问题。2. 是否需要通读 ITIL 全部 9 卷的内容，哪些是重点章节？《服务支持》和《服务交付》这两卷包含了 ITIL 的核心知识，其他几卷都是补充性的。《服务支持》卷介绍了 5 个关键流程：即事件管理、问题管理、变更管理、发布管理和配置管理。尽管服务桌面被认为是一项功能，而非流程，但它仍被包含其中，并且被认为是 IT 服务的客户报告事件、发出请求和与 IT 基础设施与业务部门进行沟通的重要接触点。事件管理的主要内容是，在发生事件（例如服务器崩溃）后尽可能快速地恢复正常的业务运营。问题管理将注意力集中在查找和消除事件的根源，防止其死灰复燃。ITIL 的独特能力是它可以将“事件”与“问题”隔离开来。通常，支持人员在查找事件的根源时，IT 部门的支持服务就会暂时处于停顿状态。ITIL 优先考虑的是为业务部门提供服务，其次才是在后台修复问题的根源。变更管理是协调和控制 IT 基础设施自身变化的过程。ITIL 将其视作实现适当批准、授权和质量保证步骤的一项协调工作。发布管理指的是 IT 变更的实际实施，包括人员、流程、技术、培训、推广、沟通和业务领域活动，以及设计的建立、测试和变更发布等内容。对大多数 IT 运营活动而言，将各种变更打包为发布单元，可以有效地降低业务所受到的影响。配置管理包括日志记录、跟踪、控制和验证基础设施信息的过程，这些信息用于描述 IT 基础设施中的每一个组件，以及各个组件之间的关系。这一过程的重点是这些项目，即所谓的 CI（配置项）之间的相互关系。所有这些信息都保存在一个逻辑 CMDB（配置管理数据库）中。3. CMDB 到底有多重要？CMDB 是建设整个 IT 基础设施的蓝图，它描述各个配置项（CI），包括硬件、软件、事件、协议、服务水平、文档等之间的相互关系，同时还用于描述整个元系统（metasystem）的工作情况。CMDB 已经成为迅速查找 IT 基础设施信息的基础，同时也是实现有效管理决策的基础。在理想条件下，每个 CI 都有各自的可配置属性。如果可能，CMDB 应该能够自动发现 CI 的相关信息，并在发生变化时对其进行跟踪，从而将维护配置项所需要的管理工作量降至最低。4.《服务交付》卷关注哪些内容，重要性如何？《服务交付》卷关注的是 IT 服务的交付和增强方式，该卷重点强调了 5 个关键的流程：即服务水平管理、可用性管理、容量管理、IT 服务连续性管理和 IT 财务管理。服务水平管理涉及 SLA（服务水平协议）的规划、协调、监视和报告。它会以连续的方式对服务进行评估，确保这些服务能够以高性价比的方式交付，同时还要满足用户的服务目标。可用性管理负责协调、设计、测量和管理 IT 基础设施的可用性，并会综合考虑基础设施和支持机构的各方面情况。它可以协调和集成各个松散结合的“孤岛”，确保 IT 能够按照必要的水平和成本提供所需的服务。这一过程会将一些关键原则结合在一起，其中包括每种服务的可靠性、可服务性、可管理性、安全性和响应性。容量管理考虑的是适应业务工作量和业务目标的 IT 容量、性能和吞吐量。从历史上看，大多数 IT 部门都会根据 IT 资源的使用方式来管理容量。ITIL 则要求 IT 部门首先了解容量的业务驱动需求，并在将其实施到 IT 基础设施之前，通过建模和预测发展将其转化为服务工作量。IT 服务连续性管理可以确保 IT 服务能够在发生重大灾难时得到恢复。它引入了关键业务功能概念，迫使 IT 部门将注意力放在服务的恢复上，不再仅仅关注技术的修复。IT 财务管理可以提供 IT 成本和支出管理所需的预算、会计和收费服务。IT 部门通常不了解其提供 IT 服务所发生的成本，这也是其总被公司董事会质疑的原因之一。IT 部门必须开发出一种能力，来明确说明 IT 服务成本以及 IT 部门的贡献，IT 财务管理将赋予他们这样的能力。 ITIL 强调其参与业务活动的具体方法，这方面，服务台意义重大。在典型的业务部门中，业务用户和客户每天都会与服务台建立联系，而且这已经成为服务支持工作流程的一个必要组成部分。同时，行政和管理部门也需要与服务水平管理过程建立接口，从而实现新服务的部署，并调查服务提供工作流程所使用的服务质量。5. 其他 7 卷的作用和意义？在理解了基本概念后，您会对其余的 7 卷有更多的了解。例如，《ITIL 简介》介绍了构成 ITIL 服务管理的基本概念；《实施 ITIL 服务的规划》解释了某个部门通过 ITIL 获得帮助的一些必要步骤；《ICT 基础设施管理》涉及了一些关键问题，比如网络服务管理、运营管理、计算机安装和验收等；《应用管理》重点讨论了软件开发和支持周期，对要求和 IT 服务的测试进行了定义。 《业务展望》卷事实上是两本书，一本面向 IT 人员，另外一本适用于商业经理。这两本书讨论了业务连续性管理、伙伴关系、外包、生存几率、以及剧烈变化过程中随机应变的业务实践。《安全管理》以 ITIL 的视角对各项安全规范和标准进行了讨论。最后一本是《软件资产管理》，它提供了管理软件和软件授权的最佳实践。 6. 为什么在美国的部署远远落后于欧洲？美国在 IT 基础设施管理的规范化方面一直落后于欧洲。最近美国开始重视 ITIL 的原因之一是，许多在美国经营的欧洲和亚洲企业都在呼吁：在更大范围内让 IT 运营符合 ITIL 的要求。另外，很多美国企业发现，有超过 2/3 的 IT 预算被全新的、不可任意支配的运营成本所吞噬，而它们对此根本没有任何控制能力。 ITIL 将改变这一现状，它可以针对具体的商业目标实施连续的小型项目，而且所有结果都是可测量的。典型的目标包括缩减 IT 成本、减少服务中断、为重大 IT 计划或商业变化做好准备，比方说企业兼并、搬迁或收购。 7. 除大型企业外，还有哪些企业需要 ITIL？小型企业或个人是否也可使用 ITIL？任何为企业提供 IT 服务的部门和/或为企业客户提供服务的部门都能从 ITIL 中受益。 例如，一家小型企业面临着网络经常中断的困扰，那么这家企业可以使用 ITIL 的问题管理流程来改善其网络环境。如果一家中型企业的 IT 基础设施非常复杂，那么这家企业就可以利用 ITIL 的配置管理解决方案，针对各类变更和新应用进行优化与评估，并为其实施绘制蓝图。8. 在对 ITIL 有了充分了解的前提下，该如何启动 ITIL 呢?首先要接受培训并获得认证。几乎所有的大型硬件/软件厂商和一些中小型企业都可以提供 ITIL 培训。您可以在网上搜索相关的 ITIL 培训机构。完成培训后，您需要利用书本、网络研讨会、图书馆材料和在线资源填补您的知识空白。比较好的 ITIL 资源包括：IT Service Success（itServiceSuccess.com）、服务水平管理（slminfo.org）和 ITSM Watch（itsmwatch.com），以及美国 IT 服务管理论坛中主要的用户组站点（itsmfusa.org）。9. 是否应该聘用一些人员做 ITIL 实施？许多公司都提供 ITIL 咨询和实施服务，但这只是采用曲线中最初级的部分。目前的市场中尚不存在所谓的领导型企业。您可以根据他人的经验来选择适当的服务商。 ITIL 告诉了我们“要做什么”，但有关“怎么做”的问题却涉及较少。目前，ITIL 被称为“IT 部门的 ERP”，它需要结合企业自身情况将人员、流程和工具相互融合。因此，ITIL 要在企业成功实施首先需要领导的积极推动，同时必须在企业中结合角色设置流程经理来落实设计的流程。在推动的过程中，企业应当考虑聘用顾问协助实施，让企业员工对 ITIL 有更为深刻的理解和认识，这对整个项目的成功帮助极大。 10. ISO 20000 与 ITIL 的关系是什么？ **ITIL 主要是一些流程，它并不提供任何衡量标准。而最近发布的 ISO 20000 是评测 IT 服务管理和改善 IT 服务的基础。它定义了针对服务商的要求，并且帮助您确定自己的工作是否符合可接受的 IT 服务管理标准。ISO 20000 可以提供具体、可测量的标准，能够用于对范围、定义条款、规划和实施服务管理、管理系统要求、全新或变更服务规划及实施、服务提供过程、关系过程、控制过程、决议过程和发布过程等领域进行审查。ITIL 资源站点■ 国外站点：\nPink Elephant (www.pinkelephant.com) 澳大利亚ITSM/ITIL权威研究咨询机构 NAI (www.nouriassociates.com) 美国ITSM/ITIL HDI (www.thinkhdi.com) 美国帮助台协会官方网站 ITSMF (www.itsmf) ITIL推广专业协会itSMF组织网站 ITIL官方网站 (www.itil.co.uk) ITSM门户网站 en.itsmportal.net ■ 国内网站： ITSM/ITIL专业论坛 www.simaone.org ","date":"2007-03-31T08:56:00Z","permalink":"https://martinliu.cn/2007/03/31/itil-faqs/","title":"[转] 十问ITIL"},{"content":"安装方法：最简单的安装方法应该是从 Linux 的安装光盘中安装，因为它比较小只有 2 ～ 3MB；很多 Linux 都包含这个软件。在 SuSE Linux 10.1 中可以找到 ntop-3.2-17。配置使用：安装之后参考说明文档做首次初始化运行，如果是通过 rpm 从 Linux 光盘中安装；相关的系统服务也已经帮你安装。在 SuSE 里运行 rcntop start 就可以启动后台进程。访问 ntop 的界面http://myserver:3000/。Tips：ntop 会吃掉比较多的内存资源，不建议在生产机上安装。它工作在第二层，采用实时抓包的方式；ntop 像是网络探针来捕获和分析网络活动，产生一些分析报表，部署时需要考虑它的部署位置。于其它系统的集成：该系统界面的访问比较的直接，没有用户认证过程。所有报表和分析结果的按两个方式保存和呈现：host 和协议。它通过 rdd 存储数据，通过 web 页面展示图片；本身不需要依赖 web server。准备尝试把它集成到 Nagios 和 OpenNMS 中。ntop 的英文说明From: http://www.ntop.org/Monitoring.htmlNTOP is helpful as an \u0026ldquo;emergency\u0026rdquo; tool. When you are experiencing response time delays or you suspect that something is wrong with your network, NTOP allows you to easily monitor the protocols running on your LAN and to determine the utilization of each.NTOP comes very well when suspicious behavior is found on your network. Suppose you have a set of local clients accessing a database on your LAN. They claim that time response is very poor. You embark on a search to determine who or what is to blame. You generally have 2 options: the application or the network. You ask the application engineer(s) to determine that the application is OK. They determine that it is. You move on to the network engineers who come to find out that you have a very high retransmission packet rate caused by the server\u0026rsquo;s faulty network card (a problem to be detected by the sysadmin using standard linux/unix commands). In a situation like this, it is likely that they were able to determine this by using a tool like NTOP. Without the help of NTOP and similar tools, finding the cause of the problem could have been extremely tedious.Some very useful sections of NTOP include:\u0026lsquo;Active TCP Sessions\u0026quot; - shows what is taking place on your network at that specific moment. For example:Client Server Data Sent Data Rcvd Active Since Last Seen Duration123.231.213.1 mail_server 3.6 MB 3.8 MB 12/08/99 19:40:01 12/20/99 20:47:31 12 day(s) 1:07:02All this information can be accessed using any standard web browser. To have enough information to work on, you may wish to run NTOP for at least a couple of days (non-stop) in a production environment. (This may vary depending on the size of your network. For a medium departmental LAN, a couple of days should be fine).\u0026lsquo;Connection Matrix\u0026rsquo; - shows which station is talking to whatserver and the amount of traffic being exchangedMonitoring of the most intensive bandwidth senders and receivers - Heavy traffic is not only caused by physical media but also by other system intensive actions (e.g. users downloading large files). This can cause severe bottlenecks to your LAN.The NTOP data presentation is impressive. Bar and Pie charts are used to demonstrate protocol utilization and packet size distribution. Data gathered from the monitoring can be logged in a file for posterior plotting using any spreadsheet application such as Sun\u0026rsquo;s Star Office. If you want to keep all of the information stored for future structured retrieval, NTOP gives you the option to store it in a SQL database.\n","date":"2007-03-21T04:09:00Z","permalink":"https://martinliu.cn/2007/03/21/ntop-web-based-network-traffic-monitor/","title":"ntop ~ Web-based network traffic monitor"},{"content":"GroundWork rpm 安装对系统造成的改变有：\n/etc/init.d/apache2 被改名为 apache2-save 导致，以前的Apache不能启动 会在/etc/ld.so.conf中加入一行/usr/local/groundwork/lib ；不知道为什么这会导致一下系统的服务不能正常运行，如：PostgreSQL和snmpd。修复方法是注释掉这一行，然后运ldconfig命令。还不知道GroundWork在没有这一行的情况下有什么问题，注释掉之后好像它还是能正常运行的。 ","date":"2007-02-28T09:14:00Z","permalink":"https://martinliu.cn/2007/02/28/groundwork-rpm-error/","title":"GroundWork rpm 安装会导致原系统的一些改变"},{"content":"为了节省服务器，我们可能不得不把所有的监控以及相关的系统都安装到一个物理的机器上。如果是从原代码安装，我相信一定有很多选项能避免它们之间的冲突。假如你是后安装的 GroundWork，它会更改系统默认的 Apache2 的配置，导致以前安装的所有的 Web 应用都不能用。在我的测试机上，先安装的 OTRS，rpm 安装，后安装的 GroundWork，也是 rpm 安装。GroundWork 安装之后，OTRS 不能登陆。根据 GroundWork 的一些文档我做了，如下的修复步骤。1）vi /etc/apache2/conf.d/otrs.conf 可以看到如下 OTRS 的 web 配置信息。# \u0026ndash;# added for OTRS (http://otrs.org/)# \u0026ndash;# agent, admin and customer frontendScriptAlias /otrs/ \u0026ldquo;/opt/otrs/bin/cgi-bin/\u0026ldquo;Alias /otrs-web/ \u0026ldquo;/opt/otrs/var/httpd/htdocs/\u0026rdquo;# load all otrs modulesPerlrequire /opt/otrs/scripts/apache2-perl-startup.pl# Apache::Reload - Reload Perl Modules when Changed on DiskPerlModule Apache2::ReloadPerlInitHandler Apache2::ReloadPerlModule Apache2::RequestRec# set mod_perl2 options# ErrorDocument 403 /otrs/customer.pl ErrorDocument 403 /otrs/index.pl SetHandler perl-script PerlResponseHandler ModPerl::Registry Options +ExecCGI PerlOptions +ParseHeaders PerlOptions +SetupEnv Order allow,deny Allow from all# directory settings AllowOverride None Options +ExecCGI -Includes Order allow,deny Allow from all AllowOverride None Order allow,deny Allow from all# MaxRequestsPerChild (so no apache child will be to big!)MaxRequestsPerChild 4002）在 GroundWork 的主目录下其实也有一个 Apache 目录，它是原系统 Apache 的替代品。进入这个目录。3）vi conf/httpd.conf 把 otrs.conf 文件中所有的内容都粘贴到这个文件中4）GroundWork 的 apache 好像没用用到 perl 模块，需要加入 perl 模块的支持；找到有很多“LoadModule”的地方加入下面这一行LoadModule perl_module modules/mod_perl.so5）Copy 系统中的 mod_perl.so 文件到/usr/local/groundwork/apache2/modules6）重新启动 gwhttpd 服务，也就是 GroundWork 系统的 web 服务7）访问 OTRS 系统 http://ip/otrs/customer.pl 成功。下面需要做的是把 OTRS 的登陆也集成到 GroundWork 的单点登陆当中；如果在能把 GroundWork 的报警也自动的集成到 OTRS 那就是完美了，欲知后事如何，且听下回分解。：）\n","date":"2007-02-27T09:40:00Z","permalink":"https://martinliu.cn/2007/02/27/groundwork-and-otrs/","title":"GroundWork和OTRS系统的集成问题"},{"content":"下个月就 OTRS::ITSM 1.0 Beta1 就发布了。OTRS 是一不错的开源的帮助台程序。之所以说它还不错是由于以下几点：\n能支持平台非常广。操作系统有Linux、Unix还有Windows；数据库有MySQL，PostgreSQL，Oracle和SQL Server。这些东西里多一个东西，多于商业软件来讲测试的工作量起码就要乘二。 安装和配置是相当的简单。我用的是SuSE Linux，是用RPM包安装，整个安装配置过程只需要10分钟。 支持多语言，目前能支持的语言有10几种，包括简繁体中文。 纯Web操作界面，Web界面可以定制；很好的邮件系统集成。有问题单生成接口，能够将第三方网络系统监控的故障告警变成问题单，再自动分配到相关的维护组。 从它的名字可以看出，他是一个“开放式问题单系统”或者说是“帮助台”“Help Desk” “工单跟踪系统”。一个单纯的问题单系统本身到没有什么特殊，不过能做到像OTRS这样像ITIL靠拢，试图做成一个遵从ITIL的开源IT服务管理解决方案的，可真的是不容易了。在看看其它的Help Desk的开源项目，都是在简单的在实现“问题管理”这个功能而已。OTRS现在最新的版本是otrs-2.1.5-01，等2.2正式发布后，OTRS::ITSM 1.0 就作为其中的一个模块也发布了。其实做到一个真真ITIL兼容的帮助台还真的不容易，我将期待它的CMDB，变更管理，以及各个流程之间的衔接。登陆这个OTRS的Demo系统来看看它到底怎么样，Check it out！！Agent/Admin Interface:http://demo.otrs.org/Customer Interface:http://customer.otrs.org/FAQ Public Interface:http://faq.otrs.org/Email:demo@otrs.orgSystem:Intel(R) Celeron(R) CPU (2 GHz) with 256 MB RAM and an IDE harddrive (current tickets ~55.000 - 2005-05-02) ","date":"2007-02-26T07:19:00Z","permalink":"https://martinliu.cn/2007/02/26/otrsitsm-itil/","title":"OTRS::ITSM期待中的开源ITIL工具"},{"content":"如果你用过 Nagios 的话，它的 2D、3D Map 一定会给你留下一些印象；2D Map 的确能比较试用一点，不过看上去还是挺难看的。NagVis 就是看到了这一点，它力求能让各种状态信息表达的更炫，更好看；它可以说是 Nagios 的一个不错的插件，直接 copy 到 Nagios 的相关目录下，配置一下就行了。它的效果如下图所示：说的在玄虚一点它可以是一个“业务流程管理视图”[CA Unicenter 中的名词，OpenView 里也有类似的概念]。其实就是把原子的监控对象：被监控节点和节点上的服务；和业务系统或者 IT 的逻辑关系相结合起来。例如：我的业务系统 A 的其中一个数据库服务器的数据库进程停了，这个可以影响到所有物理包含或者逻辑包含它的对象的状态。NagVis 试图用漂亮的图标来表达这些状态和关系，是管理者能看的更加直观。\n","date":"2007-02-25T03:09:00Z","permalink":"https://martinliu.cn/2007/02/25/nagios-nagvis/","title":"Nagios华丽的外衣NagVis"},{"content":"\n_RTT(Round-Trip Time) _\n简单说它是一个数据报在网络上两点中间往返一次的时间。是影响 TCP 性能和表征网络运行状况的重要参数。在网络中实时、准确地测量大量 TCP 设备和系统的 RTT 参数是网络管的重要环节之一。Smokeping 就是这样的自动测试系统，它向目标设备和系统发送各种类型的测试数据包，测量、记录和展示 RTT。\n_Median RTT _**中间数**\n它是中间数并不是平均值。Smokeping 有多种类型的探针，探针在默认的设置下，每 300 秒向目标设备发送 20 测探测数据包。假如这 20 个数据包都返回的话，它就记录下了 20 个 RTT，那么 Median RTT 就是第十个包的 RTT；如果有 5 个包丢失的话，那么 Median RTT 就是第八个返回的包的 RTT 值。\n_Avg RTT _**评价值**\n它是每一个测试回合中所有 RTT 的算术评价值。\nAvg pkt loss\n它是丢包率。\n上图中测试的三个服务器，是用默认的 FPing 探针探测该服务器是否在线。Smokeping 就装在 OpenNMS 上，可以看出它的 RTT 最小；奇怪的是它的丢包率却是最大。其它的，一个是美国的一个 Web 服务器，另一个是美国的 Exchange 邮件服务器。\nLast 3 Hours 最近的 3 小时\n*Median Ping RTT （__506.2 ms avg）*中间数的平均值是 5.6.2 毫秒。如果是绿色的短横线，说明一个 300 秒的周期内所有的包都返回都有 RTT 的时间记录下来；如果是蓝色的短横线则说明有 2 个包丢失。\n*Packet Loss：*丢包率。从上图中我们看出全都是绿线，所以丢包率当然是 0。\nProbe：__10 HTTP pings using echoping(1) every 300 seconds\n这张图是 2007-1-11 12:00:05 生成的。每一个绿色的短横线都是一个测试回合 300 秒内用 echoping 测试 HTTP 协议 10 次。绿色画出的是中间数的位置，一个回合中的其它值都在它附近被以灰度的形式被刻画；灰度的范围越小越好，灰色的范围像是烟雾一样笼罩在中间数附近。在中间数附近的烟越小越好，说明网络很平稳。RTT 曲线的起伏还显示了网络的负载情况。\n点击这里看一个网上的 Demo\nupdate : 2008-1-18\n现在 OpenNMS 把 smokeping 集成了，你可以在 OpenNMS 中配置使用这个功能。\n","date":"2007-02-15T08:45:00Z","permalink":"https://martinliu.cn/2007/02/15/smokeping-chart/","title":"如何看懂Smokeping图表"},{"content":"全文在＝》China OpenNMS \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;我们已经在一个中等规模的企业实施了 Nagios，用来监控一堆 Cisco 设备：交换机、路由器、防火墙，还有各种类型的服务器（Windows,Linux 和 Unix）。对我们来说 Nagios 工作的非常好。我们现在看 OpenNMS，是由于她有好看的用户界面和集成的服务资源图。我喜欢 Nagios 是由于它的模块化。我能很容易的写一个插件来完成任何相关的事情。我看到 OpenNMS 有 NRPE 和 NSCLIENT 的能力，但是有一些邮件和资源图不能彻底的采集到。有人正打算用 OpenNMS 作为 Nagios 或者其他软件的替代品？我的答案是非常确定的，可是我也非常想听到一些关于 OpenNMS 的成功或者不很成功的故事。我正在测试环境中使用的是 OpenNMS1.3.2。Thanks!Jon Christensen\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;我们也有一个和你类似的环境（路由器、交换机、各种服务器），目前有大约 250 个节点。使用一个 CentOS4 的服务器，我们已经在上面安装了 OpenNMS1.2.9，Syslog-NG，Swatch, Logtool(http://xjack.org/logtool/)，在 Windows 上用 Informant MIB，在几乎所有 Linux/Unix 上的是 NET-SNMP，和它们一起的还有很多在客户端的自定义脚本；它们中的大多数都使用 send-event.pl 或者和它无关。应为所有这些，我们已经能完全替代了 HP OpenView，虽然这是我的一面之词：这个架构是如此的模块化，以致于我们能做的比我们使用 OpenView 的还要多，因种种理由。Tim SelivanowNOC TechnicianEasyStreet Online Services, Inc.__我的个人观点：从 Nagios 转到 OpenNMS 上，其实不太容易。由于一下因素：1）Nagios 非常模块化，架构让人决定非常稳定可靠；它没有用到 Java。2）它的文档非常好，包括它官方的使用手册和用户上传的文档；从文档可以看出这个欧洲 Base 的项目非常踏实，风格严谨。开发 ONMS 的那帮老米显得比较自作聪明一点。3）Nagios 的论坛很好，有很多人可以互相帮助。\n","date":"2007-02-01T14:51:00Z","permalink":"https://martinliu.cn/2007/02/01/opennms-discuss-nagios/","title":"翻译[opennms-discuss]邮件组里的一个讨论“Nagios转变”"},{"content":"Cisco 是网络设备的老大，它的设备以稳定、成熟和高性能著称。很多用户都以自己的网络设备是 99％的 Cisco 设备而自豪。对于任何一个网络设备如果没有配置 SNMP 代理，就不能被任何管理工具管理。下面的这个连接就是关于如何配置 Cisco 的 SNMP 服务：http://www.cisco.com/univercd/cc/td/doc/product/software/ios122/122cgcr/ffun_c/fcfprt3/fcf014.htm可网管网络设备都内置有 SNMP 代理，很多网管不喜欢配置、enable SNMP 服务的理由如下：不希望 SNMP 服务占用 CPU、内存等资源；不信任 SNMP 服务的安全性；不认确认 SNMP 管理协议的价值。我个人认为：通过 SNMP 协议对网络设备管理的价值将远远高于它对设备造成的消耗和带来的风险。如果你同时面对和管理 30 台以上的网络设备，试想把它们的运行状况做一遍检查，您需要花的时间是多长。网络管理系统和网络设备的互动如下：\n网管系统主动定时读取MIB的值，存储和分析得到的数值，产生报表和报警事件。 网管系统被动作为网络设备发送Trap的目的地，网管系统需要能翻译各种网络设备的Trap信息的意义。 ","date":"2007-01-28T13:31:00Z","permalink":"https://martinliu.cn/2007/01/28/cisco-network-configure/","title":"Cisco网络设备如何配置SNMP代理"}]
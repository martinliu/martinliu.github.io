<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Terraform on Martin Liu's Blog</title><link>https://martinliu.cn/tags/terraform/</link><description>Recent content in Terraform on Martin Liu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Fri, 22 Aug 2025 08:18:35 +0800</lastBuildDate><atom:link href="https://martinliu.cn/tags/terraform/index.xml" rel="self" type="application/rss+xml"/><item><title>使用 Terraform、AWS 和 Python 构建无服务器实时数据管道</title><link>https://martinliu.cn/blog/building-a-serverless-real-time-data-pipeline-with-terraform-aws-and-python/</link><pubDate>Sat, 02 Aug 2025 15:42:33 +0800</pubDate><guid>https://martinliu.cn/blog/building-a-serverless-real-time-data-pipeline-with-terraform-aws-and-python/</guid><description>&lt;img src="https://martinliu.cn/blog/building-a-serverless-real-time-data-pipeline-with-terraform-aws-and-python/serverless-data-pipeline.png" alt="Featured image of post 使用 Terraform、AWS 和 Python 构建无服务器实时数据管道" />&lt;p>最近，我一直在利用业余时间学习和试验 AWS 的数据服务，发现它们非常引人入胜。&lt;/p>
&lt;p>在本文中，我们将探讨我是如何利用 AWS 服务（如 Data Catalog、DataBrew 和 DynamoDB）构建一个实时无服务器数据管道的，以及如何借助 Terraform 将其无缝部署到 AWS。&lt;/p>
&lt;p>无论您是数据工程领域的新手还是经验丰富的专家，本指南都将为您提供帮助！&lt;/p>
&lt;h2 id="前提条件">前提条件
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://aws.amazon.com/" target="_blank" rel="noopener"
>AWS&lt;/a> 账户&lt;/li>
&lt;li>&lt;a class="link" href="https://www.python.org/downloads/" target="_blank" rel="noopener"
>Python&lt;/a> 3&lt;/li>
&lt;li>&lt;a class="link" href="https://developer.hashicorp.com/terraform/install" target="_blank" rel="noopener"
>Terraform&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="为什么选择-terraform">为什么选择 Terraform
&lt;/h2>&lt;ul>
&lt;li>开源&lt;/li>
&lt;li>庞大的开发者社区&lt;/li>
&lt;li>不可变基础设施 (Immutable Infrastructure)&lt;/li>
&lt;li>IaC (Infrastructure as Code)&lt;/li>
&lt;li>云无关性 (Cloud agnostic)&lt;/li>
&lt;li>旨在提升我对新技术的了解&lt;/li>
&lt;/ul>
&lt;h2 id="项目结构">项目结构
&lt;/h2>&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*eEvDjru5qOJc73wpcie1Hw.png"
loading="lazy"
alt="项目结构"
>&lt;/p>
&lt;h2 id="概述">概述
&lt;/h2>&lt;p>我即不是数据工程师，也没有在构建数据管道项目中；但是，我最近接触了一些数据服务。结合我对 AWS 的普遍了解，我决定亲手探索一些新服务。&lt;/p>
&lt;p>本文源于我将构建数据管道作为一个有趣的项目来实践的经验，我发现整个过程非常有趣且富有成效。&lt;/p>
&lt;h2 id="使用到的关键服务">使用到的关键服务
&lt;/h2>&lt;h3 id="1-amazon-s3">1. Amazon S3
&lt;/h3>&lt;ul>
&lt;li>作为数据存储层。&lt;/li>
&lt;li>存储了项目中使用的 JSON 文件&lt;/li>
&lt;/ul>
&lt;h3 id="2-amazon-dynamodb">2. Amazon DynamoDB
&lt;/h3>&lt;ul>
&lt;li>作为数据库层。&lt;/li>
&lt;li>使用 DynamoDB 流 (DynamoDB streams) 和 AWS Lambda 将 JSON 数据从 DynamoDB 导出到 S3&lt;/li>
&lt;/ul>
&lt;h3 id="3-aws-glue">3. AWS Glue
&lt;/h3>&lt;ul>
&lt;li>负责数据提取、转换和加载 (ETL - Extraction, Transformation, and Loading)。&lt;/li>
&lt;li>使用 Glue Data Catalog 管理数据集的元数据 (metadata)。&lt;/li>
&lt;li>它还支持使用爬网程序 (crawler) 进行爬网，该程序自动发现架构 (schema) 并创建表；然而，在这个项目中，我们手动定义了架构，因此不需要此功能。&lt;/li>
&lt;/ul>
&lt;h3 id="4-amazon-databrew">4. Amazon DataBrew
&lt;/h3>&lt;ul>
&lt;li>用于转换 S3 中存储的数据，方法是删除重复条目。&lt;/li>
&lt;li>一旦项目放置在 S3 存储桶的路径 &lt;code>/data&lt;/code> 中，它就会作为触发作业（来自 Lambda）运行。&lt;/li>
&lt;li>指向 Glue Data Catalog 作为输入数据集。&lt;/li>
&lt;/ul>
&lt;h3 id="5-amazon-athena">5. Amazon Athena
&lt;/h3>&lt;ul>
&lt;li>使用标准 SQL 查询存储在 Glue Catalog 中的转换数据。&lt;/li>
&lt;li>完全无服务器，并与 Glue Data Catalog 集成。&lt;/li>
&lt;/ul>
&lt;h2 id="最终架构">最终架构
&lt;/h2>&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*0v_rLNRcapex3MRovi_luA.png"
loading="lazy"
alt="数据管道架构"
>&lt;/p>
&lt;h2 id="架构解释">架构解释
&lt;/h2>&lt;h3 id="第一流程">第一流程
&lt;/h3>&lt;ul>
&lt;li>一个 &lt;em>.json&lt;/em> 文件被添加到 S3 上的路径 &lt;code>/data&lt;/code>&lt;/li>
&lt;li>第一个 Glue 数据目录表 (Glue Catalog Table) 从 S3 的 &lt;code>/data&lt;/code> 路径读取数据&lt;/li>
&lt;li>上传到 &lt;code>/data&lt;/code> 会触发一个 Lambda 函数，该函数启动 DataBrew 转换作业，通过移除 &lt;code>email&lt;/code> 列中的任何重复行来清理第一个 Glue 数据目录表（输入数据集）中的数据&lt;/li>
&lt;li>DataBrew 作业将转换后的数据输出到 S3 中的新路径 &lt;code>/cleaned&lt;/code> 下，覆盖该路径中的其他项目以避免输出路径中出现重复&lt;/li>
&lt;li>第二个 Glue 数据目录表从 S3 的 &lt;code>/cleaned&lt;/code> 路径读取数据&lt;/li>
&lt;li>Athena 工作组 (workgroup) 从第二个 Glue 数据目录表读取数据并对其运行查询。这反过来又将查询结果存储在 S3 中的新输出位置 &lt;code>/athena-results/&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="第二流程">第二流程
&lt;/h3>&lt;ul>
&lt;li>一条数据被添加到 DynamoDB。&lt;/li>
&lt;li>随着新数据的增加，DynamoDB 流 (stream) 被触发&lt;/li>
&lt;li>连接到 DynamoDB 流的 Lambda 函数（用 Python 编写）被调用，它将新项目转换为 &lt;em>.json&lt;/em> 文件&lt;/li>
&lt;li>执行第一个流程中的所有步骤&lt;/li>
&lt;/ul>
&lt;p>总而言之，实时数据处理的目标是通过 DynamoDB Streams 和 S3 存储桶通知 (S3 Bucket Notification) 与 Lambda 的集成来实现的。&lt;/p>
&lt;h2 id="代码定义">代码定义
&lt;/h2>&lt;h2 id="maintf">main.tf
&lt;/h2>&lt;p>提供商 (Provider)：第一步通常是定义提供商。这里我们将云提供商定义为 &lt;em>aws&lt;/em>。&lt;/p>
&lt;p>此外，我们还包含了将在项目中使用的各种模块 (module)，并传入所有必需的变量。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-terraform" data-lang="terraform">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">terraform&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">required_providers&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">aws&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">source&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;hashicorp/aws&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;~&amp;gt; 5.0&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">required_version&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;gt;= 1.3.0&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-terraform" data-lang="terraform">&lt;span class="line">&lt;span class="cl">&lt;span class="kr">provider&lt;/span> &lt;span class="s2">&amp;#34;aws&amp;#34;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">region&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;us-east-1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>&lt;span class="nb">module&lt;/span> &lt;span class="s2">&amp;#34;s3_bucket&amp;#34;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">source&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;./modules/s3&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">bucket_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;upload-bucket-data-pipeline-234&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>&lt;span class="nb">module&lt;/span> &lt;span class="s2">&amp;#34;dynamodb_table&amp;#34;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">source&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;./modules/dynamodb&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">table_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;dynamodb-table&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>&lt;span class="nb">module&lt;/span> &lt;span class="s2">&amp;#34;lambda_function&amp;#34;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">source&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;./modules/lambda&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">lambda_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;dynamodb_to_s3&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">handler_trigger&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;dynamodb_to_s3_trigger.lambda_handler&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">s3_bucket&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">module&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">s3_bucket&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">bucket_name&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">table_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">module&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">dynamodb_table&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">table_name&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">dynamodb_stream_arn&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">module&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">dynamodb_table&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">stream_arn&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>&lt;span class="nb">module&lt;/span> &lt;span class="s2">&amp;#34;glue_catalog&amp;#34;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">source&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;./modules/glue/glue_raw&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">database_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;catalog_db&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">table_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;catalog_json_table&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">s3_location&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;s3://&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nb">module&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">s3_bucket&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">bucket_name&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">/data/&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>&lt;span class="nb">module&lt;/span> &lt;span class="s2">&amp;#34;databrew&amp;#34;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">source&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;./modules/databrew&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">glue_table&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">module&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">glue_catalog&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">table_name&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">glue_db&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">module&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">glue_catalog&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">database_name&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">s3_bucket_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">module&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">s3_bucket&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">bucket_name&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">data_zip&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">module&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">lambda_function&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">data_zip&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>&lt;span class="nb">module&lt;/span> &lt;span class="s2">&amp;#34;glue_catalog_cleaned&amp;#34;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">source&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;./modules/glue/glue_cleaned&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">database_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;catalog_cleaned_db&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">table_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;catalog_cleaned_json_table&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">s3_location&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;s3://&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nb">module&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">s3_bucket&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">bucket_name&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">/cleaned/&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>&lt;span class="nb">module&lt;/span> &lt;span class="s2">&amp;#34;athena&amp;#34;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">source&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;./modules/athena&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">result_output_location&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;s3://&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nb">module&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">s3_bucket&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">bucket_name&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">/athena-results/&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="backendtf">backend.tf
&lt;/h2>&lt;p>首先，创建 S3 存储桶用于远程存储 Terraform 状态文件 (state file)，这有助于促进协作。&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*wNoK6qiZ3af-6HkhCDH48A.png"
loading="lazy"
alt="Terraform 状态文件所在的 S3 存储桶"
>&lt;/p>
&lt;p>创建后，将以下内容添加到 &lt;code>backend.tf&lt;/code> 文件中：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-terraform" data-lang="terraform">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">terraform&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">backend&lt;/span> &lt;span class="s2">&amp;#34;s3&amp;#34;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">bucket&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;serverless-data-pipeline-backend-bucket&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">key&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;serverless-pipeline/dev/terraform.tfstate&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">region&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;us-east-1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>一旦我们运行 &lt;code>terraform init&lt;/code> 和 &lt;code>terraform apply&lt;/code> 来部署项目，我们就应该看到状态存储在存储桶中，如下所示：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*bJ3LTvt6vayJgGsRZsQc5A.png"
loading="lazy"
alt="S3 中的 Terraform 状态文件"
>&lt;/p>
&lt;ul>
&lt;li>module/main.tf : 每个服务的基础设施和配置都放置在各自的 &lt;code>main.tf&lt;/code> 文件中&lt;/li>
&lt;li>module/output.tf : 每个服务的输出详情 (output detail) 都放置在各自的 &lt;code>output.tf&lt;/code> 文件中&lt;/li>
&lt;li>module/variable.tf : 每个服务期望的输入变量 (input variables) 都放置在各自的 &lt;code>variable.tf&lt;/code> 文件中&lt;/li>
&lt;/ul>
&lt;h2 id="部署应用程序">部署应用程序
&lt;/h2>&lt;p>现在我们已准备好部署应用程序。运行以下命令进行部署。&lt;/p>
&lt;p>&lt;strong>Terraform init&lt;/strong>：这会初始化项目，拉取部署所需的所有必要软件包。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">terraform init
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>Terraform plan&lt;/strong>：这会显示提议的更改，在部署前发现任何意外更改时非常有用。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">terraform plan
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>Terraform apply&lt;/strong>：这会将项目部署到 AWS。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">terraform apply
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="测试应用程序">测试应用程序
&lt;/h2>&lt;p>S3 存储桶 (S3 bucket) 最初加载了一个 &lt;code>sample.json&lt;/code> 文件，其内容如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="line">&lt;span class="cl">&lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;id&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;1&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;John Doe&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;email&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;john@example.com&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;timestamp&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;2025-04-19T12:00:00Z&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;id&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;2&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;Mary Doe&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;email&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;mary@example.com&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;timestamp&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;2025-06-20T12:00:00Z&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;id&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;3&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;Jane Doe&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;email&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;john@example.com&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;timestamp&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;2025-06-22T12:00:00Z&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;em>注：&lt;/em> 如您所见，我们有一个重复的电子邮件地址 &lt;code>*john@example.com*&lt;/code>，理想的结果是移除这个重复条目。&lt;/p>
&lt;p>这个文件是在使用 Terraform 创建存储桶后立即上传的，因此它不会触发 DataBrew 作业，因为该触发器设置是在项目的后期才进行的。&lt;/p>
&lt;p>为了测试实时功能 (Real-time feature) 和项目的完整流程，我们可以向 S3 上传新对象，或向 DynamoDB 添加新条目。我们将向 DynamoDB 添加一个新条目来测试完整流程：&lt;/p>
&lt;p>通过 AWS 控制台 (console) 进入 DynamoDB，并添加一条新数据：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Wq6-HKR3_Itogo9ncr3C-Q.png"
loading="lazy"
>&lt;/p>
&lt;p>添加此条目将触发 DynamoDB 流 (stream)，它会使用关联的 Lambda 函数 (lambda function) 将新对象插入 S3。&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*HEIxp2piYd2b9y5pxqV2xA.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*MGNKOjFIP0mJQ4DDgG8Agw.png"
loading="lazy"
>&lt;/p>
&lt;p>前往 S3，我们看到新条目 &lt;code>7.json&lt;/code> 已添加：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*dhhBJ1oL-3OSa9JHP832oA.png"
loading="lazy"
>&lt;/p>
&lt;p>接下来，前往数据目录 (Data Catalog)，我们看到数据库 (Databases) 和表 (Tables)。&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*XFt97o-Egelq4T-PdDUQmA.png"
loading="lazy"
>&lt;/p>
&lt;p>数据目录数据库&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*V1EV7KY8iSVvMgeGIX4Fsw.png"
loading="lazy"
>&lt;/p>
&lt;p>数据目录表&lt;/p>
&lt;p>前往 DataBrew，我们看到该项目。&lt;/p>
&lt;p>一旦 Lambda 函数被添加到 &lt;code>/data&lt;/code> 路径的新内容触发，它就会启动 DataBrew 转换作业 (transformation job)：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*YeJ5a_JzUjWoD8vD9-4n-A.png"
loading="lazy"
>&lt;/p>
&lt;p>完成后，它看起来像这样：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*GZNvEGrYWP4Wom1VKMAwBQ.png"
loading="lazy"
>&lt;/p>
&lt;p>已完成的 DataBrew 作业&lt;/p>
&lt;p>DataBrew 数据血缘 (Data lineage) 允许我们查看使用 DataBrew 的流程的图形化表示。&lt;/p>
&lt;p>&lt;strong>空闲作业&lt;/strong>：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*arMXfxrhANbnvXymY8ejBg.png"
loading="lazy"
alt="空闲作业的数据血缘"
>&lt;/p>
&lt;p>&lt;strong>运行中作业&lt;/strong>：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*CgVAhqi82C2tZcIRpCtz6A.png"
loading="lazy"
alt="数据血缘的作业运行中"
>&lt;/p>
&lt;p>最后，前往 Athena，并选择 &lt;code>my-athena-workgroup&lt;/code> 工作组 (workgroup) 来运行查询。&lt;/p>
&lt;p>在 DataBrew 作业运行之前，如果我们使用 Athena 运行查询，将不会有任何结果，因为 &lt;code>/cleaned&lt;/code> 路径中还没有任何项目：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*8K6f2X_uNLtstmSxZu1q9g.png"
loading="lazy"
>&lt;/p>
&lt;p>然而，在 DataBrew 作业成功运行后，我们点击 &lt;em>&lt;strong>Run again&lt;/strong>&lt;/em> 按钮以在 Athena 中重新运行查询：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*NDVMRuZ4Kh5GdTGIIkcHnQ.png"
loading="lazy"
>&lt;/p>
&lt;p>结果如下：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*kjeCuYwKZMO-2RJJgpd0Dw.png"
loading="lazy"
>&lt;/p>
&lt;p>如果你仔细观察，会发现它移除了在项目创建时上传到 S3 的 &lt;code>sample.json&lt;/code> 文件中发现的邮箱为 &lt;code>john@example.com&lt;/code> 的重复条目。&lt;/p>
&lt;p>它还添加了邮箱为 &lt;code>mathew@gmail.com&lt;/code> 的新的 DynamoDB 条目。&lt;/p>
&lt;p>这意味着我们的管道按预期工作！！&lt;/p>
&lt;h2 id="通过-dynamodb-添加重复条目">通过 DynamoDB 添加重复条目
&lt;/h2>&lt;p>让我们通过向 DynamoDB 添加一个新条目来进一步测试，但这次它的邮箱将与我们现有的记录匹配。&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*bWxYzQotL_N0JyVhsCzpTA.png"
loading="lazy"
>&lt;/p>
&lt;p>我们添加了一个邮箱为 &lt;code>mathew@gmail.com&lt;/code> 的新冲突条目&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*C0iTx5McyVuu5836kCQ2-Q.png"
loading="lazy"
>&lt;/p>
&lt;p>这将触发一个新的 DataBrew 作业 (Job)：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Rz50Z-SHv_PHcq1UUcKIgg.png"
loading="lazy"
>&lt;/p>
&lt;p>一旦成功了，我们会看到下图：&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*iKPaL44m6-cWhAfAW1gTJg.png"
loading="lazy"
>&lt;/p>
&lt;p>接下来，前往 Athena 再次运行查询，这次它不再包含重复记录了！&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Er8Fx7_rGw4IFALgSGq6ag.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="结论">结论
&lt;/h2>&lt;p>我创建这个项目和文章是为了提高我在 Terraform 方面的技能，并亲自动手实践数据工程领域，同时磨练我的 Python 技能。&lt;/p>
&lt;p>你可以在 &lt;a class="link" href="https://github.com/chyke007/serverless-data-pipeline" target="_blank" rel="noopener"
>这里&lt;/a> 找到完整的源代码。&lt;/p>
&lt;p>我希望这篇文章能帮助你对在 AWS 中构建数据工程项目更有信心。我很高兴看到你将创造出什么！&lt;/p>
&lt;p>全栈开发人员、技术作家和 Jamstack 爱好者。热爱终身学习。&lt;/p></description></item><item><title>告别Terraform：使用为人类设计的基础设施即代码Pulumi</title><link>https://martinliu.cn/blog/infrastructure-as-code-for-humans-with-pulumi/</link><pubDate>Mon, 08 Jan 2024 11:01:38 +0800</pubDate><guid>https://martinliu.cn/blog/infrastructure-as-code-for-humans-with-pulumi/</guid><description>&lt;img src="https://martinliu.cn/blog/infrastructure-as-code-for-humans-with-pulumi/0_94eq9GcVBbFH3TeR.webp" alt="Featured image of post 告别Terraform：使用为人类设计的基础设施即代码Pulumi" />&lt;p>本文原作者：&lt;a class="link" href="https://medium.com/aws-tip/say-goodbye-to-terraform-infrastructure-as-code-for-humans-with-pulumi-76e72de1c3d9" target="_blank" rel="noopener"
>Santiago González&lt;/a>&lt;/p>
&lt;p>事先声明一下：本文并非另一篇黑HashiCorp更改Terraform许可的文章。我还有很多不再使用Terraform的考虑。在这篇文章中，我们将回顾Pulumi相对于Terraform的一些优势。这并不意味着要成为Pulumi的追捧者。它只是Terraform的替代解决方案之一，使开发人员能够直观地使用基础设施配置工具。&lt;/p>
&lt;h2 id="为什么讨厌terraform">为什么讨厌Terraform？
&lt;/h2>&lt;p>显然，我在这里写的一切都是主观的，也可能是错的。但这里总结的一切表明了，与我类似的其他许多尝试拥抱Terraform的人，希望用它作为IcA工具所遭受的挫折。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>学习曲线&lt;/strong>：Terraform拥有自己专用的领域特定语言（HCL），作为一种定义基础设施的独特方式，与传统编程语言迥然不同。这种语言遵循着对其他语言而言比较陌生的逻辑。因此，对团队来说，学习它是需要：付出极大努力，并且遵循这种&amp;hellip; 魔鬼般逻辑的语言更是需要额外的努力。&lt;/li>
&lt;li>&lt;strong>违背DevOps原则的DevOps工具&lt;/strong>：如果你在Terraform中编写代码的已经很复杂了，想象一下去编写测试，有可能是什么样子。在这里，您可以了解一下要如何才能做到这一点。这绝对是疯狂的。实际上，这意味着：并非在Terraform的代码上直接实施测试。至少我从来没见过这样的。&lt;/li>
&lt;li>&lt;strong>秘钥管理&lt;/strong>：Terraform需要与第三方解决方案集成来实现秘钥的管理。或者，您大可以使用环境变量。&lt;/li>
&lt;li>&lt;strong>团队生产力&lt;/strong>：其实很难找到一个开发人员的简历上，就写着他已经熟悉了 Terraform。因此，这意味着：你必须使用一种与项目上所使用的语言相异的语言来实现基础设施的配置，由于使用和学习其他新语言的额外工作量，会导致生产力的下降。&lt;/li>
&lt;/ul>
&lt;h2 id="pulumi能做什么">Pulumi能做什么？
&lt;/h2>&lt;p>以下是使Pulumi相对于Terraform更好的功能。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nn">com.pulumi.pulumi&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="kn">import&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nn">com.pulumi.pulumi.aws.ec2&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="kn">import&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nn">com.pulumi.pulumi.aws.rds&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="kn">import&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nn">com.pulumi.pulumi.aws.vpc&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="kd">public&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kd">class&lt;/span> &lt;span class="nc">Main&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="kd">public&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kd">static&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kt">void&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nf">main&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">[]&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="c1">// Crear una VPC&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">Vpc&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">myVpc&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">new&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Vpc&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;myVpc&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">VpcArgs&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">builder&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">cidrBlock&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;10.0.0.0/16&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="p">());&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="c1">// Crear un grupo de subredes&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">SubnetGroup&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">dbSubnetGroup&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">new&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">SubnetGroup&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;myDbSubnetGroup&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">SubnetGroupArgs&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">builder&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">subnetIds&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">myVpc&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">getPrivateSubnetIds&lt;/span>&lt;span class="p">())&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="p">());&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="c1">// Crear una instancia de AWS DocumentDB&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">Cluster&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">documentDbCluster&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">new&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Cluster&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;myDocumentDBCluster&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">ClusterArgs&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">builder&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">clusterIdentifier&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;my-docdb-cluster&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">availabilityZones&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;us-east-1a&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;us-east-1b&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">dbSubnetGroupName&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dbSubnetGroup&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">getId&lt;/span>&lt;span class="p">())&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">masterUsername&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;admin&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">masterPassword&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;mysecretpassword&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">skipFinalSnapshot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">storageEncrypted&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">applyImmediately&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">engine&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;docdb&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">engineVersion&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;4.0&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">instanceType&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;db.r5.large&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">build&lt;/span>&lt;span class="p">());&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">pulumi&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">export&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;clusterEndpoint&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">documentDbCluster&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">getEndpoint&lt;/span>&lt;span class="p">());&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="语言支持">语言支持
&lt;/h3>&lt;p>多语言和多云支持：使其具有很大的灵活性。这使您能够使用与软件项目相同的编程语言，让它对开发人员而言更加友好。此外，它实现了对所需架构的更好抽象，并且还能实现“在产生云账单之前就进行代码测试”。&lt;/p>
&lt;h3 id="pulumi具有秘钥存储">Pulumi具有秘钥存储
&lt;/h3>&lt;p>它使用集成的秘钥存储来保护所有敏感数据。这个秘钥存储解决方案在各种部署场景中无缝运行，无论您是使用我们托管的Pulumi服务、自托管的Pulumi服务、还是自我管理的后端。当您使用&amp;rsquo;pulumi new&amp;rsquo;或&amp;rsquo;pulumi stack init&amp;rsquo;创建堆栈时，Pulumi服务会自动保护好秘钥信息。如果你选择使用AWS S3或Google Cloud Storage等自我管理的云存储后端，也是在使用&amp;rsquo;pulumi new&amp;rsquo;初始化新堆栈时定义的口令来保护秘钥。无论场景如何，每个Pulumi堆栈都会收到唯一的加密密钥。&lt;/p>
&lt;h3 id="团队生产力">团队生产力
&lt;/h3>&lt;p>如果团队使用了与其项目相关联（相同）的程序开发语言，那么，他们就将更容易的对所需使用的组件负责和提供支持。这样，使用和理解具有HCL结构的项目的工作量就被消除了，团队可以继续专注于开发功能，而减少了开发成本和时间。&lt;/p>
&lt;h3 id="使用terraform状态">使用Terraform状态
&lt;/h3>&lt;p>Pulumi提供了访问和利用本地和远程Terraform状态的能力。在过渡到Pulumi或您组织内的各个团队具有不同的工具偏好时，这可能非常有价值。通过诸如状态引用支持之类的功能，您基于Terraform的构建的基础架构之上，构建Pulumi中的项目，例如利用Terraform所创建的关键VPC详细信息，如VPC ID和子网ID等信息。这简化了Pulumi和Terraform之间的集成，使其从 Terraform 的迁移变成了一个无缝的过程。&lt;/p>
&lt;h3 id="测试">测试
&lt;/h3>&lt;p>您可以选择所喜欢的测试框架，并开发进行对基础设施进行必要验证的单元和集成测试。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nn">spock.lang.Specification&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="kn">import&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nn">io.pulumi.pulumi&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="kn">import&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nn">io.pulumi.pulumi.aws.s3.Bucket&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="kn">import&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nn">io.pulumi.pulumi.runtime.Mocks&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="kn">import&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nn">org.mockito.Mockito&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="kd">class&lt;/span> &lt;span class="nc">PulumiIntegrationTest&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kd">extends&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Specification&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">def&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nf">setup&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="c1">// Set up AWS and Pulumi configurations for testing&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">pulumi&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">setMocks&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">new&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Mocks&lt;/span>&lt;span class="p">())&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c1">// Configure Pulumi mocks&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">def&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nf">cleanup&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="c1">// Clean up configurations after tests&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">pulumi&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">setMocks&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kc">null&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c1">// Restore Pulumi mocks&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">def&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;test AWS S3 bucket creation&amp;#34;&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">given&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="c1">// Set up the environment for the Pulumi program&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">def&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">program&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">new&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">pulumi&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">Stack&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;mystack&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nl">when&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="c1">// Execute the Pulumi program that creates the S3 bucket&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">program&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">apply&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nl">then&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="c1">// Verify that the S3 bucket was created successfully&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">def&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">bucketName&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">program&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">getOutput&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Bucket&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">BucketName&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="k">assert&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">bucketName&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">!=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kc">null&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">&amp;amp;&amp;amp;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">bucketName&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">!=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s">&amp;#34;&amp;#34;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nl">cleanup&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="c1">// Perform additional cleanup tasks if necessary&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="tldr-太长不读">TL;DR; 太长不读
&lt;/h2>&lt;p>尽管Terraform拥有着强大的社区支持，但实际上，对于开发团队来说，通常大家还是觉得太复杂，难以用它实现 IaC 基础设施即代码的管理。这主要是由于学习曲线及其HCL语言，它与命令性语言的逻辑不一致。由于替代解决方案如Pulumi的出现，我们可以使用软件项目中的程序语言配置基础设施资源。实际上，与Terraform相比，Pulumi会提高效率和生产力。如果您尚未决定使用哪种IaC工具，值得 先考虑Terraform可能对您的组织产生的潜在影响。&lt;/p>
&lt;p>来源：&lt;a class="link" href="https://medium.com/aws-tip/say-goodbye-to-terraform-infrastructure-as-code-for-humans-with-pulumi-76e72de1c3d9" target="_blank" rel="noopener"
>https://medium.com/aws-tip/say-goodbye-to-terraform-infrastructure-as-code-for-humans-with-pulumi-76e72de1c3d9&lt;/a>&lt;/p>
&lt;p>Feature picture ❤️ : kike &lt;a class="link" href="https://unsplash.com/@kikekiks?utm_source=medium&amp;amp;utm_medium=referral" target="_blank" rel="noopener"
>vega on Unsplash&lt;/a>&lt;/p></description></item><item><title>使用 Terraform 创建 Aks 集群</title><link>https://martinliu.cn/blog/terraform-create-aks-cluster/</link><pubDate>Mon, 13 Nov 2023 09:49:03 +0800</pubDate><guid>https://martinliu.cn/blog/terraform-create-aks-cluster/</guid><description>&lt;img src="https://martinliu.cn/blog/terraform-create-aks-cluster/154.png" alt="Featured image of post 使用 Terraform 创建 Aks 集群" />&lt;p>本文介绍如何使用 Terraform 创建一个基础配置的 Azure Kubernetes Service (AKS) 集群，可以用于快速的启动一个开发测试环境，基础特性如下。&lt;/p>
&lt;ul>
&lt;li>使用尽可能多的默认值&lt;/li>
&lt;li>node pool 使用了自动扩展，最小节点数为 1，最大节点数为 10&lt;/li>
&lt;li>AKS将使用由Azure自动创建和管理的托管身份&lt;/li>
&lt;/ul>
&lt;h2 id="登录-azure">登录 Azure
&lt;/h2>&lt;p>参考这篇文章《&lt;a class="link" href="https://martinliu.cn/blog/create-azure-sp-for-cli/" target="_blank" rel="noopener"
>创建用于命令行登录认证 Azure 的 Service Principal 必读&lt;/a>》，创建一个用于在命令行登录认证 Azure 的 Service Principal。&lt;/p>
&lt;p>为了将创建的 Service Principal 的细节信息，用于命令行变量，方便 Azure CLI 命令的参数化，还为了将所有必要的变量带入 &lt;code>.tf&lt;/code> 文件的变量中。可以参考下面的命令：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">TF_VAR_subscription_id&lt;/span>&lt;span class="o">=&lt;/span>XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXXXX
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">SERVICE_PRINCIPAL_JSON&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="k">$(&lt;/span>az ad sp create-for-rbac --name aks-getting-started-sp --role Contributor --scopes /subscriptions/&lt;span class="si">${&lt;/span>&lt;span class="nv">TF_VAR_subscription_id&lt;/span>&lt;span class="si">}&lt;/span> -o json&lt;span class="k">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">TF_VAR_client_id&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="k">$(&lt;/span>&lt;span class="nb">echo&lt;/span> &lt;span class="nv">$SERVICE_PRINCIPAL_JSON&lt;/span> &lt;span class="p">|&lt;/span> jq -r &lt;span class="s1">&amp;#39;.appId&amp;#39;&lt;/span>&lt;span class="k">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">TF_VAR_client_secret&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="k">$(&lt;/span>&lt;span class="nb">echo&lt;/span> &lt;span class="nv">$SERVICE_PRINCIPAL_JSON&lt;/span> &lt;span class="p">|&lt;/span> jq -r &lt;span class="s1">&amp;#39;.password&amp;#39;&lt;/span>&lt;span class="k">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">TF_VAR_tenant_id&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="k">$(&lt;/span>&lt;span class="nb">echo&lt;/span> &lt;span class="nv">$SERVICE_PRINCIPAL_JSON&lt;/span> &lt;span class="p">|&lt;/span> jq -r &lt;span class="s1">&amp;#39;.tenant&amp;#39;&lt;/span>&lt;span class="k">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">az login &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>--service-principal &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>--tenant &lt;span class="nv">$TF_VAR_tenant_id&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>--username &lt;span class="nv">$TF_VAR_client_id&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>--password &lt;span class="nv">$TF_VAR_client_secret&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>--output table
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>以上在创建 Service Principal 的时候，使用了 &lt;code>--scopes /subscriptions/${TF_VAR_subscription_id}&lt;/code>，这样就可以在任何一个资源组中使用这个 SP 了。假如你需要在多个不同订阅之间工作，可以灵活的使用 &lt;code>${TF_VAR_subscription_id}&lt;/code> 这个环境变量，来指定不同的订阅 ID。&lt;/p>
&lt;p>这段命令中一共设置了四个命令行的环境变量，由于需要在 .tf 文件中作为变量使用，因此需要使用 &lt;code>TF_VAR_&lt;/code> 前缀，这样 Terraform 才能识别到这些变量。&lt;/p>
&lt;h2 id="登录-terraform-cloud">登录 Terraform Cloud
&lt;/h2>&lt;p>Terrafrom 命令行工具的安装本文忽略，详见官方文档 &lt;a class="link" href="https://www.terraform.io/docs/cli/index.html" target="_blank" rel="noopener"
>Terraform CLI&lt;/a> 。&lt;/p>
&lt;p>Terraform Cloud 是 Terraform 官方提供的一种 SaaS 服务，可以用于管理 Terraform 的状态文件，以及执行 Terraform 的计划和应用。本文中使用 Terraform Cloud 来管理状态文件，以及执行计划和应用。&lt;/p>
&lt;p>首先，你需要在 Terraform Cloud 中创建一个组织，然后创建一个工作区，用于存放状态文件。然后，你需要在本地安装 Terraform CLI 命令行工具，然后使用 Terraform CLI 命令行工具，登录 Terraform Cloud。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">terraform login
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="创建-aks-集群">创建 AKS 集群
&lt;/h2>&lt;p>本文使用的样例代码在 &lt;a class="link" href="https://github.com/martinliu/azure-labs/tree/main/lab02" target="_blank" rel="noopener"
>GitHub&lt;/a> 上，你可以直接使用这个样例代码，也可以参考这个样例代码，自己创建一个 AKS 集群。&lt;/p>
&lt;p>下面是样例代码中的 &lt;code>main.tf&lt;/code> 文件，这个文件中包含了创建 AKS 集群的所有必要的配置。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-hcl" data-lang="hcl">&lt;span class="line">&lt;span class="cl">&lt;span class="k">terraform&lt;/span> {&lt;span class="c1">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"> # 使用远程 Cloud 后端
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="k">cloud&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> organization&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;DevOpsCoach&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">workspaces&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;aks-labs&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">provider&lt;/span> &lt;span class="s2">&amp;#34;azurerm&amp;#34;&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">features&lt;/span> {}&lt;span class="c1">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"> # 下面的配置允许 Terraform 以您的身份与 Azure API 进行交互，从而管理您的资源。
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"> # 从 CLI 的环境变量中取得这些实际的数值
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="n"> tenant_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">var&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">tenant_id&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> subscription_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">var&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">subscription_id&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> client_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">var&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">client_id&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> client_secret&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">var&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">client_secret&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">resource&lt;/span> &lt;span class="s2">&amp;#34;azurerm_resource_group&amp;#34; &amp;#34;example&amp;#34;&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;${local.prefix}-rg&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> location&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">local&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">location&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>以上文件中引用了两种变量，一种是从 locals.tf 文件中引用的本地变量，另一种是从命令行的环境变量中读取到的&lt;code>TF_VAR&lt;/code> 开头的变量。这样从 Terraform 命令行执行之前，就可以将这些变量设置好，然后 Terraform 就可以使用这些变量了。&lt;/p>
&lt;p>下面是样例代码中的 &lt;code>locals.tf&lt;/code> 文件，这个文件中包含了创建 AKS 集群的所有必要的本地变量。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-hcl" data-lang="hcl">&lt;span class="line">&lt;span class="cl">&lt;span class="k">locals&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> prefix&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;aks4devops&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> location&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;eastasia&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">variable&lt;/span> &lt;span class="s2">&amp;#34;client_id&amp;#34;&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> description&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Client ID for the Azure provider&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> type&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">string&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">variable&lt;/span> &lt;span class="s2">&amp;#34;client_secret&amp;#34;&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> description&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Client Secret for the Azure provider&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> type&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">string&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">variable&lt;/span> &lt;span class="s2">&amp;#34;subscription_id&amp;#34;&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> description&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Subscription ID for the Azure provider&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> type&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">string&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">variable&lt;/span> &lt;span class="s2">&amp;#34;tenant_id&amp;#34;&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> description&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Tenant ID for the Azure provider&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> type&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">string&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这里文件中设定了两个变量参数，另外还声明了四个命令带入的变量，它们是从命令行的环境变量中读取到的&lt;code>TF_VAR&lt;/code> 开头的变量。&lt;/p>
&lt;p>下面是样例代码中的 &lt;code>aks.tf&lt;/code> 文件，这个文件中包含了创建 AKS 集群的所有必要的配置。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-hcl" data-lang="hcl">&lt;span class="line">&lt;span class="cl">&lt;span class="k">resource&lt;/span> &lt;span class="s2">&amp;#34;azurerm_kubernetes_cluster&amp;#34; &amp;#34;example&amp;#34;&lt;/span> {&lt;span class="c1">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"> # AKS cluster basic information
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="n"> name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;${local.prefix}-k8s&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> location&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">azurerm_resource_group&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">example&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">location&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> resource_group_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">azurerm_resource_group&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">example&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="k">name&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> dns_prefix&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;${local.prefix}-k8s&amp;#34;&lt;/span>&lt;span class="c1">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"> # node pool settings
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="k">default_node_pool&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;default&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> node_count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> min_count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> max_count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">10&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> vm_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Standard_DS2_v2&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> enable_auto_scaling&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kt">true&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }&lt;span class="c1">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"> # AKS use system auto created identity
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="k">identity&lt;/span> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n"> type&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;SystemAssigned&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>以上集群基本上使用了所有的系统默认配置，除了设定了一个 node pool，这个 node pool 使用了自动扩展，最小节点数为 1，最大节点数为 10。&lt;/p>
&lt;p>在阅读了这些文件之后，就可以在本地执行 Terraform 的计划和应用了。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">terraform init
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">terraform plan
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">terraform apply
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在执行以上命令的过程中，我们可以在 Terraform Cloud 的 Web 界面中，看到 Terraform 的执行过程。&lt;/p>
&lt;p>&lt;img src="https://martinliu.cn/blog/terraform-create-aks-cluster/2023-11-14_23-14-28.jpg"
width="1578"
height="1044"
srcset="https://martinliu.cn/blog/terraform-create-aks-cluster/2023-11-14_23-14-28_hu_b9a1a10951828eed.jpg 480w, https://martinliu.cn/blog/terraform-create-aks-cluster/2023-11-14_23-14-28_hu_57df00e07b6e7f70.jpg 1024w"
loading="lazy"
alt="terraform runs"
class="gallery-image"
data-flex-grow="151"
data-flex-basis="362px"
>&lt;/p>
&lt;p>在测试完成了之后，可以使用下面的命令，删除 AKS 集群。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">terraform destroy
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="参考">参考
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://www.terraform.io/docs/cloud/index.html" target="_blank" rel="noopener"
>Terraform Cloud&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.terraform.io/docs/cloud/cli/install-bash.html" target="_blank" rel="noopener"
>Terraform Cloud - CLI&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.terraform.io/docs/cloud/cli/login.html" target="_blank" rel="noopener"
>Terraform Cloud - CLI - Login&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-us/cli/azure/reference-index?view=azure-cli-latest#az-login" target="_blank" rel="noopener"
>Azure CLI Login&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-us/azure/aks/" target="_blank" rel="noopener"
>Azure AKS documentation&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/kubernetes_cluster" target="_blank" rel="noopener"
>Azure AKS Terraform documentation&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>为什么我们不支持 OpenTF？</title><link>https://martinliu.cn/blog/why-we-are-not-supporting-opentf/</link><pubDate>Tue, 29 Aug 2023 09:46:45 +0800</pubDate><guid>https://martinliu.cn/blog/why-we-are-not-supporting-opentf/</guid><description>&lt;img src="https://martinliu.cn/blog/why-we-are-not-supporting-opentf/0_djNEkw3EPJvERiqT.webp" alt="Featured image of post 为什么我们不支持 OpenTF？" />&lt;blockquote>
&lt;p>作者：dragondrop.cloud
来源：&lt;a class="link" href="https://medium.com/@hello_9187/" target="_blank" rel="noopener"
>https://medium.com/@hello_9187/&lt;/a>&lt;/p>&lt;/blockquote>
&lt;h2 id="背景">背景
&lt;/h2>&lt;p>2021年8月10日，HashiCorp 将其之前的“开源”项目的许可证更改为商业源代码许可证（BSL），从而使它们成为未来所有版本的“源代码可用”。我们在这里详细讨论了此变更的原因和动机。&lt;/p>
&lt;p>2021年8月15日，OpenTF 宣言发布。其主要观点是，他们希望HashiCorp将 Terraform 的许可证恢复为真正的开源许可证，否则承诺者联盟将支持由基金会管理的 Terraform 分支。&lt;/p>
&lt;h2 id="我们的看法">我们的看法
&lt;/h2>&lt;p>我们认为 OpenTF 宣言对新许可证的描述方式有失偏颇，有利于那些受到许可证变更影响最大的盈利公司，而如果发生分支，Terraform 生态系统的潜在成本太高。此外，作为受影响方，我们不介意将 Terraform 许可给嵌入到我们自己的解决方案中，因为 HashiCorp 建立和维护的庞大支持生态系统。&lt;/p>
&lt;p>让我们详细分析这个说法*。&lt;/p>
&lt;p>*以下内容不构成法律建议，请咨询熟悉您特定情况的律师。&lt;/p>
&lt;h2 id="许可证偏颇和扭曲的陈述">许可证偏颇和扭曲的陈述
&lt;/h2>&lt;p>&lt;strong>1）&lt;/strong> 在宣言的开头部分“我们的关切：BUSL 许可证是 Terraform 的毒丸”，他们声称：
“&amp;hellip;现在，使用 Terraform 的每家公司、供应商和开发人员都必须考虑他们的行为是否可能被视为与 HashiCorp 的产品竞争。”&lt;/p>
&lt;p>这个说法似乎相当不准确。唯一需要担心许可证变更的公司是那些将“在托管或嵌入的基础上为第三方提供 Licensed Work”的公司，这些行为与 HashiCorp 的产品竞争。&lt;/p>
&lt;p>最初确实有一些关于某些具体问题的合理疑问，即如果 HashiCorp 发布与您先前发布的工具重叠的功能，会发生什么情况？然而，在 HashiCorp 的首席技术官回答了其中一些常见问题后，似乎很明显，这只会影响那些向其他公司销售软件，并且该软件与 HashiCorp 的 Terraform Cloud 和 Terraform Enterprise 产品竞争，或者将 Terraform（源代码或 CLI 二进制文件）托管或嵌入的公司。&lt;/p>
&lt;p>值得注意的是，与 HashiCorp 管理的 Terraform 产品直接竞争的三家最大公司，Spacelift、Env0 和 Scalr，在支持一个 Terraform 分支的多年里，已经做出了数百万美元的承诺（这三家公司之间共有13个全职员工，为期五年）。他们的员工和创始人一直是 OpenTF 宣言的最积极的贡献者和传播者。&lt;/p>
&lt;p>&lt;strong>2）&lt;/strong> 对于一个分支可能带来的好处的引用，这些好处在 2021 年和现在一样成立。
OpenTF 宣言列出了分支的关键原因，包括创建一个“真正的开源”、“社区驱动”、“公正”和“分层和模块化”的 Terraform。这些都是 Terraform 核心的有效关切，实际上是任何拥有的开源项目公司的问题，但是这些与 Terraform 核心仓库的问题并不是新问题。多年来，HashiCorp 社区接受社区提交的速度一直很慢，他们从未在核心中添加某些企业风格的功能（像任何拥有开源工具的公司一样）。&lt;/p>
&lt;p>在过去的大约14天里，唯一的实质性变化是一些公司的利润状况发生了变化。&lt;/p>
&lt;h2 id="分支生态系统潜在的成本非常高">分支生态系统潜在的成本非常高
&lt;/h2>&lt;p>如果发生了分支，Terraform的主干版本可能不会闲置。HashiCorp可能会感到迫切，加强其地位，并在新版本的Terraform和主干云供应商中引入不兼容的差异。在最好的情况下，这可能会导致社区为了采用新的Terraform主要版本而做很多额外的工作，在最坏的情况下，导致主干版本和分支之间的兼容性裂痕。&lt;/p>
&lt;p>这样的裂痕对于工具的应用将是毁灭性的（我应该使用哪个版本的Terraform？有什么区别？算了，我只是去选择一个替代品）以及纯粹支持Terraform的开源项目（我为哪个分支编写？我是否支持两者并增加维护工具所需的工作？）。这还可能导致巨大的重复工作量，需要永久地并行维护镜像库、provider（提供者）和Terraform核心。&lt;/p>
&lt;p>即使在发生分支的情况下，HashiCorp继续照常运营，对整个社区来说，这也像是一个巨大的重复劳动，因为分支的主要受益者只是不同的营利实体及其用户。&lt;/p>
&lt;p>总之，分支对Terraform社区可能非常、非常代价高昂。&lt;/p>
&lt;h2 id="hashicorp支持terraform社区的投入巨大">HashiCorp支持Terraform社区的投入巨大
&lt;/h2>&lt;p>Terraform社区主要是由HashiCorp维护的，与之相关的成本非常高。&lt;/p>
&lt;p>他们每年支持数十亿的提供者下载，免费的模块托管（我们的组织将其作为一个关键的分发机制）以及数十亿的Terraform二进制下载。&lt;/p>
&lt;p>上述成本投入不包括主干云Terraform提供者和Terraform核心本身的维护。不用说，HashiCorp会持续的在社区大量投入，并将继续这样做。&lt;/p>
&lt;h2 id="反论bsl的改变不就是遏制竞争吗">反论：BSL的改变不就是遏制竞争吗？
&lt;/h2>&lt;p>许多Terraform Cloud替代品，特别是Spacelift、Env0、Scalr和Digger，都为Terraform管理开发了创新的工具和功能。与此同时，他们已经从HashiCorp所做的大型生态系统投资中取得了利益。明确地说，这种方法没有错，只要能继续以接近零成本的方式进行，这是一个聪明的商业策略。&lt;/p>
&lt;p>许可证更改至少提高了所有Terraform Cloud/Enterprise竞争对手的运营成本。这些成本很可能以某种形式转嫁给他们自己的客户。这可能是通过更高的定价结构，因为许可费冲击了他们的利润率，或者是某些企业完全放弃了Terraform管理，从而选择较少（这种后续响应当然最能遏制竞争）。&lt;/p>
&lt;p>还有一件事需要记住，那就是HashiCorp也是一家企业，因此期望它们继续亏损，而与此同时，不受维护和运营Terraform社区资产所需的固定成本的约束的竞争对手直接针对它们，是不现实的。虽然这个领域的产品价格几乎肯定会因为生态系统成本更加均匀地被承担而变得更加昂贵，但如果HashiCorp变成一个不存在的实体，那也不是理想情况。&lt;/p>
&lt;h2 id="结论">结论
&lt;/h2>&lt;p>从我们的角度看，Terraform社区主干分叉的潜在成本可能非常高昂，并可能对Terraform的未来造成严重破坏。HashiCorp继续使用BSL对&amp;gt;99%的Terraform用户没有影响；但主要的OpenTF宣言作者有明确的利润动机，并已经从不同的角度呈现了这种情况。&lt;/p>
&lt;p>我们认为Terraform的分支对社区的维护成本，远远超过了少数那几家被改变了营利模式企业的商业价值，并因此我们不支持OpenTF项目。&lt;/p>
&lt;h2 id="背景-1">背景
&lt;/h2>&lt;blockquote>
&lt;p>本文作者所在的公司：如果对我们自己的偏见感到好奇，我们的公司构建了一个嵌入了Terraform CLI的产品，并具有与Terraform Cloud重叠的一些功能，特别是漂移检测，因此受到了BSL更改对Terraform 1.5.5之后版本的影响。dragondrop.cloud的使命是在使用基础设施作为代码时自动化开发者的最佳实践。我们的旗舰开源产品cloud-concierge允许开发者将他们的云计算进行编码，检测漂移，估计云计算成本和安全风险等，更多地通过拉取请求提供结果。对于大规模运行cloud-concierge的企业，我们提供了一个自托管的管理平台。&lt;/p>&lt;/blockquote></description></item><item><title>Hashicorp 的 Terraform 1.0 正式 GA 了！</title><link>https://martinliu.cn/blog/hashicorp-terraform-1-0-general-availability-cn/</link><pubDate>Tue, 15 Jun 2021 09:15:22 +0800</pubDate><guid>https://martinliu.cn/blog/hashicorp-terraform-1-0-general-availability-cn/</guid><description>&lt;img src="https://martinliu.cn/img/2021/06/0gLZ2oH.png" alt="Featured image of post Hashicorp 的 Terraform 1.0 正式 GA 了！" />&lt;p>Terraform 1.0&amp;ndash;现在GA了&amp;ndash;标志着你的自动化工作流程的互操作性、易于升级和维护方面的一个重要里程碑。&lt;/p>
&lt;p>Terraform 拥有数以亿计的下载量、成千上万的贡献和令人难以置信的社区，是最广泛采用的基础设施即代码工具。达到 1.0 是一个重要的里程碑。&lt;/p>
&lt;p>&lt;img src="https://martinliu.cn/img/cos/2021-06-15-terrafor-history.png"
loading="lazy"
alt="Terraform 的历史"
>&lt;/p>
&lt;p>本文来自：&lt;a class="link" href="https://www.hashicorp.com/blog/announcing-hashicorp-terraform-1-0-general-availability" target="_blank" rel="noopener"
>https://www.hashicorp.com/blog/announcing-hashicorp-terraform-1-0-general-availability&lt;/a>&lt;/p>
&lt;p>6 月 8 日，在 HashiConf 欧洲会议上，我们很高兴地宣布HashiCorp Terraform 1.0全面上市，这是您自动化工作流程的互操作性、易于升级和维护的一个重要里程碑。Terraform 1.0&lt;a class="link" href="https://www.terraform.io/downloads.html" target="_blank" rel="noopener"
>立即可供下载&lt;/a>，也可在HashiCorp Terraform Cloud 中使用。HashiCorp Terraform已经被大小公司的个人和团队广泛使用，成为多云配置和自动化的标准。这篇文章介绍了新的内容，以及1.0的命名对Terraform用户的意义。&lt;/p>
&lt;h2 id="更好的-terraform-state-互操作性">更好的 Terraform State 互操作性
&lt;/h2>&lt;p>Terraform 在互操作性方面取得了巨大的进步。Terraform state 现在可以在0.14.x、0.15.x和1.0.x版本之间交叉兼容。远程状态数据源的兼容性现在已经回传，支持0.12.30、0.13.6、0.14.0、0.15.0和1.0.x版本。&lt;/p>
&lt;h2 id="改进升级体验">改进升级体验
&lt;/h2>&lt;p>从 Terraform 0.15 开始，一直到1.x的生命周期，你现在可以升级到新的 Terraform 版本，你的工作流程将继续运行，就像之前那些版本一样。使用Terraform 1.x不需要升级工具、重构或其他改变。&lt;/p>
&lt;h2 id="延长维护期">延长维护期
&lt;/h2>&lt;p>所有Terraform 1.x版本将有至少18个月的维护期。这意味着HashiCorp将继续调查1.0版本的错误和发布功能，至少在这段时间内。这些修复可能会在后续的1.x版本中发布，而不一定是增量的1.0.x版本。&lt;/p>
&lt;h2 id="terraform插件sdk-v1的寿命结束">Terraform插件SDK v1的寿命结束
&lt;/h2>&lt;p>&lt;a class="link" href="https://github.com/hashicorp/terraform-plugin-sdk/" target="_blank" rel="noopener"
>Terraform插件SDK&lt;/a>是一个框架，可以让开发者创建和维护Terraform供应商。HashiCorp将在2021年7月31日结束对插件SDK第一版的支持。Terraform CLI和Terraform Cloud的用户不受此影响，不需要采取任何行动。我们鼓励受到影响的 Terraform Provider 的维护者使用我们的升级指南，转移到Terraform Plugin SDK的第二版本。按照我们的教程，开发您的Provider。其他信息可以在Terraform提供者社区讨论论坛中找到。Terraform插件SDK v1版的生命终结时间表。&lt;/p>
&lt;h2 id="10版本对terraform意味着什么">1.0版本对Terraform意味着什么？
&lt;/h2>&lt;p>1.0版本是一个巨大的成就，对于Terraform来说更是如此。对于许多为该项目做出贡献的人或参与超过100,000,000次下载的人来说，这已经是一个漫长的过程。但在HashiCorp，我们以一致的、透明的方式对待产品版本和1.0的指定，基于四个关键要求，正如2017年4月关于Packer 1.0发布的博文中所记录的那样。&lt;/p>
&lt;p>达到1.0的第一个要求是产品已经被广泛部署，在生产中经过多年的硬化。Terraform自2014年首次发布以来，一直在配置和管理基础设施，并得到了从零售业（星巴克）到证券交易所（TMX集团、德意志交易所集团）到自动驾驶汽车（Cruise）等广泛行业的信任。&lt;/p>
&lt;p>第二个要求是，主要的用例要被理解并得到良好的支持。Mitchell Hashimoto和Armon Dadgar早在2014年创建Terraform时，就已经想到了几个用例。从那时起，超过1500名贡献者开启了超过11000个 PR（GitHub 的贡献方式），这些请求增加了新的功能，并支持新的用例，这是我们从未想象过的。&lt;/p>
&lt;p>第三个要求规定了一个明确的用户体验。Terraform用户从不同的角度来处理他们的工作流程，因此我们专注于创建直观的用户界面；清晰的文档；全面的、自定进度的学习平台；以及互动的、由教师指导的研讨会。&lt;/p>
&lt;p>第四个要求是确保产品的技术架构是成熟和稳定的。&lt;/p>
&lt;p>Terraform 1.0以更大的互操作性、更容易的升级以及重要的维护期来巩固你的自动化工作流程和Terraform功能集的稳定性的形式满足了所有四个要求。&lt;/p></description></item></channel></rss>
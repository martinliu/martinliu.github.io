<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Lab on Martin Liu's Blog</title><link>https://martinliu.cn/tags/lab/</link><description>Recent content in Lab on Martin Liu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 09 Oct 2022 21:44:15 +0800</lastBuildDate><atom:link href="https://martinliu.cn/tags/lab/index.xml" rel="self" type="application/rss+xml"/><item><title>服务器虚拟化 RHEV</title><link>https://martinliu.cn/2015/03/27/e69c8de58aa1e599a8e8999ae68b9fe58c96-rhev/</link><pubDate>Fri, 27 Mar 2015 02:11:40 +0000</pubDate><guid>https://martinliu.cn/2015/03/27/e69c8de58aa1e599a8e8999ae68b9fe58c96-rhev/</guid><description>&lt;p>服务器虚拟在我的 lab 中是必选项，管理控制器端 RHEVM 安装在主服务的一个虚拟机里面。在主服务器上使用 targetcli 做了一个 iscsi 的共享存储。使用这个命令可以方便的实现 iscsi 设备。把最终的存储文件放在了 SSD 盘上的一个 100GB 的瘦制备文件上。
[bash]
╭─root@w540 ~
╰─$ targetcli
targetcli shell version 2.1.fb37
Copyright 2011-2013 by Datera, Inc and others.
For help on commands, type &amp;lsquo;help&amp;rsquo;.&lt;/p>
&lt;p>/&amp;gt; ls
o- / &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [&amp;hellip;]
o- backstores &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [&amp;hellip;]
| o- block &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [Storage Objects: 0]
| o- fileio &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [Storage Objects: 1]
| | o- iscsi1 &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [/root/iscsi01.img (100.0GiB) write-back activated]
| o- pscsi &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [Storage Objects: 0]
| o- ramdisk &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [Storage Objects: 0]
o- iscsi &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [Targets: 1]
| o- iqn.2003-01.org.linux-iscsi.w540.x8664:sn.82939fa1cd49 &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [TPGs: 1]
| o- tpg1 &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [no-gen-acls, no-auth]
| o- acls &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [ACLs: 0]
| o- luns &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [LUNs: 1]
| | o- lun0 &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [fileio/iscsi1 (/root/iscsi01.img)]
| o- portals &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [Portals: 1]
| o- 0.0.0.0:3260 &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [OK]
o- loopback &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [Targets: 0]
/&amp;gt;
[/bash]&lt;/p>
&lt;p>以上 iscsi 的存储配置参考：&lt;a class="link" href="https://access.redhat.com/solutions/894163" target="_blank" rel="noopener"
>https://access.redhat.com/solutions/894163&lt;/a>&lt;/p>
&lt;p>如果需要让所有的节点都能无障碍访问 iscsi 存储，就需要把 acl 设置为允许所有节点访问。使用下面这个命令&lt;/p>
&lt;p>[bash]
/&amp;gt; iscsi/iqn.2003-01.org.setup.lun.test/tpg1/ set attribute authentication=0 demo_mode_write_protect=0 generate_node_acls=1 cache_dynamic_acls=1&lt;/p>
&lt;p>Parameter demo_mode_write_protect is now &amp;lsquo;0&amp;rsquo;.&lt;/p>
&lt;p>Parameter authentication is now &amp;lsquo;0&amp;rsquo;.&lt;/p>
&lt;p>Parameter generate_node_acls is now &amp;lsquo;1&amp;rsquo;.&lt;/p>
&lt;p>Parameter cache_dynamic_acls is now &amp;lsquo;1&amp;rsquo;.&lt;/p>
&lt;p>/&amp;gt; ls&lt;/p>
&lt;p>o- / &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [&amp;hellip;]&lt;/p>
&lt;p>o- backstores &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [&amp;hellip;]&lt;/p>
&lt;p>| o- block &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [Storage Objects: 0]&lt;/p>
&lt;p>| o- fileio &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [Storage Objects: 0]&lt;/p>
&lt;p>| o- pscsi &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [Storage Objects: 0]&lt;/p>
&lt;p>| o- ramdisk &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [Storage Objects: 1]&lt;/p>
&lt;p>| o- test1 &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [nullio (100.0MiB) activated]&lt;/p>
&lt;p>o- iscsi &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [Targets: 1]&lt;/p>
&lt;p>| o- iqn.2003-01.org.setup.lun.test &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [TPGs: 1]&lt;/p>
&lt;p>| o- tpg1 &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [gen-acls, no-auth]&lt;/p>
&lt;p>| o- acls &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [ACLs: 0]&lt;/p>
&lt;p>| o- luns &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [LUNs: 1]&lt;/p>
&lt;p>| | o- lun0 &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;. [ramdisk/test1]&lt;/p>
&lt;p>| o- portals &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [Portals: 1]&lt;/p>
&lt;p>| o- 12.12.12.1:3260 &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [iser]&lt;/p>
&lt;p>o- loopback &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;.. [Targets: 0]&lt;/p>
&lt;p>o- srpt &amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip;&amp;hellip; [Targets: 0]&lt;/p>
&lt;p>/&amp;gt; saveconfig&lt;/p>
&lt;p>Last 10 configs saved in /etc/target/backup.&lt;/p>
&lt;p>Configuration saved to /etc/target/saveconfig.json&lt;/p>
&lt;p>/&amp;gt; exit&lt;/p>
&lt;p>Global pref auto_save_on_exit=true&lt;/p>
&lt;p>Last 10 configs saved in /etc/target/backup.&lt;/p>
&lt;p>Configuration saved to /etc/target/saveconfig.json
[/bash]&lt;/p>
&lt;p>RHEVM 的安装过程非常简洁，基本用 Satellite 配置了一下它所需要的 repos，做好视图，然后就推送给了一个 kvm 虚拟机，使用 pxe 安装好之后就行了。&lt;/p>
&lt;p>RHEVM 需要的 repos 和基本的安装命令：
[bash]&lt;/p>
&lt;h1 id="subscription-manager-repos-enablerhel-6-server-rpms">subscription-manager repos &amp;ndash;enable=rhel-6-server-rpms
&lt;/h1>&lt;h1 id="subscription-manager-repos-enablerhel-6-server-supplementary-rpms">subscription-manager repos &amp;ndash;enable=rhel-6-server-supplementary-rpms
&lt;/h1>&lt;h1 id="subscription-manager-repos-enablerhel-6-server-rhevm-35-rpms">subscription-manager repos &amp;ndash;enable=rhel-6-server-rhevm-3.5-rpms
&lt;/h1>&lt;h1 id="subscription-manager-repos-enablejb-eap-6-for-rhel-6-server-rpms">subscription-manager repos &amp;ndash;enable=jb-eap-6-for-rhel-6-server-rpms
&lt;/h1>&lt;h1 id="subscription-manager-repos-enablerhel-6-server-rhevh-rpms">subscription-manager repos &amp;ndash;enable=rhel-6-server-rhevh-rpms
&lt;/h1>&lt;h1 id="yum-install-rhevm-rhevm-dwh-rhevm-reports">yum install rhevm rhevm-dwh rhevm-reports
&lt;/h1>&lt;h1 id="engine-setup">engine-setup
&lt;/h1>&lt;p>[/bash]&lt;/p>
&lt;p>回答完 engine-setup 的所有问题就可以登录风格统一的黑底色的 RHEM 界面了。实际上有三个登录界面：用户的，管理员，和报表的。&lt;/p>
&lt;p>&lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/rhevm-web-admin.jpg" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/rhevm-web-admin-520x293.jpg"
loading="lazy"
alt="rhevm-web-admin"
>&lt;/a>&lt;/p>
&lt;p>下面需要安装跑虚拟机的 Hypervisor 了，RHEV 的 Hypervisor 有两种，一种是精简话的裁剪 rhel 版本叫做 RHEVH（偏向 vshpere 的做法），还有一种就是 rhel 的标准版，然后安装 Hypervisor 相关的包（偏向 OpenStack 的做法）。下面我会安装第二种做法。目的是：我有两台相同配置的计算节点，我希望把动态的变更他们的功能；一会做 RHEV 虚拟机的演示，一会做 OpenStack nova 的演示。&lt;/p>
&lt;p>用了一个组合视图安装了这两个服务器虚拟化节点。组合视图里如下所示：
&lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/rhev-view-compose.jpg" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/rhev-view-compose-520x286.jpg"
loading="lazy"
alt="rhev-view-compose"
>&lt;/a>
如上图所示：1）视图 1 是基础的 RHEL 操作系统 repo；2）视图 2 是 RHEV 相关的 repos 视图，其中包括了安装 RHEVM 和 host 的所有需要的 repo。考激活秘钥控制每个 repo 的默认是否开启，它们对安装后的 os 可见，但是默认并不是开启的，因此，我设置 rhevm 和 jboss 为默认关闭的，由于安装 rhev host 的情况比较多，需要安装 rhevm 的话，可以手动 enable 这需要的 repos 即可。&lt;/p>
&lt;p>安装和配置完存储之后的 RHEVM 控制台：
&lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/rhevm-hosts.jpg" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/rhevm-hosts-520x286.jpg"
loading="lazy"
alt="rhevm-hosts"
>&lt;/a>&lt;/p>
&lt;p>目前由于没有安装 OpenStack 环境，所以没有 Glance 服务，因此 iso 镜像只能暂时放在了 dis06 的一个服务器虚拟化 Hypervisor 节点上，目前是临时的方案，回头一定把 iso 放到 Glance 服务上 host。&lt;/p>
&lt;p>下面上传一个 iso 之后就可以创建虚拟机了。
[bash]
[root@rhevm03 ~]# engine-iso-uploader &amp;ndash;iso-domain=iso-dis06 upload /tmp/turnkey-jenkins-13.0-wheezy-amd64.iso
Please provide the REST API password for the admin@internal oVirt Engine user (CTRL+D to abort):
Uploading, please wait&amp;hellip;
ERROR: mount.nfs: Connection timed out&lt;/p>
&lt;p>[/bash]&lt;/p>
&lt;p>由于这个命令上传不成功，也不想排错了；到目前这个状态其实就可以在 Satellite 里面使用 RHEV 的资源提供者的方式来安装虚拟机了，如下图所示：&lt;/p>
&lt;p>&lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/sat6-built-vm-via-rhev-1.jpg" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/sat6-built-vm-via-rhev-1-520x286.jpg"
loading="lazy"
alt="sat6-built-vm-via-rhev-1"
>&lt;/a>&lt;/p>
&lt;p>手动创建 RHEV 虚拟机 1：通过 New Host 设置相关参数。选择 Deploy on 为 rhevm03（rhevm），这个配置让 sat6 去联系 RHEVM，rhevm 的配置信息必须提前输入到 sat6 中。然后还要在 sat6 中设置虚拟机的三种规格，就是 Computer profile 中的选项，这个选项确定了 cpu，ram，磁盘和网络等信息。剩下的就是最重要的 Lifecycle Evn 和 Puppet Env 了，这两个选项确定把系统安装为标准的 rhel6 的核心最小化安装。当然可以一次性完成某种应用的全套安装和配置。&lt;/p>
&lt;p>&lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/sat6-built-vm-via-rhev-2.jpg" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/sat6-built-vm-via-rhev-2-520x286.jpg"
loading="lazy"
alt="sat6-built-vm-via-rhev-2"
>&lt;/a>&lt;/p>
&lt;p>手动创建 RHEV 虚拟机 2：通过 Virtual Machine 参数可以看到 1，2，3 都来自标准的规格配置，如果需要手动修改的话，可以在这里修改，这里可以看到默认的存储是 w540-iscsi-lun0 这个之前在 RHEVM 里面配置好的 iscsi 存储。&lt;/p>
&lt;p>&lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/sat6-built-vm-via-rhev-3.jpg" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/sat6-built-vm-via-rhev-3-520x286.jpg"
loading="lazy"
alt="sat6-built-vm-via-rhev-3"
>&lt;/a>&lt;/p>
&lt;p>手动创建 RHEV 虚拟机 3：点击提交之后，sat6 就开始了实时创建 rhev 虚拟机的过程，sat6 使用 REST API 告诉 RHEVM 这些信息，然后 RHEVM 再确定使用哪个 Hypervisor 来建立并运行虚拟机。&lt;/p>
&lt;p>问题来了：如果需要在 RHEV 资源池里建立 n 个相同配置的虚拟机，管理员该如何操作？&lt;/p>
&lt;p>在 sat6 里面，管理员重复以上操作，当然需要手动操作 n 次。这样是不是很麻烦，确实很麻烦！！如何解决？这就需要一种能够实现 Orchestration 功能的工具来做，也就是自动化编排工具。这种工具最好是统一的能够跨异构资源池的，能够满足如下需求：今天企业可能是纯的 vshpere 的虚拟化环境，接下来企业有可能引入其他服务器虚拟化资源池技术，如：RHEV，Hyper-V；在以后还可能引入 OpenStack 资源池。那么这种自动化编排工具和底层的类似 satellite6 的（标准化部署工具）必须形成一个统一的平台来操作所有异构的资源池。也就是说：在 Orchestration 工具中统一管理异构资源池，并配合标准化部署工具，实现 workload 的标准化自动化部署。红帽的 Orchestration 工具是 CloudForms。它能够对接业内所有流行的资源池，如下图所示：&lt;/p>
&lt;p>&lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/cfme-cloud-provides.jpg" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/cfme-cloud-provides-520x292.jpg"
loading="lazy"
alt="cfme-cloud-provides"
>&lt;/a> &lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/cfme-infra-provides.jpg" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/cfme-infra-provides-520x293.jpg"
loading="lazy"
alt="cfme-infra-provides"
>&lt;/a>&lt;/p>
&lt;p>上图是 Satellite 的上层 Orchestration 的能力，底层必须还有标准化的部署工具支持，也就是 Satellite6，它对以上基础架构类型的支持情况，如下图所示：&lt;/p>
&lt;p>&lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/satellite6-provider.jpg" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/satellite6-provider-520x286.jpg"
loading="lazy"
alt="satellite6-provider"
>&lt;/a>&lt;/p>
&lt;p>使用 CloudForms 做上层 Orchestration 的调度，必须依赖于底层的 workload 的标准化，标准化到什么程度，从虚拟机供给的角度可以参考 Amazon AWS 的 EC2 的实际案例。如下图所示：&lt;/p>
&lt;p>&lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/ec2-types.jpg" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/ec2-types-520x258.jpg"
loading="lazy"
alt="ec2-types"
>&lt;/a>&lt;/p>
&lt;p>AWS 服务的我曾研究过一点，上图的全图下载点这里 &amp;ndash;&amp;gt; &lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/aws-%e6%9c%8d%e5%8a%a1-%e8%84%91%e5%9b%be.pdf" target="_blank" rel="noopener"
>aws-服务-脑图&lt;/a>&lt;/p>
&lt;p>以上所有是 Martin&amp;rsquo;s Lab 的搭建的一部分，下周可能去一个银行客户演示。需要做的优化还很多，请关注后续更新。&lt;/p></description></item><item><title>Martin's lab 主服务器搭建</title><link>https://martinliu.cn/2015/03/08/e4b8bbe69c8de58aa1e599a8e690ade5bbba/</link><pubDate>Sun, 08 Mar 2015 15:42:01 +0000</pubDate><guid>https://martinliu.cn/2015/03/08/e4b8bbe69c8de58aa1e599a8e690ade5bbba/</guid><description>&lt;p>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/05/Red-Hat-open-hybrid-cloud-1000x563_0.png"
loading="lazy"
alt="Red-Hat-open-hybrid-cloud-1000x563_0"
>&lt;/p>
&lt;p>上图是红帽产品和技术架构的全貌。来源是：&lt;a class="link" href="http://www.redhat.com/en/technologies/cloud-computing" target="_blank" rel="noopener"
>http://www.redhat.com/en/technologies/cloud-computing&lt;/a> 这张图我用在了我的首次给公司内部的全体销售培训上。由于我是 IT 管理背景的，因此我很习惯从云管理层往下看云引擎的各个层面。但是管理层产品，其实是后来整合纳入的。红帽起家的旗舰产品还是在底层的 RHEL。总之，我想在一个 Lab 里面实现以上所有的部分，所谓实现是让其每个部分都能在运行在假象的一个有意义的业务场景里。还好，红帽的产品全都是基于 x86 平台的，因此我用几个笔记本，再加上我家里的这台 HP MicroServer G8 服务器应该能够全部部署出来。&lt;/p>
&lt;p>做这样的一个 lab 还是要一定的规划和设计的，这些初步的规划和设计都在我的本子里手写的，就不在这里敲字了，随后我会抽空上几张图。&lt;/p>
&lt;h2 id="主服务器基本配置">主服务器基本配置
&lt;/h2>&lt;p>硬件：Lenovo W540 CPU Intel i7, RAM 32 GB, SSD 512GB, HD 1TB&lt;/p>
&lt;p>OS : RHEL 7.1&lt;/p>
&lt;p>订阅是红帽公司的业务模式，也是红帽认为最自豪的部分，红帽相信可以成为开源技术和用户之间的催化剂，它不断参与最优秀的开源技术创新，并为其用户提供最强有利的技术服务和支持。红帽技术员工可以申请一个红帽雇员订阅。我的订阅可以在网上查到如下图所示：&lt;/p>
&lt;p>&lt;a class="link" href="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/employee-sub.png" target="_blank" rel="noopener"
>&lt;img src="http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/03/employee-sub-520x295.png"
loading="lazy"
alt="employee-sub"
>&lt;/a>&lt;/p>
&lt;p>红帽的服务必须是基于订阅的每一个节点（物理、虚拟）都需要有有效的订阅，否则红帽的支持服务不能生效。对于一个已经成功注册到红帽官网，并且状态正常的服务器，应该显示如下的注册状态：&lt;/p>
&lt;p>[bash]
[root@w540 ~]# subscription-manager list&lt;/p>
&lt;p>+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+
安装的产品状态
+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+
产品名称： Red Hat Enterprise Linux Server
产品 ID： 69
版本： 7.0
构架： x86_64
状态： 已订阅
状态详情：
开始： 2014 年 09 月 09 日
结束： 2015 年 12 月 08 日
[/bash]&lt;/p>
&lt;p>红帽员工订阅意味着所有红帽产品。&lt;/p>
&lt;h2 id="基本服务配置">基本服务配置
&lt;/h2>&lt;h3 id="kvm">KVM
&lt;/h3>&lt;p>KVM 的上手还真比我想象的速度要慢一些，起码比我用 XenServer 的经历更加纠结一些。总之现在可以彻底的忘记其它任何的选项，KVM 可以满足我的所有需求了。由于主服务器有 512SSD + 32GB RAM + 8 vCPU，所以我打算把产品里的所有管理控制节点 VM 都部署在这个机器上。预计有 10 个左右的虚拟机。
安装配置方面这里就不赘述了。只把困扰我许久的几个网络配置贴出来，供参考。&lt;/p>
&lt;p>网桥 0 的功能是为所有虚拟机提供外网链接，使他们和主机一样直通主机所物理链接的局域网。
[bash]
[root@w540 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0
DEVICE=br0
ONBOOT=yes
TYPE=Bridge
BOOTPROTO=none
STP=on
DELAY=0
DNS1=192.168.0.1
DEFROUTE=yes
IPV4_FAILURE_FATAL=yes
IPV6INIT=no
DNS2=4.4.4.4
IPADDR=192.168.0.5
PREFIX=24
GATEWAY=192.168.0.1
NM_CONTROLLED=no
[/bash]&lt;/p>
&lt;p>主机原本的一块物理网卡的配置，由于增加了这个网桥，需求更新如下：
[bash]
[root@w540 ~]# cat /etc/sysconfig/network-scripts/ifcfg-enp0s25
DEVICE=enp0s25
ONBOOT=yes
BRIDGE=br0
NM_CONTROLLED=no
BOOTPROTO=none
[/bash]&lt;/p>
&lt;p>kvm 这块处理这个折腾我很久的 br0 之外，其它的功能看起来还不错，运行在 SSD 上的虚拟机也启动和运行速度飞快。&lt;/p>
&lt;h3 id="repo-服务器">Repo 服务器
&lt;/h3>&lt;p>Repos 是红帽软件仓库的简称。它具体指每个订阅内所有软件频道里面下载出来的软件包目录。下载到的某个软件包频道的 repos 目录中是一堆的 rpm 包文件，这样的目录可以制作成本地 Repos 服务器，能够提供给所有 LAN 里 RHEL OS 用来做软件的安装和升级用。
用主服务器上 1TB 的慢速普通盘来保存这些下载的 repos，安装 http 服务器，把它共享给本 lab 的 lan 中。具体的几个参考脚本如下。&lt;/p>
&lt;p>在把本服务器注册到红帽网站之后，他会默认 attach 一堆可能不需要的 repos，因此我的做法是先关闭掉所有的默认开启，然后再开启我所需要并且关注的东西。
[bash]
[root@w540 repos]# subscription-manager repos &amp;ndash;disable=&amp;quot;*&amp;quot;
[/bash]
以上命令的结果会反问，所有的被关闭的 repos。下面许开启我当前需求的 repos。
[bash]
[root@w540 repos]# cat rhel7-enable.sh
subscription-manager repos &amp;ndash;enable=rhel-7-server-extras-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-satellite-capsule-optional-6.0-rpms
subscription-manager repos &amp;ndash;enable=rhel-ha-for-rhel-7-server-rpms
subscription-manager repos &amp;ndash;enable=jb-eap-6-for-rhel-7-server-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-satellite-capsule-6.1-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-rt-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-openstack-6.0-rpms
subscription-manager repos &amp;ndash;enable=rhel-server-rhscl-7-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-rhn-tools-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-satellite-capsule-6.0-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-openstack-5.0-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-rhevh-rpms
subscription-manager repos &amp;ndash;enable=rhel-atomic-host-rpms
subscription-manager repos &amp;ndash;enable=rhel-rs-for-rhel-7-server-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-satellite-capsule-optional-6.1-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-rhev-mgmt-agent-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-openstack-6.0-installer-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-rh-common-rpms
subscription-manager repos &amp;ndash;enable=jb-eap-6.3-for-rhel-7-server-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-satellite-optional-6.0-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-satellite-6.1-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-supplementary-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-satellite-optional-6.1-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-optional-rpms
subscription-manager repos &amp;ndash;enable=rhel-7-server-satellite-6.0-rpms
subscription-manager repos &amp;ndash;enable=jb-ews-2-for-rhel-7-server-rpms
[/bash]&lt;/p>
&lt;p>接下来可以用命令来从红帽 CDN 同步下载每个 Repos 里面的软件包。
[bash]
[root@w540 rhel70]# cat sync.sh
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-satellite-6.0-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-extras-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-rhevh-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-satellite-capsule-6.0-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-openstack-5.0-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-rhev-mgmt-agent-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-atomic-host-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-optional-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-rs-for-rhel-7-server-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-rh-common-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-server-rhscl-7-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-openstack-6.0-installer-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-openstack-6.0-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=jb-eap-6.3-for-rhel-7-server-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-ha-for-rhel-7-server-rpms &amp;ndash;download_path=/data/Repos/rhel70/
reposync &amp;ndash;gpgcheck &amp;ndash;newest-only &amp;ndash;plugins &amp;ndash;downloadcomps &amp;ndash;repoid=rhel-7-server-supplementary-rpms &amp;ndash;download_path=/data/Repos/rhel70/
[/bash]&lt;/p>
&lt;p>安装 httpd 的过程就不叙述了，下面就贴一个本机的配置文件。
[bash]
Alias /repos &amp;ldquo;/data/repos&amp;rdquo;
&amp;lt;Directory &amp;ldquo;/data/repos&amp;rdquo;&amp;gt;
Options None
AllowOverride None
Order allow,deny
Allow from all
Require all granted&lt;/p>
&lt;p>[/bash]&lt;/p>
&lt;p>最后，在任何需要的机器上本地 repos 源的配置文件可以类似如下：
[bash]
[root@sat6-leb yum.repos.d]# ls
rhel70.repo
[root@sat6-leb yum.repos.d]# cat rhel70.repo
[rhel-7-server-rpms]
name=rhel-7-server-rpms
baseurl=http://192.168.0.5/repos/rhel70/rhel-7-server-rpms/
gpgcheck=0
enable=1&lt;/p>
&lt;p>[/bash]&lt;/p>
&lt;p>当然，我的目标是以后这个 lab 网内所有的机器都需要受到 satellite 6 服务器的管理和控制，并不需要在每个服务器上手动的去安装和管理 repos 内容和订阅。下面分阶段安装各种控制器节点的时候，在详细说明如何使用 satellite 6 做种子服务器生出所有的其他节点。这里的 repo 服务器还是作为最初的种子服务器，它使安装 satellite 6 服务器的源。也是作为 lab 中对于 satellite6 的一个备份选项。&lt;/p>
&lt;h3 id="nfs-服务器">NFS 服务器
&lt;/h3>&lt;p>本机的存储空间比较大，可以作为慢速 NFS 共享存储和 ISO 镜像文件服务器使用，因此，安装 nfs 服务器之后，就可以把本地的满速普通硬盘使用 nfs 的方式共享到 lab 内网了。配置文件参考如下：
[bash]
[root@w540 ~]# cat /etc/exports
/data/nfs 192.168.0.&lt;em>(rw,async)
/data/iso 192.168.0.&lt;/em>(rw,async)
/home/test 192.168.0.&lt;em>(rw,async)
[root@w540 ~]# showmount -e localhost
Export list for localhost:
/home/test 192.168.0.&lt;/em>
/data/iso 192.168.0._
/data/nfs 192.168.0._
[root@w540 ~]#
[/bash]&lt;/p>
&lt;h3 id="ntp-服务器">NTP 服务器
&lt;/h3>&lt;p>根据红帽知识库文档，选择本机这个物理服务器作为 lab 内网的时钟服务器，所有的虚拟机和其他物理机都和他同步时钟。最终的配置还没有确定。随后更新靠谱的可以供参考的配置&lt;/p></description></item><item><title>硬件就绪可开工了</title><link>https://martinliu.cn/2014/11/18/e7a1ace4bbb6e5b0b1e7bbaae58fafe5bc80e5b7a5e4ba86/</link><pubDate>Tue, 18 Nov 2014 15:16:50 +0000</pubDate><guid>https://martinliu.cn/2014/11/18/e7a1ace4bbb6e5b0b1e7bbaae58fafe5bc80e5b7a5e4ba86/</guid><description>&lt;p>昨天晚上折腾了很晚，结果扩展的 8GB 内存条死活和系统不兼容，导致 ESXi 安装卡在内存检查哪里。在京东上直接退货，然后订货 HP 专用内存条。今天下午新条子火速送达。装上后系统在也卡了。ESXi 安装顺利完成。下载了 vClient 后，导入了几个常用 ISO，安装好了 RHEL6 和 7 的模板机。接下来可以开始方案的研究了。由于这台服务器有着巨大的折腾的空间，未来的硬件升级 whish list 包括：&lt;/p>
&lt;p>[su_list icon=&amp;ldquo;icon: heart-o&amp;rdquo;]&lt;/p>
&lt;ul>
&lt;li>增加 SSD 磁盘，加速 IO 密集的虚拟机&lt;/li>
&lt;li>增加到 16GB 内存，可惜不能上 32GB，短板，相当的短&lt;/li>
&lt;li>增加新的硬盘，当前的 1TB 用完后，还有三个盘位&lt;/li>
&lt;li>升级 CPU 到 Xeon e1256l v2，据说性能可以提升三倍，逻辑 CPU 数可以到 8 颗&lt;/li>
&lt;/ul>
&lt;p>[/su_list]&lt;/p>
&lt;p>开源的东西还好，基本上都是结构简洁的居多，我可能从配置管理相关的技术开始搞起来，如 Formen，Puppet；再到 Ceph&amp;amp;gluster 等存储应用，再到 OpenStack 这样较复杂的应用。&lt;/p></description></item><item><title>我的11.11采购</title><link>https://martinliu.cn/2014/11/13/e68891e79a8411-11e98787e8b4ad/</link><pubDate>Thu, 13 Nov 2014 16:29:38 +0000</pubDate><guid>https://martinliu.cn/2014/11/13/e68891e79a8411-11e98787e8b4ad/</guid><description>&lt;p>难以置信我在 11.11 这一天也出手了。在过去的一年多里，烧过了跑步装备，烧过了跑步 GPS 手表之后；在光棍节那天，我毅然开始搭建 home lab 了。一直不想把家里也搞成工作的场所，但是来自大学时代攒机的冲动在此刻颠覆了我。&lt;/p>
&lt;p>这台主机仅仅是个开端，它只是一个空机箱，只有主板、CPU 和 2GB 内存。以后什么都需要扩展。在网上看了几篇讨论 DIY 这款机器的帖子之后，果断在京东上下单了。下单的价格是 2799，感觉目前这应该是全网最低价。另外还采购的配件有一条 8GB 的 HP 服务器用内存条，一块 1TB 的硬盘。另外，我也单独为 lab 开了一个页面，点击左侧链接就可以过去，以后关于对它的折腾都会记录在那边。&lt;/p>
&lt;p>TO Do list：&lt;/p>
&lt;p>[su_list icon=&amp;ldquo;icon: check-circle&amp;rdquo;]&lt;/p>
&lt;ul>
&lt;li>收货后组装开机&lt;/li>
&lt;li>购买 2.5 寸硬盘托架，加装入家里过剩的笔记本硬盘一块，在光驱位置附近。&lt;/li>
&lt;li>安装 vmware EXSi 在 2.5 寸的盘上&lt;/li>
&lt;/ul>
&lt;p>[/su_list]&lt;/p></description></item></channel></rss>